{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Network\n",
    "\n",
    "In this notebook, we'll be building a generative adversarial network (GAN) trained on the network flow dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/sj2363/hsn/attack_generate/gan_attack_generate/.env/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import utils, models\n",
    "reload(utils)\n",
    "reload(models)\n",
    "from utils import model_inputs, get_flow_dataset, split_benign_attack\n",
    "from models import generator, discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_flow_dataset()\n",
    "benign, attack = split_benign_attack(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9944, 40)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benign.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10056, 40)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attack.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size of input image to discriminator\n",
    "input_size = 40\n",
    "# Size of latent vector to generator\n",
    "z_size = 2\n",
    "# Sizes of hidden layers in generator and discriminator\n",
    "g_hidden_size = 128\n",
    "d_hidden_size = 128\n",
    "# Leak factor for leaky ReLU\n",
    "alpha = 0.01\n",
    "# Smoothing \n",
    "smooth = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build network\n",
    "\n",
    "Now we're building the network from the functions defined above.\n",
    "\n",
    "First is to get our inputs, `input_benign, input_z, input_attack_remains` from `model_inputs` using the sizes of the input and z.\n",
    "\n",
    "Then, we'll create the generator, `generator(input_z, z_size)`. This builds the generator with the appropriate input and output sizes.\n",
    "\n",
    "Then the discriminators. We'll build two of them, one for benign flow data and one for attack flow data. Since we want the weights to be the same for both benign and attack flow data, we need to reuse the variables. For the attack flow data, we're getting it from the output of the generator concatenated with remaining part of attack feature called `g_model`. So the benign data discriminator is `discriminator(input_benign)` while the attack discriminator is `discriminator(g_model, reuse=True)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Create our input placeholders\n",
    "input_benign, input_z, input_attack_remains = model_inputs(input_size, z_size, attack_remains_dim=input_size - z_size)\n",
    "\n",
    "# Build the model\n",
    "g_model = tf.concat([generator(input_z, z_size, n_units=g_hidden_size, alpha=alpha), input_attack_remains], 1)\n",
    "# g_model is the generator output concatenated with the remaining part of attack features\n",
    "\n",
    "d_model_benign, d_logits_benign = discriminator(input_benign, n_units=d_hidden_size, alpha=alpha)\n",
    "d_model_attack, d_logits_attack = discriminator(g_model, reuse=True, n_units=d_hidden_size, alpha=alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator and Generator Losses\n",
    "\n",
    "Now we need to calculate the losses, which is a little tricky. For the discriminator, the total loss is the sum of the losses for benign and attack flows, `d_loss = d_loss_benign + d_loss_attack`. The losses will by sigmoid cross-entropys, which we can get with `tf.nn.sigmoid_cross_entropy_with_logits`. We'll also wrap that in `tf.reduce_mean` to get the mean for all the flows in the batch. So the losses will look something like \n",
    "\n",
    "```python\n",
    "tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=labels))\n",
    "```\n",
    "\n",
    "For the benign flow logits, we'll use `d_logits_benign` which we got from the discriminator in the cell above. For the labels, we want them to be all ones, since these are all real images. To help the discriminator generalize better, the labels are reduced a bit from 1.0 to 0.9, for example,  using the parameter `smooth`. This is known as label smoothing, typically used with classifiers to improve performance. In TensorFlow, it looks something like `labels = tf.ones_like(tensor) * (1 - smooth)`\n",
    "\n",
    "The discriminator loss for the attack flow data is similar. The logits are `d_logits_attack`, which we got from passing the generator output concatenated with remaing part of attack flow features to the discriminator. These attack logits are used with labels of all zeros. Remember that we want the discriminator to output 1 for benign flows and 0 for attack images, so we need to set up the losses to reflect that.\n",
    "\n",
    "Finally, the generator losses are using `d_logits_attack`, the attack flow logits. But, now the labels are all ones. The generator is trying to fool the discriminator, so it wants to discriminator to output ones for fake images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate losses\n",
    "d_loss_benign = tf.reduce_mean(\n",
    "                  tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_benign, \n",
    "                                                          labels=tf.ones_like(d_logits_benign) * (1 - smooth)))\n",
    "d_loss_attack = tf.reduce_mean(\n",
    "                  tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_attack, \n",
    "                                                          labels=tf.zeros_like(d_logits_attack)))\n",
    "d_loss = d_loss_benign + d_loss_attack\n",
    "\n",
    "g_loss = tf.reduce_mean(\n",
    "             tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_attack,\n",
    "                                                     labels=tf.ones_like(d_logits_attack)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizers\n",
    "\n",
    "We want to update the generator and discriminator variables separately. So we need to get the variables for each part build optimizers for the two parts. To get all the trainable variables, we use `tf.trainable_variables()`. This creates a list of all the variables we've defined in our graph.\n",
    "\n",
    "For the generator optimizer, we only want to generator variables. Our past selves were nice and used a variable scope to start all of our generator variable names with `generator`. So, we just need to iterate through the list from `tf.trainable_variables()` and keep variables to start with `generator`. Each variable object has an attribute `name` which holds the name of the variable as a string (`var.name == 'weights_0'` for instance). \n",
    "\n",
    "We can do something similar with the discriminator. All the variables in the discriminator start with `discriminator`.\n",
    "\n",
    "Then, in the optimizer we pass the variable lists to `var_list` in the `minimize` method. This tells the optimizer to only update the listed variables. Something like `tf.train.AdamOptimizer().minimize(loss, var_list=var_list)` will only train the variables in `var_list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Optimizers\n",
    "learning_rate = 0.002\n",
    "\n",
    "# Get the trainable_variables, split into G and D parts\n",
    "t_vars = tf.trainable_variables()\n",
    "g_vars = [var for var in t_vars if var.name.startswith('generator')]\n",
    "d_vars = [var for var in t_vars if var.name.startswith('discriminator')]\n",
    "\n",
    "d_train_opt = tf.train.AdamOptimizer(learning_rate).minimize(d_loss, var_list=d_vars)\n",
    "g_train_opt = tf.train.AdamOptimizer(learning_rate).minimize(g_loss, var_list=g_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10... Discriminator Loss: 0.6801... Generator Loss: 2.0172\n",
      "Epoch 2/10... Discriminator Loss: 0.6494... Generator Loss: 2.2459\n",
      "Epoch 3/10... Discriminator Loss: 0.6043... Generator Loss: 2.3014\n",
      "Epoch 4/10... Discriminator Loss: 0.5806... Generator Loss: 2.2804\n",
      "Epoch 5/10... Discriminator Loss: 0.5488... Generator Loss: 2.3299\n",
      "Epoch 6/10... Discriminator Loss: 0.3934... Generator Loss: 5.7729\n",
      "Epoch 7/10... Discriminator Loss: 0.3423... Generator Loss: 5.7875\n",
      "Epoch 8/10... Discriminator Loss: 0.3299... Generator Loss: 6.9814\n",
      "Epoch 9/10... Discriminator Loss: 0.3272... Generator Loss: 7.9868\n",
      "Epoch 10/10... Discriminator Loss: 0.3266... Generator Loss: 8.6780\n",
      "Fooled rate, 0 out of 9900:0.0\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "epochs = 10\n",
    "samples = []\n",
    "losses = []\n",
    "attack_scores_by_epoch = []\n",
    "# Only save generator variables\n",
    "saver = tf.train.Saver(var_list=g_vars)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for e in range(epochs):\n",
    "        attack_scores_by_epoch.append([])\n",
    "        for ii in range(benign.shape[0]//batch_size):\n",
    "            batch_benign = benign[ii * batch_size:(ii + 1) * batch_size]\n",
    "            \n",
    "            batch_attack = attack[ii * batch_size:(ii + 1) * batch_size]\n",
    "            batch_z = batch_attack[:,:z_size]\n",
    "            batch_attack_remains = batch_attack[:,z_size:]\n",
    "            \n",
    "            attack_score = sess.run(d_model_attack, feed_dict={input_z: batch_z, input_attack_remains: batch_attack_remains})\n",
    "            attack_scores_by_epoch[-1].append(attack_score)\n",
    "            \n",
    "            # Run optimizers\n",
    "            _ = sess.run(d_train_opt, feed_dict={input_benign: batch_benign, input_z: batch_z, input_attack_remains: batch_attack_remains})\n",
    "            _ = sess.run(g_train_opt, feed_dict={input_z: batch_z, input_attack_remains: batch_attack_remains})\n",
    "        \n",
    "        # At the end of each epoch, get the losses and print them out\n",
    "        train_loss_d = sess.run(d_loss, {input_z: batch_z, input_benign: batch_benign, input_attack_remains: batch_attack_remains})\n",
    "        train_loss_g = g_loss.eval({input_z: batch_z, input_attack_remains: batch_attack_remains})\n",
    "            \n",
    "        print(\"Epoch {}/{}...\".format(e+1, epochs),\n",
    "              \"Discriminator Loss: {:.4f}...\".format(train_loss_d),\n",
    "              \"Generator Loss: {:.4f}\".format(train_loss_g))    \n",
    "        # Save losses to view after training\n",
    "        losses.append((train_loss_d, train_loss_g))\n",
    "        \n",
    "        saver.save(sess, './checkpoints/generator.ckpt')\n",
    "\n",
    "# Last epoch attack score\n",
    "fooled_times = 0\n",
    "total = 0\n",
    "for batch_attack_scores in attack_scores_by_epoch[-1]:\n",
    "    for attack_score in batch_attack_scores:\n",
    "        total += 1\n",
    "        if attack_score >= 0.5:\n",
    "            fooled_times += 1\n",
    "print('Fooled rate, {fooled_times} out of {total_times}:{rate}'.format(fooled_times = fooled_times, total_times=total,rate=fooled_times / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loss\n",
    "\n",
    "Here we'll check out the training losses for the generator and discriminator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2b3102564b70>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "losses = np.array(losses)\n",
    "plt.plot(losses.T[0], label='Discriminator')\n",
    "plt.plot(losses.T[1], label='Generator')\n",
    "plt.title(\"Training Losses\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
