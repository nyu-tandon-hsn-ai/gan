{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Network\n",
    "\n",
    "In this notebook, we'll be building a generative adversarial network (GAN) trained on the network flow dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/sj2363/hsn/attack_generate/gan_attack_generate/.env/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 1.8.0\n",
      "Eager execution: True\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from importlib import reload\n",
    "import os\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as tfe\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "print(\"TensorFlow version: {}\".format(tf.VERSION))\n",
    "print(\"Eager execution: {}\".format(tf.executing_eagerly()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils, models\n",
    "reload(utils)\n",
    "reload(models)\n",
    "from models import Generator, Discriminator\n",
    "from utils import max_norm, parse_feature_label, train_one_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输出的summary的保存目录:不要改\n",
    "OUTPUT_DIR = 'SUMMARY/'\n",
    "\n",
    "# 输出的模型的保存目录:不要改\n",
    "CHECKPOINT_DIR = 'CHECKPOINT/'\n",
    "\n",
    "# 保存data的目录:不要改\n",
    "DATA_DIR = 'data'\n",
    "\n",
    "# 相关feature:不太需要改应该\n",
    "RELEVANT_FEATURES = [' Source Port', ' Destination Port', ' Flow Duration', 'Total Length of Fwd Packets', ' Total Length of Bwd Packets', 'Bwd Packet Length Max', ' Bwd Packet Length Min', 'Flow Bytes/s', ' Flow IAT Mean', ' Flow IAT Std', ' Flow IAT Max', ' Flow IAT Min', 'Fwd IAT Total', ' Fwd IAT Mean', ' Fwd IAT Std', ' Fwd IAT Min', 'Bwd IAT Total', ' Bwd IAT Mean', ' Bwd IAT Std', ' Bwd IAT Min', 'Fwd PSH Flags', ' Bwd PSH Flags', ' Fwd URG Flags', ' Fwd Header Length', ' Bwd Packets/s', ' Packet Length Mean', ' ACK Flag Count', ' Down/Up Ratio', ' Avg Fwd Segment Size', ' Fwd Header Length.1', 'Fwd Avg Bytes/Bulk', ' Fwd Avg Packets/Bulk', ' Bwd Avg Bytes/Bulk', 'Bwd Avg Bulk Rate', 'Subflow Fwd Packets', ' Subflow Fwd Bytes', 'Init_Win_bytes_forward', ' act_data_pkt_fwd', ' Active Std', ' Active Min', ' Idle Max']\n",
    "\n",
    "# Label的名字:不太需要改应该\n",
    "LABEL_NAME = ' Label'\n",
    "\n",
    "# 记录summary的频率:不太需要改应该\n",
    "LOG_INTERVAL = 10\n",
    "\n",
    "# 数据集路径\n",
    "IDS_DATASET = os.path.join('data', 'ids2017_sampled.csv')\n",
    "\n",
    "# benign flow的label\n",
    "BENIGN_LABEL = 0\n",
    "\n",
    "# attack flow的label\n",
    "ATTACK_LABEL = 2\n",
    "\n",
    "# training dataset占总dataset的比例\n",
    "TRAIN_FRAC = 0.3\n",
    "\n",
    "# 要修改的feature的数量\n",
    "FEATURE_NUM_MODIFIED = 15\n",
    "\n",
    "# learning rate\n",
    "LEARNING_RATE = 0.01\n",
    "\n",
    "# 训练的epochs数\n",
    "EPOCHS = 20000\n",
    "\n",
    "# 是否随机选择feature\n",
    "RANDOM_SELECT_FEATURE=False\n",
    "\n",
    "## 提示：\n",
    "## 训练结束后，把SUMMARY和CHECKPOINT目录重命名后保存"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flow ID, Source IP, Source Port, Destination IP, Destination Port, Protocol, Timestamp, Flow Duration, Total Fwd Packets, Total Backward Packets,Total Length of Fwd Packets, Total Length of Bwd Packets, Fwd Packet Length Max, Fwd Packet Length Min, Fwd Packet Length Mean, Fwd Packet Length Std,Bwd Packet Length Max, Bwd Packet Length Min, Bwd Packet Length Mean, Bwd Packet Length Std,Flow Bytes/s, Flow Packets/s, Flow IAT Mean, Flow IAT Std, Flow IAT Max, Flow IAT Min,Fwd IAT Total, Fwd IAT Mean, Fwd IAT Std, Fwd IAT Max, Fwd IAT Min,Bwd IAT Total, Bwd IAT Mean, Bwd IAT Std, Bwd IAT Max, Bwd IAT Min,Fwd PSH Flags, Bwd PSH Flags, Fwd URG Flags, Bwd URG Flags, Fwd Header Length, Bwd Header Length,Fwd Packets/s, Bwd Packets/s, Min Packet Length, Max Packet Length, Packet Length Mean, Packet Length Std, Packet Length Variance,FIN Flag Count, SYN Flag Count, RST Flag Count, PSH Flag Count, ACK Flag Count, URG Flag Count, CWE Flag Count, ECE Flag Count, Down/Up Ratio, Average Packet Size, Avg Fwd Segment Size, Avg Bwd Segment Size, Fwd Header Length.1,Fwd Avg Bytes/Bulk, Fwd Avg Packets/Bulk, Fwd Avg Bulk Rate, Bwd Avg Bytes/Bulk, Bwd Avg Packets/Bulk,Bwd Avg Bulk Rate,Subflow Fwd Packets, Subflow Fwd Bytes, Subflow Bwd Packets, Subflow Bwd Bytes,Init_Win_bytes_forward, Init_Win_bytes_backward, act_data_pkt_fwd, min_seg_size_forward,Active Mean, Active Std, Active Max, Active Min,Idle Mean, Idle Std, Idle Max, Idle Min, Label\r\n",
      "214102,192.168.10.8,50305,23.194.108.67,80,6,5/7/2017 9:35,5559809,3,1,12,0.0,6,0,4.0,3.464101615,0,0,0.0,0.0,2.158347526,0.719449175,1853269.667,3189322.073,5535956.0,39.0,5559809.0,2779904.5,3897645.41,5535956.0,23853.0,0.0,0.0,0.0,0.0,0.0,0,0,0,0,72,32,0.539586881,0.179862294,0,6,2.4,3.286335345,10.8,0,0,0,1,0,0,0,0,0,3.0,4.0,0.0,72,0,0,0,0,0,0,3,12,1,0,8192,29200,2,20,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0\r\n",
      "36502,172.217.11.3,80,192.168.10.8,49917,6,5/7/2017 9:31,18,1,1,6,6.0,6,6,6.0,0.0,6,6,6.0,0.0,666666.6667,111111.1111,18.0,0.0,18.0,18.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0,0,0,0,20,20,55555.55556,55555.55556,6,6,6.0,0.0,0.0,0,0,0,0,1,1,0,0,1,9.0,6.0,6.0,20,0,0,0,0,0,0,1,6,1,6,343,16560,0,20,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0\r\n",
      "24975,192.168.10.50,80,172.16.0.1,51484,6,5/7/2017 11:00,12859,1,3,0,18.0,0,0,0.0,0.0,6,6,6.0,0.0,1399.797807,311.0661793,4286.333333,6734.794825,12049.0,1.0,0.0,0.0,0.0,0.0,0.0,12050.0,6025.0,8519.2225,12049.0,1.0,0,0,0,0,32,60,77.76654483,233.2996345,0,6,3.6,3.286335345,10.8,0,0,0,0,1,0,0,0,3,4.5,0.0,6.0,32,0,0,0,0,0,0,1,0,3,18,235,0,0,32,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0\r\n",
      "151291,192.168.10.19,27610,192.168.10.3,53,17,5/7/2017 3:08,231,2,2,62,94.0,31,31,31.0,0.0,47,47,47.0,0.0,675324.6753,17316.01732,77.0,91.27978966,179.0,3.0,3.0,3.0,0.0,3.0,3.0,49.0,49.0,0.0,49.0,49.0,0,0,0,0,40,40,8658.008658,8658.008658,31,47,37.4,8.76356092,76.8,0,0,0,0,0,0,0,0,1,46.75,31.0,47.0,40,0,0,0,0,0,0,2,62,2,94,-1,-1,1,20,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0\r\n"
     ]
    }
   ],
   "source": [
    "# quick view of dataset\n",
    "!head -n5 {IDS_DATASET}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv\n",
    "df = pd.read_csv(IDS_DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract relevant features and label name\n",
    "df = df[RELEVANT_FEATURES + [LABEL_NAME]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract bengin and attack flows we want\n",
    "benign_df, attack_df = df[(df[LABEL_NAME] == BENIGN_LABEL)], df[(df[LABEL_NAME] == ATTACK_LABEL)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/sj2363/hsn/attack_generate/gan_attack_generate/.env/lib/python3.6/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "# rewrite label values\n",
    "benign_df.loc[:, LABEL_NAME] = 0\n",
    "attack_df.loc[:, LABEL_NAME] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to numpy\n",
    "benign, attack = benign_df.values, attack_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max normalization\n",
    "benign[:, :len(RELEVANT_FEATURES)] = max_norm(benign[:, :len(RELEVANT_FEATURES)])\n",
    "attack[:, :len(RELEVANT_FEATURES)] = max_norm(attack[:, :len(RELEVANT_FEATURES)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/sj2363/hsn/attack_generate/gan_attack_generate/.env/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# do train, test split separately on benign and attack\n",
    "benign_train, benign_test = train_test_split(benign, train_size=TRAIN_FRAC)\n",
    "attack_train, attack_test = train_test_split(attack, train_size=TRAIN_FRAC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat to get testing data\n",
    "test_np = np.concatenate([benign_test, attack_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to benign train dataset and attack train dataset\n",
    "benign_train_dataset, attack_train_dataset = tf.data.Dataset.from_tensor_slices(benign_train), tf.data.Dataset.from_tensor_slices(attack_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benign example features: tf.Tensor(\n",
      "[9.47178047e-01 8.26536500e-04 5.01436585e-04 3.35219766e-04\n",
      " 1.19429590e-06 5.73630137e-03 1.15318417e-01 1.19541447e-02\n",
      " 9.38611530e-04 0.00000000e+00 5.09872877e-04 9.38611530e-04\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 8.50946146e-05\n",
      " 1.66212353e-05 4.26122037e-02 0.00000000e+00 1.42857143e-01\n",
      " 2.19922380e-02 8.50946146e-05 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 3.35219766e-04\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00], shape=(41,), dtype=float64)\n",
      "benign example label: tf.Tensor(0, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# deal with benign train dataset\n",
    "benign_train_dataset = benign_train_dataset.map(parse_feature_label)\n",
    "benign_train_dataset = benign_train_dataset.shuffle(buffer_size=benign_train.shape[0] * 5)  # randomize\n",
    "benign_train_dataset = benign_train_dataset.batch(100) # make batch\n",
    "\n",
    "# View a single example entry from a batch\n",
    "benign_features, benign_label = iter(benign_train_dataset).next()\n",
    "print(\"benign example features:\", benign_features[0])\n",
    "print(\"benign example label:\", benign_label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attack example features: tf.Tensor(\n",
      "[2.93579932e-01 0.00000000e+00 2.52223495e-08 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 8.92857154e-08 0.00000000e+00 2.54237290e-08 2.75573192e-04\n",
      " 2.52100842e-08 8.90585253e-08 0.00000000e+00 1.53668844e-04\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 5.76923077e-02\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 5.76923077e-02 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 8.59589041e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00], shape=(41,), dtype=float64)\n",
      "attack example label: tf.Tensor(1, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# deal with attack train dataset\n",
    "attack_train_dataset = attack_train_dataset.map(parse_feature_label)\n",
    "attack_train_dataset = attack_train_dataset.shuffle(buffer_size=attack_train.shape[0] * 5)  # randomize\n",
    "attack_train_dataset = attack_train_dataset.batch(100) # make batch\n",
    "\n",
    "# View a single example entry from a batch\n",
    "attack_features, attack_label = iter(attack_train_dataset).next()\n",
    "print(\"attack example features:\", attack_features[0])\n",
    "print(\"attack example label:\", attack_label[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(input_shape=len(RELEVANT_FEATURES), output_shape=FEATURE_NUM_MODIFIED)\n",
    "discriminator = Discriminator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.train.AdamOptimizer(learning_rate=LEARNING_RATE)\n",
    "discriminator_optimizer = tf.train.AdamOptimizer(learning_rate=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Tensorflow Training Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.contrib.eager.python.checkpointable_utils.InitializationOnlyStatus at 0x2b4efc0d4518>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_counter = tf.train.get_or_create_global_step()\n",
    "summary_writer = tf.contrib.summary.create_file_writer(\n",
    "      OUTPUT_DIR, flush_millis=1000)\n",
    "checkpoint_prefix = os.path.join(CHECKPOINT_DIR, 'ckpt')\n",
    "latest_cpkt = tf.train.latest_checkpoint(CHECKPOINT_DIR)\n",
    "if latest_cpkt:\n",
    "    print('Using latest checkpoint at ' + latest_cpkt)\n",
    "model_objects = {\n",
    "    'generator': generator,\n",
    "    'discriminator': discriminator,\n",
    "    'generator_optimizer': generator_optimizer,\n",
    "    'discriminator_optimizer': discriminator_optimizer,\n",
    "    'step_counter': step_counter\n",
    "}\n",
    "checkpoint = tfe.Checkpoint(**model_objects)\n",
    "# Restore variables on creation if a checkpoint exists.\n",
    "checkpoint.restore(latest_cpkt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2.378508\tAverage Discriminator Loss: 0.982748\n",
      "\n",
      "Train time for epoch #1 (step 1): 1.606882\n",
      "Batch #10\tAverage Generator Loss: 4.524645\tAverage Discriminator Loss: 1.633949\n",
      "\n",
      "Train time for epoch #2 (step 2): 1.416448\n",
      "Batch #10\tAverage Generator Loss: 7.508555\tAverage Discriminator Loss: 1.804198\n",
      "\n",
      "Train time for epoch #3 (step 3): 1.417856\n",
      "Batch #10\tAverage Generator Loss: 3.670270\tAverage Discriminator Loss: 1.380155\n",
      "\n",
      "Train time for epoch #4 (step 4): 1.375160\n",
      "Batch #10\tAverage Generator Loss: 6.219086\tAverage Discriminator Loss: 0.862147\n",
      "\n",
      "Train time for epoch #5 (step 5): 1.416094\n",
      "Batch #10\tAverage Generator Loss: 3.885069\tAverage Discriminator Loss: 0.913086\n",
      "\n",
      "Train time for epoch #6 (step 6): 1.397432\n",
      "Batch #10\tAverage Generator Loss: 6.967915\tAverage Discriminator Loss: 0.540294\n",
      "\n",
      "Train time for epoch #7 (step 7): 1.409770\n",
      "Batch #10\tAverage Generator Loss: 11.832751\tAverage Discriminator Loss: 0.347888\n",
      "\n",
      "Train time for epoch #8 (step 8): 1.390265\n",
      "Batch #10\tAverage Generator Loss: 9.985389\tAverage Discriminator Loss: 0.537263\n",
      "\n",
      "Train time for epoch #9 (step 9): 1.510472\n",
      "Batch #10\tAverage Generator Loss: 16.981237\tAverage Discriminator Loss: 0.384066\n",
      "\n",
      "Train time for epoch #10 (step 10): 1.507321\n",
      "Batch #10\tAverage Generator Loss: 11.801623\tAverage Discriminator Loss: 0.306271\n",
      "\n",
      "Train time for epoch #11 (step 11): 1.358491\n",
      "Batch #10\tAverage Generator Loss: 15.634404\tAverage Discriminator Loss: 0.364040\n",
      "\n",
      "Train time for epoch #12 (step 12): 1.340020\n",
      "Batch #10\tAverage Generator Loss: 17.698238\tAverage Discriminator Loss: 0.209553\n",
      "\n",
      "Train time for epoch #13 (step 13): 1.548917\n",
      "Batch #10\tAverage Generator Loss: 19.711201\tAverage Discriminator Loss: 0.486259\n",
      "\n",
      "Train time for epoch #14 (step 14): 1.334553\n",
      "Batch #10\tAverage Generator Loss: 16.607812\tAverage Discriminator Loss: 0.436963\n",
      "\n",
      "Train time for epoch #15 (step 15): 1.427506\n",
      "Batch #10\tAverage Generator Loss: 18.745979\tAverage Discriminator Loss: 0.240236\n",
      "\n",
      "Train time for epoch #16 (step 16): 1.349804\n",
      "Batch #10\tAverage Generator Loss: 19.598322\tAverage Discriminator Loss: 0.251243\n",
      "\n",
      "Train time for epoch #17 (step 17): 1.346624\n",
      "Batch #10\tAverage Generator Loss: 20.121360\tAverage Discriminator Loss: 0.288175\n",
      "\n",
      "Train time for epoch #18 (step 18): 1.444112\n",
      "Batch #10\tAverage Generator Loss: 25.914599\tAverage Discriminator Loss: 0.241380\n",
      "\n",
      "Train time for epoch #19 (step 19): 1.501717\n",
      "Batch #10\tAverage Generator Loss: 28.700306\tAverage Discriminator Loss: 0.500982\n",
      "\n",
      "Train time for epoch #20 (step 20): 1.386962\n",
      "Batch #10\tAverage Generator Loss: 22.534237\tAverage Discriminator Loss: 0.220836\n",
      "\n",
      "Train time for epoch #21 (step 21): 1.393994\n",
      "Batch #10\tAverage Generator Loss: 34.286609\tAverage Discriminator Loss: 1.126920\n",
      "\n",
      "Train time for epoch #22 (step 22): 1.456509\n",
      "Batch #10\tAverage Generator Loss: 15.770432\tAverage Discriminator Loss: 0.308446\n",
      "\n",
      "Train time for epoch #23 (step 23): 1.365032\n",
      "Batch #10\tAverage Generator Loss: 11.321505\tAverage Discriminator Loss: 0.287778\n",
      "\n",
      "Train time for epoch #24 (step 24): 1.351659\n",
      "Batch #10\tAverage Generator Loss: 16.780664\tAverage Discriminator Loss: 0.397985\n",
      "\n",
      "Train time for epoch #25 (step 25): 1.308087\n",
      "Batch #10\tAverage Generator Loss: 19.824644\tAverage Discriminator Loss: 0.269575\n",
      "\n",
      "Train time for epoch #26 (step 26): 1.301811\n",
      "Batch #10\tAverage Generator Loss: 18.625375\tAverage Discriminator Loss: 0.280223\n",
      "\n",
      "Train time for epoch #27 (step 27): 1.365782\n",
      "Batch #10\tAverage Generator Loss: 23.833862\tAverage Discriminator Loss: 0.237568\n",
      "\n",
      "Train time for epoch #28 (step 28): 1.479605\n",
      "Batch #10\tAverage Generator Loss: 26.952540\tAverage Discriminator Loss: 0.119275\n",
      "\n",
      "Train time for epoch #29 (step 29): 1.446649\n",
      "Batch #10\tAverage Generator Loss: 32.104300\tAverage Discriminator Loss: 0.102589\n",
      "\n",
      "Train time for epoch #30 (step 30): 1.407056\n",
      "Batch #10\tAverage Generator Loss: 35.120393\tAverage Discriminator Loss: 0.257895\n",
      "\n",
      "Train time for epoch #31 (step 31): 1.455757\n",
      "Batch #10\tAverage Generator Loss: 27.612205\tAverage Discriminator Loss: 0.400905\n",
      "\n",
      "Train time for epoch #32 (step 32): 1.394311\n",
      "Batch #10\tAverage Generator Loss: 30.198047\tAverage Discriminator Loss: 0.206741\n",
      "\n",
      "Train time for epoch #33 (step 33): 1.370869\n",
      "Batch #10\tAverage Generator Loss: 23.051957\tAverage Discriminator Loss: 0.114298\n",
      "\n",
      "Train time for epoch #34 (step 34): 1.362047\n",
      "Batch #10\tAverage Generator Loss: 29.496018\tAverage Discriminator Loss: 0.216744\n",
      "\n",
      "Train time for epoch #35 (step 35): 1.418978\n",
      "Batch #10\tAverage Generator Loss: 25.348479\tAverage Discriminator Loss: 0.267093\n",
      "\n",
      "Train time for epoch #36 (step 36): 1.358754\n",
      "Batch #10\tAverage Generator Loss: 33.147146\tAverage Discriminator Loss: 0.167921\n",
      "\n",
      "Train time for epoch #37 (step 37): 1.485968\n",
      "Batch #10\tAverage Generator Loss: 30.337960\tAverage Discriminator Loss: 0.195811\n",
      "\n",
      "Train time for epoch #38 (step 38): 1.336571\n",
      "Batch #10\tAverage Generator Loss: 38.110688\tAverage Discriminator Loss: 0.131930\n",
      "\n",
      "Train time for epoch #39 (step 39): 1.510815\n",
      "Batch #10\tAverage Generator Loss: 32.704689\tAverage Discriminator Loss: 0.285542\n",
      "\n",
      "Train time for epoch #40 (step 40): 1.390916\n",
      "Batch #10\tAverage Generator Loss: 31.610562\tAverage Discriminator Loss: 0.296441\n",
      "\n",
      "Train time for epoch #41 (step 41): 1.417722\n",
      "Batch #10\tAverage Generator Loss: 37.778687\tAverage Discriminator Loss: 0.098781\n",
      "\n",
      "Train time for epoch #42 (step 42): 1.374331\n",
      "Batch #10\tAverage Generator Loss: 25.368455\tAverage Discriminator Loss: 0.091369\n",
      "\n",
      "Train time for epoch #43 (step 43): 1.511040\n",
      "Batch #10\tAverage Generator Loss: 29.083051\tAverage Discriminator Loss: 0.031469\n",
      "\n",
      "Train time for epoch #44 (step 44): 1.486651\n",
      "Batch #10\tAverage Generator Loss: 40.382242\tAverage Discriminator Loss: 0.109219\n",
      "\n",
      "Train time for epoch #45 (step 45): 1.424865\n",
      "Batch #10\tAverage Generator Loss: 37.543690\tAverage Discriminator Loss: 0.091482\n",
      "\n",
      "Train time for epoch #46 (step 46): 1.335869\n",
      "Batch #10\tAverage Generator Loss: 27.249711\tAverage Discriminator Loss: 0.097826\n",
      "\n",
      "Train time for epoch #47 (step 47): 1.501514\n",
      "Batch #10\tAverage Generator Loss: 33.356854\tAverage Discriminator Loss: 0.114570\n",
      "\n",
      "Train time for epoch #48 (step 48): 1.340156\n",
      "Batch #10\tAverage Generator Loss: 37.527885\tAverage Discriminator Loss: 0.073500\n",
      "\n",
      "Train time for epoch #49 (step 49): 1.396988\n",
      "Batch #10\tAverage Generator Loss: 32.876680\tAverage Discriminator Loss: 0.189114\n",
      "\n",
      "Train time for epoch #50 (step 50): 1.376925\n",
      "Batch #10\tAverage Generator Loss: 43.572953\tAverage Discriminator Loss: 0.157460\n",
      "\n",
      "Train time for epoch #51 (step 51): 1.388524\n",
      "Batch #10\tAverage Generator Loss: 30.281790\tAverage Discriminator Loss: 0.253993\n",
      "\n",
      "Train time for epoch #52 (step 52): 1.450079\n",
      "Batch #10\tAverage Generator Loss: 42.197158\tAverage Discriminator Loss: 0.118731\n",
      "\n",
      "Train time for epoch #53 (step 53): 1.353232\n",
      "Batch #10\tAverage Generator Loss: 39.990904\tAverage Discriminator Loss: 0.158208\n",
      "\n",
      "Train time for epoch #54 (step 54): 1.466175\n",
      "Batch #10\tAverage Generator Loss: 37.992428\tAverage Discriminator Loss: 0.063756\n",
      "\n",
      "Train time for epoch #55 (step 55): 1.348360\n",
      "Batch #10\tAverage Generator Loss: 42.048018\tAverage Discriminator Loss: 0.220816\n",
      "\n",
      "Train time for epoch #56 (step 56): 1.400528\n",
      "Batch #10\tAverage Generator Loss: 55.752674\tAverage Discriminator Loss: 0.176128\n",
      "\n",
      "Train time for epoch #57 (step 57): 1.353760\n",
      "Batch #10\tAverage Generator Loss: 44.025436\tAverage Discriminator Loss: 0.103115\n",
      "\n",
      "Train time for epoch #58 (step 58): 1.438709\n",
      "Batch #10\tAverage Generator Loss: 39.381260\tAverage Discriminator Loss: 0.169501\n",
      "\n",
      "Train time for epoch #59 (step 59): 1.348643\n",
      "Batch #10\tAverage Generator Loss: 41.292399\tAverage Discriminator Loss: 0.050741\n",
      "\n",
      "Train time for epoch #60 (step 60): 1.479066\n",
      "Batch #10\tAverage Generator Loss: 46.581626\tAverage Discriminator Loss: 0.030575\n",
      "\n",
      "Train time for epoch #61 (step 61): 1.399422\n",
      "Batch #10\tAverage Generator Loss: 54.033871\tAverage Discriminator Loss: 0.078306\n",
      "\n",
      "Train time for epoch #62 (step 62): 1.452734\n",
      "Batch #10\tAverage Generator Loss: 62.410452\tAverage Discriminator Loss: 0.072390\n",
      "\n",
      "Train time for epoch #63 (step 63): 1.410547\n",
      "Batch #10\tAverage Generator Loss: 50.907160\tAverage Discriminator Loss: 0.130949\n",
      "\n",
      "Train time for epoch #64 (step 64): 1.404400\n",
      "Batch #10\tAverage Generator Loss: 45.163299\tAverage Discriminator Loss: 0.110493\n",
      "\n",
      "Train time for epoch #65 (step 65): 1.350477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 43.719670\tAverage Discriminator Loss: 0.060091\n",
      "\n",
      "Train time for epoch #66 (step 66): 1.383076\n",
      "Batch #10\tAverage Generator Loss: 48.472795\tAverage Discriminator Loss: 0.167133\n",
      "\n",
      "Train time for epoch #67 (step 67): 1.305131\n",
      "Batch #10\tAverage Generator Loss: 41.060191\tAverage Discriminator Loss: 0.102658\n",
      "\n",
      "Train time for epoch #68 (step 68): 1.405823\n",
      "Batch #10\tAverage Generator Loss: 53.857782\tAverage Discriminator Loss: 0.115115\n",
      "\n",
      "Train time for epoch #69 (step 69): 1.339426\n",
      "Batch #10\tAverage Generator Loss: 42.412526\tAverage Discriminator Loss: 0.044617\n",
      "\n",
      "Train time for epoch #70 (step 70): 1.389057\n",
      "Batch #10\tAverage Generator Loss: 45.034400\tAverage Discriminator Loss: 0.241916\n",
      "\n",
      "Train time for epoch #71 (step 71): 1.552267\n",
      "Batch #10\tAverage Generator Loss: 47.179978\tAverage Discriminator Loss: 0.044026\n",
      "\n",
      "Train time for epoch #72 (step 72): 1.424548\n",
      "Batch #10\tAverage Generator Loss: 53.258494\tAverage Discriminator Loss: 0.166915\n",
      "\n",
      "Train time for epoch #73 (step 73): 1.339505\n",
      "Batch #10\tAverage Generator Loss: 49.361071\tAverage Discriminator Loss: 0.133297\n",
      "\n",
      "Train time for epoch #74 (step 74): 1.333656\n",
      "Batch #10\tAverage Generator Loss: 60.920768\tAverage Discriminator Loss: 0.031040\n",
      "\n",
      "Train time for epoch #75 (step 75): 1.395663\n",
      "Batch #10\tAverage Generator Loss: 52.563583\tAverage Discriminator Loss: 0.038294\n",
      "\n",
      "Train time for epoch #76 (step 76): 1.414421\n",
      "Batch #10\tAverage Generator Loss: 53.008355\tAverage Discriminator Loss: 0.046395\n",
      "\n",
      "Train time for epoch #77 (step 77): 1.431713\n",
      "Batch #10\tAverage Generator Loss: 60.595921\tAverage Discriminator Loss: 0.124883\n",
      "\n",
      "Train time for epoch #78 (step 78): 1.356745\n",
      "Batch #10\tAverage Generator Loss: 65.508166\tAverage Discriminator Loss: 0.043300\n",
      "\n",
      "Train time for epoch #79 (step 79): 1.360498\n",
      "Batch #10\tAverage Generator Loss: 61.180229\tAverage Discriminator Loss: 0.129024\n",
      "\n",
      "Train time for epoch #80 (step 80): 1.516733\n",
      "Batch #10\tAverage Generator Loss: 69.081271\tAverage Discriminator Loss: 0.031611\n",
      "\n",
      "Train time for epoch #81 (step 81): 1.447731\n",
      "Batch #10\tAverage Generator Loss: 62.382478\tAverage Discriminator Loss: 0.191314\n",
      "\n",
      "Train time for epoch #82 (step 82): 1.377820\n",
      "Batch #10\tAverage Generator Loss: 43.017010\tAverage Discriminator Loss: 0.185868\n",
      "\n",
      "Train time for epoch #83 (step 83): 1.395081\n",
      "Batch #10\tAverage Generator Loss: 47.475467\tAverage Discriminator Loss: 0.088921\n",
      "\n",
      "Train time for epoch #84 (step 84): 1.381057\n",
      "Batch #10\tAverage Generator Loss: 43.465461\tAverage Discriminator Loss: 0.162940\n",
      "\n",
      "Train time for epoch #85 (step 85): 1.404837\n",
      "Batch #10\tAverage Generator Loss: 62.235733\tAverage Discriminator Loss: 0.071022\n",
      "\n",
      "Train time for epoch #86 (step 86): 1.356330\n",
      "Batch #10\tAverage Generator Loss: 62.616596\tAverage Discriminator Loss: 0.047873\n",
      "\n",
      "Train time for epoch #87 (step 87): 1.388902\n",
      "Batch #10\tAverage Generator Loss: 47.025729\tAverage Discriminator Loss: 0.120647\n",
      "\n",
      "Train time for epoch #88 (step 88): 1.351408\n",
      "Batch #10\tAverage Generator Loss: 45.889587\tAverage Discriminator Loss: 0.028349\n",
      "\n",
      "Train time for epoch #89 (step 89): 1.384610\n",
      "Batch #10\tAverage Generator Loss: 73.134416\tAverage Discriminator Loss: 0.097619\n",
      "\n",
      "Train time for epoch #90 (step 90): 1.449226\n",
      "Batch #10\tAverage Generator Loss: 51.863710\tAverage Discriminator Loss: 0.013955\n",
      "\n",
      "Train time for epoch #91 (step 91): 1.433372\n",
      "Batch #10\tAverage Generator Loss: 65.603709\tAverage Discriminator Loss: 0.060745\n",
      "\n",
      "Train time for epoch #92 (step 92): 1.432939\n",
      "Batch #10\tAverage Generator Loss: 70.251643\tAverage Discriminator Loss: 0.022804\n",
      "\n",
      "Train time for epoch #93 (step 93): 1.561702\n",
      "Batch #10\tAverage Generator Loss: 56.822638\tAverage Discriminator Loss: 0.062867\n",
      "\n",
      "Train time for epoch #94 (step 94): 1.412339\n",
      "Batch #10\tAverage Generator Loss: 83.578759\tAverage Discriminator Loss: 0.011544\n",
      "\n",
      "Train time for epoch #95 (step 95): 1.417143\n",
      "Batch #10\tAverage Generator Loss: 57.364791\tAverage Discriminator Loss: 0.038005\n",
      "\n",
      "Train time for epoch #96 (step 96): 1.351253\n",
      "Batch #10\tAverage Generator Loss: 64.362727\tAverage Discriminator Loss: 0.106259\n",
      "\n",
      "Train time for epoch #97 (step 97): 1.397021\n",
      "Batch #10\tAverage Generator Loss: 67.266842\tAverage Discriminator Loss: 0.025030\n",
      "\n",
      "Train time for epoch #98 (step 98): 1.300928\n",
      "Batch #10\tAverage Generator Loss: 60.534811\tAverage Discriminator Loss: 0.016673\n",
      "\n",
      "Train time for epoch #99 (step 99): 1.303893\n",
      "Batch #10\tAverage Generator Loss: 58.276431\tAverage Discriminator Loss: 0.080485\n",
      "\n",
      "Train time for epoch #100 (step 100): 1.462123\n",
      "Batch #10\tAverage Generator Loss: 62.512694\tAverage Discriminator Loss: 0.107011\n",
      "\n",
      "Train time for epoch #101 (step 101): 1.364527\n",
      "Batch #10\tAverage Generator Loss: 64.330900\tAverage Discriminator Loss: 0.045814\n",
      "\n",
      "Train time for epoch #102 (step 102): 1.385823\n",
      "Batch #10\tAverage Generator Loss: 64.006595\tAverage Discriminator Loss: 0.158473\n",
      "\n",
      "Train time for epoch #103 (step 103): 1.455603\n",
      "Batch #10\tAverage Generator Loss: 48.572921\tAverage Discriminator Loss: 0.057914\n",
      "\n",
      "Train time for epoch #104 (step 104): 1.346198\n",
      "Batch #10\tAverage Generator Loss: 54.956212\tAverage Discriminator Loss: 0.092389\n",
      "\n",
      "Train time for epoch #105 (step 105): 1.509419\n",
      "Batch #10\tAverage Generator Loss: 67.230960\tAverage Discriminator Loss: 0.023956\n",
      "\n",
      "Train time for epoch #106 (step 106): 1.344122\n",
      "Batch #10\tAverage Generator Loss: 66.418843\tAverage Discriminator Loss: 0.054175\n",
      "\n",
      "Train time for epoch #107 (step 107): 1.358117\n",
      "Batch #10\tAverage Generator Loss: 71.658015\tAverage Discriminator Loss: 0.008282\n",
      "\n",
      "Train time for epoch #108 (step 108): 1.399770\n",
      "Batch #10\tAverage Generator Loss: 61.742512\tAverage Discriminator Loss: 0.118271\n",
      "\n",
      "Train time for epoch #109 (step 109): 1.491354\n",
      "Batch #10\tAverage Generator Loss: 76.719614\tAverage Discriminator Loss: 0.121104\n",
      "\n",
      "Train time for epoch #110 (step 110): 1.349043\n",
      "Batch #10\tAverage Generator Loss: 72.001458\tAverage Discriminator Loss: 0.026716\n",
      "\n",
      "Train time for epoch #111 (step 111): 1.403789\n",
      "Batch #10\tAverage Generator Loss: 73.984427\tAverage Discriminator Loss: 0.117150\n",
      "\n",
      "Train time for epoch #112 (step 112): 1.435963\n",
      "Batch #10\tAverage Generator Loss: 73.628944\tAverage Discriminator Loss: 0.027564\n",
      "\n",
      "Train time for epoch #113 (step 113): 1.393865\n",
      "Batch #10\tAverage Generator Loss: 70.489222\tAverage Discriminator Loss: 0.013790\n",
      "\n",
      "Train time for epoch #114 (step 114): 1.399340\n",
      "Batch #10\tAverage Generator Loss: 67.530672\tAverage Discriminator Loss: 0.049500\n",
      "\n",
      "Train time for epoch #115 (step 115): 1.381921\n",
      "Batch #10\tAverage Generator Loss: 62.150483\tAverage Discriminator Loss: 0.030161\n",
      "\n",
      "Train time for epoch #116 (step 116): 1.423171\n",
      "Batch #10\tAverage Generator Loss: 77.029320\tAverage Discriminator Loss: 0.032788\n",
      "\n",
      "Train time for epoch #117 (step 117): 1.421840\n",
      "Batch #10\tAverage Generator Loss: 81.685120\tAverage Discriminator Loss: 0.029792\n",
      "\n",
      "Train time for epoch #118 (step 118): 1.364392\n",
      "Batch #10\tAverage Generator Loss: 71.649957\tAverage Discriminator Loss: 0.017030\n",
      "\n",
      "Train time for epoch #119 (step 119): 1.347220\n",
      "Batch #10\tAverage Generator Loss: 92.219502\tAverage Discriminator Loss: 0.047098\n",
      "\n",
      "Train time for epoch #120 (step 120): 1.439111\n",
      "Batch #10\tAverage Generator Loss: 70.446754\tAverage Discriminator Loss: 0.002129\n",
      "\n",
      "Train time for epoch #121 (step 121): 1.592336\n",
      "Batch #10\tAverage Generator Loss: 80.282166\tAverage Discriminator Loss: 0.300237\n",
      "\n",
      "Train time for epoch #122 (step 122): 1.499827\n",
      "Batch #10\tAverage Generator Loss: 74.981849\tAverage Discriminator Loss: 0.058896\n",
      "\n",
      "Train time for epoch #123 (step 123): 1.488700\n",
      "Batch #10\tAverage Generator Loss: 72.278488\tAverage Discriminator Loss: 0.044336\n",
      "\n",
      "Train time for epoch #124 (step 124): 1.389222\n",
      "Batch #10\tAverage Generator Loss: 79.665020\tAverage Discriminator Loss: 0.099518\n",
      "\n",
      "Train time for epoch #125 (step 125): 1.361614\n",
      "Batch #10\tAverage Generator Loss: 78.315632\tAverage Discriminator Loss: 0.022662\n",
      "\n",
      "Train time for epoch #126 (step 126): 1.433591\n",
      "Batch #10\tAverage Generator Loss: 96.518456\tAverage Discriminator Loss: 0.005915\n",
      "\n",
      "Train time for epoch #127 (step 127): 1.448165\n",
      "Batch #10\tAverage Generator Loss: 71.423198\tAverage Discriminator Loss: 0.011531\n",
      "\n",
      "Train time for epoch #128 (step 128): 1.347594\n",
      "Batch #10\tAverage Generator Loss: 70.721136\tAverage Discriminator Loss: 0.045002\n",
      "\n",
      "Train time for epoch #129 (step 129): 1.506514\n",
      "Batch #10\tAverage Generator Loss: 82.802116\tAverage Discriminator Loss: 0.002734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #130 (step 130): 1.444254\n",
      "Batch #10\tAverage Generator Loss: 79.783440\tAverage Discriminator Loss: 0.019578\n",
      "\n",
      "Train time for epoch #131 (step 131): 1.428519\n",
      "Batch #10\tAverage Generator Loss: 75.057911\tAverage Discriminator Loss: 0.011092\n",
      "\n",
      "Train time for epoch #132 (step 132): 1.349677\n",
      "Batch #10\tAverage Generator Loss: 82.271469\tAverage Discriminator Loss: 0.007619\n",
      "\n",
      "Train time for epoch #133 (step 133): 1.403341\n",
      "Batch #10\tAverage Generator Loss: 78.897205\tAverage Discriminator Loss: 0.008742\n",
      "\n",
      "Train time for epoch #134 (step 134): 1.451640\n",
      "Batch #10\tAverage Generator Loss: 74.785960\tAverage Discriminator Loss: 0.039000\n",
      "\n",
      "Train time for epoch #135 (step 135): 1.428718\n",
      "Batch #10\tAverage Generator Loss: 73.217596\tAverage Discriminator Loss: 0.093775\n",
      "\n",
      "Train time for epoch #136 (step 136): 1.419865\n",
      "Batch #10\tAverage Generator Loss: 71.006862\tAverage Discriminator Loss: 0.031512\n",
      "\n",
      "Train time for epoch #137 (step 137): 1.345772\n",
      "Batch #10\tAverage Generator Loss: 75.677615\tAverage Discriminator Loss: 0.038082\n",
      "\n",
      "Train time for epoch #138 (step 138): 1.289548\n",
      "Batch #10\tAverage Generator Loss: 73.734291\tAverage Discriminator Loss: 0.028893\n",
      "\n",
      "Train time for epoch #139 (step 139): 1.416919\n",
      "Batch #10\tAverage Generator Loss: 97.069296\tAverage Discriminator Loss: 0.011516\n",
      "\n",
      "Train time for epoch #140 (step 140): 1.434349\n",
      "Batch #10\tAverage Generator Loss: 72.227647\tAverage Discriminator Loss: 0.006634\n",
      "\n",
      "Train time for epoch #141 (step 141): 1.340636\n",
      "Batch #10\tAverage Generator Loss: 97.658499\tAverage Discriminator Loss: 0.005434\n",
      "\n",
      "Train time for epoch #142 (step 142): 1.394735\n",
      "Batch #10\tAverage Generator Loss: 86.864553\tAverage Discriminator Loss: 0.011231\n",
      "\n",
      "Train time for epoch #143 (step 143): 1.418402\n",
      "Batch #10\tAverage Generator Loss: 81.822029\tAverage Discriminator Loss: 0.010241\n",
      "\n",
      "Train time for epoch #144 (step 144): 1.388071\n",
      "Batch #10\tAverage Generator Loss: 116.671557\tAverage Discriminator Loss: 0.035851\n",
      "\n",
      "Train time for epoch #145 (step 145): 1.357281\n",
      "Batch #10\tAverage Generator Loss: 96.337893\tAverage Discriminator Loss: 0.017294\n",
      "\n",
      "Train time for epoch #146 (step 146): 1.502956\n",
      "Batch #10\tAverage Generator Loss: 102.471077\tAverage Discriminator Loss: 0.004024\n",
      "\n",
      "Train time for epoch #147 (step 147): 1.459743\n",
      "Batch #10\tAverage Generator Loss: 107.732838\tAverage Discriminator Loss: 0.003137\n",
      "\n",
      "Train time for epoch #148 (step 148): 1.410713\n",
      "Batch #10\tAverage Generator Loss: 106.061892\tAverage Discriminator Loss: 0.001513\n",
      "\n",
      "Train time for epoch #149 (step 149): 1.447606\n",
      "Batch #10\tAverage Generator Loss: 101.828285\tAverage Discriminator Loss: 0.008721\n",
      "\n",
      "Train time for epoch #150 (step 150): 1.393437\n",
      "Batch #10\tAverage Generator Loss: 111.093554\tAverage Discriminator Loss: 0.003316\n",
      "\n",
      "Train time for epoch #151 (step 151): 1.469267\n",
      "Batch #10\tAverage Generator Loss: 119.485255\tAverage Discriminator Loss: 0.003729\n",
      "\n",
      "Train time for epoch #152 (step 152): 1.520504\n",
      "Batch #10\tAverage Generator Loss: 98.945468\tAverage Discriminator Loss: 0.002807\n",
      "\n",
      "Train time for epoch #153 (step 153): 1.440966\n",
      "Batch #10\tAverage Generator Loss: 92.547077\tAverage Discriminator Loss: 0.000996\n",
      "\n",
      "Train time for epoch #154 (step 154): 1.394600\n",
      "Batch #10\tAverage Generator Loss: 117.122256\tAverage Discriminator Loss: 0.003670\n",
      "\n",
      "Train time for epoch #155 (step 155): 1.446758\n",
      "Batch #10\tAverage Generator Loss: 98.744647\tAverage Discriminator Loss: 0.003512\n",
      "\n",
      "Train time for epoch #156 (step 156): 1.338838\n",
      "Batch #10\tAverage Generator Loss: 110.825013\tAverage Discriminator Loss: 0.001252\n",
      "\n",
      "Train time for epoch #157 (step 157): 1.403924\n",
      "Batch #10\tAverage Generator Loss: 106.430384\tAverage Discriminator Loss: 0.000916\n",
      "\n",
      "Train time for epoch #158 (step 158): 1.490490\n",
      "Batch #10\tAverage Generator Loss: 112.643541\tAverage Discriminator Loss: 0.005707\n",
      "\n",
      "Train time for epoch #159 (step 159): 1.401891\n",
      "Batch #10\tAverage Generator Loss: 107.351178\tAverage Discriminator Loss: 0.053951\n",
      "\n",
      "Train time for epoch #160 (step 160): 1.439925\n",
      "Batch #10\tAverage Generator Loss: 115.804570\tAverage Discriminator Loss: 0.062479\n",
      "\n",
      "Train time for epoch #161 (step 161): 1.335537\n",
      "Batch #10\tAverage Generator Loss: 105.158414\tAverage Discriminator Loss: 0.014366\n",
      "\n",
      "Train time for epoch #162 (step 162): 1.386245\n",
      "Batch #10\tAverage Generator Loss: 108.602611\tAverage Discriminator Loss: 0.137182\n",
      "\n",
      "Train time for epoch #163 (step 163): 1.358489\n",
      "Batch #10\tAverage Generator Loss: 119.216611\tAverage Discriminator Loss: 0.004764\n",
      "\n",
      "Train time for epoch #164 (step 164): 1.396398\n",
      "Batch #10\tAverage Generator Loss: 108.820570\tAverage Discriminator Loss: 0.075905\n",
      "\n",
      "Train time for epoch #165 (step 165): 1.403355\n",
      "Batch #10\tAverage Generator Loss: 124.795942\tAverage Discriminator Loss: 0.006991\n",
      "\n",
      "Train time for epoch #166 (step 166): 1.382360\n",
      "Batch #10\tAverage Generator Loss: 91.046668\tAverage Discriminator Loss: 0.031736\n",
      "\n",
      "Train time for epoch #167 (step 167): 1.351272\n",
      "Batch #10\tAverage Generator Loss: 101.343952\tAverage Discriminator Loss: 0.015138\n",
      "\n",
      "Train time for epoch #168 (step 168): 1.383888\n",
      "Batch #10\tAverage Generator Loss: 124.025597\tAverage Discriminator Loss: 0.081595\n",
      "\n",
      "Train time for epoch #169 (step 169): 1.557198\n",
      "Batch #10\tAverage Generator Loss: 98.799105\tAverage Discriminator Loss: 0.226036\n",
      "\n",
      "Train time for epoch #170 (step 170): 1.455007\n",
      "Batch #10\tAverage Generator Loss: 118.649264\tAverage Discriminator Loss: 0.026839\n",
      "\n",
      "Train time for epoch #171 (step 171): 1.544147\n",
      "Batch #10\tAverage Generator Loss: 108.771316\tAverage Discriminator Loss: 0.037751\n",
      "\n",
      "Train time for epoch #172 (step 172): 1.465331\n",
      "Batch #10\tAverage Generator Loss: 106.708908\tAverage Discriminator Loss: 0.002512\n",
      "\n",
      "Train time for epoch #173 (step 173): 1.472048\n",
      "Batch #10\tAverage Generator Loss: 98.951793\tAverage Discriminator Loss: 0.025019\n",
      "\n",
      "Train time for epoch #174 (step 174): 1.311298\n",
      "Batch #10\tAverage Generator Loss: 97.392771\tAverage Discriminator Loss: 0.001788\n",
      "\n",
      "Train time for epoch #175 (step 175): 1.409510\n",
      "Batch #10\tAverage Generator Loss: 114.414031\tAverage Discriminator Loss: 0.181788\n",
      "\n",
      "Train time for epoch #176 (step 176): 1.344154\n",
      "Batch #10\tAverage Generator Loss: 121.640536\tAverage Discriminator Loss: 0.090004\n",
      "\n",
      "Train time for epoch #177 (step 177): 1.404802\n",
      "Batch #10\tAverage Generator Loss: 111.071105\tAverage Discriminator Loss: 0.035432\n",
      "\n",
      "Train time for epoch #178 (step 178): 1.388077\n",
      "Batch #10\tAverage Generator Loss: 109.899942\tAverage Discriminator Loss: 0.067780\n",
      "\n",
      "Train time for epoch #179 (step 179): 1.464567\n",
      "Batch #10\tAverage Generator Loss: 87.646276\tAverage Discriminator Loss: 0.137687\n",
      "\n",
      "Train time for epoch #180 (step 180): 1.423602\n",
      "Batch #10\tAverage Generator Loss: 87.102774\tAverage Discriminator Loss: 0.007808\n",
      "\n",
      "Train time for epoch #181 (step 181): 1.431768\n",
      "Batch #10\tAverage Generator Loss: 80.244182\tAverage Discriminator Loss: 0.049499\n",
      "\n",
      "Train time for epoch #182 (step 182): 1.478268\n",
      "Batch #10\tAverage Generator Loss: 79.731692\tAverage Discriminator Loss: 0.017075\n",
      "\n",
      "Train time for epoch #183 (step 183): 1.375654\n",
      "Batch #10\tAverage Generator Loss: 95.188288\tAverage Discriminator Loss: 0.008573\n",
      "\n",
      "Train time for epoch #184 (step 184): 1.442293\n",
      "Batch #10\tAverage Generator Loss: 96.214432\tAverage Discriminator Loss: 0.007694\n",
      "\n",
      "Train time for epoch #185 (step 185): 1.393451\n",
      "Batch #10\tAverage Generator Loss: 105.145181\tAverage Discriminator Loss: 0.002174\n",
      "\n",
      "Train time for epoch #186 (step 186): 1.468098\n",
      "Batch #10\tAverage Generator Loss: 99.526224\tAverage Discriminator Loss: 0.001920\n",
      "\n",
      "Train time for epoch #187 (step 187): 1.481282\n",
      "Batch #10\tAverage Generator Loss: 97.683921\tAverage Discriminator Loss: 0.006482\n",
      "\n",
      "Train time for epoch #188 (step 188): 1.352656\n",
      "Batch #10\tAverage Generator Loss: 99.179137\tAverage Discriminator Loss: 0.002608\n",
      "\n",
      "Train time for epoch #189 (step 189): 1.397782\n",
      "Batch #10\tAverage Generator Loss: 99.840436\tAverage Discriminator Loss: 0.006486\n",
      "\n",
      "Train time for epoch #190 (step 190): 1.411336\n",
      "Batch #10\tAverage Generator Loss: 116.532506\tAverage Discriminator Loss: 0.007098\n",
      "\n",
      "Train time for epoch #191 (step 191): 1.444799\n",
      "Batch #10\tAverage Generator Loss: 111.232774\tAverage Discriminator Loss: 0.006825\n",
      "\n",
      "Train time for epoch #192 (step 192): 1.357005\n",
      "Batch #10\tAverage Generator Loss: 98.241749\tAverage Discriminator Loss: 0.004304\n",
      "\n",
      "Train time for epoch #193 (step 193): 1.339307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 93.416564\tAverage Discriminator Loss: 0.000964\n",
      "\n",
      "Train time for epoch #194 (step 194): 1.358894\n",
      "Batch #10\tAverage Generator Loss: 100.762606\tAverage Discriminator Loss: 0.001708\n",
      "\n",
      "Train time for epoch #195 (step 195): 1.406810\n",
      "Batch #10\tAverage Generator Loss: 99.112370\tAverage Discriminator Loss: 0.001216\n",
      "\n",
      "Train time for epoch #196 (step 196): 1.387016\n",
      "Batch #10\tAverage Generator Loss: 108.202218\tAverage Discriminator Loss: 0.022989\n",
      "\n",
      "Train time for epoch #197 (step 197): 1.342002\n",
      "Batch #10\tAverage Generator Loss: 101.378024\tAverage Discriminator Loss: 0.000978\n",
      "\n",
      "Train time for epoch #198 (step 198): 1.458368\n",
      "Batch #10\tAverage Generator Loss: 100.538174\tAverage Discriminator Loss: 0.001484\n",
      "\n",
      "Train time for epoch #199 (step 199): 1.472627\n",
      "Batch #10\tAverage Generator Loss: 129.895750\tAverage Discriminator Loss: 0.118197\n",
      "\n",
      "Train time for epoch #200 (step 200): 1.349593\n",
      "Batch #10\tAverage Generator Loss: 92.995124\tAverage Discriminator Loss: 0.175635\n",
      "\n",
      "Train time for epoch #201 (step 201): 1.296213\n",
      "Batch #10\tAverage Generator Loss: 116.287949\tAverage Discriminator Loss: 0.019407\n",
      "\n",
      "Train time for epoch #202 (step 202): 1.433179\n",
      "Batch #10\tAverage Generator Loss: 120.754650\tAverage Discriminator Loss: 0.023558\n",
      "\n",
      "Train time for epoch #203 (step 203): 1.485685\n",
      "Batch #10\tAverage Generator Loss: 95.584700\tAverage Discriminator Loss: 0.002765\n",
      "\n",
      "Train time for epoch #204 (step 204): 1.395303\n",
      "Batch #10\tAverage Generator Loss: 114.933047\tAverage Discriminator Loss: 0.126813\n",
      "\n",
      "Train time for epoch #205 (step 205): 1.413820\n",
      "Batch #10\tAverage Generator Loss: 102.703996\tAverage Discriminator Loss: 0.010040\n",
      "\n",
      "Train time for epoch #206 (step 206): 1.356328\n",
      "Batch #10\tAverage Generator Loss: 97.012249\tAverage Discriminator Loss: 0.002583\n",
      "\n",
      "Train time for epoch #207 (step 207): 1.510849\n",
      "Batch #10\tAverage Generator Loss: 99.372553\tAverage Discriminator Loss: 0.003490\n",
      "\n",
      "Train time for epoch #208 (step 208): 1.432605\n",
      "Batch #10\tAverage Generator Loss: 117.187871\tAverage Discriminator Loss: 0.003658\n",
      "\n",
      "Train time for epoch #209 (step 209): 1.353547\n",
      "Batch #10\tAverage Generator Loss: 106.233337\tAverage Discriminator Loss: 0.002657\n",
      "\n",
      "Train time for epoch #210 (step 210): 1.347809\n",
      "Batch #10\tAverage Generator Loss: 108.932798\tAverage Discriminator Loss: 0.067595\n",
      "\n",
      "Train time for epoch #211 (step 211): 1.498313\n",
      "Batch #10\tAverage Generator Loss: 95.454582\tAverage Discriminator Loss: 0.006818\n",
      "\n",
      "Train time for epoch #212 (step 212): 1.393884\n",
      "Batch #10\tAverage Generator Loss: 96.806444\tAverage Discriminator Loss: 0.004802\n",
      "\n",
      "Train time for epoch #213 (step 213): 1.421986\n",
      "Batch #10\tAverage Generator Loss: 109.414717\tAverage Discriminator Loss: 0.002207\n",
      "\n",
      "Train time for epoch #214 (step 214): 1.420006\n",
      "Batch #10\tAverage Generator Loss: 94.456594\tAverage Discriminator Loss: 0.003432\n",
      "\n",
      "Train time for epoch #215 (step 215): 1.364250\n",
      "Batch #10\tAverage Generator Loss: 95.267562\tAverage Discriminator Loss: 0.075686\n",
      "\n",
      "Train time for epoch #216 (step 216): 1.419659\n",
      "Batch #10\tAverage Generator Loss: 102.288758\tAverage Discriminator Loss: 0.064142\n",
      "\n",
      "Train time for epoch #217 (step 217): 1.353426\n",
      "Batch #10\tAverage Generator Loss: 87.701443\tAverage Discriminator Loss: 0.111289\n",
      "\n",
      "Train time for epoch #218 (step 218): 1.396697\n",
      "Batch #10\tAverage Generator Loss: 95.076351\tAverage Discriminator Loss: 0.223290\n",
      "\n",
      "Train time for epoch #219 (step 219): 1.402377\n",
      "Batch #10\tAverage Generator Loss: 120.958392\tAverage Discriminator Loss: 0.143444\n",
      "\n",
      "Train time for epoch #220 (step 220): 1.399062\n",
      "Batch #10\tAverage Generator Loss: 81.979494\tAverage Discriminator Loss: 0.053177\n",
      "\n",
      "Train time for epoch #221 (step 221): 1.469012\n",
      "Batch #10\tAverage Generator Loss: 83.739478\tAverage Discriminator Loss: 0.018684\n",
      "\n",
      "Train time for epoch #222 (step 222): 1.533141\n",
      "Batch #10\tAverage Generator Loss: 102.233167\tAverage Discriminator Loss: 0.039783\n",
      "\n",
      "Train time for epoch #223 (step 223): 1.381883\n",
      "Batch #10\tAverage Generator Loss: 97.701123\tAverage Discriminator Loss: 0.017047\n",
      "\n",
      "Train time for epoch #224 (step 224): 1.466623\n",
      "Batch #10\tAverage Generator Loss: 94.888064\tAverage Discriminator Loss: 0.071998\n",
      "\n",
      "Train time for epoch #225 (step 225): 1.397432\n",
      "Batch #10\tAverage Generator Loss: 115.793492\tAverage Discriminator Loss: 0.054187\n",
      "\n",
      "Train time for epoch #226 (step 226): 1.373665\n",
      "Batch #10\tAverage Generator Loss: 92.523233\tAverage Discriminator Loss: 0.009664\n",
      "\n",
      "Train time for epoch #227 (step 227): 1.361199\n",
      "Batch #10\tAverage Generator Loss: 91.997157\tAverage Discriminator Loss: 0.003142\n",
      "\n",
      "Train time for epoch #228 (step 228): 1.504978\n",
      "Batch #10\tAverage Generator Loss: 115.321790\tAverage Discriminator Loss: 0.131425\n",
      "\n",
      "Train time for epoch #229 (step 229): 1.448001\n",
      "Batch #10\tAverage Generator Loss: 110.524586\tAverage Discriminator Loss: 0.083360\n",
      "\n",
      "Train time for epoch #230 (step 230): 1.447175\n",
      "Batch #10\tAverage Generator Loss: 104.078524\tAverage Discriminator Loss: 0.015730\n",
      "\n",
      "Train time for epoch #231 (step 231): 1.464630\n",
      "Batch #10\tAverage Generator Loss: 112.094604\tAverage Discriminator Loss: 0.008253\n",
      "\n",
      "Train time for epoch #232 (step 232): 1.404684\n",
      "Batch #10\tAverage Generator Loss: 119.960665\tAverage Discriminator Loss: 0.009386\n",
      "\n",
      "Train time for epoch #233 (step 233): 1.346054\n",
      "Batch #10\tAverage Generator Loss: 127.040582\tAverage Discriminator Loss: 0.061304\n",
      "\n",
      "Train time for epoch #234 (step 234): 1.446537\n",
      "Batch #10\tAverage Generator Loss: 108.409540\tAverage Discriminator Loss: 0.012756\n",
      "\n",
      "Train time for epoch #235 (step 235): 1.345632\n",
      "Batch #10\tAverage Generator Loss: 97.931077\tAverage Discriminator Loss: 0.005724\n",
      "\n",
      "Train time for epoch #236 (step 236): 1.385888\n",
      "Batch #10\tAverage Generator Loss: 121.327432\tAverage Discriminator Loss: 0.018694\n",
      "\n",
      "Train time for epoch #237 (step 237): 1.352339\n",
      "Batch #10\tAverage Generator Loss: 107.868398\tAverage Discriminator Loss: 0.040549\n",
      "\n",
      "Train time for epoch #238 (step 238): 1.543163\n",
      "Batch #10\tAverage Generator Loss: 132.336018\tAverage Discriminator Loss: 0.005939\n",
      "\n",
      "Train time for epoch #239 (step 239): 1.368219\n",
      "Batch #10\tAverage Generator Loss: 106.236761\tAverage Discriminator Loss: 0.042667\n",
      "\n",
      "Train time for epoch #240 (step 240): 1.399033\n",
      "Batch #10\tAverage Generator Loss: 101.577464\tAverage Discriminator Loss: 0.002253\n",
      "\n",
      "Train time for epoch #241 (step 241): 1.446419\n",
      "Batch #10\tAverage Generator Loss: 123.215314\tAverage Discriminator Loss: 0.003466\n",
      "\n",
      "Train time for epoch #242 (step 242): 1.408916\n",
      "Batch #10\tAverage Generator Loss: 104.554225\tAverage Discriminator Loss: 0.089250\n",
      "\n",
      "Train time for epoch #243 (step 243): 1.410812\n",
      "Batch #10\tAverage Generator Loss: 129.232909\tAverage Discriminator Loss: 0.020054\n",
      "\n",
      "Train time for epoch #244 (step 244): 1.440404\n",
      "Batch #10\tAverage Generator Loss: 103.566917\tAverage Discriminator Loss: 0.013008\n",
      "\n",
      "Train time for epoch #245 (step 245): 1.360629\n",
      "Batch #10\tAverage Generator Loss: 114.791959\tAverage Discriminator Loss: 0.003747\n",
      "\n",
      "Train time for epoch #246 (step 246): 1.408364\n",
      "Batch #10\tAverage Generator Loss: 108.727523\tAverage Discriminator Loss: 0.009514\n",
      "\n",
      "Train time for epoch #247 (step 247): 1.474073\n",
      "Batch #10\tAverage Generator Loss: 139.813186\tAverage Discriminator Loss: 0.004559\n",
      "\n",
      "Train time for epoch #248 (step 248): 1.351531\n",
      "Batch #10\tAverage Generator Loss: 118.072424\tAverage Discriminator Loss: 0.034897\n",
      "\n",
      "Train time for epoch #249 (step 249): 1.450324\n",
      "Batch #10\tAverage Generator Loss: 119.015998\tAverage Discriminator Loss: 0.061373\n",
      "\n",
      "Train time for epoch #250 (step 250): 1.466045\n",
      "Batch #10\tAverage Generator Loss: 96.205691\tAverage Discriminator Loss: 0.046562\n",
      "\n",
      "Train time for epoch #251 (step 251): 1.418238\n",
      "Batch #10\tAverage Generator Loss: 108.645983\tAverage Discriminator Loss: 0.009890\n",
      "\n",
      "Train time for epoch #252 (step 252): 1.390461\n",
      "Batch #10\tAverage Generator Loss: 88.638876\tAverage Discriminator Loss: 0.006343\n",
      "\n",
      "Train time for epoch #253 (step 253): 1.365349\n",
      "Batch #10\tAverage Generator Loss: 122.767350\tAverage Discriminator Loss: 0.005860\n",
      "\n",
      "Train time for epoch #254 (step 254): 1.411577\n",
      "Batch #10\tAverage Generator Loss: 104.865912\tAverage Discriminator Loss: 0.002994\n",
      "\n",
      "Train time for epoch #255 (step 255): 1.404022\n",
      "Batch #10\tAverage Generator Loss: 109.883826\tAverage Discriminator Loss: 0.151545\n",
      "\n",
      "Train time for epoch #256 (step 256): 1.452841\n",
      "Batch #10\tAverage Generator Loss: 101.231726\tAverage Discriminator Loss: 0.024586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #257 (step 257): 1.308382\n",
      "Batch #10\tAverage Generator Loss: 130.791785\tAverage Discriminator Loss: 0.021970\n",
      "\n",
      "Train time for epoch #258 (step 258): 1.543749\n",
      "Batch #10\tAverage Generator Loss: 115.742498\tAverage Discriminator Loss: 0.013297\n",
      "\n",
      "Train time for epoch #259 (step 259): 1.534768\n",
      "Batch #10\tAverage Generator Loss: 116.794262\tAverage Discriminator Loss: 0.044320\n",
      "\n",
      "Train time for epoch #260 (step 260): 1.393329\n",
      "Batch #10\tAverage Generator Loss: 138.601792\tAverage Discriminator Loss: 0.003807\n",
      "\n",
      "Train time for epoch #261 (step 261): 1.360785\n",
      "Batch #10\tAverage Generator Loss: 101.711391\tAverage Discriminator Loss: 0.011479\n",
      "\n",
      "Train time for epoch #262 (step 262): 1.348392\n",
      "Batch #10\tAverage Generator Loss: 118.051826\tAverage Discriminator Loss: 0.007049\n",
      "\n",
      "Train time for epoch #263 (step 263): 1.432537\n",
      "Batch #10\tAverage Generator Loss: 117.328975\tAverage Discriminator Loss: 0.001182\n",
      "\n",
      "Train time for epoch #264 (step 264): 1.400729\n",
      "Batch #10\tAverage Generator Loss: 117.226006\tAverage Discriminator Loss: 0.009268\n",
      "\n",
      "Train time for epoch #265 (step 265): 1.407798\n",
      "Batch #10\tAverage Generator Loss: 108.731033\tAverage Discriminator Loss: 0.002154\n",
      "\n",
      "Train time for epoch #266 (step 266): 1.342430\n",
      "Batch #10\tAverage Generator Loss: 159.548267\tAverage Discriminator Loss: 0.001196\n",
      "\n",
      "Train time for epoch #267 (step 267): 1.345603\n",
      "Batch #10\tAverage Generator Loss: 130.691591\tAverage Discriminator Loss: 0.005498\n",
      "\n",
      "Train time for epoch #268 (step 268): 1.347698\n",
      "Batch #10\tAverage Generator Loss: 123.422002\tAverage Discriminator Loss: 0.012965\n",
      "\n",
      "Train time for epoch #269 (step 269): 1.373448\n",
      "Batch #10\tAverage Generator Loss: 131.747958\tAverage Discriminator Loss: 0.010126\n",
      "\n",
      "Train time for epoch #270 (step 270): 1.375064\n",
      "Batch #10\tAverage Generator Loss: 137.957005\tAverage Discriminator Loss: 0.001177\n",
      "\n",
      "Train time for epoch #271 (step 271): 1.481995\n",
      "Batch #10\tAverage Generator Loss: 129.400880\tAverage Discriminator Loss: 0.000576\n",
      "\n",
      "Train time for epoch #272 (step 272): 1.395429\n",
      "Batch #10\tAverage Generator Loss: 119.378403\tAverage Discriminator Loss: 0.012977\n",
      "\n",
      "Train time for epoch #273 (step 273): 1.427929\n",
      "Batch #10\tAverage Generator Loss: 130.191443\tAverage Discriminator Loss: 0.008481\n",
      "\n",
      "Train time for epoch #274 (step 274): 1.489897\n",
      "Batch #10\tAverage Generator Loss: 123.125274\tAverage Discriminator Loss: 0.001381\n",
      "\n",
      "Train time for epoch #275 (step 275): 1.529152\n",
      "Batch #10\tAverage Generator Loss: 122.877128\tAverage Discriminator Loss: 0.002020\n",
      "\n",
      "Train time for epoch #276 (step 276): 1.441032\n",
      "Batch #10\tAverage Generator Loss: 132.063305\tAverage Discriminator Loss: 0.000616\n",
      "\n",
      "Train time for epoch #277 (step 277): 1.507247\n",
      "Batch #10\tAverage Generator Loss: 125.675418\tAverage Discriminator Loss: 0.010708\n",
      "\n",
      "Train time for epoch #278 (step 278): 1.448659\n",
      "Batch #10\tAverage Generator Loss: 136.034648\tAverage Discriminator Loss: 0.000527\n",
      "\n",
      "Train time for epoch #279 (step 279): 1.366277\n",
      "Batch #10\tAverage Generator Loss: 107.227971\tAverage Discriminator Loss: 0.096558\n",
      "\n",
      "Train time for epoch #280 (step 280): 1.507918\n",
      "Batch #10\tAverage Generator Loss: 121.506828\tAverage Discriminator Loss: 0.098949\n",
      "\n",
      "Train time for epoch #281 (step 281): 1.366854\n",
      "Batch #10\tAverage Generator Loss: 112.467334\tAverage Discriminator Loss: 0.094560\n",
      "\n",
      "Train time for epoch #282 (step 282): 1.482503\n",
      "Batch #10\tAverage Generator Loss: 126.951616\tAverage Discriminator Loss: 0.048689\n",
      "\n",
      "Train time for epoch #283 (step 283): 1.383101\n",
      "Batch #10\tAverage Generator Loss: 143.115337\tAverage Discriminator Loss: 0.005340\n",
      "\n",
      "Train time for epoch #284 (step 284): 1.537189\n",
      "Batch #10\tAverage Generator Loss: 150.895708\tAverage Discriminator Loss: 0.003990\n",
      "\n",
      "Train time for epoch #285 (step 285): 1.334912\n",
      "Batch #10\tAverage Generator Loss: 140.318691\tAverage Discriminator Loss: 0.044539\n",
      "\n",
      "Train time for epoch #286 (step 286): 1.472443\n",
      "Batch #10\tAverage Generator Loss: 119.712730\tAverage Discriminator Loss: 0.011394\n",
      "\n",
      "Train time for epoch #287 (step 287): 1.415967\n",
      "Batch #10\tAverage Generator Loss: 136.782478\tAverage Discriminator Loss: 0.004829\n",
      "\n",
      "Train time for epoch #288 (step 288): 1.405852\n",
      "Batch #10\tAverage Generator Loss: 128.644440\tAverage Discriminator Loss: 0.004637\n",
      "\n",
      "Train time for epoch #289 (step 289): 1.342068\n",
      "Batch #10\tAverage Generator Loss: 149.721980\tAverage Discriminator Loss: 0.004247\n",
      "\n",
      "Train time for epoch #290 (step 290): 1.467293\n",
      "Batch #10\tAverage Generator Loss: 138.612305\tAverage Discriminator Loss: 0.001888\n",
      "\n",
      "Train time for epoch #291 (step 291): 1.357758\n",
      "Batch #10\tAverage Generator Loss: 125.231001\tAverage Discriminator Loss: 0.114792\n",
      "\n",
      "Train time for epoch #292 (step 292): 1.459287\n",
      "Batch #10\tAverage Generator Loss: 120.242064\tAverage Discriminator Loss: 0.011886\n",
      "\n",
      "Train time for epoch #293 (step 293): 1.451692\n",
      "Batch #10\tAverage Generator Loss: 121.318841\tAverage Discriminator Loss: 0.056675\n",
      "\n",
      "Train time for epoch #294 (step 294): 1.497129\n",
      "Batch #10\tAverage Generator Loss: 111.940486\tAverage Discriminator Loss: 0.004756\n",
      "\n",
      "Train time for epoch #295 (step 295): 1.427975\n",
      "Batch #10\tAverage Generator Loss: 128.416401\tAverage Discriminator Loss: 0.001973\n",
      "\n",
      "Train time for epoch #296 (step 296): 1.431829\n",
      "Batch #10\tAverage Generator Loss: 111.228778\tAverage Discriminator Loss: 0.001375\n",
      "\n",
      "Train time for epoch #297 (step 297): 1.437913\n",
      "Batch #10\tAverage Generator Loss: 115.418251\tAverage Discriminator Loss: 0.013347\n",
      "\n",
      "Train time for epoch #298 (step 298): 1.391863\n",
      "Batch #10\tAverage Generator Loss: 119.543793\tAverage Discriminator Loss: 0.023087\n",
      "\n",
      "Train time for epoch #299 (step 299): 1.518227\n",
      "Batch #10\tAverage Generator Loss: 124.643611\tAverage Discriminator Loss: 0.006520\n",
      "\n",
      "Train time for epoch #300 (step 300): 1.394785\n",
      "Batch #10\tAverage Generator Loss: 137.638285\tAverage Discriminator Loss: 0.005141\n",
      "\n",
      "Train time for epoch #301 (step 301): 1.418377\n",
      "Batch #10\tAverage Generator Loss: 122.465135\tAverage Discriminator Loss: 0.003040\n",
      "\n",
      "Train time for epoch #302 (step 302): 1.302191\n",
      "Batch #10\tAverage Generator Loss: 133.018383\tAverage Discriminator Loss: 0.001588\n",
      "\n",
      "Train time for epoch #303 (step 303): 1.405866\n",
      "Batch #10\tAverage Generator Loss: 143.510070\tAverage Discriminator Loss: 0.001120\n",
      "\n",
      "Train time for epoch #304 (step 304): 1.457136\n",
      "Batch #10\tAverage Generator Loss: 130.466428\tAverage Discriminator Loss: 0.004367\n",
      "\n",
      "Train time for epoch #305 (step 305): 1.342038\n",
      "Batch #10\tAverage Generator Loss: 154.228711\tAverage Discriminator Loss: 0.001598\n",
      "\n",
      "Train time for epoch #306 (step 306): 1.383904\n",
      "Batch #10\tAverage Generator Loss: 127.648161\tAverage Discriminator Loss: 0.003286\n",
      "\n",
      "Train time for epoch #307 (step 307): 1.306289\n",
      "Batch #10\tAverage Generator Loss: 156.041460\tAverage Discriminator Loss: 0.043344\n",
      "\n",
      "Train time for epoch #308 (step 308): 1.393272\n",
      "Batch #10\tAverage Generator Loss: 157.296928\tAverage Discriminator Loss: 0.013253\n",
      "\n",
      "Train time for epoch #309 (step 309): 1.450565\n",
      "Batch #10\tAverage Generator Loss: 153.328347\tAverage Discriminator Loss: 0.001516\n",
      "\n",
      "Train time for epoch #310 (step 310): 1.425780\n",
      "Batch #10\tAverage Generator Loss: 147.366695\tAverage Discriminator Loss: 0.019201\n",
      "\n",
      "Train time for epoch #311 (step 311): 1.444427\n",
      "Batch #10\tAverage Generator Loss: 145.257405\tAverage Discriminator Loss: 0.002358\n",
      "\n",
      "Train time for epoch #312 (step 312): 1.423496\n",
      "Batch #10\tAverage Generator Loss: 138.707922\tAverage Discriminator Loss: 0.002835\n",
      "\n",
      "Train time for epoch #313 (step 313): 1.506214\n",
      "Batch #10\tAverage Generator Loss: 132.239310\tAverage Discriminator Loss: 0.001076\n",
      "\n",
      "Train time for epoch #314 (step 314): 1.476065\n",
      "Batch #10\tAverage Generator Loss: 128.459264\tAverage Discriminator Loss: 0.002370\n",
      "\n",
      "Train time for epoch #315 (step 315): 1.465042\n",
      "Batch #10\tAverage Generator Loss: 144.210889\tAverage Discriminator Loss: 0.001265\n",
      "\n",
      "Train time for epoch #316 (step 316): 1.354558\n",
      "Batch #10\tAverage Generator Loss: 152.951292\tAverage Discriminator Loss: 0.001159\n",
      "\n",
      "Train time for epoch #317 (step 317): 1.407715\n",
      "Batch #10\tAverage Generator Loss: 145.244851\tAverage Discriminator Loss: 0.036986\n",
      "\n",
      "Train time for epoch #318 (step 318): 1.517434\n",
      "Batch #10\tAverage Generator Loss: 139.131407\tAverage Discriminator Loss: 0.030398\n",
      "\n",
      "Train time for epoch #319 (step 319): 1.405056\n",
      "Batch #10\tAverage Generator Loss: 131.976774\tAverage Discriminator Loss: 0.001248\n",
      "\n",
      "Train time for epoch #320 (step 320): 1.367573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 130.937373\tAverage Discriminator Loss: 0.002435\n",
      "\n",
      "Train time for epoch #321 (step 321): 1.316062\n",
      "Batch #10\tAverage Generator Loss: 134.729460\tAverage Discriminator Loss: 0.000539\n",
      "\n",
      "Train time for epoch #322 (step 322): 1.529064\n",
      "Batch #10\tAverage Generator Loss: 150.342322\tAverage Discriminator Loss: 0.000304\n",
      "\n",
      "Train time for epoch #323 (step 323): 1.340029\n",
      "Batch #10\tAverage Generator Loss: 160.932410\tAverage Discriminator Loss: 0.003824\n",
      "\n",
      "Train time for epoch #324 (step 324): 1.401284\n",
      "Batch #10\tAverage Generator Loss: 140.342084\tAverage Discriminator Loss: 0.003643\n",
      "\n",
      "Train time for epoch #325 (step 325): 1.436667\n",
      "Batch #10\tAverage Generator Loss: 141.929371\tAverage Discriminator Loss: 0.072354\n",
      "\n",
      "Train time for epoch #326 (step 326): 1.416584\n",
      "Batch #10\tAverage Generator Loss: 122.064178\tAverage Discriminator Loss: 0.029017\n",
      "\n",
      "Train time for epoch #327 (step 327): 1.372137\n",
      "Batch #10\tAverage Generator Loss: 147.549822\tAverage Discriminator Loss: 0.013394\n",
      "\n",
      "Train time for epoch #328 (step 328): 1.350114\n",
      "Batch #10\tAverage Generator Loss: 107.464757\tAverage Discriminator Loss: 0.006192\n",
      "\n",
      "Train time for epoch #329 (step 329): 1.391827\n",
      "Batch #10\tAverage Generator Loss: 126.563142\tAverage Discriminator Loss: 0.005764\n",
      "\n",
      "Train time for epoch #330 (step 330): 1.448152\n",
      "Batch #10\tAverage Generator Loss: 148.201822\tAverage Discriminator Loss: 0.001392\n",
      "\n",
      "Train time for epoch #331 (step 331): 1.416414\n",
      "Batch #10\tAverage Generator Loss: 158.003619\tAverage Discriminator Loss: 0.002079\n",
      "\n",
      "Train time for epoch #332 (step 332): 1.465917\n",
      "Batch #10\tAverage Generator Loss: 172.159679\tAverage Discriminator Loss: 0.001034\n",
      "\n",
      "Train time for epoch #333 (step 333): 1.314808\n",
      "Batch #10\tAverage Generator Loss: 151.597951\tAverage Discriminator Loss: 0.002576\n",
      "\n",
      "Train time for epoch #334 (step 334): 1.456263\n",
      "Batch #10\tAverage Generator Loss: 152.558107\tAverage Discriminator Loss: 0.002332\n",
      "\n",
      "Train time for epoch #335 (step 335): 1.403544\n",
      "Batch #10\tAverage Generator Loss: 137.851309\tAverage Discriminator Loss: 0.001015\n",
      "\n",
      "Train time for epoch #336 (step 336): 1.400476\n",
      "Batch #10\tAverage Generator Loss: 163.251427\tAverage Discriminator Loss: 0.000862\n",
      "\n",
      "Train time for epoch #337 (step 337): 1.457713\n",
      "Batch #10\tAverage Generator Loss: 146.911494\tAverage Discriminator Loss: 0.000667\n",
      "\n",
      "Train time for epoch #338 (step 338): 1.352596\n",
      "Batch #10\tAverage Generator Loss: 129.163578\tAverage Discriminator Loss: 0.002576\n",
      "\n",
      "Train time for epoch #339 (step 339): 1.442008\n",
      "Batch #10\tAverage Generator Loss: 155.477189\tAverage Discriminator Loss: 0.000803\n",
      "\n",
      "Train time for epoch #340 (step 340): 1.416235\n",
      "Batch #10\tAverage Generator Loss: 170.419784\tAverage Discriminator Loss: 0.000656\n",
      "\n",
      "Train time for epoch #341 (step 341): 1.345879\n",
      "Batch #10\tAverage Generator Loss: 157.058923\tAverage Discriminator Loss: 0.001329\n",
      "\n",
      "Train time for epoch #342 (step 342): 1.311355\n",
      "Batch #10\tAverage Generator Loss: 176.921207\tAverage Discriminator Loss: 0.000650\n",
      "\n",
      "Train time for epoch #343 (step 343): 1.434362\n",
      "Batch #10\tAverage Generator Loss: 151.567260\tAverage Discriminator Loss: 0.000763\n",
      "\n",
      "Train time for epoch #344 (step 344): 1.384619\n",
      "Batch #10\tAverage Generator Loss: 176.291267\tAverage Discriminator Loss: 0.000375\n",
      "\n",
      "Train time for epoch #345 (step 345): 1.419539\n",
      "Batch #10\tAverage Generator Loss: 164.059232\tAverage Discriminator Loss: 0.000322\n",
      "\n",
      "Train time for epoch #346 (step 346): 1.354363\n",
      "Batch #10\tAverage Generator Loss: 169.006064\tAverage Discriminator Loss: 0.006661\n",
      "\n",
      "Train time for epoch #347 (step 347): 1.346750\n",
      "Batch #10\tAverage Generator Loss: 143.288542\tAverage Discriminator Loss: 0.001782\n",
      "\n",
      "Train time for epoch #348 (step 348): 1.399602\n",
      "Batch #10\tAverage Generator Loss: 188.782889\tAverage Discriminator Loss: 0.001240\n",
      "\n",
      "Train time for epoch #349 (step 349): 1.561639\n",
      "Batch #10\tAverage Generator Loss: 146.045145\tAverage Discriminator Loss: 0.000687\n",
      "\n",
      "Train time for epoch #350 (step 350): 1.403114\n",
      "Batch #10\tAverage Generator Loss: 168.853733\tAverage Discriminator Loss: 0.001172\n",
      "\n",
      "Train time for epoch #351 (step 351): 1.414452\n",
      "Batch #10\tAverage Generator Loss: 163.745739\tAverage Discriminator Loss: 0.000492\n",
      "\n",
      "Train time for epoch #352 (step 352): 1.439548\n",
      "Batch #10\tAverage Generator Loss: 167.150688\tAverage Discriminator Loss: 0.000361\n",
      "\n",
      "Train time for epoch #353 (step 353): 1.452091\n",
      "Batch #10\tAverage Generator Loss: 179.197368\tAverage Discriminator Loss: 0.000575\n",
      "\n",
      "Train time for epoch #354 (step 354): 1.458827\n",
      "Batch #10\tAverage Generator Loss: 167.685950\tAverage Discriminator Loss: 0.000562\n",
      "\n",
      "Train time for epoch #355 (step 355): 1.364948\n",
      "Batch #10\tAverage Generator Loss: 160.939362\tAverage Discriminator Loss: 0.000633\n",
      "\n",
      "Train time for epoch #356 (step 356): 1.457518\n",
      "Batch #10\tAverage Generator Loss: 171.232567\tAverage Discriminator Loss: 0.000298\n",
      "\n",
      "Train time for epoch #357 (step 357): 1.477998\n",
      "Batch #10\tAverage Generator Loss: 157.887558\tAverage Discriminator Loss: 0.001870\n",
      "\n",
      "Train time for epoch #358 (step 358): 1.383218\n",
      "Batch #10\tAverage Generator Loss: 147.183719\tAverage Discriminator Loss: 0.000957\n",
      "\n",
      "Train time for epoch #359 (step 359): 1.375962\n",
      "Batch #10\tAverage Generator Loss: 142.983442\tAverage Discriminator Loss: 0.153723\n",
      "\n",
      "Train time for epoch #360 (step 360): 1.488876\n",
      "Batch #10\tAverage Generator Loss: 159.601694\tAverage Discriminator Loss: 0.060921\n",
      "\n",
      "Train time for epoch #361 (step 361): 1.558949\n",
      "Batch #10\tAverage Generator Loss: 153.633670\tAverage Discriminator Loss: 0.009390\n",
      "\n",
      "Train time for epoch #362 (step 362): 1.311120\n",
      "Batch #10\tAverage Generator Loss: 149.048534\tAverage Discriminator Loss: 0.055733\n",
      "\n",
      "Train time for epoch #363 (step 363): 1.353405\n",
      "Batch #10\tAverage Generator Loss: 156.719437\tAverage Discriminator Loss: 0.003356\n",
      "\n",
      "Train time for epoch #364 (step 364): 1.364782\n",
      "Batch #10\tAverage Generator Loss: 147.787228\tAverage Discriminator Loss: 0.004289\n",
      "\n",
      "Train time for epoch #365 (step 365): 1.516777\n",
      "Batch #10\tAverage Generator Loss: 137.071366\tAverage Discriminator Loss: 0.001153\n",
      "\n",
      "Train time for epoch #366 (step 366): 1.359460\n",
      "Batch #10\tAverage Generator Loss: 175.619373\tAverage Discriminator Loss: 0.000517\n",
      "\n",
      "Train time for epoch #367 (step 367): 1.495378\n",
      "Batch #10\tAverage Generator Loss: 150.675956\tAverage Discriminator Loss: 0.000473\n",
      "\n",
      "Train time for epoch #368 (step 368): 1.494156\n",
      "Batch #10\tAverage Generator Loss: 158.243420\tAverage Discriminator Loss: 0.007578\n",
      "\n",
      "Train time for epoch #369 (step 369): 1.464768\n",
      "Batch #10\tAverage Generator Loss: 166.043414\tAverage Discriminator Loss: 0.001495\n",
      "\n",
      "Train time for epoch #370 (step 370): 1.347241\n",
      "Batch #10\tAverage Generator Loss: 211.769522\tAverage Discriminator Loss: 0.000619\n",
      "\n",
      "Train time for epoch #371 (step 371): 1.433044\n",
      "Batch #10\tAverage Generator Loss: 190.363927\tAverage Discriminator Loss: 0.033610\n",
      "\n",
      "Train time for epoch #372 (step 372): 1.460917\n",
      "Batch #10\tAverage Generator Loss: 174.560109\tAverage Discriminator Loss: 0.032093\n",
      "\n",
      "Train time for epoch #373 (step 373): 1.467676\n",
      "Batch #10\tAverage Generator Loss: 205.842667\tAverage Discriminator Loss: 0.001517\n",
      "\n",
      "Train time for epoch #374 (step 374): 1.558854\n",
      "Batch #10\tAverage Generator Loss: 166.340767\tAverage Discriminator Loss: 0.000717\n",
      "\n",
      "Train time for epoch #375 (step 375): 1.386793\n",
      "Batch #10\tAverage Generator Loss: 208.287899\tAverage Discriminator Loss: 0.032317\n",
      "\n",
      "Train time for epoch #376 (step 376): 1.400422\n",
      "Batch #10\tAverage Generator Loss: 190.123847\tAverage Discriminator Loss: 0.001989\n",
      "\n",
      "Train time for epoch #377 (step 377): 1.450752\n",
      "Batch #10\tAverage Generator Loss: 239.057347\tAverage Discriminator Loss: 0.003063\n",
      "\n",
      "Train time for epoch #378 (step 378): 1.483952\n",
      "Batch #10\tAverage Generator Loss: 219.910706\tAverage Discriminator Loss: 0.000722\n",
      "\n",
      "Train time for epoch #379 (step 379): 1.434377\n",
      "Batch #10\tAverage Generator Loss: 200.209611\tAverage Discriminator Loss: 0.174514\n",
      "\n",
      "Train time for epoch #380 (step 380): 1.408493\n",
      "Batch #10\tAverage Generator Loss: 186.325314\tAverage Discriminator Loss: 0.000365\n",
      "\n",
      "Train time for epoch #381 (step 381): 1.377843\n",
      "Batch #10\tAverage Generator Loss: 194.817506\tAverage Discriminator Loss: 0.175900\n",
      "\n",
      "Train time for epoch #382 (step 382): 1.481823\n",
      "Batch #10\tAverage Generator Loss: 196.408670\tAverage Discriminator Loss: 0.028456\n",
      "\n",
      "Train time for epoch #383 (step 383): 1.404135\n",
      "Batch #10\tAverage Generator Loss: 193.841546\tAverage Discriminator Loss: 0.012565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #384 (step 384): 1.583540\n",
      "Batch #10\tAverage Generator Loss: 180.837383\tAverage Discriminator Loss: 0.018019\n",
      "\n",
      "Train time for epoch #385 (step 385): 1.390132\n",
      "Batch #10\tAverage Generator Loss: 203.281965\tAverage Discriminator Loss: 0.004532\n",
      "\n",
      "Train time for epoch #386 (step 386): 1.425405\n",
      "Batch #10\tAverage Generator Loss: 206.527650\tAverage Discriminator Loss: 0.001045\n",
      "\n",
      "Train time for epoch #387 (step 387): 1.535869\n",
      "Batch #10\tAverage Generator Loss: 198.787033\tAverage Discriminator Loss: 0.000592\n",
      "\n",
      "Train time for epoch #388 (step 388): 1.407684\n",
      "Batch #10\tAverage Generator Loss: 176.039732\tAverage Discriminator Loss: 0.000404\n",
      "\n",
      "Train time for epoch #389 (step 389): 1.430062\n",
      "Batch #10\tAverage Generator Loss: 191.652693\tAverage Discriminator Loss: 0.000383\n",
      "\n",
      "Train time for epoch #390 (step 390): 1.487530\n",
      "Batch #10\tAverage Generator Loss: 184.259888\tAverage Discriminator Loss: 0.001126\n",
      "\n",
      "Train time for epoch #391 (step 391): 1.503994\n",
      "Batch #10\tAverage Generator Loss: 184.495241\tAverage Discriminator Loss: 0.051143\n",
      "\n",
      "Train time for epoch #392 (step 392): 1.411905\n",
      "Batch #10\tAverage Generator Loss: 151.905793\tAverage Discriminator Loss: 0.083786\n",
      "\n",
      "Train time for epoch #393 (step 393): 1.453012\n",
      "Batch #10\tAverage Generator Loss: 120.199861\tAverage Discriminator Loss: 0.074818\n",
      "\n",
      "Train time for epoch #394 (step 394): 1.346627\n",
      "Batch #10\tAverage Generator Loss: 108.413020\tAverage Discriminator Loss: 0.074864\n",
      "\n",
      "Train time for epoch #395 (step 395): 1.664314\n",
      "Batch #10\tAverage Generator Loss: 153.554575\tAverage Discriminator Loss: 0.091492\n",
      "\n",
      "Train time for epoch #396 (step 396): 1.490915\n",
      "Batch #10\tAverage Generator Loss: 116.050091\tAverage Discriminator Loss: 0.013656\n",
      "\n",
      "Train time for epoch #397 (step 397): 1.308547\n",
      "Batch #10\tAverage Generator Loss: 123.445294\tAverage Discriminator Loss: 0.006739\n",
      "\n",
      "Train time for epoch #398 (step 398): 1.460479\n",
      "Batch #10\tAverage Generator Loss: 112.357482\tAverage Discriminator Loss: 0.003527\n",
      "\n",
      "Train time for epoch #399 (step 399): 1.360729\n",
      "Batch #10\tAverage Generator Loss: 122.025806\tAverage Discriminator Loss: 0.003441\n",
      "\n",
      "Train time for epoch #400 (step 400): 1.404581\n",
      "Batch #10\tAverage Generator Loss: 118.824522\tAverage Discriminator Loss: 0.001827\n",
      "\n",
      "Train time for epoch #401 (step 401): 1.515090\n",
      "Batch #10\tAverage Generator Loss: 137.983799\tAverage Discriminator Loss: 0.047771\n",
      "\n",
      "Train time for epoch #402 (step 402): 1.526972\n",
      "Batch #10\tAverage Generator Loss: 147.476758\tAverage Discriminator Loss: 0.007081\n",
      "\n",
      "Train time for epoch #403 (step 403): 1.337855\n",
      "Batch #10\tAverage Generator Loss: 146.885724\tAverage Discriminator Loss: 0.005204\n",
      "\n",
      "Train time for epoch #404 (step 404): 1.424661\n",
      "Batch #10\tAverage Generator Loss: 146.014914\tAverage Discriminator Loss: 0.004987\n",
      "\n",
      "Train time for epoch #405 (step 405): 1.421535\n",
      "Batch #10\tAverage Generator Loss: 146.633721\tAverage Discriminator Loss: 0.002334\n",
      "\n",
      "Train time for epoch #406 (step 406): 1.407686\n",
      "Batch #10\tAverage Generator Loss: 146.210905\tAverage Discriminator Loss: 0.005830\n",
      "\n",
      "Train time for epoch #407 (step 407): 1.503411\n",
      "Batch #10\tAverage Generator Loss: 148.722668\tAverage Discriminator Loss: 0.040041\n",
      "\n",
      "Train time for epoch #408 (step 408): 1.346614\n",
      "Batch #10\tAverage Generator Loss: 122.758241\tAverage Discriminator Loss: 0.071174\n",
      "\n",
      "Train time for epoch #409 (step 409): 1.452121\n",
      "Batch #10\tAverage Generator Loss: 119.454589\tAverage Discriminator Loss: 0.029824\n",
      "\n",
      "Train time for epoch #410 (step 410): 1.608089\n",
      "Batch #10\tAverage Generator Loss: 147.164625\tAverage Discriminator Loss: 0.048648\n",
      "\n",
      "Train time for epoch #411 (step 411): 1.352854\n",
      "Batch #10\tAverage Generator Loss: 134.050993\tAverage Discriminator Loss: 0.006763\n",
      "\n",
      "Train time for epoch #412 (step 412): 1.414237\n",
      "Batch #10\tAverage Generator Loss: 141.720581\tAverage Discriminator Loss: 0.044073\n",
      "\n",
      "Train time for epoch #413 (step 413): 1.470048\n",
      "Batch #10\tAverage Generator Loss: 139.105046\tAverage Discriminator Loss: 0.010591\n",
      "\n",
      "Train time for epoch #414 (step 414): 1.377267\n",
      "Batch #10\tAverage Generator Loss: 122.178425\tAverage Discriminator Loss: 0.007770\n",
      "\n",
      "Train time for epoch #415 (step 415): 1.544034\n",
      "Batch #10\tAverage Generator Loss: 135.658402\tAverage Discriminator Loss: 0.004013\n",
      "\n",
      "Train time for epoch #416 (step 416): 1.446105\n",
      "Batch #10\tAverage Generator Loss: 123.814417\tAverage Discriminator Loss: 0.008118\n",
      "\n",
      "Train time for epoch #417 (step 417): 1.392802\n",
      "Batch #10\tAverage Generator Loss: 147.603719\tAverage Discriminator Loss: 0.003737\n",
      "\n",
      "Train time for epoch #418 (step 418): 1.350870\n",
      "Batch #10\tAverage Generator Loss: 152.471019\tAverage Discriminator Loss: 0.017400\n",
      "\n",
      "Train time for epoch #419 (step 419): 1.458125\n",
      "Batch #10\tAverage Generator Loss: 187.106515\tAverage Discriminator Loss: 0.005558\n",
      "\n",
      "Train time for epoch #420 (step 420): 1.355667\n",
      "Batch #10\tAverage Generator Loss: 129.456688\tAverage Discriminator Loss: 0.011860\n",
      "\n",
      "Train time for epoch #421 (step 421): 1.306665\n",
      "Batch #10\tAverage Generator Loss: 158.659595\tAverage Discriminator Loss: 0.005278\n",
      "\n",
      "Train time for epoch #422 (step 422): 1.311412\n",
      "Batch #10\tAverage Generator Loss: 159.726751\tAverage Discriminator Loss: 0.001534\n",
      "\n",
      "Train time for epoch #423 (step 423): 1.352354\n",
      "Batch #10\tAverage Generator Loss: 167.121372\tAverage Discriminator Loss: 0.000899\n",
      "\n",
      "Train time for epoch #424 (step 424): 1.477471\n",
      "Batch #10\tAverage Generator Loss: 163.083710\tAverage Discriminator Loss: 0.014703\n",
      "\n",
      "Train time for epoch #425 (step 425): 1.432329\n",
      "Batch #10\tAverage Generator Loss: 164.171832\tAverage Discriminator Loss: 0.022770\n",
      "\n",
      "Train time for epoch #426 (step 426): 1.340338\n",
      "Batch #10\tAverage Generator Loss: 148.189156\tAverage Discriminator Loss: 0.001356\n",
      "\n",
      "Train time for epoch #427 (step 427): 1.404585\n",
      "Batch #10\tAverage Generator Loss: 168.728676\tAverage Discriminator Loss: 0.012554\n",
      "\n",
      "Train time for epoch #428 (step 428): 1.402660\n",
      "Batch #10\tAverage Generator Loss: 149.183784\tAverage Discriminator Loss: 0.011096\n",
      "\n",
      "Train time for epoch #429 (step 429): 1.533829\n",
      "Batch #10\tAverage Generator Loss: 151.213151\tAverage Discriminator Loss: 0.000731\n",
      "\n",
      "Train time for epoch #430 (step 430): 1.355705\n",
      "Batch #10\tAverage Generator Loss: 144.931666\tAverage Discriminator Loss: 0.006267\n",
      "\n",
      "Train time for epoch #431 (step 431): 1.355056\n",
      "Batch #10\tAverage Generator Loss: 131.334284\tAverage Discriminator Loss: 0.001161\n",
      "\n",
      "Train time for epoch #432 (step 432): 1.351938\n",
      "Batch #10\tAverage Generator Loss: 180.298118\tAverage Discriminator Loss: 0.000723\n",
      "\n",
      "Train time for epoch #433 (step 433): 1.429076\n",
      "Batch #10\tAverage Generator Loss: 162.314421\tAverage Discriminator Loss: 0.000635\n",
      "\n",
      "Train time for epoch #434 (step 434): 1.355950\n",
      "Batch #10\tAverage Generator Loss: 147.281136\tAverage Discriminator Loss: 0.000552\n",
      "\n",
      "Train time for epoch #435 (step 435): 1.406141\n",
      "Batch #10\tAverage Generator Loss: 185.577295\tAverage Discriminator Loss: 0.037199\n",
      "\n",
      "Train time for epoch #436 (step 436): 1.466467\n",
      "Batch #10\tAverage Generator Loss: 166.006934\tAverage Discriminator Loss: 0.003189\n",
      "\n",
      "Train time for epoch #437 (step 437): 1.450689\n",
      "Batch #10\tAverage Generator Loss: 144.425447\tAverage Discriminator Loss: 0.001693\n",
      "\n",
      "Train time for epoch #438 (step 438): 1.371278\n",
      "Batch #10\tAverage Generator Loss: 133.033356\tAverage Discriminator Loss: 0.014138\n",
      "\n",
      "Train time for epoch #439 (step 439): 1.539121\n",
      "Batch #10\tAverage Generator Loss: 154.484002\tAverage Discriminator Loss: 0.004715\n",
      "\n",
      "Train time for epoch #440 (step 440): 1.401512\n",
      "Batch #10\tAverage Generator Loss: 147.062722\tAverage Discriminator Loss: 0.001707\n",
      "\n",
      "Train time for epoch #441 (step 441): 1.452977\n",
      "Batch #10\tAverage Generator Loss: 151.056687\tAverage Discriminator Loss: 0.096244\n",
      "\n",
      "Train time for epoch #442 (step 442): 1.444174\n",
      "Batch #10\tAverage Generator Loss: 138.658963\tAverage Discriminator Loss: 0.014147\n",
      "\n",
      "Train time for epoch #443 (step 443): 1.485095\n",
      "Batch #10\tAverage Generator Loss: 174.849641\tAverage Discriminator Loss: 0.006818\n",
      "\n",
      "Train time for epoch #444 (step 444): 1.401248\n",
      "Batch #10\tAverage Generator Loss: 164.236876\tAverage Discriminator Loss: 0.005613\n",
      "\n",
      "Train time for epoch #445 (step 445): 1.384705\n",
      "Batch #10\tAverage Generator Loss: 172.385003\tAverage Discriminator Loss: 0.001993\n",
      "\n",
      "Train time for epoch #446 (step 446): 1.442012\n",
      "Batch #10\tAverage Generator Loss: 153.944340\tAverage Discriminator Loss: 0.001466\n",
      "\n",
      "Train time for epoch #447 (step 447): 1.407627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 158.821402\tAverage Discriminator Loss: 0.001062\n",
      "\n",
      "Train time for epoch #448 (step 448): 1.461548\n",
      "Batch #10\tAverage Generator Loss: 175.572947\tAverage Discriminator Loss: 0.000918\n",
      "\n",
      "Train time for epoch #449 (step 449): 1.408326\n",
      "Batch #10\tAverage Generator Loss: 158.441399\tAverage Discriminator Loss: 0.001090\n",
      "\n",
      "Train time for epoch #450 (step 450): 1.408327\n",
      "Batch #10\tAverage Generator Loss: 164.054304\tAverage Discriminator Loss: 0.018200\n",
      "\n",
      "Train time for epoch #451 (step 451): 1.439480\n",
      "Batch #10\tAverage Generator Loss: 174.357970\tAverage Discriminator Loss: 0.002384\n",
      "\n",
      "Train time for epoch #452 (step 452): 1.514456\n",
      "Batch #10\tAverage Generator Loss: 201.709180\tAverage Discriminator Loss: 0.001531\n",
      "\n",
      "Train time for epoch #453 (step 453): 1.415065\n",
      "Batch #10\tAverage Generator Loss: 171.154987\tAverage Discriminator Loss: 0.002090\n",
      "\n",
      "Train time for epoch #454 (step 454): 1.499106\n",
      "Batch #10\tAverage Generator Loss: 164.081709\tAverage Discriminator Loss: 0.001134\n",
      "\n",
      "Train time for epoch #455 (step 455): 1.447337\n",
      "Batch #10\tAverage Generator Loss: 172.697348\tAverage Discriminator Loss: 0.003416\n",
      "\n",
      "Train time for epoch #456 (step 456): 1.377684\n",
      "Batch #10\tAverage Generator Loss: 177.882426\tAverage Discriminator Loss: 0.017251\n",
      "\n",
      "Train time for epoch #457 (step 457): 1.393164\n",
      "Batch #10\tAverage Generator Loss: 208.450742\tAverage Discriminator Loss: 0.002917\n",
      "\n",
      "Train time for epoch #458 (step 458): 1.480249\n",
      "Batch #10\tAverage Generator Loss: 176.805158\tAverage Discriminator Loss: 0.000378\n",
      "\n",
      "Train time for epoch #459 (step 459): 1.307765\n",
      "Batch #10\tAverage Generator Loss: 185.129060\tAverage Discriminator Loss: 0.003435\n",
      "\n",
      "Train time for epoch #460 (step 460): 1.407294\n",
      "Batch #10\tAverage Generator Loss: 171.529442\tAverage Discriminator Loss: 0.000350\n",
      "\n",
      "Train time for epoch #461 (step 461): 1.478404\n",
      "Batch #10\tAverage Generator Loss: 142.536853\tAverage Discriminator Loss: 0.008452\n",
      "\n",
      "Train time for epoch #462 (step 462): 1.469016\n",
      "Batch #10\tAverage Generator Loss: 184.705997\tAverage Discriminator Loss: 0.007928\n",
      "\n",
      "Train time for epoch #463 (step 463): 1.429292\n",
      "Batch #10\tAverage Generator Loss: 173.948330\tAverage Discriminator Loss: 0.000624\n",
      "\n",
      "Train time for epoch #464 (step 464): 1.393752\n",
      "Batch #10\tAverage Generator Loss: 165.235917\tAverage Discriminator Loss: 0.000737\n",
      "\n",
      "Train time for epoch #465 (step 465): 1.407959\n",
      "Batch #10\tAverage Generator Loss: 171.262960\tAverage Discriminator Loss: 0.028214\n",
      "\n",
      "Train time for epoch #466 (step 466): 1.360373\n",
      "Batch #10\tAverage Generator Loss: 156.713979\tAverage Discriminator Loss: 0.000243\n",
      "\n",
      "Train time for epoch #467 (step 467): 1.370078\n",
      "Batch #10\tAverage Generator Loss: 126.508555\tAverage Discriminator Loss: 0.010492\n",
      "\n",
      "Train time for epoch #468 (step 468): 1.431268\n",
      "Batch #10\tAverage Generator Loss: 157.019405\tAverage Discriminator Loss: 0.001027\n",
      "\n",
      "Train time for epoch #469 (step 469): 1.510746\n",
      "Batch #10\tAverage Generator Loss: 164.047421\tAverage Discriminator Loss: 0.002547\n",
      "\n",
      "Train time for epoch #470 (step 470): 1.467820\n",
      "Batch #10\tAverage Generator Loss: 182.036813\tAverage Discriminator Loss: 0.001190\n",
      "\n",
      "Train time for epoch #471 (step 471): 1.380361\n",
      "Batch #10\tAverage Generator Loss: 176.394065\tAverage Discriminator Loss: 0.001182\n",
      "\n",
      "Train time for epoch #472 (step 472): 1.420108\n",
      "Batch #10\tAverage Generator Loss: 159.782576\tAverage Discriminator Loss: 0.000801\n",
      "\n",
      "Train time for epoch #473 (step 473): 1.423598\n",
      "Batch #10\tAverage Generator Loss: 180.291537\tAverage Discriminator Loss: 0.000544\n",
      "\n",
      "Train time for epoch #474 (step 474): 1.439542\n",
      "Batch #10\tAverage Generator Loss: 173.389900\tAverage Discriminator Loss: 0.000492\n",
      "\n",
      "Train time for epoch #475 (step 475): 1.317179\n",
      "Batch #10\tAverage Generator Loss: 171.287818\tAverage Discriminator Loss: 0.000323\n",
      "\n",
      "Train time for epoch #476 (step 476): 1.425345\n",
      "Batch #10\tAverage Generator Loss: 185.518128\tAverage Discriminator Loss: 0.000306\n",
      "\n",
      "Train time for epoch #477 (step 477): 1.499264\n",
      "Batch #10\tAverage Generator Loss: 178.639637\tAverage Discriminator Loss: 0.000256\n",
      "\n",
      "Train time for epoch #478 (step 478): 1.417300\n",
      "Batch #10\tAverage Generator Loss: 182.493468\tAverage Discriminator Loss: 0.000229\n",
      "\n",
      "Train time for epoch #479 (step 479): 1.409186\n",
      "Batch #10\tAverage Generator Loss: 157.325031\tAverage Discriminator Loss: 0.000204\n",
      "\n",
      "Train time for epoch #480 (step 480): 1.441721\n",
      "Batch #10\tAverage Generator Loss: 162.423223\tAverage Discriminator Loss: 0.000181\n",
      "\n",
      "Train time for epoch #481 (step 481): 1.511817\n",
      "Batch #10\tAverage Generator Loss: 189.363091\tAverage Discriminator Loss: 0.000181\n",
      "\n",
      "Train time for epoch #482 (step 482): 1.365706\n",
      "Batch #10\tAverage Generator Loss: 183.661401\tAverage Discriminator Loss: 0.000173\n",
      "\n",
      "Train time for epoch #483 (step 483): 1.427348\n",
      "Batch #10\tAverage Generator Loss: 164.919707\tAverage Discriminator Loss: 0.000806\n",
      "\n",
      "Train time for epoch #484 (step 484): 1.451341\n",
      "Batch #10\tAverage Generator Loss: 187.754347\tAverage Discriminator Loss: 0.001557\n",
      "\n",
      "Train time for epoch #485 (step 485): 1.349568\n",
      "Batch #10\tAverage Generator Loss: 202.554179\tAverage Discriminator Loss: 0.000649\n",
      "\n",
      "Train time for epoch #486 (step 486): 1.374593\n",
      "Batch #10\tAverage Generator Loss: 197.442966\tAverage Discriminator Loss: 0.001936\n",
      "\n",
      "Train time for epoch #487 (step 487): 1.401895\n",
      "Batch #10\tAverage Generator Loss: 184.474390\tAverage Discriminator Loss: 0.000251\n",
      "\n",
      "Train time for epoch #488 (step 488): 1.471356\n",
      "Batch #10\tAverage Generator Loss: 190.529082\tAverage Discriminator Loss: 0.001351\n",
      "\n",
      "Train time for epoch #489 (step 489): 1.434090\n",
      "Batch #10\tAverage Generator Loss: 197.506824\tAverage Discriminator Loss: 0.005551\n",
      "\n",
      "Train time for epoch #490 (step 490): 1.399630\n",
      "Batch #10\tAverage Generator Loss: 233.703105\tAverage Discriminator Loss: 0.000830\n",
      "\n",
      "Train time for epoch #491 (step 491): 1.406381\n",
      "Batch #10\tAverage Generator Loss: 170.432850\tAverage Discriminator Loss: 0.002687\n",
      "\n",
      "Train time for epoch #492 (step 492): 1.411073\n",
      "Batch #10\tAverage Generator Loss: 243.921060\tAverage Discriminator Loss: 0.000719\n",
      "\n",
      "Train time for epoch #493 (step 493): 1.363395\n",
      "Batch #10\tAverage Generator Loss: 206.820557\tAverage Discriminator Loss: 0.009494\n",
      "\n",
      "Train time for epoch #494 (step 494): 1.358840\n",
      "Batch #10\tAverage Generator Loss: 246.391727\tAverage Discriminator Loss: 0.000354\n",
      "\n",
      "Train time for epoch #495 (step 495): 1.352769\n",
      "Batch #10\tAverage Generator Loss: 206.275377\tAverage Discriminator Loss: 0.016441\n",
      "\n",
      "Train time for epoch #496 (step 496): 1.534280\n",
      "Batch #10\tAverage Generator Loss: 225.846136\tAverage Discriminator Loss: 0.001607\n",
      "\n",
      "Train time for epoch #497 (step 497): 1.357658\n",
      "Batch #10\tAverage Generator Loss: 227.992818\tAverage Discriminator Loss: 0.005897\n",
      "\n",
      "Train time for epoch #498 (step 498): 1.305483\n",
      "Batch #10\tAverage Generator Loss: 190.369113\tAverage Discriminator Loss: 0.003882\n",
      "\n",
      "Train time for epoch #499 (step 499): 1.360296\n",
      "Batch #10\tAverage Generator Loss: 204.855559\tAverage Discriminator Loss: 0.001416\n",
      "\n",
      "Train time for epoch #500 (step 500): 1.415182\n",
      "Batch #10\tAverage Generator Loss: 192.215501\tAverage Discriminator Loss: 0.000205\n",
      "\n",
      "Train time for epoch #501 (step 501): 1.351424\n",
      "Batch #10\tAverage Generator Loss: 208.844990\tAverage Discriminator Loss: 0.002483\n",
      "\n",
      "Train time for epoch #502 (step 502): 1.394787\n",
      "Batch #10\tAverage Generator Loss: 228.072952\tAverage Discriminator Loss: 0.000773\n",
      "\n",
      "Train time for epoch #503 (step 503): 1.483324\n",
      "Batch #10\tAverage Generator Loss: 216.656973\tAverage Discriminator Loss: 0.001079\n",
      "\n",
      "Train time for epoch #504 (step 504): 1.475501\n",
      "Batch #10\tAverage Generator Loss: 243.511568\tAverage Discriminator Loss: 0.000361\n",
      "\n",
      "Train time for epoch #505 (step 505): 1.511245\n",
      "Batch #10\tAverage Generator Loss: 240.240868\tAverage Discriminator Loss: 0.000852\n",
      "\n",
      "Train time for epoch #506 (step 506): 1.408703\n",
      "Batch #10\tAverage Generator Loss: 241.687300\tAverage Discriminator Loss: 0.001409\n",
      "\n",
      "Train time for epoch #507 (step 507): 1.336250\n",
      "Batch #10\tAverage Generator Loss: 228.075060\tAverage Discriminator Loss: 0.000145\n",
      "\n",
      "Train time for epoch #508 (step 508): 1.454451\n",
      "Batch #10\tAverage Generator Loss: 179.095747\tAverage Discriminator Loss: 0.135079\n",
      "\n",
      "Train time for epoch #509 (step 509): 1.502385\n",
      "Batch #10\tAverage Generator Loss: 189.801112\tAverage Discriminator Loss: 0.060892\n",
      "\n",
      "Train time for epoch #510 (step 510): 1.508019\n",
      "Batch #10\tAverage Generator Loss: 214.425427\tAverage Discriminator Loss: 0.012908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #511 (step 511): 1.411107\n",
      "Batch #10\tAverage Generator Loss: 167.540443\tAverage Discriminator Loss: 0.014260\n",
      "\n",
      "Train time for epoch #512 (step 512): 1.355430\n",
      "Batch #10\tAverage Generator Loss: 164.494387\tAverage Discriminator Loss: 0.024891\n",
      "\n",
      "Train time for epoch #513 (step 513): 1.383679\n",
      "Batch #10\tAverage Generator Loss: 159.004345\tAverage Discriminator Loss: 0.023488\n",
      "\n",
      "Train time for epoch #514 (step 514): 1.349182\n",
      "Batch #10\tAverage Generator Loss: 178.835645\tAverage Discriminator Loss: 0.012167\n",
      "\n",
      "Train time for epoch #515 (step 515): 1.425772\n",
      "Batch #10\tAverage Generator Loss: 171.010208\tAverage Discriminator Loss: 0.190858\n",
      "\n",
      "Train time for epoch #516 (step 516): 1.359067\n",
      "Batch #10\tAverage Generator Loss: 179.773441\tAverage Discriminator Loss: 0.045880\n",
      "\n",
      "Train time for epoch #517 (step 517): 1.453596\n",
      "Batch #10\tAverage Generator Loss: 144.095375\tAverage Discriminator Loss: 0.032945\n",
      "\n",
      "Train time for epoch #518 (step 518): 1.360782\n",
      "Batch #10\tAverage Generator Loss: 149.716349\tAverage Discriminator Loss: 0.356341\n",
      "\n",
      "Train time for epoch #519 (step 519): 1.402727\n",
      "Batch #10\tAverage Generator Loss: 108.429692\tAverage Discriminator Loss: 0.006128\n",
      "\n",
      "Train time for epoch #520 (step 520): 1.476170\n",
      "Batch #10\tAverage Generator Loss: 189.308093\tAverage Discriminator Loss: 0.555048\n",
      "\n",
      "Train time for epoch #521 (step 521): 1.512509\n",
      "Batch #10\tAverage Generator Loss: 132.479714\tAverage Discriminator Loss: 0.110277\n",
      "\n",
      "Train time for epoch #522 (step 522): 1.316907\n",
      "Batch #10\tAverage Generator Loss: 159.754080\tAverage Discriminator Loss: 0.178291\n",
      "\n",
      "Train time for epoch #523 (step 523): 1.359872\n",
      "Batch #10\tAverage Generator Loss: 134.361860\tAverage Discriminator Loss: 0.086789\n",
      "\n",
      "Train time for epoch #524 (step 524): 1.370322\n",
      "Batch #10\tAverage Generator Loss: 148.557787\tAverage Discriminator Loss: 0.016962\n",
      "\n",
      "Train time for epoch #525 (step 525): 1.505161\n",
      "Batch #10\tAverage Generator Loss: 165.719133\tAverage Discriminator Loss: 0.023008\n",
      "\n",
      "Train time for epoch #526 (step 526): 1.422229\n",
      "Batch #10\tAverage Generator Loss: 145.464795\tAverage Discriminator Loss: 0.067763\n",
      "\n",
      "Train time for epoch #527 (step 527): 1.406866\n",
      "Batch #10\tAverage Generator Loss: 144.838894\tAverage Discriminator Loss: 0.005557\n",
      "\n",
      "Train time for epoch #528 (step 528): 1.412585\n",
      "Batch #10\tAverage Generator Loss: 159.488456\tAverage Discriminator Loss: 0.003162\n",
      "\n",
      "Train time for epoch #529 (step 529): 1.465417\n",
      "Batch #10\tAverage Generator Loss: 149.314854\tAverage Discriminator Loss: 0.001451\n",
      "\n",
      "Train time for epoch #530 (step 530): 1.358715\n",
      "Batch #10\tAverage Generator Loss: 147.986281\tAverage Discriminator Loss: 0.177385\n",
      "\n",
      "Train time for epoch #531 (step 531): 1.360777\n",
      "Batch #10\tAverage Generator Loss: 196.786051\tAverage Discriminator Loss: 0.121230\n",
      "\n",
      "Train time for epoch #532 (step 532): 1.415782\n",
      "Batch #10\tAverage Generator Loss: 136.122654\tAverage Discriminator Loss: 0.104950\n",
      "\n",
      "Train time for epoch #533 (step 533): 1.351461\n",
      "Batch #10\tAverage Generator Loss: 165.096897\tAverage Discriminator Loss: 0.051780\n",
      "\n",
      "Train time for epoch #534 (step 534): 1.466635\n",
      "Batch #10\tAverage Generator Loss: 161.635656\tAverage Discriminator Loss: 0.010190\n",
      "\n",
      "Train time for epoch #535 (step 535): 1.417700\n",
      "Batch #10\tAverage Generator Loss: 194.508665\tAverage Discriminator Loss: 0.030062\n",
      "\n",
      "Train time for epoch #536 (step 536): 1.455546\n",
      "Batch #10\tAverage Generator Loss: 158.891476\tAverage Discriminator Loss: 0.005460\n",
      "\n",
      "Train time for epoch #537 (step 537): 1.387805\n",
      "Batch #10\tAverage Generator Loss: 201.026170\tAverage Discriminator Loss: 0.002059\n",
      "\n",
      "Train time for epoch #538 (step 538): 1.513034\n",
      "Batch #10\tAverage Generator Loss: 141.109789\tAverage Discriminator Loss: 0.001334\n",
      "\n",
      "Train time for epoch #539 (step 539): 1.468878\n",
      "Batch #10\tAverage Generator Loss: 179.162112\tAverage Discriminator Loss: 0.015347\n",
      "\n",
      "Train time for epoch #540 (step 540): 1.367889\n",
      "Batch #10\tAverage Generator Loss: 156.973999\tAverage Discriminator Loss: 0.002724\n",
      "\n",
      "Train time for epoch #541 (step 541): 1.399689\n",
      "Batch #10\tAverage Generator Loss: 172.698106\tAverage Discriminator Loss: 0.000788\n",
      "\n",
      "Train time for epoch #542 (step 542): 1.356970\n",
      "Batch #10\tAverage Generator Loss: 121.598397\tAverage Discriminator Loss: 0.007254\n",
      "\n",
      "Train time for epoch #543 (step 543): 1.355337\n",
      "Batch #10\tAverage Generator Loss: 144.529506\tAverage Discriminator Loss: 0.001475\n",
      "\n",
      "Train time for epoch #544 (step 544): 1.478665\n",
      "Batch #10\tAverage Generator Loss: 152.577588\tAverage Discriminator Loss: 0.011315\n",
      "\n",
      "Train time for epoch #545 (step 545): 1.401653\n",
      "Batch #10\tAverage Generator Loss: 166.353514\tAverage Discriminator Loss: 0.038339\n",
      "\n",
      "Train time for epoch #546 (step 546): 1.358060\n",
      "Batch #10\tAverage Generator Loss: 151.244218\tAverage Discriminator Loss: 0.089799\n",
      "\n",
      "Train time for epoch #547 (step 547): 1.427305\n",
      "Batch #10\tAverage Generator Loss: 156.574456\tAverage Discriminator Loss: 0.011173\n",
      "\n",
      "Train time for epoch #548 (step 548): 1.363353\n",
      "Batch #10\tAverage Generator Loss: 145.691233\tAverage Discriminator Loss: 0.000619\n",
      "\n",
      "Train time for epoch #549 (step 549): 1.547753\n",
      "Batch #10\tAverage Generator Loss: 135.074330\tAverage Discriminator Loss: 0.006974\n",
      "\n",
      "Train time for epoch #550 (step 550): 1.427024\n",
      "Batch #10\tAverage Generator Loss: 142.179773\tAverage Discriminator Loss: 0.001804\n",
      "\n",
      "Train time for epoch #551 (step 551): 1.305681\n",
      "Batch #10\tAverage Generator Loss: 136.376770\tAverage Discriminator Loss: 0.001223\n",
      "\n",
      "Train time for epoch #552 (step 552): 1.441634\n",
      "Batch #10\tAverage Generator Loss: 146.898345\tAverage Discriminator Loss: 0.000968\n",
      "\n",
      "Train time for epoch #553 (step 553): 1.455979\n",
      "Batch #10\tAverage Generator Loss: 164.738368\tAverage Discriminator Loss: 0.008891\n",
      "\n",
      "Train time for epoch #554 (step 554): 1.505718\n",
      "Batch #10\tAverage Generator Loss: 153.397386\tAverage Discriminator Loss: 0.015467\n",
      "\n",
      "Train time for epoch #555 (step 555): 1.355171\n",
      "Batch #10\tAverage Generator Loss: 156.039985\tAverage Discriminator Loss: 0.001887\n",
      "\n",
      "Train time for epoch #556 (step 556): 1.389378\n",
      "Batch #10\tAverage Generator Loss: 176.773504\tAverage Discriminator Loss: 0.001172\n",
      "\n",
      "Train time for epoch #557 (step 557): 1.456893\n",
      "Batch #10\tAverage Generator Loss: 169.206574\tAverage Discriminator Loss: 0.000921\n",
      "\n",
      "Train time for epoch #558 (step 558): 1.453635\n",
      "Batch #10\tAverage Generator Loss: 158.324809\tAverage Discriminator Loss: 0.001731\n",
      "\n",
      "Train time for epoch #559 (step 559): 1.406685\n",
      "Batch #10\tAverage Generator Loss: 160.236419\tAverage Discriminator Loss: 0.002629\n",
      "\n",
      "Train time for epoch #560 (step 560): 1.359576\n",
      "Batch #10\tAverage Generator Loss: 163.371168\tAverage Discriminator Loss: 0.003137\n",
      "\n",
      "Train time for epoch #561 (step 561): 1.371898\n",
      "Batch #10\tAverage Generator Loss: 163.104192\tAverage Discriminator Loss: 0.004193\n",
      "\n",
      "Train time for epoch #562 (step 562): 1.455359\n",
      "Batch #10\tAverage Generator Loss: 165.235806\tAverage Discriminator Loss: 0.001269\n",
      "\n",
      "Train time for epoch #563 (step 563): 1.418858\n",
      "Batch #10\tAverage Generator Loss: 172.754221\tAverage Discriminator Loss: 0.001459\n",
      "\n",
      "Train time for epoch #564 (step 564): 1.589881\n",
      "Batch #10\tAverage Generator Loss: 181.340190\tAverage Discriminator Loss: 0.003790\n",
      "\n",
      "Train time for epoch #565 (step 565): 1.476259\n",
      "Batch #10\tAverage Generator Loss: 159.217072\tAverage Discriminator Loss: 0.000665\n",
      "\n",
      "Train time for epoch #566 (step 566): 1.400727\n",
      "Batch #10\tAverage Generator Loss: 165.489246\tAverage Discriminator Loss: 0.001366\n",
      "\n",
      "Train time for epoch #567 (step 567): 1.411795\n",
      "Batch #10\tAverage Generator Loss: 173.014065\tAverage Discriminator Loss: 0.000647\n",
      "\n",
      "Train time for epoch #568 (step 568): 1.474594\n",
      "Batch #10\tAverage Generator Loss: 175.071996\tAverage Discriminator Loss: 0.042844\n",
      "\n",
      "Train time for epoch #569 (step 569): 1.469370\n",
      "Batch #10\tAverage Generator Loss: 167.124299\tAverage Discriminator Loss: 0.019011\n",
      "\n",
      "Train time for epoch #570 (step 570): 1.356738\n",
      "Batch #10\tAverage Generator Loss: 169.704258\tAverage Discriminator Loss: 0.000869\n",
      "\n",
      "Train time for epoch #571 (step 571): 1.307596\n",
      "Batch #10\tAverage Generator Loss: 186.313276\tAverage Discriminator Loss: 0.003325\n",
      "\n",
      "Train time for epoch #572 (step 572): 1.353042\n",
      "Batch #10\tAverage Generator Loss: 213.787482\tAverage Discriminator Loss: 0.002341\n",
      "\n",
      "Train time for epoch #573 (step 573): 1.502236\n",
      "Batch #10\tAverage Generator Loss: 193.434042\tAverage Discriminator Loss: 0.001176\n",
      "\n",
      "Train time for epoch #574 (step 574): 1.467534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 166.231506\tAverage Discriminator Loss: 0.000521\n",
      "\n",
      "Train time for epoch #575 (step 575): 1.371455\n",
      "Batch #10\tAverage Generator Loss: 179.906438\tAverage Discriminator Loss: 0.000461\n",
      "\n",
      "Train time for epoch #576 (step 576): 1.365885\n",
      "Batch #10\tAverage Generator Loss: 163.067190\tAverage Discriminator Loss: 0.000375\n",
      "\n",
      "Train time for epoch #577 (step 577): 1.361982\n",
      "Batch #10\tAverage Generator Loss: 175.418575\tAverage Discriminator Loss: 0.000337\n",
      "\n",
      "Train time for epoch #578 (step 578): 1.471390\n",
      "Batch #10\tAverage Generator Loss: 176.288618\tAverage Discriminator Loss: 0.000297\n",
      "\n",
      "Train time for epoch #579 (step 579): 1.352039\n",
      "Batch #10\tAverage Generator Loss: 191.756632\tAverage Discriminator Loss: 0.000270\n",
      "\n",
      "Train time for epoch #580 (step 580): 1.364389\n",
      "Batch #10\tAverage Generator Loss: 191.399657\tAverage Discriminator Loss: 0.000257\n",
      "\n",
      "Train time for epoch #581 (step 581): 1.353034\n",
      "Batch #10\tAverage Generator Loss: 182.873179\tAverage Discriminator Loss: 0.000232\n",
      "\n",
      "Train time for epoch #582 (step 582): 1.363772\n",
      "Batch #10\tAverage Generator Loss: 197.808959\tAverage Discriminator Loss: 0.000433\n",
      "\n",
      "Train time for epoch #583 (step 583): 1.468519\n",
      "Batch #10\tAverage Generator Loss: 192.130431\tAverage Discriminator Loss: 0.000218\n",
      "\n",
      "Train time for epoch #584 (step 584): 1.482087\n",
      "Batch #10\tAverage Generator Loss: 185.701659\tAverage Discriminator Loss: 0.000181\n",
      "\n",
      "Train time for epoch #585 (step 585): 1.371990\n",
      "Batch #10\tAverage Generator Loss: 160.354858\tAverage Discriminator Loss: 0.001124\n",
      "\n",
      "Train time for epoch #586 (step 586): 1.388014\n",
      "Batch #10\tAverage Generator Loss: 194.024773\tAverage Discriminator Loss: 0.003330\n",
      "\n",
      "Train time for epoch #587 (step 587): 1.380934\n",
      "Batch #10\tAverage Generator Loss: 177.142130\tAverage Discriminator Loss: 0.024996\n",
      "\n",
      "Train time for epoch #588 (step 588): 1.414991\n",
      "Batch #10\tAverage Generator Loss: 174.576297\tAverage Discriminator Loss: 0.051307\n",
      "\n",
      "Train time for epoch #589 (step 589): 1.532662\n",
      "Batch #10\tAverage Generator Loss: 160.396743\tAverage Discriminator Loss: 0.001325\n",
      "\n",
      "Train time for epoch #590 (step 590): 1.350072\n",
      "Batch #10\tAverage Generator Loss: 164.504996\tAverage Discriminator Loss: 0.068257\n",
      "\n",
      "Train time for epoch #591 (step 591): 1.365906\n",
      "Batch #10\tAverage Generator Loss: 164.334131\tAverage Discriminator Loss: 0.001230\n",
      "\n",
      "Train time for epoch #592 (step 592): 1.395246\n",
      "Batch #10\tAverage Generator Loss: 196.900053\tAverage Discriminator Loss: 0.000263\n",
      "\n",
      "Train time for epoch #593 (step 593): 1.428433\n",
      "Batch #10\tAverage Generator Loss: 194.840959\tAverage Discriminator Loss: 0.008248\n",
      "\n",
      "Train time for epoch #594 (step 594): 1.371389\n",
      "Batch #10\tAverage Generator Loss: 166.796082\tAverage Discriminator Loss: 0.005267\n",
      "\n",
      "Train time for epoch #595 (step 595): 1.533391\n",
      "Batch #10\tAverage Generator Loss: 184.106234\tAverage Discriminator Loss: 0.001945\n",
      "\n",
      "Train time for epoch #596 (step 596): 1.468218\n",
      "Batch #10\tAverage Generator Loss: 172.849888\tAverage Discriminator Loss: 0.000684\n",
      "\n",
      "Train time for epoch #597 (step 597): 1.422692\n",
      "Batch #10\tAverage Generator Loss: 177.515560\tAverage Discriminator Loss: 0.000428\n",
      "\n",
      "Train time for epoch #598 (step 598): 1.487606\n",
      "Batch #10\tAverage Generator Loss: 180.559395\tAverage Discriminator Loss: 0.000342\n",
      "\n",
      "Train time for epoch #599 (step 599): 1.437750\n",
      "Batch #10\tAverage Generator Loss: 150.642810\tAverage Discriminator Loss: 0.001821\n",
      "\n",
      "Train time for epoch #600 (step 600): 1.406617\n",
      "Batch #10\tAverage Generator Loss: 173.305386\tAverage Discriminator Loss: 0.000394\n",
      "\n",
      "Train time for epoch #601 (step 601): 1.351102\n",
      "Batch #10\tAverage Generator Loss: 168.790961\tAverage Discriminator Loss: 0.002640\n",
      "\n",
      "Train time for epoch #602 (step 602): 1.468621\n",
      "Batch #10\tAverage Generator Loss: 199.495150\tAverage Discriminator Loss: 0.000400\n",
      "\n",
      "Train time for epoch #603 (step 603): 1.548354\n",
      "Batch #10\tAverage Generator Loss: 170.165772\tAverage Discriminator Loss: 0.013236\n",
      "\n",
      "Train time for epoch #604 (step 604): 1.475691\n",
      "Batch #10\tAverage Generator Loss: 195.090259\tAverage Discriminator Loss: 0.013805\n",
      "\n",
      "Train time for epoch #605 (step 605): 1.365813\n",
      "Batch #10\tAverage Generator Loss: 176.373018\tAverage Discriminator Loss: 0.000289\n",
      "\n",
      "Train time for epoch #606 (step 606): 1.347850\n",
      "Batch #10\tAverage Generator Loss: 185.097340\tAverage Discriminator Loss: 0.003262\n",
      "\n",
      "Train time for epoch #607 (step 607): 1.398916\n",
      "Batch #10\tAverage Generator Loss: 202.645602\tAverage Discriminator Loss: 0.001438\n",
      "\n",
      "Train time for epoch #608 (step 608): 1.411289\n",
      "Batch #10\tAverage Generator Loss: 188.767617\tAverage Discriminator Loss: 0.001659\n",
      "\n",
      "Train time for epoch #609 (step 609): 1.482182\n",
      "Batch #10\tAverage Generator Loss: 183.978641\tAverage Discriminator Loss: 0.000493\n",
      "\n",
      "Train time for epoch #610 (step 610): 1.373473\n",
      "Batch #10\tAverage Generator Loss: 167.373026\tAverage Discriminator Loss: 0.000382\n",
      "\n",
      "Train time for epoch #611 (step 611): 1.509718\n",
      "Batch #10\tAverage Generator Loss: 181.370757\tAverage Discriminator Loss: 0.000285\n",
      "\n",
      "Train time for epoch #612 (step 612): 1.365183\n",
      "Batch #10\tAverage Generator Loss: 189.661514\tAverage Discriminator Loss: 0.000402\n",
      "\n",
      "Train time for epoch #613 (step 613): 1.460396\n",
      "Batch #10\tAverage Generator Loss: 191.481877\tAverage Discriminator Loss: 0.000277\n",
      "\n",
      "Train time for epoch #614 (step 614): 1.358383\n",
      "Batch #10\tAverage Generator Loss: 182.408061\tAverage Discriminator Loss: 0.000236\n",
      "\n",
      "Train time for epoch #615 (step 615): 1.548070\n",
      "Batch #10\tAverage Generator Loss: 217.238292\tAverage Discriminator Loss: 0.011963\n",
      "\n",
      "Train time for epoch #616 (step 616): 1.358340\n",
      "Batch #10\tAverage Generator Loss: 222.234227\tAverage Discriminator Loss: 0.010566\n",
      "\n",
      "Train time for epoch #617 (step 617): 1.378642\n",
      "Batch #10\tAverage Generator Loss: 180.716935\tAverage Discriminator Loss: 0.010687\n",
      "\n",
      "Train time for epoch #618 (step 618): 1.481960\n",
      "Batch #10\tAverage Generator Loss: 215.722202\tAverage Discriminator Loss: 0.007139\n",
      "\n",
      "Train time for epoch #619 (step 619): 1.526260\n",
      "Batch #10\tAverage Generator Loss: 206.945183\tAverage Discriminator Loss: 0.000435\n",
      "\n",
      "Train time for epoch #620 (step 620): 1.438263\n",
      "Batch #10\tAverage Generator Loss: 195.870190\tAverage Discriminator Loss: 0.000702\n",
      "\n",
      "Train time for epoch #621 (step 621): 1.417227\n",
      "Batch #10\tAverage Generator Loss: 208.058865\tAverage Discriminator Loss: 0.000286\n",
      "\n",
      "Train time for epoch #622 (step 622): 1.487379\n",
      "Batch #10\tAverage Generator Loss: 197.725401\tAverage Discriminator Loss: 0.000280\n",
      "\n",
      "Train time for epoch #623 (step 623): 1.406565\n",
      "Batch #10\tAverage Generator Loss: 186.078580\tAverage Discriminator Loss: 0.000267\n",
      "\n",
      "Train time for epoch #624 (step 624): 1.626487\n",
      "Batch #10\tAverage Generator Loss: 196.044449\tAverage Discriminator Loss: 0.000827\n",
      "\n",
      "Train time for epoch #625 (step 625): 1.416572\n",
      "Batch #10\tAverage Generator Loss: 174.024669\tAverage Discriminator Loss: 0.000336\n",
      "\n",
      "Train time for epoch #626 (step 626): 1.406668\n",
      "Batch #10\tAverage Generator Loss: 211.182841\tAverage Discriminator Loss: 0.002848\n",
      "\n",
      "Train time for epoch #627 (step 627): 1.414929\n",
      "Batch #10\tAverage Generator Loss: 176.202491\tAverage Discriminator Loss: 0.000339\n",
      "\n",
      "Train time for epoch #628 (step 628): 1.559674\n",
      "Batch #10\tAverage Generator Loss: 188.815634\tAverage Discriminator Loss: 0.000610\n",
      "\n",
      "Train time for epoch #629 (step 629): 1.414900\n",
      "Batch #10\tAverage Generator Loss: 174.109586\tAverage Discriminator Loss: 0.001157\n",
      "\n",
      "Train time for epoch #630 (step 630): 1.419376\n",
      "Batch #10\tAverage Generator Loss: 201.783181\tAverage Discriminator Loss: 0.000593\n",
      "\n",
      "Train time for epoch #631 (step 631): 1.399919\n",
      "Batch #10\tAverage Generator Loss: 191.839506\tAverage Discriminator Loss: 0.000439\n",
      "\n",
      "Train time for epoch #632 (step 632): 1.427772\n",
      "Batch #10\tAverage Generator Loss: 206.488584\tAverage Discriminator Loss: 0.000333\n",
      "\n",
      "Train time for epoch #633 (step 633): 1.566104\n",
      "Batch #10\tAverage Generator Loss: 209.196355\tAverage Discriminator Loss: 0.000243\n",
      "\n",
      "Train time for epoch #634 (step 634): 1.418441\n",
      "Batch #10\tAverage Generator Loss: 168.883565\tAverage Discriminator Loss: 0.000212\n",
      "\n",
      "Train time for epoch #635 (step 635): 1.569156\n",
      "Batch #10\tAverage Generator Loss: 195.611914\tAverage Discriminator Loss: 0.000172\n",
      "\n",
      "Train time for epoch #636 (step 636): 1.445311\n",
      "Batch #10\tAverage Generator Loss: 227.966751\tAverage Discriminator Loss: 0.021047\n",
      "\n",
      "Train time for epoch #637 (step 637): 1.539806\n",
      "Batch #10\tAverage Generator Loss: 233.708601\tAverage Discriminator Loss: 0.000509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #638 (step 638): 1.400982\n",
      "Batch #10\tAverage Generator Loss: 205.219484\tAverage Discriminator Loss: 0.000177\n",
      "\n",
      "Train time for epoch #639 (step 639): 1.506542\n",
      "Batch #10\tAverage Generator Loss: 220.699744\tAverage Discriminator Loss: 0.000164\n",
      "\n",
      "Train time for epoch #640 (step 640): 1.359540\n",
      "Batch #10\tAverage Generator Loss: 205.782254\tAverage Discriminator Loss: 0.000125\n",
      "\n",
      "Train time for epoch #641 (step 641): 1.361467\n",
      "Batch #10\tAverage Generator Loss: 207.405382\tAverage Discriminator Loss: 0.000118\n",
      "\n",
      "Train time for epoch #642 (step 642): 1.501263\n",
      "Batch #10\tAverage Generator Loss: 203.477141\tAverage Discriminator Loss: 0.000126\n",
      "\n",
      "Train time for epoch #643 (step 643): 1.476260\n",
      "Batch #10\tAverage Generator Loss: 213.077553\tAverage Discriminator Loss: 0.000112\n",
      "\n",
      "Train time for epoch #644 (step 644): 1.413927\n",
      "Batch #10\tAverage Generator Loss: 188.967036\tAverage Discriminator Loss: 0.000117\n",
      "\n",
      "Train time for epoch #645 (step 645): 1.529531\n",
      "Batch #10\tAverage Generator Loss: 198.925642\tAverage Discriminator Loss: 0.000108\n",
      "\n",
      "Train time for epoch #646 (step 646): 1.398219\n",
      "Batch #10\tAverage Generator Loss: 201.552396\tAverage Discriminator Loss: 0.000460\n",
      "\n",
      "Train time for epoch #647 (step 647): 1.583469\n",
      "Batch #10\tAverage Generator Loss: 191.487608\tAverage Discriminator Loss: 0.001354\n",
      "\n",
      "Train time for epoch #648 (step 648): 1.364963\n",
      "Batch #10\tAverage Generator Loss: 204.332729\tAverage Discriminator Loss: 0.000183\n",
      "\n",
      "Train time for epoch #649 (step 649): 1.411611\n",
      "Batch #10\tAverage Generator Loss: 193.901675\tAverage Discriminator Loss: 0.078884\n",
      "\n",
      "Train time for epoch #650 (step 650): 1.419247\n",
      "Batch #10\tAverage Generator Loss: 206.490691\tAverage Discriminator Loss: 0.004927\n",
      "\n",
      "Train time for epoch #651 (step 651): 1.459129\n",
      "Batch #10\tAverage Generator Loss: 200.002798\tAverage Discriminator Loss: 0.000754\n",
      "\n",
      "Train time for epoch #652 (step 652): 1.362111\n",
      "Batch #10\tAverage Generator Loss: 187.690145\tAverage Discriminator Loss: 0.005729\n",
      "\n",
      "Train time for epoch #653 (step 653): 1.362495\n",
      "Batch #10\tAverage Generator Loss: 216.647655\tAverage Discriminator Loss: 0.000970\n",
      "\n",
      "Train time for epoch #654 (step 654): 1.362988\n",
      "Batch #10\tAverage Generator Loss: 231.149146\tAverage Discriminator Loss: 0.000742\n",
      "\n",
      "Train time for epoch #655 (step 655): 1.371659\n",
      "Batch #10\tAverage Generator Loss: 220.966673\tAverage Discriminator Loss: 0.000285\n",
      "\n",
      "Train time for epoch #656 (step 656): 1.514729\n",
      "Batch #10\tAverage Generator Loss: 197.729045\tAverage Discriminator Loss: 0.005151\n",
      "\n",
      "Train time for epoch #657 (step 657): 1.419465\n",
      "Batch #10\tAverage Generator Loss: 249.585706\tAverage Discriminator Loss: 0.003666\n",
      "\n",
      "Train time for epoch #658 (step 658): 1.383965\n",
      "Batch #10\tAverage Generator Loss: 216.188684\tAverage Discriminator Loss: 0.000869\n",
      "\n",
      "Train time for epoch #659 (step 659): 1.460911\n",
      "Batch #10\tAverage Generator Loss: 215.097901\tAverage Discriminator Loss: 0.005267\n",
      "\n",
      "Train time for epoch #660 (step 660): 1.493442\n",
      "Batch #10\tAverage Generator Loss: 225.155687\tAverage Discriminator Loss: 0.000554\n",
      "\n",
      "Train time for epoch #661 (step 661): 1.358382\n",
      "Batch #10\tAverage Generator Loss: 209.053614\tAverage Discriminator Loss: 0.028497\n",
      "\n",
      "Train time for epoch #662 (step 662): 1.493405\n",
      "Batch #10\tAverage Generator Loss: 235.914915\tAverage Discriminator Loss: 0.000177\n",
      "\n",
      "Train time for epoch #663 (step 663): 1.292602\n",
      "Batch #10\tAverage Generator Loss: 206.352682\tAverage Discriminator Loss: 0.013565\n",
      "\n",
      "Train time for epoch #664 (step 664): 1.565135\n",
      "Batch #10\tAverage Generator Loss: 209.943491\tAverage Discriminator Loss: 0.003174\n",
      "\n",
      "Train time for epoch #665 (step 665): 1.428659\n",
      "Batch #10\tAverage Generator Loss: 242.543167\tAverage Discriminator Loss: 0.000514\n",
      "\n",
      "Train time for epoch #666 (step 666): 1.352948\n",
      "Batch #10\tAverage Generator Loss: 242.449792\tAverage Discriminator Loss: 0.001604\n",
      "\n",
      "Train time for epoch #667 (step 667): 1.366383\n",
      "Batch #10\tAverage Generator Loss: 200.791551\tAverage Discriminator Loss: 0.000631\n",
      "\n",
      "Train time for epoch #668 (step 668): 1.561300\n",
      "Batch #10\tAverage Generator Loss: 207.767612\tAverage Discriminator Loss: 0.000203\n",
      "\n",
      "Train time for epoch #669 (step 669): 1.342988\n",
      "Batch #10\tAverage Generator Loss: 243.027263\tAverage Discriminator Loss: 0.000169\n",
      "\n",
      "Train time for epoch #670 (step 670): 1.305760\n",
      "Batch #10\tAverage Generator Loss: 227.917322\tAverage Discriminator Loss: 0.001405\n",
      "\n",
      "Train time for epoch #671 (step 671): 1.511984\n",
      "Batch #10\tAverage Generator Loss: 210.316444\tAverage Discriminator Loss: 0.000851\n",
      "\n",
      "Train time for epoch #672 (step 672): 1.434944\n",
      "Batch #10\tAverage Generator Loss: 234.921284\tAverage Discriminator Loss: 0.028693\n",
      "\n",
      "Train time for epoch #673 (step 673): 1.403212\n",
      "Batch #10\tAverage Generator Loss: 253.287766\tAverage Discriminator Loss: 0.000329\n",
      "\n",
      "Train time for epoch #674 (step 674): 1.360888\n",
      "Batch #10\tAverage Generator Loss: 219.208720\tAverage Discriminator Loss: 0.000206\n",
      "\n",
      "Train time for epoch #675 (step 675): 1.463422\n",
      "Batch #10\tAverage Generator Loss: 217.548846\tAverage Discriminator Loss: 0.036002\n",
      "\n",
      "Train time for epoch #676 (step 676): 1.387582\n",
      "Batch #10\tAverage Generator Loss: 213.074306\tAverage Discriminator Loss: 0.003458\n",
      "\n",
      "Train time for epoch #677 (step 677): 1.369771\n",
      "Batch #10\tAverage Generator Loss: 224.816429\tAverage Discriminator Loss: 0.000224\n",
      "\n",
      "Train time for epoch #678 (step 678): 1.514049\n",
      "Batch #10\tAverage Generator Loss: 250.421599\tAverage Discriminator Loss: 0.009282\n",
      "\n",
      "Train time for epoch #679 (step 679): 1.353221\n",
      "Batch #10\tAverage Generator Loss: 233.762535\tAverage Discriminator Loss: 0.000602\n",
      "\n",
      "Train time for epoch #680 (step 680): 1.445315\n",
      "Batch #10\tAverage Generator Loss: 233.336519\tAverage Discriminator Loss: 0.000468\n",
      "\n",
      "Train time for epoch #681 (step 681): 1.522207\n",
      "Batch #10\tAverage Generator Loss: 221.939429\tAverage Discriminator Loss: 0.000289\n",
      "\n",
      "Train time for epoch #682 (step 682): 1.351441\n",
      "Batch #10\tAverage Generator Loss: 227.528011\tAverage Discriminator Loss: 0.001565\n",
      "\n",
      "Train time for epoch #683 (step 683): 1.418721\n",
      "Batch #10\tAverage Generator Loss: 234.606532\tAverage Discriminator Loss: 0.000521\n",
      "\n",
      "Train time for epoch #684 (step 684): 1.452650\n",
      "Batch #10\tAverage Generator Loss: 210.661530\tAverage Discriminator Loss: 0.000536\n",
      "\n",
      "Train time for epoch #685 (step 685): 1.369373\n",
      "Batch #10\tAverage Generator Loss: 225.845947\tAverage Discriminator Loss: 0.000290\n",
      "\n",
      "Train time for epoch #686 (step 686): 1.429908\n",
      "Batch #10\tAverage Generator Loss: 220.983100\tAverage Discriminator Loss: 0.000227\n",
      "\n",
      "Train time for epoch #687 (step 687): 1.373106\n",
      "Batch #10\tAverage Generator Loss: 233.410464\tAverage Discriminator Loss: 0.001627\n",
      "\n",
      "Train time for epoch #688 (step 688): 1.484530\n",
      "Batch #10\tAverage Generator Loss: 226.509888\tAverage Discriminator Loss: 0.005248\n",
      "\n",
      "Train time for epoch #689 (step 689): 1.421576\n",
      "Batch #10\tAverage Generator Loss: 229.091990\tAverage Discriminator Loss: 0.018472\n",
      "\n",
      "Train time for epoch #690 (step 690): 1.425386\n",
      "Batch #10\tAverage Generator Loss: 215.984061\tAverage Discriminator Loss: 0.000552\n",
      "\n",
      "Train time for epoch #691 (step 691): 1.400822\n",
      "Batch #10\tAverage Generator Loss: 206.710303\tAverage Discriminator Loss: 0.000283\n",
      "\n",
      "Train time for epoch #692 (step 692): 1.424174\n",
      "Batch #10\tAverage Generator Loss: 214.060330\tAverage Discriminator Loss: 0.000168\n",
      "\n",
      "Train time for epoch #693 (step 693): 1.378992\n",
      "Batch #10\tAverage Generator Loss: 207.593567\tAverage Discriminator Loss: 0.044610\n",
      "\n",
      "Train time for epoch #694 (step 694): 1.357977\n",
      "Batch #10\tAverage Generator Loss: 210.202946\tAverage Discriminator Loss: 0.008428\n",
      "\n",
      "Train time for epoch #695 (step 695): 1.368803\n",
      "Batch #10\tAverage Generator Loss: 231.230778\tAverage Discriminator Loss: 0.005720\n",
      "\n",
      "Train time for epoch #696 (step 696): 1.368083\n",
      "Batch #10\tAverage Generator Loss: 208.619214\tAverage Discriminator Loss: 0.000234\n",
      "\n",
      "Train time for epoch #697 (step 697): 1.351029\n",
      "Batch #10\tAverage Generator Loss: 216.892794\tAverage Discriminator Loss: 0.000091\n",
      "\n",
      "Train time for epoch #698 (step 698): 1.481212\n",
      "Batch #10\tAverage Generator Loss: 225.430783\tAverage Discriminator Loss: 0.000368\n",
      "\n",
      "Train time for epoch #699 (step 699): 1.532794\n",
      "Batch #10\tAverage Generator Loss: 212.820863\tAverage Discriminator Loss: 0.000069\n",
      "\n",
      "Train time for epoch #700 (step 700): 1.458200\n",
      "Batch #10\tAverage Generator Loss: 203.525166\tAverage Discriminator Loss: 0.037697\n",
      "\n",
      "Train time for epoch #701 (step 701): 1.421067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 169.416808\tAverage Discriminator Loss: 0.001017\n",
      "\n",
      "Train time for epoch #702 (step 702): 1.438348\n",
      "Batch #10\tAverage Generator Loss: 179.282267\tAverage Discriminator Loss: 0.000468\n",
      "\n",
      "Train time for epoch #703 (step 703): 1.490591\n",
      "Batch #10\tAverage Generator Loss: 188.878354\tAverage Discriminator Loss: 0.000289\n",
      "\n",
      "Train time for epoch #704 (step 704): 1.400322\n",
      "Batch #10\tAverage Generator Loss: 214.932821\tAverage Discriminator Loss: 0.070780\n",
      "\n",
      "Train time for epoch #705 (step 705): 1.439070\n",
      "Batch #10\tAverage Generator Loss: 168.408396\tAverage Discriminator Loss: 0.072746\n",
      "\n",
      "Train time for epoch #706 (step 706): 1.406078\n",
      "Batch #10\tAverage Generator Loss: 161.596967\tAverage Discriminator Loss: 0.008560\n",
      "\n",
      "Train time for epoch #707 (step 707): 1.384185\n",
      "Batch #10\tAverage Generator Loss: 209.972568\tAverage Discriminator Loss: 0.068533\n",
      "\n",
      "Train time for epoch #708 (step 708): 1.299212\n",
      "Batch #10\tAverage Generator Loss: 177.907851\tAverage Discriminator Loss: 0.003150\n",
      "\n",
      "Train time for epoch #709 (step 709): 1.444996\n",
      "Batch #10\tAverage Generator Loss: 232.403604\tAverage Discriminator Loss: 0.005588\n",
      "\n",
      "Train time for epoch #710 (step 710): 1.429475\n",
      "Batch #10\tAverage Generator Loss: 231.206247\tAverage Discriminator Loss: 0.000542\n",
      "\n",
      "Train time for epoch #711 (step 711): 1.358362\n",
      "Batch #10\tAverage Generator Loss: 191.838702\tAverage Discriminator Loss: 0.004620\n",
      "\n",
      "Train time for epoch #712 (step 712): 1.508609\n",
      "Batch #10\tAverage Generator Loss: 238.678267\tAverage Discriminator Loss: 0.000270\n",
      "\n",
      "Train time for epoch #713 (step 713): 1.417762\n",
      "Batch #10\tAverage Generator Loss: 224.560141\tAverage Discriminator Loss: 0.000548\n",
      "\n",
      "Train time for epoch #714 (step 714): 1.440788\n",
      "Batch #10\tAverage Generator Loss: 206.434267\tAverage Discriminator Loss: 0.047358\n",
      "\n",
      "Train time for epoch #715 (step 715): 1.403039\n",
      "Batch #10\tAverage Generator Loss: 185.438809\tAverage Discriminator Loss: 0.001795\n",
      "\n",
      "Train time for epoch #716 (step 716): 1.507836\n",
      "Batch #10\tAverage Generator Loss: 202.708876\tAverage Discriminator Loss: 0.033319\n",
      "\n",
      "Train time for epoch #717 (step 717): 1.367539\n",
      "Batch #10\tAverage Generator Loss: 202.214909\tAverage Discriminator Loss: 0.006700\n",
      "\n",
      "Train time for epoch #718 (step 718): 1.451358\n",
      "Batch #10\tAverage Generator Loss: 172.407306\tAverage Discriminator Loss: 0.001884\n",
      "\n",
      "Train time for epoch #719 (step 719): 1.457734\n",
      "Batch #10\tAverage Generator Loss: 146.435029\tAverage Discriminator Loss: 0.000742\n",
      "\n",
      "Train time for epoch #720 (step 720): 1.493019\n",
      "Batch #10\tAverage Generator Loss: 188.855906\tAverage Discriminator Loss: 0.000344\n",
      "\n",
      "Train time for epoch #721 (step 721): 1.404616\n",
      "Batch #10\tAverage Generator Loss: 195.303069\tAverage Discriminator Loss: 0.000199\n",
      "\n",
      "Train time for epoch #722 (step 722): 1.415204\n",
      "Batch #10\tAverage Generator Loss: 185.116405\tAverage Discriminator Loss: 0.000429\n",
      "\n",
      "Train time for epoch #723 (step 723): 1.379061\n",
      "Batch #10\tAverage Generator Loss: 194.012135\tAverage Discriminator Loss: 0.000225\n",
      "\n",
      "Train time for epoch #724 (step 724): 1.508696\n",
      "Batch #10\tAverage Generator Loss: 176.170119\tAverage Discriminator Loss: 0.000431\n",
      "\n",
      "Train time for epoch #725 (step 725): 1.425754\n",
      "Batch #10\tAverage Generator Loss: 213.910216\tAverage Discriminator Loss: 0.000370\n",
      "\n",
      "Train time for epoch #726 (step 726): 1.430433\n",
      "Batch #10\tAverage Generator Loss: 185.366828\tAverage Discriminator Loss: 0.000332\n",
      "\n",
      "Train time for epoch #727 (step 727): 1.414151\n",
      "Batch #10\tAverage Generator Loss: 199.436057\tAverage Discriminator Loss: 0.002557\n",
      "\n",
      "Train time for epoch #728 (step 728): 1.369306\n",
      "Batch #10\tAverage Generator Loss: 179.766199\tAverage Discriminator Loss: 0.000801\n",
      "\n",
      "Train time for epoch #729 (step 729): 1.371320\n",
      "Batch #10\tAverage Generator Loss: 199.278186\tAverage Discriminator Loss: 0.001857\n",
      "\n",
      "Train time for epoch #730 (step 730): 1.361462\n",
      "Batch #10\tAverage Generator Loss: 178.142933\tAverage Discriminator Loss: 0.001517\n",
      "\n",
      "Train time for epoch #731 (step 731): 1.450710\n",
      "Batch #10\tAverage Generator Loss: 205.140486\tAverage Discriminator Loss: 0.000478\n",
      "\n",
      "Train time for epoch #732 (step 732): 1.493343\n",
      "Batch #10\tAverage Generator Loss: 185.156266\tAverage Discriminator Loss: 0.000293\n",
      "\n",
      "Train time for epoch #733 (step 733): 1.535107\n",
      "Batch #10\tAverage Generator Loss: 182.328198\tAverage Discriminator Loss: 0.000299\n",
      "\n",
      "Train time for epoch #734 (step 734): 1.583438\n",
      "Batch #10\tAverage Generator Loss: 216.674910\tAverage Discriminator Loss: 0.000299\n",
      "\n",
      "Train time for epoch #735 (step 735): 1.419869\n",
      "Batch #10\tAverage Generator Loss: 191.814265\tAverage Discriminator Loss: 0.127385\n",
      "\n",
      "Train time for epoch #736 (step 736): 1.412904\n",
      "Batch #10\tAverage Generator Loss: 181.507070\tAverage Discriminator Loss: 0.014768\n",
      "\n",
      "Train time for epoch #737 (step 737): 1.472887\n",
      "Batch #10\tAverage Generator Loss: 185.164605\tAverage Discriminator Loss: 0.009912\n",
      "\n",
      "Train time for epoch #738 (step 738): 1.520880\n",
      "Batch #10\tAverage Generator Loss: 198.500421\tAverage Discriminator Loss: 0.003174\n",
      "\n",
      "Train time for epoch #739 (step 739): 1.379712\n",
      "Batch #10\tAverage Generator Loss: 243.402995\tAverage Discriminator Loss: 0.001784\n",
      "\n",
      "Train time for epoch #740 (step 740): 1.360208\n",
      "Batch #10\tAverage Generator Loss: 216.530421\tAverage Discriminator Loss: 0.000932\n",
      "\n",
      "Train time for epoch #741 (step 741): 1.489577\n",
      "Batch #10\tAverage Generator Loss: 220.618956\tAverage Discriminator Loss: 0.000587\n",
      "\n",
      "Train time for epoch #742 (step 742): 1.415260\n",
      "Batch #10\tAverage Generator Loss: 213.526917\tAverage Discriminator Loss: 0.000507\n",
      "\n",
      "Train time for epoch #743 (step 743): 1.381193\n",
      "Batch #10\tAverage Generator Loss: 195.550214\tAverage Discriminator Loss: 0.000427\n",
      "\n",
      "Train time for epoch #744 (step 744): 1.515539\n",
      "Batch #10\tAverage Generator Loss: 212.295079\tAverage Discriminator Loss: 0.098064\n",
      "\n",
      "Train time for epoch #745 (step 745): 1.414353\n",
      "Batch #10\tAverage Generator Loss: 241.731400\tAverage Discriminator Loss: 0.001817\n",
      "\n",
      "Train time for epoch #746 (step 746): 1.351504\n",
      "Batch #10\tAverage Generator Loss: 195.668581\tAverage Discriminator Loss: 0.043248\n",
      "\n",
      "Train time for epoch #747 (step 747): 1.392624\n",
      "Batch #10\tAverage Generator Loss: 216.943369\tAverage Discriminator Loss: 0.011559\n",
      "\n",
      "Train time for epoch #748 (step 748): 1.527173\n",
      "Batch #10\tAverage Generator Loss: 224.616979\tAverage Discriminator Loss: 0.001059\n",
      "\n",
      "Train time for epoch #749 (step 749): 1.406602\n",
      "Batch #10\tAverage Generator Loss: 211.309232\tAverage Discriminator Loss: 0.000744\n",
      "\n",
      "Train time for epoch #750 (step 750): 1.470494\n",
      "Batch #10\tAverage Generator Loss: 225.106467\tAverage Discriminator Loss: 0.000520\n",
      "\n",
      "Train time for epoch #751 (step 751): 1.412489\n",
      "Batch #10\tAverage Generator Loss: 244.859277\tAverage Discriminator Loss: 0.000501\n",
      "\n",
      "Train time for epoch #752 (step 752): 1.497425\n",
      "Batch #10\tAverage Generator Loss: 220.877437\tAverage Discriminator Loss: 0.000496\n",
      "\n",
      "Train time for epoch #753 (step 753): 1.352649\n",
      "Batch #10\tAverage Generator Loss: 209.576062\tAverage Discriminator Loss: 0.000434\n",
      "\n",
      "Train time for epoch #754 (step 754): 1.320306\n",
      "Batch #10\tAverage Generator Loss: 193.016059\tAverage Discriminator Loss: 0.000565\n",
      "\n",
      "Train time for epoch #755 (step 755): 1.360697\n",
      "Batch #10\tAverage Generator Loss: 218.208696\tAverage Discriminator Loss: 0.000296\n",
      "\n",
      "Train time for epoch #756 (step 756): 1.511765\n",
      "Batch #10\tAverage Generator Loss: 231.651881\tAverage Discriminator Loss: 0.004051\n",
      "\n",
      "Train time for epoch #757 (step 757): 1.581219\n",
      "Batch #10\tAverage Generator Loss: 179.443161\tAverage Discriminator Loss: 0.005891\n",
      "\n",
      "Train time for epoch #758 (step 758): 1.325442\n",
      "Batch #10\tAverage Generator Loss: 218.489403\tAverage Discriminator Loss: 0.005515\n",
      "\n",
      "Train time for epoch #759 (step 759): 1.408649\n",
      "Batch #10\tAverage Generator Loss: 203.338942\tAverage Discriminator Loss: 0.000430\n",
      "\n",
      "Train time for epoch #760 (step 760): 1.483076\n",
      "Batch #10\tAverage Generator Loss: 237.953201\tAverage Discriminator Loss: 0.056917\n",
      "\n",
      "Train time for epoch #761 (step 761): 1.392711\n",
      "Batch #10\tAverage Generator Loss: 221.754576\tAverage Discriminator Loss: 0.000614\n",
      "\n",
      "Train time for epoch #762 (step 762): 1.593263\n",
      "Batch #10\tAverage Generator Loss: 250.940396\tAverage Discriminator Loss: 0.001017\n",
      "\n",
      "Train time for epoch #763 (step 763): 1.496056\n",
      "Batch #10\tAverage Generator Loss: 215.795732\tAverage Discriminator Loss: 0.032477\n",
      "\n",
      "Train time for epoch #764 (step 764): 1.403033\n",
      "Batch #10\tAverage Generator Loss: 254.420847\tAverage Discriminator Loss: 0.022040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #765 (step 765): 1.510212\n",
      "Batch #10\tAverage Generator Loss: 213.637144\tAverage Discriminator Loss: 0.015198\n",
      "\n",
      "Train time for epoch #766 (step 766): 1.359907\n",
      "Batch #10\tAverage Generator Loss: 218.179301\tAverage Discriminator Loss: 0.001102\n",
      "\n",
      "Train time for epoch #767 (step 767): 1.412319\n",
      "Batch #10\tAverage Generator Loss: 216.855792\tAverage Discriminator Loss: 0.004794\n",
      "\n",
      "Train time for epoch #768 (step 768): 1.507240\n",
      "Batch #10\tAverage Generator Loss: 236.932700\tAverage Discriminator Loss: 0.000727\n",
      "\n",
      "Train time for epoch #769 (step 769): 1.561524\n",
      "Batch #10\tAverage Generator Loss: 193.832074\tAverage Discriminator Loss: 0.002208\n",
      "\n",
      "Train time for epoch #770 (step 770): 1.505381\n",
      "Batch #10\tAverage Generator Loss: 245.759203\tAverage Discriminator Loss: 0.003460\n",
      "\n",
      "Train time for epoch #771 (step 771): 1.410935\n",
      "Batch #10\tAverage Generator Loss: 215.024332\tAverage Discriminator Loss: 0.000445\n",
      "\n",
      "Train time for epoch #772 (step 772): 1.473869\n",
      "Batch #10\tAverage Generator Loss: 247.450746\tAverage Discriminator Loss: 0.000339\n",
      "\n",
      "Train time for epoch #773 (step 773): 1.377588\n",
      "Batch #10\tAverage Generator Loss: 257.612743\tAverage Discriminator Loss: 0.000969\n",
      "\n",
      "Train time for epoch #774 (step 774): 1.433248\n",
      "Batch #10\tAverage Generator Loss: 259.751029\tAverage Discriminator Loss: 0.000420\n",
      "\n",
      "Train time for epoch #775 (step 775): 1.363471\n",
      "Batch #10\tAverage Generator Loss: 247.973878\tAverage Discriminator Loss: 0.000384\n",
      "\n",
      "Train time for epoch #776 (step 776): 1.309212\n",
      "Batch #10\tAverage Generator Loss: 251.249232\tAverage Discriminator Loss: 0.000494\n",
      "\n",
      "Train time for epoch #777 (step 777): 1.415898\n",
      "Batch #10\tAverage Generator Loss: 268.022176\tAverage Discriminator Loss: 0.000255\n",
      "\n",
      "Train time for epoch #778 (step 778): 1.469072\n",
      "Batch #10\tAverage Generator Loss: 216.350346\tAverage Discriminator Loss: 0.000454\n",
      "\n",
      "Train time for epoch #779 (step 779): 1.433177\n",
      "Batch #10\tAverage Generator Loss: 227.384351\tAverage Discriminator Loss: 0.005598\n",
      "\n",
      "Train time for epoch #780 (step 780): 1.484791\n",
      "Batch #10\tAverage Generator Loss: 270.523949\tAverage Discriminator Loss: 0.000463\n",
      "\n",
      "Train time for epoch #781 (step 781): 1.469228\n",
      "Batch #10\tAverage Generator Loss: 249.691394\tAverage Discriminator Loss: 0.001182\n",
      "\n",
      "Train time for epoch #782 (step 782): 1.427312\n",
      "Batch #10\tAverage Generator Loss: 244.023358\tAverage Discriminator Loss: 0.000393\n",
      "\n",
      "Train time for epoch #783 (step 783): 1.502352\n",
      "Batch #10\tAverage Generator Loss: 223.156450\tAverage Discriminator Loss: 0.000392\n",
      "\n",
      "Train time for epoch #784 (step 784): 1.502688\n",
      "Batch #10\tAverage Generator Loss: 259.200494\tAverage Discriminator Loss: 0.000283\n",
      "\n",
      "Train time for epoch #785 (step 785): 1.416688\n",
      "Batch #10\tAverage Generator Loss: 248.928152\tAverage Discriminator Loss: 0.000264\n",
      "\n",
      "Train time for epoch #786 (step 786): 1.450073\n",
      "Batch #10\tAverage Generator Loss: 236.612357\tAverage Discriminator Loss: 0.000576\n",
      "\n",
      "Train time for epoch #787 (step 787): 1.371454\n",
      "Batch #10\tAverage Generator Loss: 239.712872\tAverage Discriminator Loss: 0.000248\n",
      "\n",
      "Train time for epoch #788 (step 788): 1.411667\n",
      "Batch #10\tAverage Generator Loss: 240.998372\tAverage Discriminator Loss: 0.000712\n",
      "\n",
      "Train time for epoch #789 (step 789): 1.432903\n",
      "Batch #10\tAverage Generator Loss: 242.104118\tAverage Discriminator Loss: 0.000715\n",
      "\n",
      "Train time for epoch #790 (step 790): 1.422957\n",
      "Batch #10\tAverage Generator Loss: 256.462979\tAverage Discriminator Loss: 0.000285\n",
      "\n",
      "Train time for epoch #791 (step 791): 1.369239\n",
      "Batch #10\tAverage Generator Loss: 277.837854\tAverage Discriminator Loss: 0.000194\n",
      "\n",
      "Train time for epoch #792 (step 792): 1.551467\n",
      "Batch #10\tAverage Generator Loss: 228.827646\tAverage Discriminator Loss: 0.000180\n",
      "\n",
      "Train time for epoch #793 (step 793): 1.318416\n",
      "Batch #10\tAverage Generator Loss: 224.266745\tAverage Discriminator Loss: 0.002445\n",
      "\n",
      "Train time for epoch #794 (step 794): 1.427823\n",
      "Batch #10\tAverage Generator Loss: 278.034859\tAverage Discriminator Loss: 0.000153\n",
      "\n",
      "Train time for epoch #795 (step 795): 1.428062\n",
      "Batch #10\tAverage Generator Loss: 266.075397\tAverage Discriminator Loss: 0.000148\n",
      "\n",
      "Train time for epoch #796 (step 796): 1.438010\n",
      "Batch #10\tAverage Generator Loss: 223.352707\tAverage Discriminator Loss: 0.000408\n",
      "\n",
      "Train time for epoch #797 (step 797): 1.405375\n",
      "Batch #10\tAverage Generator Loss: 205.925347\tAverage Discriminator Loss: 0.015927\n",
      "\n",
      "Train time for epoch #798 (step 798): 1.360392\n",
      "Batch #10\tAverage Generator Loss: 202.025385\tAverage Discriminator Loss: 0.000129\n",
      "\n",
      "Train time for epoch #799 (step 799): 1.359595\n",
      "Batch #10\tAverage Generator Loss: 198.535860\tAverage Discriminator Loss: 0.000082\n",
      "\n",
      "Train time for epoch #800 (step 800): 1.361961\n",
      "Batch #10\tAverage Generator Loss: 200.440116\tAverage Discriminator Loss: 0.001705\n",
      "\n",
      "Train time for epoch #801 (step 801): 1.475613\n",
      "Batch #10\tAverage Generator Loss: 252.816101\tAverage Discriminator Loss: 0.000718\n",
      "\n",
      "Train time for epoch #802 (step 802): 1.372808\n",
      "Batch #10\tAverage Generator Loss: 246.766132\tAverage Discriminator Loss: 0.000389\n",
      "\n",
      "Train time for epoch #803 (step 803): 1.605304\n",
      "Batch #10\tAverage Generator Loss: 240.327914\tAverage Discriminator Loss: 0.003343\n",
      "\n",
      "Train time for epoch #804 (step 804): 1.380847\n",
      "Batch #10\tAverage Generator Loss: 232.121669\tAverage Discriminator Loss: 0.000314\n",
      "\n",
      "Train time for epoch #805 (step 805): 1.357324\n",
      "Batch #10\tAverage Generator Loss: 203.729189\tAverage Discriminator Loss: 0.001919\n",
      "\n",
      "Train time for epoch #806 (step 806): 1.352789\n",
      "Batch #10\tAverage Generator Loss: 200.230553\tAverage Discriminator Loss: 0.000497\n",
      "\n",
      "Train time for epoch #807 (step 807): 1.514783\n",
      "Batch #10\tAverage Generator Loss: 250.285251\tAverage Discriminator Loss: 0.081674\n",
      "\n",
      "Train time for epoch #808 (step 808): 1.423200\n",
      "Batch #10\tAverage Generator Loss: 208.518925\tAverage Discriminator Loss: 0.002717\n",
      "\n",
      "Train time for epoch #809 (step 809): 1.426605\n",
      "Batch #10\tAverage Generator Loss: 254.439337\tAverage Discriminator Loss: 0.000555\n",
      "\n",
      "Train time for epoch #810 (step 810): 1.488615\n",
      "Batch #10\tAverage Generator Loss: 273.460980\tAverage Discriminator Loss: 0.000689\n",
      "\n",
      "Train time for epoch #811 (step 811): 1.373648\n",
      "Batch #10\tAverage Generator Loss: 265.484950\tAverage Discriminator Loss: 0.000294\n",
      "\n",
      "Train time for epoch #812 (step 812): 1.359230\n",
      "Batch #10\tAverage Generator Loss: 277.287041\tAverage Discriminator Loss: 0.000189\n",
      "\n",
      "Train time for epoch #813 (step 813): 1.449070\n",
      "Batch #10\tAverage Generator Loss: 264.471198\tAverage Discriminator Loss: 0.000139\n",
      "\n",
      "Train time for epoch #814 (step 814): 1.369978\n",
      "Batch #10\tAverage Generator Loss: 257.285500\tAverage Discriminator Loss: 0.000794\n",
      "\n",
      "Train time for epoch #815 (step 815): 1.324387\n",
      "Batch #10\tAverage Generator Loss: 267.428868\tAverage Discriminator Loss: 0.000272\n",
      "\n",
      "Train time for epoch #816 (step 816): 1.498351\n",
      "Batch #10\tAverage Generator Loss: 250.388974\tAverage Discriminator Loss: 0.000201\n",
      "\n",
      "Train time for epoch #817 (step 817): 1.430390\n",
      "Batch #10\tAverage Generator Loss: 266.592075\tAverage Discriminator Loss: 0.000157\n",
      "\n",
      "Train time for epoch #818 (step 818): 1.469033\n",
      "Batch #10\tAverage Generator Loss: 256.902362\tAverage Discriminator Loss: 0.168031\n",
      "\n",
      "Train time for epoch #819 (step 819): 1.609446\n",
      "Batch #10\tAverage Generator Loss: 235.644308\tAverage Discriminator Loss: 0.038167\n",
      "\n",
      "Train time for epoch #820 (step 820): 1.393358\n",
      "Batch #10\tAverage Generator Loss: 195.485304\tAverage Discriminator Loss: 0.053409\n",
      "\n",
      "Train time for epoch #821 (step 821): 1.368585\n",
      "Batch #10\tAverage Generator Loss: 247.244319\tAverage Discriminator Loss: 0.000312\n",
      "\n",
      "Train time for epoch #822 (step 822): 1.498943\n",
      "Batch #10\tAverage Generator Loss: 219.018629\tAverage Discriminator Loss: 0.082653\n",
      "\n",
      "Train time for epoch #823 (step 823): 1.426339\n",
      "Batch #10\tAverage Generator Loss: 179.550389\tAverage Discriminator Loss: 0.110539\n",
      "\n",
      "Train time for epoch #824 (step 824): 1.450173\n",
      "Batch #10\tAverage Generator Loss: 245.060657\tAverage Discriminator Loss: 0.034389\n",
      "\n",
      "Train time for epoch #825 (step 825): 1.462500\n",
      "Batch #10\tAverage Generator Loss: 199.213849\tAverage Discriminator Loss: 0.017479\n",
      "\n",
      "Train time for epoch #826 (step 826): 1.360480\n",
      "Batch #10\tAverage Generator Loss: 160.723819\tAverage Discriminator Loss: 0.091344\n",
      "\n",
      "Train time for epoch #827 (step 827): 1.407211\n",
      "Batch #10\tAverage Generator Loss: 181.434307\tAverage Discriminator Loss: 0.014807\n",
      "\n",
      "Train time for epoch #828 (step 828): 1.464920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 231.470214\tAverage Discriminator Loss: 0.037348\n",
      "\n",
      "Train time for epoch #829 (step 829): 1.470273\n",
      "Batch #10\tAverage Generator Loss: 354.835716\tAverage Discriminator Loss: 0.020431\n",
      "\n",
      "Train time for epoch #830 (step 830): 1.459639\n",
      "Batch #10\tAverage Generator Loss: 229.055184\tAverage Discriminator Loss: 0.062973\n",
      "\n",
      "Train time for epoch #831 (step 831): 1.461375\n",
      "Batch #10\tAverage Generator Loss: 225.384559\tAverage Discriminator Loss: 0.020729\n",
      "\n",
      "Train time for epoch #832 (step 832): 1.580317\n",
      "Batch #10\tAverage Generator Loss: 246.445335\tAverage Discriminator Loss: 0.063484\n",
      "\n",
      "Train time for epoch #833 (step 833): 1.451766\n",
      "Batch #10\tAverage Generator Loss: 237.536139\tAverage Discriminator Loss: 0.047478\n",
      "\n",
      "Train time for epoch #834 (step 834): 1.415637\n",
      "Batch #10\tAverage Generator Loss: 213.023080\tAverage Discriminator Loss: 0.000309\n",
      "\n",
      "Train time for epoch #835 (step 835): 1.315217\n",
      "Batch #10\tAverage Generator Loss: 236.288939\tAverage Discriminator Loss: 0.084206\n",
      "\n",
      "Train time for epoch #836 (step 836): 1.453644\n",
      "Batch #10\tAverage Generator Loss: 301.344919\tAverage Discriminator Loss: 0.007791\n",
      "\n",
      "Train time for epoch #837 (step 837): 1.366004\n",
      "Batch #10\tAverage Generator Loss: 265.233899\tAverage Discriminator Loss: 0.000770\n",
      "\n",
      "Train time for epoch #838 (step 838): 1.456075\n",
      "Batch #10\tAverage Generator Loss: 283.454551\tAverage Discriminator Loss: 0.000154\n",
      "\n",
      "Train time for epoch #839 (step 839): 1.366485\n",
      "Batch #10\tAverage Generator Loss: 259.937077\tAverage Discriminator Loss: 0.017213\n",
      "\n",
      "Train time for epoch #840 (step 840): 1.308368\n",
      "Batch #10\tAverage Generator Loss: 331.316606\tAverage Discriminator Loss: 0.003821\n",
      "\n",
      "Train time for epoch #841 (step 841): 1.498953\n",
      "Batch #10\tAverage Generator Loss: 327.981058\tAverage Discriminator Loss: 0.001605\n",
      "\n",
      "Train time for epoch #842 (step 842): 1.370515\n",
      "Batch #10\tAverage Generator Loss: 296.840691\tAverage Discriminator Loss: 0.000797\n",
      "\n",
      "Train time for epoch #843 (step 843): 1.510479\n",
      "Batch #10\tAverage Generator Loss: 275.502380\tAverage Discriminator Loss: 0.000320\n",
      "\n",
      "Train time for epoch #844 (step 844): 1.365367\n",
      "Batch #10\tAverage Generator Loss: 314.942567\tAverage Discriminator Loss: 0.000283\n",
      "\n",
      "Train time for epoch #845 (step 845): 1.357438\n",
      "Batch #10\tAverage Generator Loss: 248.876733\tAverage Discriminator Loss: 0.000335\n",
      "\n",
      "Train time for epoch #846 (step 846): 1.364103\n",
      "Batch #10\tAverage Generator Loss: 297.177078\tAverage Discriminator Loss: 0.000336\n",
      "\n",
      "Train time for epoch #847 (step 847): 1.415471\n",
      "Batch #10\tAverage Generator Loss: 236.582812\tAverage Discriminator Loss: 0.053482\n",
      "\n",
      "Train time for epoch #848 (step 848): 1.329094\n",
      "Batch #10\tAverage Generator Loss: 335.557074\tAverage Discriminator Loss: 0.035707\n",
      "\n",
      "Train time for epoch #849 (step 849): 1.452997\n",
      "Batch #10\tAverage Generator Loss: 283.371786\tAverage Discriminator Loss: 0.000072\n",
      "\n",
      "Train time for epoch #850 (step 850): 1.440115\n",
      "Batch #10\tAverage Generator Loss: 251.863078\tAverage Discriminator Loss: 0.035753\n",
      "\n",
      "Train time for epoch #851 (step 851): 1.453975\n",
      "Batch #10\tAverage Generator Loss: 276.287611\tAverage Discriminator Loss: 0.009119\n",
      "\n",
      "Train time for epoch #852 (step 852): 1.432382\n",
      "Batch #10\tAverage Generator Loss: 279.720290\tAverage Discriminator Loss: 0.000954\n",
      "\n",
      "Train time for epoch #853 (step 853): 1.456587\n",
      "Batch #10\tAverage Generator Loss: 306.234282\tAverage Discriminator Loss: 0.001607\n",
      "\n",
      "Train time for epoch #854 (step 854): 1.374024\n",
      "Batch #10\tAverage Generator Loss: 285.381519\tAverage Discriminator Loss: 0.106739\n",
      "\n",
      "Train time for epoch #855 (step 855): 1.437126\n",
      "Batch #10\tAverage Generator Loss: 263.252627\tAverage Discriminator Loss: 0.013544\n",
      "\n",
      "Train time for epoch #856 (step 856): 1.375556\n",
      "Batch #10\tAverage Generator Loss: 305.832713\tAverage Discriminator Loss: 0.001005\n",
      "\n",
      "Train time for epoch #857 (step 857): 1.450049\n",
      "Batch #10\tAverage Generator Loss: 291.690414\tAverage Discriminator Loss: 0.000876\n",
      "\n",
      "Train time for epoch #858 (step 858): 1.591878\n",
      "Batch #10\tAverage Generator Loss: 311.630385\tAverage Discriminator Loss: 0.007719\n",
      "\n",
      "Train time for epoch #859 (step 859): 1.358414\n",
      "Batch #10\tAverage Generator Loss: 250.501722\tAverage Discriminator Loss: 0.000874\n",
      "\n",
      "Train time for epoch #860 (step 860): 1.369984\n",
      "Batch #10\tAverage Generator Loss: 330.001280\tAverage Discriminator Loss: 0.000700\n",
      "\n",
      "Train time for epoch #861 (step 861): 1.442078\n",
      "Batch #10\tAverage Generator Loss: 279.828539\tAverage Discriminator Loss: 0.000619\n",
      "\n",
      "Train time for epoch #862 (step 862): 1.354479\n",
      "Batch #10\tAverage Generator Loss: 278.032547\tAverage Discriminator Loss: 0.000511\n",
      "\n",
      "Train time for epoch #863 (step 863): 1.356491\n",
      "Batch #10\tAverage Generator Loss: 276.853496\tAverage Discriminator Loss: 0.000461\n",
      "\n",
      "Train time for epoch #864 (step 864): 1.440819\n",
      "Batch #10\tAverage Generator Loss: 271.067004\tAverage Discriminator Loss: 0.008133\n",
      "\n",
      "Train time for epoch #865 (step 865): 1.417665\n",
      "Batch #10\tAverage Generator Loss: 243.219151\tAverage Discriminator Loss: 0.005221\n",
      "\n",
      "Train time for epoch #866 (step 866): 1.368485\n",
      "Batch #10\tAverage Generator Loss: 305.112726\tAverage Discriminator Loss: 0.000475\n",
      "\n",
      "Train time for epoch #867 (step 867): 1.426276\n",
      "Batch #10\tAverage Generator Loss: 285.642017\tAverage Discriminator Loss: 0.000408\n",
      "\n",
      "Train time for epoch #868 (step 868): 1.377235\n",
      "Batch #10\tAverage Generator Loss: 285.364194\tAverage Discriminator Loss: 0.000339\n",
      "\n",
      "Train time for epoch #869 (step 869): 1.375234\n",
      "Batch #10\tAverage Generator Loss: 326.233054\tAverage Discriminator Loss: 0.000294\n",
      "\n",
      "Train time for epoch #870 (step 870): 1.448360\n",
      "Batch #10\tAverage Generator Loss: 301.442741\tAverage Discriminator Loss: 0.007855\n",
      "\n",
      "Train time for epoch #871 (step 871): 1.325802\n",
      "Batch #10\tAverage Generator Loss: 285.881740\tAverage Discriminator Loss: 0.001865\n",
      "\n",
      "Train time for epoch #872 (step 872): 1.427311\n",
      "Batch #10\tAverage Generator Loss: 317.739940\tAverage Discriminator Loss: 0.000479\n",
      "\n",
      "Train time for epoch #873 (step 873): 1.478615\n",
      "Batch #10\tAverage Generator Loss: 265.435069\tAverage Discriminator Loss: 0.000392\n",
      "\n",
      "Train time for epoch #874 (step 874): 1.558586\n",
      "Batch #10\tAverage Generator Loss: 283.194411\tAverage Discriminator Loss: 0.000329\n",
      "\n",
      "Train time for epoch #875 (step 875): 1.437192\n",
      "Batch #10\tAverage Generator Loss: 296.169806\tAverage Discriminator Loss: 0.006341\n",
      "\n",
      "Train time for epoch #876 (step 876): 1.494982\n",
      "Batch #10\tAverage Generator Loss: 276.423920\tAverage Discriminator Loss: 0.001590\n",
      "\n",
      "Train time for epoch #877 (step 877): 1.473031\n",
      "Batch #10\tAverage Generator Loss: 291.022636\tAverage Discriminator Loss: 0.000737\n",
      "\n",
      "Train time for epoch #878 (step 878): 1.516515\n",
      "Batch #10\tAverage Generator Loss: 295.838557\tAverage Discriminator Loss: 0.000495\n",
      "\n",
      "Train time for epoch #879 (step 879): 1.516053\n",
      "Batch #10\tAverage Generator Loss: 297.811309\tAverage Discriminator Loss: 0.000347\n",
      "\n",
      "Train time for epoch #880 (step 880): 1.457480\n",
      "Batch #10\tAverage Generator Loss: 353.365591\tAverage Discriminator Loss: 0.000290\n",
      "\n",
      "Train time for epoch #881 (step 881): 1.502415\n",
      "Batch #10\tAverage Generator Loss: 293.870792\tAverage Discriminator Loss: 0.065864\n",
      "\n",
      "Train time for epoch #882 (step 882): 1.455422\n",
      "Batch #10\tAverage Generator Loss: 330.398126\tAverage Discriminator Loss: 0.001267\n",
      "\n",
      "Train time for epoch #883 (step 883): 1.427901\n",
      "Batch #10\tAverage Generator Loss: 231.455029\tAverage Discriminator Loss: 0.000042\n",
      "\n",
      "Train time for epoch #884 (step 884): 1.558225\n",
      "Batch #10\tAverage Generator Loss: 313.580801\tAverage Discriminator Loss: 0.000068\n",
      "\n",
      "Train time for epoch #885 (step 885): 1.347837\n",
      "Batch #10\tAverage Generator Loss: 266.900414\tAverage Discriminator Loss: 0.000108\n",
      "\n",
      "Train time for epoch #886 (step 886): 1.332943\n",
      "Batch #10\tAverage Generator Loss: 293.498065\tAverage Discriminator Loss: 0.316802\n",
      "\n",
      "Train time for epoch #887 (step 887): 1.493739\n",
      "Batch #10\tAverage Generator Loss: 266.433342\tAverage Discriminator Loss: 0.002938\n",
      "\n",
      "Train time for epoch #888 (step 888): 1.424336\n",
      "Batch #10\tAverage Generator Loss: 244.407551\tAverage Discriminator Loss: 0.089161\n",
      "\n",
      "Train time for epoch #889 (step 889): 1.534258\n",
      "Batch #10\tAverage Generator Loss: 241.789915\tAverage Discriminator Loss: 0.005026\n",
      "\n",
      "Train time for epoch #890 (step 890): 1.377419\n",
      "Batch #10\tAverage Generator Loss: 241.465964\tAverage Discriminator Loss: 0.003106\n",
      "\n",
      "Train time for epoch #891 (step 891): 1.584396\n",
      "Batch #10\tAverage Generator Loss: 267.363950\tAverage Discriminator Loss: 0.002021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #892 (step 892): 1.318129\n",
      "Batch #10\tAverage Generator Loss: 259.698814\tAverage Discriminator Loss: 0.000544\n",
      "\n",
      "Train time for epoch #893 (step 893): 1.350923\n",
      "Batch #10\tAverage Generator Loss: 263.833115\tAverage Discriminator Loss: 0.041513\n",
      "\n",
      "Train time for epoch #894 (step 894): 1.354183\n",
      "Batch #10\tAverage Generator Loss: 285.074337\tAverage Discriminator Loss: 0.003593\n",
      "\n",
      "Train time for epoch #895 (step 895): 1.379063\n",
      "Batch #10\tAverage Generator Loss: 288.622594\tAverage Discriminator Loss: 0.001359\n",
      "\n",
      "Train time for epoch #896 (step 896): 1.362660\n",
      "Batch #10\tAverage Generator Loss: 250.629749\tAverage Discriminator Loss: 0.001843\n",
      "\n",
      "Train time for epoch #897 (step 897): 1.419230\n",
      "Batch #10\tAverage Generator Loss: 272.119480\tAverage Discriminator Loss: 0.001283\n",
      "\n",
      "Train time for epoch #898 (step 898): 1.362259\n",
      "Batch #10\tAverage Generator Loss: 267.780905\tAverage Discriminator Loss: 0.000695\n",
      "\n",
      "Train time for epoch #899 (step 899): 1.372011\n",
      "Batch #10\tAverage Generator Loss: 284.081718\tAverage Discriminator Loss: 0.000691\n",
      "\n",
      "Train time for epoch #900 (step 900): 1.358432\n",
      "Batch #10\tAverage Generator Loss: 316.978973\tAverage Discriminator Loss: 0.000484\n",
      "\n",
      "Train time for epoch #901 (step 901): 1.534464\n",
      "Batch #10\tAverage Generator Loss: 274.437052\tAverage Discriminator Loss: 0.000467\n",
      "\n",
      "Train time for epoch #902 (step 902): 1.411831\n",
      "Batch #10\tAverage Generator Loss: 309.102382\tAverage Discriminator Loss: 0.000380\n",
      "\n",
      "Train time for epoch #903 (step 903): 1.453083\n",
      "Batch #10\tAverage Generator Loss: 300.010912\tAverage Discriminator Loss: 0.000336\n",
      "\n",
      "Train time for epoch #904 (step 904): 1.419165\n",
      "Batch #10\tAverage Generator Loss: 324.579895\tAverage Discriminator Loss: 0.004132\n",
      "\n",
      "Train time for epoch #905 (step 905): 1.331854\n",
      "Batch #10\tAverage Generator Loss: 228.942377\tAverage Discriminator Loss: 0.000504\n",
      "\n",
      "Train time for epoch #906 (step 906): 1.397165\n",
      "Batch #10\tAverage Generator Loss: 262.691052\tAverage Discriminator Loss: 0.000509\n",
      "\n",
      "Train time for epoch #907 (step 907): 1.453166\n",
      "Batch #10\tAverage Generator Loss: 286.006700\tAverage Discriminator Loss: 0.000389\n",
      "\n",
      "Train time for epoch #908 (step 908): 1.411301\n",
      "Batch #10\tAverage Generator Loss: 311.163362\tAverage Discriminator Loss: 0.000326\n",
      "\n",
      "Train time for epoch #909 (step 909): 1.433953\n",
      "Batch #10\tAverage Generator Loss: 278.024484\tAverage Discriminator Loss: 0.000560\n",
      "\n",
      "Train time for epoch #910 (step 910): 1.414623\n",
      "Batch #10\tAverage Generator Loss: 260.659192\tAverage Discriminator Loss: 0.000415\n",
      "\n",
      "Train time for epoch #911 (step 911): 1.485047\n",
      "Batch #10\tAverage Generator Loss: 280.266634\tAverage Discriminator Loss: 0.008415\n",
      "\n",
      "Train time for epoch #912 (step 912): 1.442620\n",
      "Batch #10\tAverage Generator Loss: 309.334184\tAverage Discriminator Loss: 0.000468\n",
      "\n",
      "Train time for epoch #913 (step 913): 1.454567\n",
      "Batch #10\tAverage Generator Loss: 320.779439\tAverage Discriminator Loss: 0.001282\n",
      "\n",
      "Train time for epoch #914 (step 914): 1.420382\n",
      "Batch #10\tAverage Generator Loss: 340.861406\tAverage Discriminator Loss: 0.000525\n",
      "\n",
      "Train time for epoch #915 (step 915): 1.398043\n",
      "Batch #10\tAverage Generator Loss: 291.718317\tAverage Discriminator Loss: 0.000400\n",
      "\n",
      "Train time for epoch #916 (step 916): 1.406916\n",
      "Batch #10\tAverage Generator Loss: 272.605762\tAverage Discriminator Loss: 0.000416\n",
      "\n",
      "Train time for epoch #917 (step 917): 1.396735\n",
      "Batch #10\tAverage Generator Loss: 291.493527\tAverage Discriminator Loss: 0.000318\n",
      "\n",
      "Train time for epoch #918 (step 918): 1.413913\n",
      "Batch #10\tAverage Generator Loss: 316.334479\tAverage Discriminator Loss: 0.000277\n",
      "\n",
      "Train time for epoch #919 (step 919): 1.396589\n",
      "Batch #10\tAverage Generator Loss: 306.691478\tAverage Discriminator Loss: 0.000243\n",
      "\n",
      "Train time for epoch #920 (step 920): 1.402726\n",
      "Batch #10\tAverage Generator Loss: 324.005698\tAverage Discriminator Loss: 0.000232\n",
      "\n",
      "Train time for epoch #921 (step 921): 1.368108\n",
      "Batch #10\tAverage Generator Loss: 293.631759\tAverage Discriminator Loss: 0.007533\n",
      "\n",
      "Train time for epoch #922 (step 922): 1.412950\n",
      "Batch #10\tAverage Generator Loss: 320.600879\tAverage Discriminator Loss: 0.000983\n",
      "\n",
      "Train time for epoch #923 (step 923): 1.380293\n",
      "Batch #10\tAverage Generator Loss: 270.497693\tAverage Discriminator Loss: 0.000257\n",
      "\n",
      "Train time for epoch #924 (step 924): 1.518153\n",
      "Batch #10\tAverage Generator Loss: 328.290594\tAverage Discriminator Loss: 0.000178\n",
      "\n",
      "Train time for epoch #925 (step 925): 1.419620\n",
      "Batch #10\tAverage Generator Loss: 258.526537\tAverage Discriminator Loss: 0.000162\n",
      "\n",
      "Train time for epoch #926 (step 926): 1.424999\n",
      "Batch #10\tAverage Generator Loss: 311.899008\tAverage Discriminator Loss: 0.000151\n",
      "\n",
      "Train time for epoch #927 (step 927): 1.396474\n",
      "Batch #10\tAverage Generator Loss: 312.194894\tAverage Discriminator Loss: 0.000177\n",
      "\n",
      "Train time for epoch #928 (step 928): 1.370962\n",
      "Batch #10\tAverage Generator Loss: 278.152295\tAverage Discriminator Loss: 0.029369\n",
      "\n",
      "Train time for epoch #929 (step 929): 1.562387\n",
      "Batch #10\tAverage Generator Loss: 320.849716\tAverage Discriminator Loss: 0.000188\n",
      "\n",
      "Train time for epoch #930 (step 930): 1.476801\n",
      "Batch #10\tAverage Generator Loss: 315.046339\tAverage Discriminator Loss: 0.076524\n",
      "\n",
      "Train time for epoch #931 (step 931): 1.466010\n",
      "Batch #10\tAverage Generator Loss: 274.005077\tAverage Discriminator Loss: 0.001714\n",
      "\n",
      "Train time for epoch #932 (step 932): 1.547829\n",
      "Batch #10\tAverage Generator Loss: 298.351385\tAverage Discriminator Loss: 0.000267\n",
      "\n",
      "Train time for epoch #933 (step 933): 1.458434\n",
      "Batch #10\tAverage Generator Loss: 262.514001\tAverage Discriminator Loss: 0.000223\n",
      "\n",
      "Train time for epoch #934 (step 934): 1.441823\n",
      "Batch #10\tAverage Generator Loss: 260.665370\tAverage Discriminator Loss: 0.000196\n",
      "\n",
      "Train time for epoch #935 (step 935): 1.429695\n",
      "Batch #10\tAverage Generator Loss: 270.951960\tAverage Discriminator Loss: 0.000150\n",
      "\n",
      "Train time for epoch #936 (step 936): 1.463767\n",
      "Batch #10\tAverage Generator Loss: 272.104335\tAverage Discriminator Loss: 0.000153\n",
      "\n",
      "Train time for epoch #937 (step 937): 1.427785\n",
      "Batch #10\tAverage Generator Loss: 286.942427\tAverage Discriminator Loss: 0.048869\n",
      "\n",
      "Train time for epoch #938 (step 938): 1.492164\n",
      "Batch #10\tAverage Generator Loss: 280.710222\tAverage Discriminator Loss: 0.000189\n",
      "\n",
      "Train time for epoch #939 (step 939): 1.371694\n",
      "Batch #10\tAverage Generator Loss: 284.138171\tAverage Discriminator Loss: 0.000699\n",
      "\n",
      "Train time for epoch #940 (step 940): 1.375551\n",
      "Batch #10\tAverage Generator Loss: 281.622405\tAverage Discriminator Loss: 0.000134\n",
      "\n",
      "Train time for epoch #941 (step 941): 1.420483\n",
      "Batch #10\tAverage Generator Loss: 257.861655\tAverage Discriminator Loss: 0.000844\n",
      "\n",
      "Train time for epoch #942 (step 942): 1.590224\n",
      "Batch #10\tAverage Generator Loss: 345.628665\tAverage Discriminator Loss: 0.001023\n",
      "\n",
      "Train time for epoch #943 (step 943): 1.378011\n",
      "Batch #10\tAverage Generator Loss: 299.339572\tAverage Discriminator Loss: 0.000252\n",
      "\n",
      "Train time for epoch #944 (step 944): 1.332170\n",
      "Batch #10\tAverage Generator Loss: 263.881356\tAverage Discriminator Loss: 0.000187\n",
      "\n",
      "Train time for epoch #945 (step 945): 1.416853\n",
      "Batch #10\tAverage Generator Loss: 302.434062\tAverage Discriminator Loss: 0.000153\n",
      "\n",
      "Train time for epoch #946 (step 946): 1.438708\n",
      "Batch #10\tAverage Generator Loss: 306.170271\tAverage Discriminator Loss: 0.000152\n",
      "\n",
      "Train time for epoch #947 (step 947): 1.379282\n",
      "Batch #10\tAverage Generator Loss: 281.631702\tAverage Discriminator Loss: 0.000147\n",
      "\n",
      "Train time for epoch #948 (step 948): 1.482815\n",
      "Batch #10\tAverage Generator Loss: 283.525184\tAverage Discriminator Loss: 0.000291\n",
      "\n",
      "Train time for epoch #949 (step 949): 1.380664\n",
      "Batch #10\tAverage Generator Loss: 261.099818\tAverage Discriminator Loss: 0.010873\n",
      "\n",
      "Train time for epoch #950 (step 950): 1.550753\n",
      "Batch #10\tAverage Generator Loss: 331.334328\tAverage Discriminator Loss: 0.002576\n",
      "\n",
      "Train time for epoch #951 (step 951): 1.400318\n",
      "Batch #10\tAverage Generator Loss: 291.915623\tAverage Discriminator Loss: 0.000603\n",
      "\n",
      "Train time for epoch #952 (step 952): 1.503335\n",
      "Batch #10\tAverage Generator Loss: 307.189832\tAverage Discriminator Loss: 0.000324\n",
      "\n",
      "Train time for epoch #953 (step 953): 1.421861\n",
      "Batch #10\tAverage Generator Loss: 322.414285\tAverage Discriminator Loss: 0.000258\n",
      "\n",
      "Train time for epoch #954 (step 954): 1.346220\n",
      "Batch #10\tAverage Generator Loss: 264.413590\tAverage Discriminator Loss: 0.000219\n",
      "\n",
      "Train time for epoch #955 (step 955): 1.338476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 336.636316\tAverage Discriminator Loss: 0.000310\n",
      "\n",
      "Train time for epoch #956 (step 956): 1.464485\n",
      "Batch #10\tAverage Generator Loss: 346.242828\tAverage Discriminator Loss: 0.011514\n",
      "\n",
      "Train time for epoch #957 (step 957): 1.416927\n",
      "Batch #10\tAverage Generator Loss: 377.953244\tAverage Discriminator Loss: 0.002739\n",
      "\n",
      "Train time for epoch #958 (step 958): 1.318789\n",
      "Batch #10\tAverage Generator Loss: 360.977338\tAverage Discriminator Loss: 0.000489\n",
      "\n",
      "Train time for epoch #959 (step 959): 1.381023\n",
      "Batch #10\tAverage Generator Loss: 327.004575\tAverage Discriminator Loss: 0.000310\n",
      "\n",
      "Train time for epoch #960 (step 960): 1.436071\n",
      "Batch #10\tAverage Generator Loss: 332.275026\tAverage Discriminator Loss: 0.000302\n",
      "\n",
      "Train time for epoch #961 (step 961): 1.480705\n",
      "Batch #10\tAverage Generator Loss: 313.721806\tAverage Discriminator Loss: 0.000890\n",
      "\n",
      "Train time for epoch #962 (step 962): 1.445446\n",
      "Batch #10\tAverage Generator Loss: 316.530408\tAverage Discriminator Loss: 0.000263\n",
      "\n",
      "Train time for epoch #963 (step 963): 1.524665\n",
      "Batch #10\tAverage Generator Loss: 321.032040\tAverage Discriminator Loss: 0.000264\n",
      "\n",
      "Train time for epoch #964 (step 964): 1.381250\n",
      "Batch #10\tAverage Generator Loss: 326.404805\tAverage Discriminator Loss: 0.000247\n",
      "\n",
      "Train time for epoch #965 (step 965): 1.321513\n",
      "Batch #10\tAverage Generator Loss: 327.890097\tAverage Discriminator Loss: 0.000228\n",
      "\n",
      "Train time for epoch #966 (step 966): 1.514901\n",
      "Batch #10\tAverage Generator Loss: 332.304328\tAverage Discriminator Loss: 0.000193\n",
      "\n",
      "Train time for epoch #967 (step 967): 1.384855\n",
      "Batch #10\tAverage Generator Loss: 281.413583\tAverage Discriminator Loss: 0.000182\n",
      "\n",
      "Train time for epoch #968 (step 968): 1.374024\n",
      "Batch #10\tAverage Generator Loss: 290.063646\tAverage Discriminator Loss: 0.000174\n",
      "\n",
      "Train time for epoch #969 (step 969): 1.372610\n",
      "Batch #10\tAverage Generator Loss: 301.074184\tAverage Discriminator Loss: 0.000165\n",
      "\n",
      "Train time for epoch #970 (step 970): 1.426506\n",
      "Batch #10\tAverage Generator Loss: 335.205858\tAverage Discriminator Loss: 0.000365\n",
      "\n",
      "Train time for epoch #971 (step 971): 1.496819\n",
      "Batch #10\tAverage Generator Loss: 309.419435\tAverage Discriminator Loss: 0.000158\n",
      "\n",
      "Train time for epoch #972 (step 972): 1.451434\n",
      "Batch #10\tAverage Generator Loss: 335.929197\tAverage Discriminator Loss: 0.527772\n",
      "\n",
      "Train time for epoch #973 (step 973): 1.420373\n",
      "Batch #10\tAverage Generator Loss: 228.629592\tAverage Discriminator Loss: 0.017305\n",
      "\n",
      "Train time for epoch #974 (step 974): 1.398915\n",
      "Batch #10\tAverage Generator Loss: 210.932229\tAverage Discriminator Loss: 0.115057\n",
      "\n",
      "Train time for epoch #975 (step 975): 1.388149\n",
      "Batch #10\tAverage Generator Loss: 297.553542\tAverage Discriminator Loss: 0.002988\n",
      "\n",
      "Train time for epoch #976 (step 976): 1.380360\n",
      "Batch #10\tAverage Generator Loss: 266.385526\tAverage Discriminator Loss: 0.000607\n",
      "\n",
      "Train time for epoch #977 (step 977): 1.424522\n",
      "Batch #10\tAverage Generator Loss: 347.130800\tAverage Discriminator Loss: 0.000510\n",
      "\n",
      "Train time for epoch #978 (step 978): 1.519939\n",
      "Batch #10\tAverage Generator Loss: 267.122905\tAverage Discriminator Loss: 0.000537\n",
      "\n",
      "Train time for epoch #979 (step 979): 1.450603\n",
      "Batch #10\tAverage Generator Loss: 346.614067\tAverage Discriminator Loss: 0.000567\n",
      "\n",
      "Train time for epoch #980 (step 980): 1.300329\n",
      "Batch #10\tAverage Generator Loss: 288.245547\tAverage Discriminator Loss: 0.000291\n",
      "\n",
      "Train time for epoch #981 (step 981): 1.558136\n",
      "Batch #10\tAverage Generator Loss: 249.569083\tAverage Discriminator Loss: 0.000266\n",
      "\n",
      "Train time for epoch #982 (step 982): 1.370384\n",
      "Batch #10\tAverage Generator Loss: 316.951779\tAverage Discriminator Loss: 0.001922\n",
      "\n",
      "Train time for epoch #983 (step 983): 1.464842\n",
      "Batch #10\tAverage Generator Loss: 330.126066\tAverage Discriminator Loss: 0.010421\n",
      "\n",
      "Train time for epoch #984 (step 984): 1.408510\n",
      "Batch #10\tAverage Generator Loss: 306.734226\tAverage Discriminator Loss: 0.041144\n",
      "\n",
      "Train time for epoch #985 (step 985): 1.418716\n",
      "Batch #10\tAverage Generator Loss: 291.145491\tAverage Discriminator Loss: 0.025383\n",
      "\n",
      "Train time for epoch #986 (step 986): 1.400066\n",
      "Batch #10\tAverage Generator Loss: 339.235586\tAverage Discriminator Loss: 0.017183\n",
      "\n",
      "Train time for epoch #987 (step 987): 1.413078\n",
      "Batch #10\tAverage Generator Loss: 298.236719\tAverage Discriminator Loss: 0.000136\n",
      "\n",
      "Train time for epoch #988 (step 988): 1.719290\n",
      "Batch #10\tAverage Generator Loss: 280.536017\tAverage Discriminator Loss: 0.000109\n",
      "\n",
      "Train time for epoch #989 (step 989): 1.499413\n",
      "Batch #10\tAverage Generator Loss: 267.496097\tAverage Discriminator Loss: 0.204151\n",
      "\n",
      "Train time for epoch #990 (step 990): 1.564554\n",
      "Batch #10\tAverage Generator Loss: 278.537831\tAverage Discriminator Loss: 0.000609\n",
      "\n",
      "Train time for epoch #991 (step 991): 1.386049\n",
      "Batch #10\tAverage Generator Loss: 299.317416\tAverage Discriminator Loss: 0.000180\n",
      "\n",
      "Train time for epoch #992 (step 992): 1.394775\n",
      "Batch #10\tAverage Generator Loss: 264.819611\tAverage Discriminator Loss: 0.007327\n",
      "\n",
      "Train time for epoch #993 (step 993): 1.310514\n",
      "Batch #10\tAverage Generator Loss: 312.781971\tAverage Discriminator Loss: 0.004383\n",
      "\n",
      "Train time for epoch #994 (step 994): 1.427536\n",
      "Batch #10\tAverage Generator Loss: 302.692825\tAverage Discriminator Loss: 0.001629\n",
      "\n",
      "Train time for epoch #995 (step 995): 1.331305\n",
      "Batch #10\tAverage Generator Loss: 266.570519\tAverage Discriminator Loss: 0.000804\n",
      "\n",
      "Train time for epoch #996 (step 996): 1.449937\n",
      "Batch #10\tAverage Generator Loss: 285.486746\tAverage Discriminator Loss: 0.000657\n",
      "\n",
      "Train time for epoch #997 (step 997): 1.402201\n",
      "Batch #10\tAverage Generator Loss: 347.075073\tAverage Discriminator Loss: 0.000395\n",
      "\n",
      "Train time for epoch #998 (step 998): 1.573340\n",
      "Batch #10\tAverage Generator Loss: 311.095653\tAverage Discriminator Loss: 0.000345\n",
      "\n",
      "Train time for epoch #999 (step 999): 1.354795\n",
      "Batch #10\tAverage Generator Loss: 291.598466\tAverage Discriminator Loss: 0.000921\n",
      "\n",
      "Train time for epoch #1000 (step 1000): 1.579093\n",
      "Batch #10\tAverage Generator Loss: 314.635719\tAverage Discriminator Loss: 0.000328\n",
      "\n",
      "Train time for epoch #1001 (step 1001): 1.426381\n",
      "Batch #10\tAverage Generator Loss: 317.198013\tAverage Discriminator Loss: 0.000372\n",
      "\n",
      "Train time for epoch #1002 (step 1002): 1.427135\n",
      "Batch #10\tAverage Generator Loss: 331.921358\tAverage Discriminator Loss: 0.000951\n",
      "\n",
      "Train time for epoch #1003 (step 1003): 1.430650\n",
      "Batch #10\tAverage Generator Loss: 320.184115\tAverage Discriminator Loss: 0.000825\n",
      "\n",
      "Train time for epoch #1004 (step 1004): 1.409864\n",
      "Batch #10\tAverage Generator Loss: 263.199857\tAverage Discriminator Loss: 0.333942\n",
      "\n",
      "Train time for epoch #1005 (step 1005): 1.357955\n",
      "Batch #10\tAverage Generator Loss: 353.849310\tAverage Discriminator Loss: 0.073396\n",
      "\n",
      "Train time for epoch #1006 (step 1006): 1.448251\n",
      "Batch #10\tAverage Generator Loss: 410.871173\tAverage Discriminator Loss: 0.034613\n",
      "\n",
      "Train time for epoch #1007 (step 1007): 1.393162\n",
      "Batch #10\tAverage Generator Loss: 387.770789\tAverage Discriminator Loss: 0.000432\n",
      "\n",
      "Train time for epoch #1008 (step 1008): 1.551805\n",
      "Batch #10\tAverage Generator Loss: 307.521689\tAverage Discriminator Loss: 0.022611\n",
      "\n",
      "Train time for epoch #1009 (step 1009): 1.425178\n",
      "Batch #10\tAverage Generator Loss: 373.700029\tAverage Discriminator Loss: 0.002520\n",
      "\n",
      "Train time for epoch #1010 (step 1010): 1.421604\n",
      "Batch #10\tAverage Generator Loss: 342.669868\tAverage Discriminator Loss: 0.000296\n",
      "\n",
      "Train time for epoch #1011 (step 1011): 1.382780\n",
      "Batch #10\tAverage Generator Loss: 326.171954\tAverage Discriminator Loss: 0.000246\n",
      "\n",
      "Train time for epoch #1012 (step 1012): 1.413217\n",
      "Batch #10\tAverage Generator Loss: 336.891261\tAverage Discriminator Loss: 0.015637\n",
      "\n",
      "Train time for epoch #1013 (step 1013): 1.490417\n",
      "Batch #10\tAverage Generator Loss: 357.678825\tAverage Discriminator Loss: 0.070291\n",
      "\n",
      "Train time for epoch #1014 (step 1014): 1.402895\n",
      "Batch #10\tAverage Generator Loss: 370.894325\tAverage Discriminator Loss: 0.002126\n",
      "\n",
      "Train time for epoch #1015 (step 1015): 1.550987\n",
      "Batch #10\tAverage Generator Loss: 355.691057\tAverage Discriminator Loss: 0.000308\n",
      "\n",
      "Train time for epoch #1016 (step 1016): 1.403056\n",
      "Batch #10\tAverage Generator Loss: 344.184656\tAverage Discriminator Loss: 0.000163\n",
      "\n",
      "Train time for epoch #1017 (step 1017): 1.439187\n",
      "Batch #10\tAverage Generator Loss: 364.795244\tAverage Discriminator Loss: 0.000120\n",
      "\n",
      "Train time for epoch #1018 (step 1018): 1.428421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 321.768631\tAverage Discriminator Loss: 0.000107\n",
      "\n",
      "Train time for epoch #1019 (step 1019): 1.390447\n",
      "Batch #10\tAverage Generator Loss: 348.558006\tAverage Discriminator Loss: 0.002897\n",
      "\n",
      "Train time for epoch #1020 (step 1020): 1.382917\n",
      "Batch #10\tAverage Generator Loss: 369.347723\tAverage Discriminator Loss: 0.000274\n",
      "\n",
      "Train time for epoch #1021 (step 1021): 1.317954\n",
      "Batch #10\tAverage Generator Loss: 376.375041\tAverage Discriminator Loss: 0.000181\n",
      "\n",
      "Train time for epoch #1022 (step 1022): 1.363926\n",
      "Batch #10\tAverage Generator Loss: 340.664125\tAverage Discriminator Loss: 0.000170\n",
      "\n",
      "Train time for epoch #1023 (step 1023): 1.367105\n",
      "Batch #10\tAverage Generator Loss: 318.461186\tAverage Discriminator Loss: 0.010739\n",
      "\n",
      "Train time for epoch #1024 (step 1024): 1.376239\n",
      "Batch #10\tAverage Generator Loss: 266.395428\tAverage Discriminator Loss: 0.125676\n",
      "\n",
      "Train time for epoch #1025 (step 1025): 1.456864\n",
      "Batch #10\tAverage Generator Loss: 349.800656\tAverage Discriminator Loss: 0.016213\n",
      "\n",
      "Train time for epoch #1026 (step 1026): 1.492999\n",
      "Batch #10\tAverage Generator Loss: 365.225674\tAverage Discriminator Loss: 0.000310\n",
      "\n",
      "Train time for epoch #1027 (step 1027): 1.404214\n",
      "Batch #10\tAverage Generator Loss: 325.762296\tAverage Discriminator Loss: 0.012371\n",
      "\n",
      "Train time for epoch #1028 (step 1028): 1.363546\n",
      "Batch #10\tAverage Generator Loss: 323.601122\tAverage Discriminator Loss: 0.000120\n",
      "\n",
      "Train time for epoch #1029 (step 1029): 1.413609\n",
      "Batch #10\tAverage Generator Loss: 342.092752\tAverage Discriminator Loss: 0.000076\n",
      "\n",
      "Train time for epoch #1030 (step 1030): 1.371266\n",
      "Batch #10\tAverage Generator Loss: 371.375742\tAverage Discriminator Loss: 0.000072\n",
      "\n",
      "Train time for epoch #1031 (step 1031): 1.479353\n",
      "Batch #10\tAverage Generator Loss: 298.143212\tAverage Discriminator Loss: 0.083111\n",
      "\n",
      "Train time for epoch #1032 (step 1032): 1.430472\n",
      "Batch #10\tAverage Generator Loss: 299.164742\tAverage Discriminator Loss: 0.000537\n",
      "\n",
      "Train time for epoch #1033 (step 1033): 1.499353\n",
      "Batch #10\tAverage Generator Loss: 336.281320\tAverage Discriminator Loss: 0.005713\n",
      "\n",
      "Train time for epoch #1034 (step 1034): 1.432835\n",
      "Batch #10\tAverage Generator Loss: 307.212280\tAverage Discriminator Loss: 0.000230\n",
      "\n",
      "Train time for epoch #1035 (step 1035): 1.500108\n",
      "Batch #10\tAverage Generator Loss: 326.317004\tAverage Discriminator Loss: 0.000169\n",
      "\n",
      "Train time for epoch #1036 (step 1036): 1.381857\n",
      "Batch #10\tAverage Generator Loss: 310.793452\tAverage Discriminator Loss: 0.000353\n",
      "\n",
      "Train time for epoch #1037 (step 1037): 1.433582\n",
      "Batch #10\tAverage Generator Loss: 319.523015\tAverage Discriminator Loss: 0.000175\n",
      "\n",
      "Train time for epoch #1038 (step 1038): 1.443554\n",
      "Batch #10\tAverage Generator Loss: 330.629051\tAverage Discriminator Loss: 0.000164\n",
      "\n",
      "Train time for epoch #1039 (step 1039): 1.315636\n",
      "Batch #10\tAverage Generator Loss: 310.463968\tAverage Discriminator Loss: 0.000161\n",
      "\n",
      "Train time for epoch #1040 (step 1040): 1.374516\n",
      "Batch #10\tAverage Generator Loss: 251.936779\tAverage Discriminator Loss: 0.026735\n",
      "\n",
      "Train time for epoch #1041 (step 1041): 1.420094\n",
      "Batch #10\tAverage Generator Loss: 332.538083\tAverage Discriminator Loss: 0.017549\n",
      "\n",
      "Train time for epoch #1042 (step 1042): 1.502802\n",
      "Batch #10\tAverage Generator Loss: 315.144200\tAverage Discriminator Loss: 0.001357\n",
      "\n",
      "Train time for epoch #1043 (step 1043): 1.581968\n",
      "Batch #10\tAverage Generator Loss: 281.272969\tAverage Discriminator Loss: 0.001558\n",
      "\n",
      "Train time for epoch #1044 (step 1044): 1.386173\n",
      "Batch #10\tAverage Generator Loss: 294.815364\tAverage Discriminator Loss: 0.000508\n",
      "\n",
      "Train time for epoch #1045 (step 1045): 1.423827\n",
      "Batch #10\tAverage Generator Loss: 325.534416\tAverage Discriminator Loss: 0.001342\n",
      "\n",
      "Train time for epoch #1046 (step 1046): 1.416672\n",
      "Batch #10\tAverage Generator Loss: 302.891832\tAverage Discriminator Loss: 0.000435\n",
      "\n",
      "Train time for epoch #1047 (step 1047): 1.400656\n",
      "Batch #10\tAverage Generator Loss: 331.927214\tAverage Discriminator Loss: 0.000420\n",
      "\n",
      "Train time for epoch #1048 (step 1048): 1.389568\n",
      "Batch #10\tAverage Generator Loss: 283.872971\tAverage Discriminator Loss: 0.000352\n",
      "\n",
      "Train time for epoch #1049 (step 1049): 1.367883\n",
      "Batch #10\tAverage Generator Loss: 290.397296\tAverage Discriminator Loss: 0.000310\n",
      "\n",
      "Train time for epoch #1050 (step 1050): 1.389671\n",
      "Batch #10\tAverage Generator Loss: 308.312506\tAverage Discriminator Loss: 0.000443\n",
      "\n",
      "Train time for epoch #1051 (step 1051): 1.324633\n",
      "Batch #10\tAverage Generator Loss: 334.491359\tAverage Discriminator Loss: 0.000632\n",
      "\n",
      "Train time for epoch #1052 (step 1052): 1.366524\n",
      "Batch #10\tAverage Generator Loss: 298.757698\tAverage Discriminator Loss: 0.000500\n",
      "\n",
      "Train time for epoch #1053 (step 1053): 1.502938\n",
      "Batch #10\tAverage Generator Loss: 284.854617\tAverage Discriminator Loss: 0.000419\n",
      "\n",
      "Train time for epoch #1054 (step 1054): 1.324423\n",
      "Batch #10\tAverage Generator Loss: 344.766205\tAverage Discriminator Loss: 0.000346\n",
      "\n",
      "Train time for epoch #1055 (step 1055): 1.381490\n",
      "Batch #10\tAverage Generator Loss: 320.791251\tAverage Discriminator Loss: 0.000293\n",
      "\n",
      "Train time for epoch #1056 (step 1056): 1.383093\n",
      "Batch #10\tAverage Generator Loss: 320.436989\tAverage Discriminator Loss: 0.000266\n",
      "\n",
      "Train time for epoch #1057 (step 1057): 1.394417\n",
      "Batch #10\tAverage Generator Loss: 299.914192\tAverage Discriminator Loss: 0.010888\n",
      "\n",
      "Train time for epoch #1058 (step 1058): 1.371475\n",
      "Batch #10\tAverage Generator Loss: 310.203917\tAverage Discriminator Loss: 0.000373\n",
      "\n",
      "Train time for epoch #1059 (step 1059): 1.482759\n",
      "Batch #10\tAverage Generator Loss: 325.140079\tAverage Discriminator Loss: 0.001498\n",
      "\n",
      "Train time for epoch #1060 (step 1060): 1.472525\n",
      "Batch #10\tAverage Generator Loss: 305.723091\tAverage Discriminator Loss: 0.000249\n",
      "\n",
      "Train time for epoch #1061 (step 1061): 1.447952\n",
      "Batch #10\tAverage Generator Loss: 292.529616\tAverage Discriminator Loss: 0.006838\n",
      "\n",
      "Train time for epoch #1062 (step 1062): 1.438581\n",
      "Batch #10\tAverage Generator Loss: 322.744989\tAverage Discriminator Loss: 0.000487\n",
      "\n",
      "Train time for epoch #1063 (step 1063): 1.471202\n",
      "Batch #10\tAverage Generator Loss: 326.915794\tAverage Discriminator Loss: 0.001568\n",
      "\n",
      "Train time for epoch #1064 (step 1064): 1.437447\n",
      "Batch #10\tAverage Generator Loss: 282.921060\tAverage Discriminator Loss: 0.000998\n",
      "\n",
      "Train time for epoch #1065 (step 1065): 1.411800\n",
      "Batch #10\tAverage Generator Loss: 306.531876\tAverage Discriminator Loss: 0.000601\n",
      "\n",
      "Train time for epoch #1066 (step 1066): 1.403189\n",
      "Batch #10\tAverage Generator Loss: 319.163533\tAverage Discriminator Loss: 0.000444\n",
      "\n",
      "Train time for epoch #1067 (step 1067): 1.439016\n",
      "Batch #10\tAverage Generator Loss: 302.619072\tAverage Discriminator Loss: 0.000359\n",
      "\n",
      "Train time for epoch #1068 (step 1068): 1.376793\n",
      "Batch #10\tAverage Generator Loss: 334.621269\tAverage Discriminator Loss: 0.000295\n",
      "\n",
      "Train time for epoch #1069 (step 1069): 1.377139\n",
      "Batch #10\tAverage Generator Loss: 317.217606\tAverage Discriminator Loss: 0.004878\n",
      "\n",
      "Train time for epoch #1070 (step 1070): 1.422154\n",
      "Batch #10\tAverage Generator Loss: 331.505992\tAverage Discriminator Loss: 0.000326\n",
      "\n",
      "Train time for epoch #1071 (step 1071): 1.361207\n",
      "Batch #10\tAverage Generator Loss: 319.544397\tAverage Discriminator Loss: 0.000314\n",
      "\n",
      "Train time for epoch #1072 (step 1072): 1.463856\n",
      "Batch #10\tAverage Generator Loss: 314.043669\tAverage Discriminator Loss: 0.000284\n",
      "\n",
      "Train time for epoch #1073 (step 1073): 1.555870\n",
      "Batch #10\tAverage Generator Loss: 310.625090\tAverage Discriminator Loss: 0.002643\n",
      "\n",
      "Train time for epoch #1074 (step 1074): 1.543144\n",
      "Batch #10\tAverage Generator Loss: 308.131226\tAverage Discriminator Loss: 0.000488\n",
      "\n",
      "Train time for epoch #1075 (step 1075): 1.409760\n",
      "Batch #10\tAverage Generator Loss: 309.276883\tAverage Discriminator Loss: 0.000428\n",
      "\n",
      "Train time for epoch #1076 (step 1076): 1.372764\n",
      "Batch #10\tAverage Generator Loss: 336.208023\tAverage Discriminator Loss: 0.000324\n",
      "\n",
      "Train time for epoch #1077 (step 1077): 1.360803\n",
      "Batch #10\tAverage Generator Loss: 294.847174\tAverage Discriminator Loss: 0.000266\n",
      "\n",
      "Train time for epoch #1078 (step 1078): 1.370827\n",
      "Batch #10\tAverage Generator Loss: 371.680745\tAverage Discriminator Loss: 0.000256\n",
      "\n",
      "Train time for epoch #1079 (step 1079): 1.468190\n",
      "Batch #10\tAverage Generator Loss: 335.734499\tAverage Discriminator Loss: 0.000362\n",
      "\n",
      "Train time for epoch #1080 (step 1080): 1.430987\n",
      "Batch #10\tAverage Generator Loss: 301.455447\tAverage Discriminator Loss: 0.000215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #1081 (step 1081): 1.442383\n",
      "Batch #10\tAverage Generator Loss: 349.145610\tAverage Discriminator Loss: 0.000198\n",
      "\n",
      "Train time for epoch #1082 (step 1082): 1.357984\n",
      "Batch #10\tAverage Generator Loss: 295.380247\tAverage Discriminator Loss: 0.000496\n",
      "\n",
      "Train time for epoch #1083 (step 1083): 1.401893\n",
      "Batch #10\tAverage Generator Loss: 292.473656\tAverage Discriminator Loss: 0.052742\n",
      "\n",
      "Train time for epoch #1084 (step 1084): 1.437278\n",
      "Batch #10\tAverage Generator Loss: 262.474986\tAverage Discriminator Loss: 0.000759\n",
      "\n",
      "Train time for epoch #1085 (step 1085): 1.674602\n",
      "Batch #10\tAverage Generator Loss: 332.146028\tAverage Discriminator Loss: 0.004525\n",
      "\n",
      "Train time for epoch #1086 (step 1086): 1.284314\n",
      "Batch #10\tAverage Generator Loss: 330.423961\tAverage Discriminator Loss: 0.000273\n",
      "\n",
      "Train time for epoch #1087 (step 1087): 1.435941\n",
      "Batch #10\tAverage Generator Loss: 305.605582\tAverage Discriminator Loss: 0.000295\n",
      "\n",
      "Train time for epoch #1088 (step 1088): 1.410312\n",
      "Batch #10\tAverage Generator Loss: 308.655482\tAverage Discriminator Loss: 0.000196\n",
      "\n",
      "Train time for epoch #1089 (step 1089): 1.388053\n",
      "Batch #10\tAverage Generator Loss: 309.527829\tAverage Discriminator Loss: 0.000151\n",
      "\n",
      "Train time for epoch #1090 (step 1090): 1.475642\n",
      "Batch #10\tAverage Generator Loss: 354.596109\tAverage Discriminator Loss: 0.000480\n",
      "\n",
      "Train time for epoch #1091 (step 1091): 1.619175\n",
      "Batch #10\tAverage Generator Loss: 307.514969\tAverage Discriminator Loss: 0.000147\n",
      "\n",
      "Train time for epoch #1092 (step 1092): 1.472527\n",
      "Batch #10\tAverage Generator Loss: 341.744853\tAverage Discriminator Loss: 0.000154\n",
      "\n",
      "Train time for epoch #1093 (step 1093): 1.543325\n",
      "Batch #10\tAverage Generator Loss: 280.865567\tAverage Discriminator Loss: 0.001041\n",
      "\n",
      "Train time for epoch #1094 (step 1094): 1.371491\n",
      "Batch #10\tAverage Generator Loss: 281.578918\tAverage Discriminator Loss: 0.000153\n",
      "\n",
      "Train time for epoch #1095 (step 1095): 1.383308\n",
      "Batch #10\tAverage Generator Loss: 337.374802\tAverage Discriminator Loss: 0.000177\n",
      "\n",
      "Train time for epoch #1096 (step 1096): 1.465996\n",
      "Batch #10\tAverage Generator Loss: 346.524658\tAverage Discriminator Loss: 0.004610\n",
      "\n",
      "Train time for epoch #1097 (step 1097): 1.370453\n",
      "Batch #10\tAverage Generator Loss: 332.736388\tAverage Discriminator Loss: 0.000359\n",
      "\n",
      "Train time for epoch #1098 (step 1098): 1.392390\n",
      "Batch #10\tAverage Generator Loss: 312.818910\tAverage Discriminator Loss: 0.000258\n",
      "\n",
      "Train time for epoch #1099 (step 1099): 1.387147\n",
      "Batch #10\tAverage Generator Loss: 301.910136\tAverage Discriminator Loss: 0.000266\n",
      "\n",
      "Train time for epoch #1100 (step 1100): 1.381591\n",
      "Batch #10\tAverage Generator Loss: 367.462747\tAverage Discriminator Loss: 0.000735\n",
      "\n",
      "Train time for epoch #1101 (step 1101): 1.413939\n",
      "Batch #10\tAverage Generator Loss: 350.310004\tAverage Discriminator Loss: 0.001371\n",
      "\n",
      "Train time for epoch #1102 (step 1102): 1.361737\n",
      "Batch #10\tAverage Generator Loss: 338.233670\tAverage Discriminator Loss: 0.000257\n",
      "\n",
      "Train time for epoch #1103 (step 1103): 1.433742\n",
      "Batch #10\tAverage Generator Loss: 322.667426\tAverage Discriminator Loss: 0.000162\n",
      "\n",
      "Train time for epoch #1104 (step 1104): 1.360469\n",
      "Batch #10\tAverage Generator Loss: 292.968936\tAverage Discriminator Loss: 0.000127\n",
      "\n",
      "Train time for epoch #1105 (step 1105): 1.538944\n",
      "Batch #10\tAverage Generator Loss: 296.434644\tAverage Discriminator Loss: 0.003943\n",
      "\n",
      "Train time for epoch #1106 (step 1106): 1.404481\n",
      "Batch #10\tAverage Generator Loss: 345.713058\tAverage Discriminator Loss: 0.000548\n",
      "\n",
      "Train time for epoch #1107 (step 1107): 1.409293\n",
      "Batch #10\tAverage Generator Loss: 306.867578\tAverage Discriminator Loss: 0.000470\n",
      "\n",
      "Train time for epoch #1108 (step 1108): 1.460248\n",
      "Batch #10\tAverage Generator Loss: 333.775224\tAverage Discriminator Loss: 0.000275\n",
      "\n",
      "Train time for epoch #1109 (step 1109): 1.463400\n",
      "Batch #10\tAverage Generator Loss: 278.497406\tAverage Discriminator Loss: 0.000212\n",
      "\n",
      "Train time for epoch #1110 (step 1110): 1.374199\n",
      "Batch #10\tAverage Generator Loss: 336.051254\tAverage Discriminator Loss: 0.000181\n",
      "\n",
      "Train time for epoch #1111 (step 1111): 1.367019\n",
      "Batch #10\tAverage Generator Loss: 317.591486\tAverage Discriminator Loss: 0.000148\n",
      "\n",
      "Train time for epoch #1112 (step 1112): 1.373427\n",
      "Batch #10\tAverage Generator Loss: 354.986736\tAverage Discriminator Loss: 0.000143\n",
      "\n",
      "Train time for epoch #1113 (step 1113): 1.460682\n",
      "Batch #10\tAverage Generator Loss: 344.669636\tAverage Discriminator Loss: 0.000135\n",
      "\n",
      "Train time for epoch #1114 (step 1114): 1.456380\n",
      "Batch #10\tAverage Generator Loss: 318.154349\tAverage Discriminator Loss: 0.000121\n",
      "\n",
      "Train time for epoch #1115 (step 1115): 1.368942\n",
      "Batch #10\tAverage Generator Loss: 322.949721\tAverage Discriminator Loss: 0.000110\n",
      "\n",
      "Train time for epoch #1116 (step 1116): 1.620113\n",
      "Batch #10\tAverage Generator Loss: 313.473607\tAverage Discriminator Loss: 0.000442\n",
      "\n",
      "Train time for epoch #1117 (step 1117): 1.366987\n",
      "Batch #10\tAverage Generator Loss: 342.742859\tAverage Discriminator Loss: 0.000111\n",
      "\n",
      "Train time for epoch #1118 (step 1118): 1.497178\n",
      "Batch #10\tAverage Generator Loss: 335.868323\tAverage Discriminator Loss: 0.000104\n",
      "\n",
      "Train time for epoch #1119 (step 1119): 1.424672\n",
      "Batch #10\tAverage Generator Loss: 359.948553\tAverage Discriminator Loss: 0.000103\n",
      "\n",
      "Train time for epoch #1120 (step 1120): 1.389730\n",
      "Batch #10\tAverage Generator Loss: 343.217946\tAverage Discriminator Loss: 0.000085\n",
      "\n",
      "Train time for epoch #1121 (step 1121): 1.380537\n",
      "Batch #10\tAverage Generator Loss: 333.219670\tAverage Discriminator Loss: 0.000085\n",
      "\n",
      "Train time for epoch #1122 (step 1122): 1.363410\n",
      "Batch #10\tAverage Generator Loss: 334.963103\tAverage Discriminator Loss: 0.000190\n",
      "\n",
      "Train time for epoch #1123 (step 1123): 1.389490\n",
      "Batch #10\tAverage Generator Loss: 309.816644\tAverage Discriminator Loss: 0.000087\n",
      "\n",
      "Train time for epoch #1124 (step 1124): 1.426212\n",
      "Batch #10\tAverage Generator Loss: 316.845844\tAverage Discriminator Loss: 0.000081\n",
      "\n",
      "Train time for epoch #1125 (step 1125): 1.421761\n",
      "Batch #10\tAverage Generator Loss: 305.874963\tAverage Discriminator Loss: 0.000085\n",
      "\n",
      "Train time for epoch #1126 (step 1126): 1.425450\n",
      "Batch #10\tAverage Generator Loss: 296.493221\tAverage Discriminator Loss: 0.000073\n",
      "\n",
      "Train time for epoch #1127 (step 1127): 1.409580\n",
      "Batch #10\tAverage Generator Loss: 333.633391\tAverage Discriminator Loss: 0.000078\n",
      "\n",
      "Train time for epoch #1128 (step 1128): 1.529963\n",
      "Batch #10\tAverage Generator Loss: 333.016187\tAverage Discriminator Loss: 0.030421\n",
      "\n",
      "Train time for epoch #1129 (step 1129): 1.373599\n",
      "Batch #10\tAverage Generator Loss: 307.873086\tAverage Discriminator Loss: 0.035706\n",
      "\n",
      "Train time for epoch #1130 (step 1130): 1.373009\n",
      "Batch #10\tAverage Generator Loss: 333.074905\tAverage Discriminator Loss: 0.000914\n",
      "\n",
      "Train time for epoch #1131 (step 1131): 1.367122\n",
      "Batch #10\tAverage Generator Loss: 350.777454\tAverage Discriminator Loss: 0.000782\n",
      "\n",
      "Train time for epoch #1132 (step 1132): 1.408287\n",
      "Batch #10\tAverage Generator Loss: 357.117519\tAverage Discriminator Loss: 0.000359\n",
      "\n",
      "Train time for epoch #1133 (step 1133): 1.380700\n",
      "Batch #10\tAverage Generator Loss: 330.898579\tAverage Discriminator Loss: 0.000272\n",
      "\n",
      "Train time for epoch #1134 (step 1134): 1.406490\n",
      "Batch #10\tAverage Generator Loss: 351.090709\tAverage Discriminator Loss: 0.002845\n",
      "\n",
      "Train time for epoch #1135 (step 1135): 1.373546\n",
      "Batch #10\tAverage Generator Loss: 342.913710\tAverage Discriminator Loss: 0.006028\n",
      "\n",
      "Train time for epoch #1136 (step 1136): 1.373543\n",
      "Batch #10\tAverage Generator Loss: 361.994292\tAverage Discriminator Loss: 0.001171\n",
      "\n",
      "Train time for epoch #1137 (step 1137): 1.504371\n",
      "Batch #10\tAverage Generator Loss: 361.561865\tAverage Discriminator Loss: 0.006013\n",
      "\n",
      "Train time for epoch #1138 (step 1138): 1.373398\n",
      "Batch #10\tAverage Generator Loss: 385.058412\tAverage Discriminator Loss: 0.000729\n",
      "\n",
      "Train time for epoch #1139 (step 1139): 1.459914\n",
      "Batch #10\tAverage Generator Loss: 361.402866\tAverage Discriminator Loss: 0.000373\n",
      "\n",
      "Train time for epoch #1140 (step 1140): 1.353130\n",
      "Batch #10\tAverage Generator Loss: 363.739322\tAverage Discriminator Loss: 0.004546\n",
      "\n",
      "Train time for epoch #1141 (step 1141): 1.704959\n",
      "Batch #10\tAverage Generator Loss: 341.987024\tAverage Discriminator Loss: 0.000402\n",
      "\n",
      "Train time for epoch #1142 (step 1142): 1.374930\n",
      "Batch #10\tAverage Generator Loss: 366.170316\tAverage Discriminator Loss: 0.001364\n",
      "\n",
      "Train time for epoch #1143 (step 1143): 1.381097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 317.420706\tAverage Discriminator Loss: 0.000460\n",
      "\n",
      "Train time for epoch #1144 (step 1144): 1.422402\n",
      "Batch #10\tAverage Generator Loss: 358.733917\tAverage Discriminator Loss: 0.000545\n",
      "\n",
      "Train time for epoch #1145 (step 1145): 1.466238\n",
      "Batch #10\tAverage Generator Loss: 376.848574\tAverage Discriminator Loss: 0.000269\n",
      "\n",
      "Train time for epoch #1146 (step 1146): 1.358868\n",
      "Batch #10\tAverage Generator Loss: 372.744304\tAverage Discriminator Loss: 0.000721\n",
      "\n",
      "Train time for epoch #1147 (step 1147): 1.374605\n",
      "Batch #10\tAverage Generator Loss: 378.632767\tAverage Discriminator Loss: 0.000277\n",
      "\n",
      "Train time for epoch #1148 (step 1148): 1.471408\n",
      "Batch #10\tAverage Generator Loss: 389.701364\tAverage Discriminator Loss: 0.000236\n",
      "\n",
      "Train time for epoch #1149 (step 1149): 1.432872\n",
      "Batch #10\tAverage Generator Loss: 332.576952\tAverage Discriminator Loss: 0.075302\n",
      "\n",
      "Train time for epoch #1150 (step 1150): 1.440723\n",
      "Batch #10\tAverage Generator Loss: 353.899207\tAverage Discriminator Loss: 0.037305\n",
      "\n",
      "Train time for epoch #1151 (step 1151): 1.474310\n",
      "Batch #10\tAverage Generator Loss: 339.063622\tAverage Discriminator Loss: 0.003681\n",
      "\n",
      "Train time for epoch #1152 (step 1152): 1.486201\n",
      "Batch #10\tAverage Generator Loss: 325.452905\tAverage Discriminator Loss: 0.000259\n",
      "\n",
      "Train time for epoch #1153 (step 1153): 1.374119\n",
      "Batch #10\tAverage Generator Loss: 330.433780\tAverage Discriminator Loss: 0.002152\n",
      "\n",
      "Train time for epoch #1154 (step 1154): 1.505036\n",
      "Batch #10\tAverage Generator Loss: 313.797334\tAverage Discriminator Loss: 0.002270\n",
      "\n",
      "Train time for epoch #1155 (step 1155): 1.424402\n",
      "Batch #10\tAverage Generator Loss: 392.979465\tAverage Discriminator Loss: 0.000562\n",
      "\n",
      "Train time for epoch #1156 (step 1156): 1.453322\n",
      "Batch #10\tAverage Generator Loss: 310.834261\tAverage Discriminator Loss: 0.000496\n",
      "\n",
      "Train time for epoch #1157 (step 1157): 1.359267\n",
      "Batch #10\tAverage Generator Loss: 318.227167\tAverage Discriminator Loss: 0.001323\n",
      "\n",
      "Train time for epoch #1158 (step 1158): 1.359931\n",
      "Batch #10\tAverage Generator Loss: 340.194479\tAverage Discriminator Loss: 0.000313\n",
      "\n",
      "Train time for epoch #1159 (step 1159): 1.419531\n",
      "Batch #10\tAverage Generator Loss: 347.978653\tAverage Discriminator Loss: 0.000965\n",
      "\n",
      "Train time for epoch #1160 (step 1160): 1.500015\n",
      "Batch #10\tAverage Generator Loss: 282.625148\tAverage Discriminator Loss: 0.000404\n",
      "\n",
      "Train time for epoch #1161 (step 1161): 1.431739\n",
      "Batch #10\tAverage Generator Loss: 304.446158\tAverage Discriminator Loss: 0.001610\n",
      "\n",
      "Train time for epoch #1162 (step 1162): 1.516858\n",
      "Batch #10\tAverage Generator Loss: 322.332946\tAverage Discriminator Loss: 0.000441\n",
      "\n",
      "Train time for epoch #1163 (step 1163): 1.371435\n",
      "Batch #10\tAverage Generator Loss: 329.194495\tAverage Discriminator Loss: 0.000353\n",
      "\n",
      "Train time for epoch #1164 (step 1164): 1.332264\n",
      "Batch #10\tAverage Generator Loss: 351.087773\tAverage Discriminator Loss: 0.000246\n",
      "\n",
      "Train time for epoch #1165 (step 1165): 1.397154\n",
      "Batch #10\tAverage Generator Loss: 347.728749\tAverage Discriminator Loss: 0.000180\n",
      "\n",
      "Train time for epoch #1166 (step 1166): 1.429446\n",
      "Batch #10\tAverage Generator Loss: 324.022255\tAverage Discriminator Loss: 0.000179\n",
      "\n",
      "Train time for epoch #1167 (step 1167): 1.370473\n",
      "Batch #10\tAverage Generator Loss: 336.726294\tAverage Discriminator Loss: 0.000139\n",
      "\n",
      "Train time for epoch #1168 (step 1168): 1.399619\n",
      "Batch #10\tAverage Generator Loss: 316.922995\tAverage Discriminator Loss: 0.000109\n",
      "\n",
      "Train time for epoch #1169 (step 1169): 1.454312\n",
      "Batch #10\tAverage Generator Loss: 316.858784\tAverage Discriminator Loss: 0.000109\n",
      "\n",
      "Train time for epoch #1170 (step 1170): 1.442409\n",
      "Batch #10\tAverage Generator Loss: 348.746085\tAverage Discriminator Loss: 0.041303\n",
      "\n",
      "Train time for epoch #1171 (step 1171): 1.389120\n",
      "Batch #10\tAverage Generator Loss: 341.289983\tAverage Discriminator Loss: 0.000108\n",
      "\n",
      "Train time for epoch #1172 (step 1172): 1.366753\n",
      "Batch #10\tAverage Generator Loss: 343.139586\tAverage Discriminator Loss: 0.003162\n",
      "\n",
      "Train time for epoch #1173 (step 1173): 1.461729\n",
      "Batch #10\tAverage Generator Loss: 369.258942\tAverage Discriminator Loss: 0.002424\n",
      "\n",
      "Train time for epoch #1174 (step 1174): 1.427879\n",
      "Batch #10\tAverage Generator Loss: 364.147940\tAverage Discriminator Loss: 0.000392\n",
      "\n",
      "Train time for epoch #1175 (step 1175): 1.460690\n",
      "Batch #10\tAverage Generator Loss: 342.498355\tAverage Discriminator Loss: 0.013598\n",
      "\n",
      "Train time for epoch #1176 (step 1176): 1.430666\n",
      "Batch #10\tAverage Generator Loss: 353.339029\tAverage Discriminator Loss: 0.000091\n",
      "\n",
      "Train time for epoch #1177 (step 1177): 1.476156\n",
      "Batch #10\tAverage Generator Loss: 334.813945\tAverage Discriminator Loss: 0.000128\n",
      "\n",
      "Train time for epoch #1178 (step 1178): 1.423976\n",
      "Batch #10\tAverage Generator Loss: 283.826439\tAverage Discriminator Loss: 0.104633\n",
      "\n",
      "Train time for epoch #1179 (step 1179): 1.365509\n",
      "Batch #10\tAverage Generator Loss: 258.608525\tAverage Discriminator Loss: 0.015984\n",
      "\n",
      "Train time for epoch #1180 (step 1180): 1.368612\n",
      "Batch #10\tAverage Generator Loss: 414.544962\tAverage Discriminator Loss: 0.000179\n",
      "\n",
      "Train time for epoch #1181 (step 1181): 1.421486\n",
      "Batch #10\tAverage Generator Loss: 344.217160\tAverage Discriminator Loss: 0.000588\n",
      "\n",
      "Train time for epoch #1182 (step 1182): 1.340101\n",
      "Batch #10\tAverage Generator Loss: 359.820056\tAverage Discriminator Loss: 0.000393\n",
      "\n",
      "Train time for epoch #1183 (step 1183): 1.408331\n",
      "Batch #10\tAverage Generator Loss: 418.600696\tAverage Discriminator Loss: 0.000222\n",
      "\n",
      "Train time for epoch #1184 (step 1184): 1.494342\n",
      "Batch #10\tAverage Generator Loss: 319.346204\tAverage Discriminator Loss: 0.000146\n",
      "\n",
      "Train time for epoch #1185 (step 1185): 1.285719\n",
      "Batch #10\tAverage Generator Loss: 416.518996\tAverage Discriminator Loss: 0.000302\n",
      "\n",
      "Train time for epoch #1186 (step 1186): 1.478973\n",
      "Batch #10\tAverage Generator Loss: 336.607628\tAverage Discriminator Loss: 0.010445\n",
      "\n",
      "Train time for epoch #1187 (step 1187): 1.516114\n",
      "Batch #10\tAverage Generator Loss: 355.877994\tAverage Discriminator Loss: 0.005904\n",
      "\n",
      "Train time for epoch #1188 (step 1188): 1.533116\n",
      "Batch #10\tAverage Generator Loss: 388.141797\tAverage Discriminator Loss: 0.000531\n",
      "\n",
      "Train time for epoch #1189 (step 1189): 1.406147\n",
      "Batch #10\tAverage Generator Loss: 355.795576\tAverage Discriminator Loss: 0.000959\n",
      "\n",
      "Train time for epoch #1190 (step 1190): 1.557816\n",
      "Batch #10\tAverage Generator Loss: 433.555141\tAverage Discriminator Loss: 0.000358\n",
      "\n",
      "Train time for epoch #1191 (step 1191): 1.365596\n",
      "Batch #10\tAverage Generator Loss: 382.764034\tAverage Discriminator Loss: 0.000195\n",
      "\n",
      "Train time for epoch #1192 (step 1192): 1.381184\n",
      "Batch #10\tAverage Generator Loss: 364.776817\tAverage Discriminator Loss: 0.000180\n",
      "\n",
      "Train time for epoch #1193 (step 1193): 1.518920\n",
      "Batch #10\tAverage Generator Loss: 354.016452\tAverage Discriminator Loss: 0.000261\n",
      "\n",
      "Train time for epoch #1194 (step 1194): 1.372939\n",
      "Batch #10\tAverage Generator Loss: 324.805249\tAverage Discriminator Loss: 0.000349\n",
      "\n",
      "Train time for epoch #1195 (step 1195): 1.756767\n",
      "Batch #10\tAverage Generator Loss: 406.726883\tAverage Discriminator Loss: 0.000253\n",
      "\n",
      "Train time for epoch #1196 (step 1196): 1.358828\n",
      "Batch #10\tAverage Generator Loss: 333.352393\tAverage Discriminator Loss: 0.000238\n",
      "\n",
      "Train time for epoch #1197 (step 1197): 1.329119\n",
      "Batch #10\tAverage Generator Loss: 384.544897\tAverage Discriminator Loss: 0.000249\n",
      "\n",
      "Train time for epoch #1198 (step 1198): 1.362792\n",
      "Batch #10\tAverage Generator Loss: 384.986510\tAverage Discriminator Loss: 0.002546\n",
      "\n",
      "Train time for epoch #1199 (step 1199): 1.518126\n",
      "Batch #10\tAverage Generator Loss: 383.249316\tAverage Discriminator Loss: 0.000275\n",
      "\n",
      "Train time for epoch #1200 (step 1200): 1.341049\n",
      "Batch #10\tAverage Generator Loss: 367.458928\tAverage Discriminator Loss: 0.000129\n",
      "\n",
      "Train time for epoch #1201 (step 1201): 1.467411\n",
      "Batch #10\tAverage Generator Loss: 418.333630\tAverage Discriminator Loss: 0.000121\n",
      "\n",
      "Train time for epoch #1202 (step 1202): 1.443093\n",
      "Batch #10\tAverage Generator Loss: 412.448193\tAverage Discriminator Loss: 0.000109\n",
      "\n",
      "Train time for epoch #1203 (step 1203): 1.434496\n",
      "Batch #10\tAverage Generator Loss: 343.356413\tAverage Discriminator Loss: 0.002005\n",
      "\n",
      "Train time for epoch #1204 (step 1204): 1.497585\n",
      "Batch #10\tAverage Generator Loss: 337.166613\tAverage Discriminator Loss: 0.108414\n",
      "\n",
      "Train time for epoch #1205 (step 1205): 1.428946\n",
      "Batch #10\tAverage Generator Loss: 321.143363\tAverage Discriminator Loss: 0.000270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #1206 (step 1206): 1.358055\n",
      "Batch #10\tAverage Generator Loss: 328.432234\tAverage Discriminator Loss: 0.000289\n",
      "\n",
      "Train time for epoch #1207 (step 1207): 1.433098\n",
      "Batch #10\tAverage Generator Loss: 299.746705\tAverage Discriminator Loss: 0.026474\n",
      "\n",
      "Train time for epoch #1208 (step 1208): 1.475689\n",
      "Batch #10\tAverage Generator Loss: 319.684343\tAverage Discriminator Loss: 0.000676\n",
      "\n",
      "Train time for epoch #1209 (step 1209): 1.412467\n",
      "Batch #10\tAverage Generator Loss: 273.686862\tAverage Discriminator Loss: 0.000108\n",
      "\n",
      "Train time for epoch #1210 (step 1210): 1.469708\n",
      "Batch #10\tAverage Generator Loss: 294.342207\tAverage Discriminator Loss: 0.001992\n",
      "\n",
      "Train time for epoch #1211 (step 1211): 1.531971\n",
      "Batch #10\tAverage Generator Loss: 306.069650\tAverage Discriminator Loss: 0.000653\n",
      "\n",
      "Train time for epoch #1212 (step 1212): 1.401047\n",
      "Batch #10\tAverage Generator Loss: 312.247412\tAverage Discriminator Loss: 0.000563\n",
      "\n",
      "Train time for epoch #1213 (step 1213): 1.557248\n",
      "Batch #10\tAverage Generator Loss: 301.394281\tAverage Discriminator Loss: 0.000274\n",
      "\n",
      "Train time for epoch #1214 (step 1214): 1.450945\n",
      "Batch #10\tAverage Generator Loss: 311.406343\tAverage Discriminator Loss: 0.000603\n",
      "\n",
      "Train time for epoch #1215 (step 1215): 1.395760\n",
      "Batch #10\tAverage Generator Loss: 326.992574\tAverage Discriminator Loss: 0.000200\n",
      "\n",
      "Train time for epoch #1216 (step 1216): 1.421237\n",
      "Batch #10\tAverage Generator Loss: 332.175327\tAverage Discriminator Loss: 0.000558\n",
      "\n",
      "Train time for epoch #1217 (step 1217): 1.423057\n",
      "Batch #10\tAverage Generator Loss: 306.037267\tAverage Discriminator Loss: 0.005338\n",
      "\n",
      "Train time for epoch #1218 (step 1218): 1.464060\n",
      "Batch #10\tAverage Generator Loss: 334.256750\tAverage Discriminator Loss: 0.003371\n",
      "\n",
      "Train time for epoch #1219 (step 1219): 1.386186\n",
      "Batch #10\tAverage Generator Loss: 274.888781\tAverage Discriminator Loss: 0.000944\n",
      "\n",
      "Train time for epoch #1220 (step 1220): 1.432112\n",
      "Batch #10\tAverage Generator Loss: 300.740431\tAverage Discriminator Loss: 0.000107\n",
      "\n",
      "Train time for epoch #1221 (step 1221): 1.460173\n",
      "Batch #10\tAverage Generator Loss: 303.965442\tAverage Discriminator Loss: 0.007177\n",
      "\n",
      "Train time for epoch #1222 (step 1222): 1.416516\n",
      "Batch #10\tAverage Generator Loss: 288.597310\tAverage Discriminator Loss: 0.004827\n",
      "\n",
      "Train time for epoch #1223 (step 1223): 1.426806\n",
      "Batch #10\tAverage Generator Loss: 361.448618\tAverage Discriminator Loss: 0.000743\n",
      "\n",
      "Train time for epoch #1224 (step 1224): 1.364101\n",
      "Batch #10\tAverage Generator Loss: 333.875336\tAverage Discriminator Loss: 0.000136\n",
      "\n",
      "Train time for epoch #1225 (step 1225): 1.564403\n",
      "Batch #10\tAverage Generator Loss: 321.490508\tAverage Discriminator Loss: 0.000093\n",
      "\n",
      "Train time for epoch #1226 (step 1226): 1.434324\n",
      "Batch #10\tAverage Generator Loss: 308.725871\tAverage Discriminator Loss: 0.001313\n",
      "\n",
      "Train time for epoch #1227 (step 1227): 1.386765\n",
      "Batch #10\tAverage Generator Loss: 314.729916\tAverage Discriminator Loss: 0.000132\n",
      "\n",
      "Train time for epoch #1228 (step 1228): 1.481731\n",
      "Batch #10\tAverage Generator Loss: 377.298817\tAverage Discriminator Loss: 0.000486\n",
      "\n",
      "Train time for epoch #1229 (step 1229): 1.385075\n",
      "Batch #10\tAverage Generator Loss: 282.448353\tAverage Discriminator Loss: 0.000820\n",
      "\n",
      "Train time for epoch #1230 (step 1230): 1.368584\n",
      "Batch #10\tAverage Generator Loss: 306.141723\tAverage Discriminator Loss: 0.000255\n",
      "\n",
      "Train time for epoch #1231 (step 1231): 1.365727\n",
      "Batch #10\tAverage Generator Loss: 310.040912\tAverage Discriminator Loss: 0.002225\n",
      "\n",
      "Train time for epoch #1232 (step 1232): 1.463273\n",
      "Batch #10\tAverage Generator Loss: 332.366470\tAverage Discriminator Loss: 0.000857\n",
      "\n",
      "Train time for epoch #1233 (step 1233): 1.428034\n",
      "Batch #10\tAverage Generator Loss: 259.902547\tAverage Discriminator Loss: 0.003476\n",
      "\n",
      "Train time for epoch #1234 (step 1234): 1.432970\n",
      "Batch #10\tAverage Generator Loss: 239.563486\tAverage Discriminator Loss: 0.004416\n",
      "\n",
      "Train time for epoch #1235 (step 1235): 1.520767\n",
      "Batch #10\tAverage Generator Loss: 281.808231\tAverage Discriminator Loss: 0.000093\n",
      "\n",
      "Train time for epoch #1236 (step 1236): 1.335185\n",
      "Batch #10\tAverage Generator Loss: 331.115814\tAverage Discriminator Loss: 0.000052\n",
      "\n",
      "Train time for epoch #1237 (step 1237): 1.483127\n",
      "Batch #10\tAverage Generator Loss: 338.144960\tAverage Discriminator Loss: 0.009742\n",
      "\n",
      "Train time for epoch #1238 (step 1238): 1.387644\n",
      "Batch #10\tAverage Generator Loss: 285.102909\tAverage Discriminator Loss: 0.005488\n",
      "\n",
      "Train time for epoch #1239 (step 1239): 1.344177\n",
      "Batch #10\tAverage Generator Loss: 348.628883\tAverage Discriminator Loss: 0.000263\n",
      "\n",
      "Train time for epoch #1240 (step 1240): 1.507055\n",
      "Batch #10\tAverage Generator Loss: 354.429190\tAverage Discriminator Loss: 0.000088\n",
      "\n",
      "Train time for epoch #1241 (step 1241): 1.528459\n",
      "Batch #10\tAverage Generator Loss: 382.443396\tAverage Discriminator Loss: 0.000078\n",
      "\n",
      "Train time for epoch #1242 (step 1242): 1.476497\n",
      "Batch #10\tAverage Generator Loss: 377.731871\tAverage Discriminator Loss: 0.000234\n",
      "\n",
      "Train time for epoch #1243 (step 1243): 1.371531\n",
      "Batch #10\tAverage Generator Loss: 304.798241\tAverage Discriminator Loss: 0.013106\n",
      "\n",
      "Train time for epoch #1244 (step 1244): 1.424713\n",
      "Batch #10\tAverage Generator Loss: 329.632610\tAverage Discriminator Loss: 0.000184\n",
      "\n",
      "Train time for epoch #1245 (step 1245): 1.439546\n",
      "Batch #10\tAverage Generator Loss: 322.169371\tAverage Discriminator Loss: 0.005908\n",
      "\n",
      "Train time for epoch #1246 (step 1246): 1.440569\n",
      "Batch #10\tAverage Generator Loss: 364.615950\tAverage Discriminator Loss: 0.005531\n",
      "\n",
      "Train time for epoch #1247 (step 1247): 1.354754\n",
      "Batch #10\tAverage Generator Loss: 350.739848\tAverage Discriminator Loss: 0.000446\n",
      "\n",
      "Train time for epoch #1248 (step 1248): 1.467129\n",
      "Batch #10\tAverage Generator Loss: 275.002204\tAverage Discriminator Loss: 0.081833\n",
      "\n",
      "Train time for epoch #1249 (step 1249): 1.411117\n",
      "Batch #10\tAverage Generator Loss: 358.062129\tAverage Discriminator Loss: 0.000803\n",
      "\n",
      "Train time for epoch #1250 (step 1250): 1.425355\n",
      "Batch #10\tAverage Generator Loss: 335.785025\tAverage Discriminator Loss: 0.000359\n",
      "\n",
      "Train time for epoch #1251 (step 1251): 1.374248\n",
      "Batch #10\tAverage Generator Loss: 341.025151\tAverage Discriminator Loss: 0.000933\n",
      "\n",
      "Train time for epoch #1252 (step 1252): 1.452416\n",
      "Batch #10\tAverage Generator Loss: 425.787854\tAverage Discriminator Loss: 0.007356\n",
      "\n",
      "Train time for epoch #1253 (step 1253): 1.480350\n",
      "Batch #10\tAverage Generator Loss: 429.981807\tAverage Discriminator Loss: 0.000176\n",
      "\n",
      "Train time for epoch #1254 (step 1254): 1.463809\n",
      "Batch #10\tAverage Generator Loss: 379.153262\tAverage Discriminator Loss: 0.000241\n",
      "\n",
      "Train time for epoch #1255 (step 1255): 1.467918\n",
      "Batch #10\tAverage Generator Loss: 416.599207\tAverage Discriminator Loss: 0.000116\n",
      "\n",
      "Train time for epoch #1256 (step 1256): 1.486268\n",
      "Batch #10\tAverage Generator Loss: 436.501764\tAverage Discriminator Loss: 0.000109\n",
      "\n",
      "Train time for epoch #1257 (step 1257): 1.420758\n",
      "Batch #10\tAverage Generator Loss: 407.520740\tAverage Discriminator Loss: 0.000098\n",
      "\n",
      "Train time for epoch #1258 (step 1258): 1.412950\n",
      "Batch #10\tAverage Generator Loss: 381.865906\tAverage Discriminator Loss: 0.000623\n",
      "\n",
      "Train time for epoch #1259 (step 1259): 1.411719\n",
      "Batch #10\tAverage Generator Loss: 357.491826\tAverage Discriminator Loss: 0.007150\n",
      "\n",
      "Train time for epoch #1260 (step 1260): 1.580308\n",
      "Batch #10\tAverage Generator Loss: 403.819284\tAverage Discriminator Loss: 0.005915\n",
      "\n",
      "Train time for epoch #1261 (step 1261): 1.405095\n",
      "Batch #10\tAverage Generator Loss: 364.125407\tAverage Discriminator Loss: 0.000251\n",
      "\n",
      "Train time for epoch #1262 (step 1262): 1.418139\n",
      "Batch #10\tAverage Generator Loss: 336.486580\tAverage Discriminator Loss: 0.000323\n",
      "\n",
      "Train time for epoch #1263 (step 1263): 1.442653\n",
      "Batch #10\tAverage Generator Loss: 354.341159\tAverage Discriminator Loss: 0.000198\n",
      "\n",
      "Train time for epoch #1264 (step 1264): 1.416733\n",
      "Batch #10\tAverage Generator Loss: 339.426655\tAverage Discriminator Loss: 0.000285\n",
      "\n",
      "Train time for epoch #1265 (step 1265): 1.449347\n",
      "Batch #10\tAverage Generator Loss: 352.410327\tAverage Discriminator Loss: 0.040519\n",
      "\n",
      "Train time for epoch #1266 (step 1266): 1.503124\n",
      "Batch #10\tAverage Generator Loss: 386.940674\tAverage Discriminator Loss: 0.000249\n",
      "\n",
      "Train time for epoch #1267 (step 1267): 1.371666\n",
      "Batch #10\tAverage Generator Loss: 337.977249\tAverage Discriminator Loss: 0.040189\n",
      "\n",
      "Train time for epoch #1268 (step 1268): 1.467980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 267.689165\tAverage Discriminator Loss: 0.093066\n",
      "\n",
      "Train time for epoch #1269 (step 1269): 1.588304\n",
      "Batch #10\tAverage Generator Loss: 263.442961\tAverage Discriminator Loss: 0.030961\n",
      "\n",
      "Train time for epoch #1270 (step 1270): 1.471503\n",
      "Batch #10\tAverage Generator Loss: 274.114378\tAverage Discriminator Loss: 0.005636\n",
      "\n",
      "Train time for epoch #1271 (step 1271): 1.480526\n",
      "Batch #10\tAverage Generator Loss: 267.348026\tAverage Discriminator Loss: 0.003587\n",
      "\n",
      "Train time for epoch #1272 (step 1272): 1.487619\n",
      "Batch #10\tAverage Generator Loss: 301.724514\tAverage Discriminator Loss: 0.000790\n",
      "\n",
      "Train time for epoch #1273 (step 1273): 1.490010\n",
      "Batch #10\tAverage Generator Loss: 313.832010\tAverage Discriminator Loss: 0.000718\n",
      "\n",
      "Train time for epoch #1274 (step 1274): 1.402209\n",
      "Batch #10\tAverage Generator Loss: 352.852258\tAverage Discriminator Loss: 0.000332\n",
      "\n",
      "Train time for epoch #1275 (step 1275): 1.526984\n",
      "Batch #10\tAverage Generator Loss: 294.035143\tAverage Discriminator Loss: 0.001501\n",
      "\n",
      "Train time for epoch #1276 (step 1276): 1.517900\n",
      "Batch #10\tAverage Generator Loss: 309.184156\tAverage Discriminator Loss: 0.000286\n",
      "\n",
      "Train time for epoch #1277 (step 1277): 1.480436\n",
      "Batch #10\tAverage Generator Loss: 300.410721\tAverage Discriminator Loss: 0.000564\n",
      "\n",
      "Train time for epoch #1278 (step 1278): 1.487834\n",
      "Batch #10\tAverage Generator Loss: 257.140419\tAverage Discriminator Loss: 0.000576\n",
      "\n",
      "Train time for epoch #1279 (step 1279): 1.382227\n",
      "Batch #10\tAverage Generator Loss: 277.356065\tAverage Discriminator Loss: 0.000871\n",
      "\n",
      "Train time for epoch #1280 (step 1280): 1.425710\n",
      "Batch #10\tAverage Generator Loss: 353.617384\tAverage Discriminator Loss: 0.001032\n",
      "\n",
      "Train time for epoch #1281 (step 1281): 1.558765\n",
      "Batch #10\tAverage Generator Loss: 282.578515\tAverage Discriminator Loss: 0.000720\n",
      "\n",
      "Train time for epoch #1282 (step 1282): 1.433800\n",
      "Batch #10\tAverage Generator Loss: 335.771040\tAverage Discriminator Loss: 0.000603\n",
      "\n",
      "Train time for epoch #1283 (step 1283): 1.438642\n",
      "Batch #10\tAverage Generator Loss: 329.800208\tAverage Discriminator Loss: 0.000317\n",
      "\n",
      "Train time for epoch #1284 (step 1284): 1.457305\n",
      "Batch #10\tAverage Generator Loss: 294.848175\tAverage Discriminator Loss: 0.000282\n",
      "\n",
      "Train time for epoch #1285 (step 1285): 1.403984\n",
      "Batch #10\tAverage Generator Loss: 315.678226\tAverage Discriminator Loss: 0.000221\n",
      "\n",
      "Train time for epoch #1286 (step 1286): 1.372447\n",
      "Batch #10\tAverage Generator Loss: 284.619980\tAverage Discriminator Loss: 0.011114\n",
      "\n",
      "Train time for epoch #1287 (step 1287): 1.557031\n",
      "Batch #10\tAverage Generator Loss: 340.599529\tAverage Discriminator Loss: 0.000918\n",
      "\n",
      "Train time for epoch #1288 (step 1288): 1.428799\n",
      "Batch #10\tAverage Generator Loss: 392.911942\tAverage Discriminator Loss: 0.000194\n",
      "\n",
      "Train time for epoch #1289 (step 1289): 1.388540\n",
      "Batch #10\tAverage Generator Loss: 340.520883\tAverage Discriminator Loss: 0.018779\n",
      "\n",
      "Train time for epoch #1290 (step 1290): 1.387471\n",
      "Batch #10\tAverage Generator Loss: 348.639006\tAverage Discriminator Loss: 0.001474\n",
      "\n",
      "Train time for epoch #1291 (step 1291): 1.420659\n",
      "Batch #10\tAverage Generator Loss: 347.158167\tAverage Discriminator Loss: 0.000080\n",
      "\n",
      "Train time for epoch #1292 (step 1292): 1.412590\n",
      "Batch #10\tAverage Generator Loss: 364.385629\tAverage Discriminator Loss: 0.003085\n",
      "\n",
      "Train time for epoch #1293 (step 1293): 1.501840\n",
      "Batch #10\tAverage Generator Loss: 310.034692\tAverage Discriminator Loss: 0.000074\n",
      "\n",
      "Train time for epoch #1294 (step 1294): 1.292539\n",
      "Batch #10\tAverage Generator Loss: 374.838542\tAverage Discriminator Loss: 0.000090\n",
      "\n",
      "Train time for epoch #1295 (step 1295): 1.459721\n",
      "Batch #10\tAverage Generator Loss: 351.388591\tAverage Discriminator Loss: 0.000079\n",
      "\n",
      "Train time for epoch #1296 (step 1296): 1.442540\n",
      "Batch #10\tAverage Generator Loss: 308.411804\tAverage Discriminator Loss: 0.007696\n",
      "\n",
      "Train time for epoch #1297 (step 1297): 1.442622\n",
      "Batch #10\tAverage Generator Loss: 327.810831\tAverage Discriminator Loss: 0.006663\n",
      "\n",
      "Train time for epoch #1298 (step 1298): 1.380748\n",
      "Batch #10\tAverage Generator Loss: 389.205168\tAverage Discriminator Loss: 0.000259\n",
      "\n",
      "Train time for epoch #1299 (step 1299): 1.436285\n",
      "Batch #10\tAverage Generator Loss: 339.622391\tAverage Discriminator Loss: 0.099106\n",
      "\n",
      "Train time for epoch #1300 (step 1300): 1.524025\n",
      "Batch #10\tAverage Generator Loss: 321.866345\tAverage Discriminator Loss: 0.000203\n",
      "\n",
      "Train time for epoch #1301 (step 1301): 1.382539\n",
      "Batch #10\tAverage Generator Loss: 343.218059\tAverage Discriminator Loss: 0.007828\n",
      "\n",
      "Train time for epoch #1302 (step 1302): 1.466729\n",
      "Batch #10\tAverage Generator Loss: 284.909286\tAverage Discriminator Loss: 0.002750\n",
      "\n",
      "Train time for epoch #1303 (step 1303): 1.372010\n",
      "Batch #10\tAverage Generator Loss: 330.868813\tAverage Discriminator Loss: 0.000282\n",
      "\n",
      "Train time for epoch #1304 (step 1304): 1.428626\n",
      "Batch #10\tAverage Generator Loss: 311.110020\tAverage Discriminator Loss: 0.000264\n",
      "\n",
      "Train time for epoch #1305 (step 1305): 1.513109\n",
      "Batch #10\tAverage Generator Loss: 313.362709\tAverage Discriminator Loss: 0.000415\n",
      "\n",
      "Train time for epoch #1306 (step 1306): 1.379640\n",
      "Batch #10\tAverage Generator Loss: 290.301918\tAverage Discriminator Loss: 0.003053\n",
      "\n",
      "Train time for epoch #1307 (step 1307): 1.496918\n",
      "Batch #10\tAverage Generator Loss: 275.813522\tAverage Discriminator Loss: 0.001473\n",
      "\n",
      "Train time for epoch #1308 (step 1308): 1.388389\n",
      "Batch #10\tAverage Generator Loss: 308.575563\tAverage Discriminator Loss: 0.000372\n",
      "\n",
      "Train time for epoch #1309 (step 1309): 1.421250\n",
      "Batch #10\tAverage Generator Loss: 299.948810\tAverage Discriminator Loss: 0.000189\n",
      "\n",
      "Train time for epoch #1310 (step 1310): 1.448668\n",
      "Batch #10\tAverage Generator Loss: 292.081555\tAverage Discriminator Loss: 0.000216\n",
      "\n",
      "Train time for epoch #1311 (step 1311): 1.498681\n",
      "Batch #10\tAverage Generator Loss: 290.926172\tAverage Discriminator Loss: 0.000221\n",
      "\n",
      "Train time for epoch #1312 (step 1312): 1.473737\n",
      "Batch #10\tAverage Generator Loss: 329.774261\tAverage Discriminator Loss: 0.000240\n",
      "\n",
      "Train time for epoch #1313 (step 1313): 1.445594\n",
      "Batch #10\tAverage Generator Loss: 295.072040\tAverage Discriminator Loss: 0.003200\n",
      "\n",
      "Train time for epoch #1314 (step 1314): 1.396066\n",
      "Batch #10\tAverage Generator Loss: 331.819231\tAverage Discriminator Loss: 0.000391\n",
      "\n",
      "Train time for epoch #1315 (step 1315): 1.484843\n",
      "Batch #10\tAverage Generator Loss: 344.422559\tAverage Discriminator Loss: 0.000354\n",
      "\n",
      "Train time for epoch #1316 (step 1316): 1.370592\n",
      "Batch #10\tAverage Generator Loss: 309.140697\tAverage Discriminator Loss: 0.000270\n",
      "\n",
      "Train time for epoch #1317 (step 1317): 1.522590\n",
      "Batch #10\tAverage Generator Loss: 330.763997\tAverage Discriminator Loss: 0.000751\n",
      "\n",
      "Train time for epoch #1318 (step 1318): 1.330211\n",
      "Batch #10\tAverage Generator Loss: 298.407577\tAverage Discriminator Loss: 0.000208\n",
      "\n",
      "Train time for epoch #1319 (step 1319): 1.577858\n",
      "Batch #10\tAverage Generator Loss: 285.656122\tAverage Discriminator Loss: 0.000199\n",
      "\n",
      "Train time for epoch #1320 (step 1320): 1.398366\n",
      "Batch #10\tAverage Generator Loss: 330.212749\tAverage Discriminator Loss: 0.000207\n",
      "\n",
      "Train time for epoch #1321 (step 1321): 1.522883\n",
      "Batch #10\tAverage Generator Loss: 303.894777\tAverage Discriminator Loss: 0.000170\n",
      "\n",
      "Train time for epoch #1322 (step 1322): 1.386104\n",
      "Batch #10\tAverage Generator Loss: 337.453416\tAverage Discriminator Loss: 0.018002\n",
      "\n",
      "Train time for epoch #1323 (step 1323): 1.419516\n",
      "Batch #10\tAverage Generator Loss: 293.661160\tAverage Discriminator Loss: 0.000080\n",
      "\n",
      "Train time for epoch #1324 (step 1324): 1.436484\n",
      "Batch #10\tAverage Generator Loss: 278.732153\tAverage Discriminator Loss: 0.000065\n",
      "\n",
      "Train time for epoch #1325 (step 1325): 1.381876\n",
      "Batch #10\tAverage Generator Loss: 298.955292\tAverage Discriminator Loss: 0.006669\n",
      "\n",
      "Train time for epoch #1326 (step 1326): 1.478028\n",
      "Batch #10\tAverage Generator Loss: 288.193864\tAverage Discriminator Loss: 0.016771\n",
      "\n",
      "Train time for epoch #1327 (step 1327): 1.484297\n",
      "Batch #10\tAverage Generator Loss: 269.248428\tAverage Discriminator Loss: 0.000875\n",
      "\n",
      "Train time for epoch #1328 (step 1328): 1.473702\n",
      "Batch #10\tAverage Generator Loss: 284.280647\tAverage Discriminator Loss: 0.000112\n",
      "\n",
      "Train time for epoch #1329 (step 1329): 1.397294\n",
      "Batch #10\tAverage Generator Loss: 265.692886\tAverage Discriminator Loss: 0.000077\n",
      "\n",
      "Train time for epoch #1330 (step 1330): 1.440699\n",
      "Batch #10\tAverage Generator Loss: 258.079393\tAverage Discriminator Loss: 0.283469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #1331 (step 1331): 1.378119\n",
      "Batch #10\tAverage Generator Loss: 295.269810\tAverage Discriminator Loss: 0.021724\n",
      "\n",
      "Train time for epoch #1332 (step 1332): 1.673163\n",
      "Batch #10\tAverage Generator Loss: 327.865161\tAverage Discriminator Loss: 0.007890\n",
      "\n",
      "Train time for epoch #1333 (step 1333): 1.425517\n",
      "Batch #10\tAverage Generator Loss: 408.461194\tAverage Discriminator Loss: 0.018662\n",
      "\n",
      "Train time for epoch #1334 (step 1334): 1.489001\n",
      "Batch #10\tAverage Generator Loss: 306.460761\tAverage Discriminator Loss: 0.177566\n",
      "\n",
      "Train time for epoch #1335 (step 1335): 1.360226\n",
      "Batch #10\tAverage Generator Loss: 344.605060\tAverage Discriminator Loss: 0.031795\n",
      "\n",
      "Train time for epoch #1336 (step 1336): 1.568077\n",
      "Batch #10\tAverage Generator Loss: 218.096220\tAverage Discriminator Loss: 0.029311\n",
      "\n",
      "Train time for epoch #1337 (step 1337): 1.336451\n",
      "Batch #10\tAverage Generator Loss: 271.367026\tAverage Discriminator Loss: 0.003217\n",
      "\n",
      "Train time for epoch #1338 (step 1338): 1.371956\n",
      "Batch #10\tAverage Generator Loss: 236.962840\tAverage Discriminator Loss: 0.000173\n",
      "\n",
      "Train time for epoch #1339 (step 1339): 1.390330\n",
      "Batch #10\tAverage Generator Loss: 289.547101\tAverage Discriminator Loss: 0.000356\n",
      "\n",
      "Train time for epoch #1340 (step 1340): 1.489250\n",
      "Batch #10\tAverage Generator Loss: 278.193896\tAverage Discriminator Loss: 0.000091\n",
      "\n",
      "Train time for epoch #1341 (step 1341): 1.426553\n",
      "Batch #10\tAverage Generator Loss: 256.647078\tAverage Discriminator Loss: 0.000083\n",
      "\n",
      "Train time for epoch #1342 (step 1342): 1.456373\n",
      "Batch #10\tAverage Generator Loss: 263.690987\tAverage Discriminator Loss: 0.000197\n",
      "\n",
      "Train time for epoch #1343 (step 1343): 1.376398\n",
      "Batch #10\tAverage Generator Loss: 278.711504\tAverage Discriminator Loss: 0.000305\n",
      "\n",
      "Train time for epoch #1344 (step 1344): 1.370431\n",
      "Batch #10\tAverage Generator Loss: 260.398718\tAverage Discriminator Loss: 0.000115\n",
      "\n",
      "Train time for epoch #1345 (step 1345): 1.382031\n",
      "Batch #10\tAverage Generator Loss: 284.172153\tAverage Discriminator Loss: 0.000212\n",
      "\n",
      "Train time for epoch #1346 (step 1346): 1.423914\n",
      "Batch #10\tAverage Generator Loss: 277.120256\tAverage Discriminator Loss: 0.000132\n",
      "\n",
      "Train time for epoch #1347 (step 1347): 1.367109\n",
      "Batch #10\tAverage Generator Loss: 267.712506\tAverage Discriminator Loss: 0.003529\n",
      "\n",
      "Train time for epoch #1348 (step 1348): 1.445473\n",
      "Batch #10\tAverage Generator Loss: 297.872205\tAverage Discriminator Loss: 0.000368\n",
      "\n",
      "Train time for epoch #1349 (step 1349): 1.422415\n",
      "Batch #10\tAverage Generator Loss: 262.768050\tAverage Discriminator Loss: 0.000332\n",
      "\n",
      "Train time for epoch #1350 (step 1350): 1.494900\n",
      "Batch #10\tAverage Generator Loss: 251.100304\tAverage Discriminator Loss: 0.000241\n",
      "\n",
      "Train time for epoch #1351 (step 1351): 1.411285\n",
      "Batch #10\tAverage Generator Loss: 263.054018\tAverage Discriminator Loss: 0.000594\n",
      "\n",
      "Train time for epoch #1352 (step 1352): 1.391337\n",
      "Batch #10\tAverage Generator Loss: 268.810269\tAverage Discriminator Loss: 0.000204\n",
      "\n",
      "Train time for epoch #1353 (step 1353): 1.531484\n",
      "Batch #10\tAverage Generator Loss: 283.899034\tAverage Discriminator Loss: 0.000204\n",
      "\n",
      "Train time for epoch #1354 (step 1354): 1.373784\n",
      "Batch #10\tAverage Generator Loss: 299.159990\tAverage Discriminator Loss: 0.000169\n",
      "\n",
      "Train time for epoch #1355 (step 1355): 1.532600\n",
      "Batch #10\tAverage Generator Loss: 283.918050\tAverage Discriminator Loss: 0.000133\n",
      "\n",
      "Train time for epoch #1356 (step 1356): 1.378311\n",
      "Batch #10\tAverage Generator Loss: 279.915715\tAverage Discriminator Loss: 0.093451\n",
      "\n",
      "Train time for epoch #1357 (step 1357): 1.328521\n",
      "Batch #10\tAverage Generator Loss: 230.968842\tAverage Discriminator Loss: 0.000056\n",
      "\n",
      "Train time for epoch #1358 (step 1358): 1.510366\n",
      "Batch #10\tAverage Generator Loss: 293.195871\tAverage Discriminator Loss: 0.000036\n",
      "\n",
      "Train time for epoch #1359 (step 1359): 1.409821\n",
      "Batch #10\tAverage Generator Loss: 276.159323\tAverage Discriminator Loss: 0.001315\n",
      "\n",
      "Train time for epoch #1360 (step 1360): 1.434093\n",
      "Batch #10\tAverage Generator Loss: 286.990051\tAverage Discriminator Loss: 0.000064\n",
      "\n",
      "Train time for epoch #1361 (step 1361): 1.425242\n",
      "Batch #10\tAverage Generator Loss: 259.492384\tAverage Discriminator Loss: 0.004200\n",
      "\n",
      "Train time for epoch #1362 (step 1362): 1.432455\n",
      "Batch #10\tAverage Generator Loss: 289.622836\tAverage Discriminator Loss: 0.003017\n",
      "\n",
      "Train time for epoch #1363 (step 1363): 1.473757\n",
      "Batch #10\tAverage Generator Loss: 288.568331\tAverage Discriminator Loss: 0.000236\n",
      "\n",
      "Train time for epoch #1364 (step 1364): 1.390246\n",
      "Batch #10\tAverage Generator Loss: 255.429770\tAverage Discriminator Loss: 0.000733\n",
      "\n",
      "Train time for epoch #1365 (step 1365): 1.477698\n",
      "Batch #10\tAverage Generator Loss: 325.763849\tAverage Discriminator Loss: 0.003509\n",
      "\n",
      "Train time for epoch #1366 (step 1366): 1.416274\n",
      "Batch #10\tAverage Generator Loss: 293.873367\tAverage Discriminator Loss: 0.001139\n",
      "\n",
      "Train time for epoch #1367 (step 1367): 1.563128\n",
      "Batch #10\tAverage Generator Loss: 280.336037\tAverage Discriminator Loss: 0.000298\n",
      "\n",
      "Train time for epoch #1368 (step 1368): 1.492808\n",
      "Batch #10\tAverage Generator Loss: 349.352390\tAverage Discriminator Loss: 0.000250\n",
      "\n",
      "Train time for epoch #1369 (step 1369): 1.422269\n",
      "Batch #10\tAverage Generator Loss: 298.246717\tAverage Discriminator Loss: 0.000209\n",
      "\n",
      "Train time for epoch #1370 (step 1370): 1.382430\n",
      "Batch #10\tAverage Generator Loss: 334.361371\tAverage Discriminator Loss: 0.001059\n",
      "\n",
      "Train time for epoch #1371 (step 1371): 1.423503\n",
      "Batch #10\tAverage Generator Loss: 318.046365\tAverage Discriminator Loss: 0.000454\n",
      "\n",
      "Train time for epoch #1372 (step 1372): 1.426957\n",
      "Batch #10\tAverage Generator Loss: 303.658437\tAverage Discriminator Loss: 0.002389\n",
      "\n",
      "Train time for epoch #1373 (step 1373): 1.492630\n",
      "Batch #10\tAverage Generator Loss: 354.015390\tAverage Discriminator Loss: 0.000907\n",
      "\n",
      "Train time for epoch #1374 (step 1374): 1.382234\n",
      "Batch #10\tAverage Generator Loss: 298.454936\tAverage Discriminator Loss: 0.000536\n",
      "\n",
      "Train time for epoch #1375 (step 1375): 1.462381\n",
      "Batch #10\tAverage Generator Loss: 334.089810\tAverage Discriminator Loss: 0.000276\n",
      "\n",
      "Train time for epoch #1376 (step 1376): 1.504416\n",
      "Batch #10\tAverage Generator Loss: 332.660320\tAverage Discriminator Loss: 0.000198\n",
      "\n",
      "Train time for epoch #1377 (step 1377): 1.302423\n",
      "Batch #10\tAverage Generator Loss: 350.651360\tAverage Discriminator Loss: 0.000179\n",
      "\n",
      "Train time for epoch #1378 (step 1378): 1.538797\n",
      "Batch #10\tAverage Generator Loss: 317.698111\tAverage Discriminator Loss: 0.000145\n",
      "\n",
      "Train time for epoch #1379 (step 1379): 1.477355\n",
      "Batch #10\tAverage Generator Loss: 352.518234\tAverage Discriminator Loss: 0.002923\n",
      "\n",
      "Train time for epoch #1380 (step 1380): 1.381632\n",
      "Batch #10\tAverage Generator Loss: 322.814639\tAverage Discriminator Loss: 0.009444\n",
      "\n",
      "Train time for epoch #1381 (step 1381): 1.377545\n",
      "Batch #10\tAverage Generator Loss: 299.822363\tAverage Discriminator Loss: 0.001147\n",
      "\n",
      "Train time for epoch #1382 (step 1382): 1.406994\n",
      "Batch #10\tAverage Generator Loss: 354.344469\tAverage Discriminator Loss: 0.000370\n",
      "\n",
      "Train time for epoch #1383 (step 1383): 1.418352\n",
      "Batch #10\tAverage Generator Loss: 327.194238\tAverage Discriminator Loss: 0.108429\n",
      "\n",
      "Train time for epoch #1384 (step 1384): 1.471935\n",
      "Batch #10\tAverage Generator Loss: 285.140630\tAverage Discriminator Loss: 0.000336\n",
      "\n",
      "Train time for epoch #1385 (step 1385): 1.378245\n",
      "Batch #10\tAverage Generator Loss: 259.313419\tAverage Discriminator Loss: 0.001474\n",
      "\n",
      "Train time for epoch #1386 (step 1386): 1.393579\n",
      "Batch #10\tAverage Generator Loss: 274.034354\tAverage Discriminator Loss: 0.000153\n",
      "\n",
      "Train time for epoch #1387 (step 1387): 1.417980\n",
      "Batch #10\tAverage Generator Loss: 284.074040\tAverage Discriminator Loss: 0.010965\n",
      "\n",
      "Train time for epoch #1388 (step 1388): 1.425231\n",
      "Batch #10\tAverage Generator Loss: 302.624084\tAverage Discriminator Loss: 0.000282\n",
      "\n",
      "Train time for epoch #1389 (step 1389): 1.433333\n",
      "Batch #10\tAverage Generator Loss: 292.968738\tAverage Discriminator Loss: 0.000327\n",
      "\n",
      "Train time for epoch #1390 (step 1390): 1.386093\n",
      "Batch #10\tAverage Generator Loss: 272.208217\tAverage Discriminator Loss: 0.000292\n",
      "\n",
      "Train time for epoch #1391 (step 1391): 1.437987\n",
      "Batch #10\tAverage Generator Loss: 273.446652\tAverage Discriminator Loss: 0.000384\n",
      "\n",
      "Train time for epoch #1392 (step 1392): 1.478868\n",
      "Batch #10\tAverage Generator Loss: 272.167133\tAverage Discriminator Loss: 0.003314\n",
      "\n",
      "Train time for epoch #1393 (step 1393): 1.625367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 301.826974\tAverage Discriminator Loss: 0.000951\n",
      "\n",
      "Train time for epoch #1394 (step 1394): 1.354975\n",
      "Batch #10\tAverage Generator Loss: 285.121286\tAverage Discriminator Loss: 0.001186\n",
      "\n",
      "Train time for epoch #1395 (step 1395): 1.384287\n",
      "Batch #10\tAverage Generator Loss: 293.907475\tAverage Discriminator Loss: 0.000552\n",
      "\n",
      "Train time for epoch #1396 (step 1396): 1.366853\n",
      "Batch #10\tAverage Generator Loss: 307.187866\tAverage Discriminator Loss: 0.000403\n",
      "\n",
      "Train time for epoch #1397 (step 1397): 1.533649\n",
      "Batch #10\tAverage Generator Loss: 299.769710\tAverage Discriminator Loss: 0.000307\n",
      "\n",
      "Train time for epoch #1398 (step 1398): 1.481485\n",
      "Batch #10\tAverage Generator Loss: 323.055489\tAverage Discriminator Loss: 0.000239\n",
      "\n",
      "Train time for epoch #1399 (step 1399): 1.400088\n",
      "Batch #10\tAverage Generator Loss: 294.701062\tAverage Discriminator Loss: 0.000219\n",
      "\n",
      "Train time for epoch #1400 (step 1400): 1.495574\n",
      "Batch #10\tAverage Generator Loss: 425.371739\tAverage Discriminator Loss: 0.121307\n",
      "\n",
      "Train time for epoch #1401 (step 1401): 1.375593\n",
      "Batch #10\tAverage Generator Loss: 331.328362\tAverage Discriminator Loss: 0.322597\n",
      "\n",
      "Train time for epoch #1402 (step 1402): 1.515910\n",
      "Batch #10\tAverage Generator Loss: 517.290005\tAverage Discriminator Loss: 0.004924\n",
      "\n",
      "Train time for epoch #1403 (step 1403): 1.505687\n",
      "Batch #10\tAverage Generator Loss: 408.896057\tAverage Discriminator Loss: 0.003865\n",
      "\n",
      "Train time for epoch #1404 (step 1404): 1.415422\n",
      "Batch #10\tAverage Generator Loss: 396.799818\tAverage Discriminator Loss: 0.000987\n",
      "\n",
      "Train time for epoch #1405 (step 1405): 1.373228\n",
      "Batch #10\tAverage Generator Loss: 392.503519\tAverage Discriminator Loss: 0.000050\n",
      "\n",
      "Train time for epoch #1406 (step 1406): 1.501944\n",
      "Batch #10\tAverage Generator Loss: 376.969379\tAverage Discriminator Loss: 0.000077\n",
      "\n",
      "Train time for epoch #1407 (step 1407): 1.392608\n",
      "Batch #10\tAverage Generator Loss: 519.020543\tAverage Discriminator Loss: 0.272070\n",
      "\n",
      "Train time for epoch #1408 (step 1408): 1.380746\n",
      "Batch #10\tAverage Generator Loss: 523.522003\tAverage Discriminator Loss: 0.002381\n",
      "\n",
      "Train time for epoch #1409 (step 1409): 1.412846\n",
      "Batch #10\tAverage Generator Loss: 499.406639\tAverage Discriminator Loss: 0.008581\n",
      "\n",
      "Train time for epoch #1410 (step 1410): 1.415864\n",
      "Batch #10\tAverage Generator Loss: 698.142136\tAverage Discriminator Loss: 0.410940\n",
      "\n",
      "Train time for epoch #1411 (step 1411): 1.426240\n",
      "Batch #10\tAverage Generator Loss: 721.657849\tAverage Discriminator Loss: 0.002769\n",
      "\n",
      "Train time for epoch #1412 (step 1412): 1.444274\n",
      "Batch #10\tAverage Generator Loss: 538.935358\tAverage Discriminator Loss: 0.000043\n",
      "\n",
      "Train time for epoch #1413 (step 1413): 1.434252\n",
      "Batch #10\tAverage Generator Loss: 720.846605\tAverage Discriminator Loss: 0.000074\n",
      "\n",
      "Train time for epoch #1414 (step 1414): 1.520081\n",
      "Batch #10\tAverage Generator Loss: 1085.544785\tAverage Discriminator Loss: 0.000071\n",
      "\n",
      "Train time for epoch #1415 (step 1415): 1.511554\n",
      "Batch #10\tAverage Generator Loss: 703.960136\tAverage Discriminator Loss: 0.000071\n",
      "\n",
      "Train time for epoch #1416 (step 1416): 1.618733\n",
      "Batch #10\tAverage Generator Loss: 842.638503\tAverage Discriminator Loss: 0.000064\n",
      "\n",
      "Train time for epoch #1417 (step 1417): 1.428078\n",
      "Batch #10\tAverage Generator Loss: 773.931564\tAverage Discriminator Loss: 0.000048\n",
      "\n",
      "Train time for epoch #1418 (step 1418): 1.626785\n",
      "Batch #10\tAverage Generator Loss: 914.132001\tAverage Discriminator Loss: 0.013629\n",
      "\n",
      "Train time for epoch #1419 (step 1419): 1.515018\n",
      "Batch #10\tAverage Generator Loss: 784.594934\tAverage Discriminator Loss: 0.000110\n",
      "\n",
      "Train time for epoch #1420 (step 1420): 1.413894\n",
      "Batch #10\tAverage Generator Loss: 692.788547\tAverage Discriminator Loss: 0.000143\n",
      "\n",
      "Train time for epoch #1421 (step 1421): 1.444017\n",
      "Batch #10\tAverage Generator Loss: 613.651089\tAverage Discriminator Loss: 0.000127\n",
      "\n",
      "Train time for epoch #1422 (step 1422): 1.430969\n",
      "Batch #10\tAverage Generator Loss: 630.772441\tAverage Discriminator Loss: 0.000127\n",
      "\n",
      "Train time for epoch #1423 (step 1423): 1.375908\n",
      "Batch #10\tAverage Generator Loss: 748.799500\tAverage Discriminator Loss: 0.002430\n",
      "\n",
      "Train time for epoch #1424 (step 1424): 1.384651\n",
      "Batch #10\tAverage Generator Loss: 553.296921\tAverage Discriminator Loss: 0.001010\n",
      "\n",
      "Train time for epoch #1425 (step 1425): 1.440389\n",
      "Batch #10\tAverage Generator Loss: 617.316022\tAverage Discriminator Loss: 0.000367\n",
      "\n",
      "Train time for epoch #1426 (step 1426): 1.443096\n",
      "Batch #10\tAverage Generator Loss: 464.716191\tAverage Discriminator Loss: 0.045929\n",
      "\n",
      "Train time for epoch #1427 (step 1427): 1.567283\n",
      "Batch #10\tAverage Generator Loss: 559.176166\tAverage Discriminator Loss: 0.042278\n",
      "\n",
      "Train time for epoch #1428 (step 1428): 1.420167\n",
      "Batch #10\tAverage Generator Loss: 554.820737\tAverage Discriminator Loss: 0.000023\n",
      "\n",
      "Train time for epoch #1429 (step 1429): 1.384795\n",
      "Batch #10\tAverage Generator Loss: 476.008246\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #1430 (step 1430): 1.433239\n",
      "Batch #10\tAverage Generator Loss: 493.368747\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #1431 (step 1431): 1.401923\n",
      "Batch #10\tAverage Generator Loss: 574.739444\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #1432 (step 1432): 1.389871\n",
      "Batch #10\tAverage Generator Loss: 534.895944\tAverage Discriminator Loss: 0.010826\n",
      "\n",
      "Train time for epoch #1433 (step 1433): 1.440132\n",
      "Batch #10\tAverage Generator Loss: 530.038950\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #1434 (step 1434): 1.429641\n",
      "Batch #10\tAverage Generator Loss: 493.103696\tAverage Discriminator Loss: 0.000041\n",
      "\n",
      "Train time for epoch #1435 (step 1435): 1.389540\n",
      "Batch #10\tAverage Generator Loss: 545.358133\tAverage Discriminator Loss: 0.000021\n",
      "\n",
      "Train time for epoch #1436 (step 1436): 1.502186\n",
      "Batch #10\tAverage Generator Loss: 523.309064\tAverage Discriminator Loss: 0.031413\n",
      "\n",
      "Train time for epoch #1437 (step 1437): 1.427990\n",
      "Batch #10\tAverage Generator Loss: 540.143442\tAverage Discriminator Loss: 0.001559\n",
      "\n",
      "Train time for epoch #1438 (step 1438): 1.478601\n",
      "Batch #10\tAverage Generator Loss: 543.810809\tAverage Discriminator Loss: 0.000093\n",
      "\n",
      "Train time for epoch #1439 (step 1439): 1.400497\n",
      "Batch #10\tAverage Generator Loss: 556.389310\tAverage Discriminator Loss: 0.000069\n",
      "\n",
      "Train time for epoch #1440 (step 1440): 1.326216\n",
      "Batch #10\tAverage Generator Loss: 524.626636\tAverage Discriminator Loss: 0.000129\n",
      "\n",
      "Train time for epoch #1441 (step 1441): 1.497703\n",
      "Batch #10\tAverage Generator Loss: 655.650854\tAverage Discriminator Loss: 0.000225\n",
      "\n",
      "Train time for epoch #1442 (step 1442): 1.503475\n",
      "Batch #10\tAverage Generator Loss: 565.187473\tAverage Discriminator Loss: 0.000193\n",
      "\n",
      "Train time for epoch #1443 (step 1443): 1.384781\n",
      "Batch #10\tAverage Generator Loss: 517.223422\tAverage Discriminator Loss: 0.000210\n",
      "\n",
      "Train time for epoch #1444 (step 1444): 1.435038\n",
      "Batch #10\tAverage Generator Loss: 545.868030\tAverage Discriminator Loss: 0.000190\n",
      "\n",
      "Train time for epoch #1445 (step 1445): 1.462314\n",
      "Batch #10\tAverage Generator Loss: 494.565599\tAverage Discriminator Loss: 0.000157\n",
      "\n",
      "Train time for epoch #1446 (step 1446): 1.352379\n",
      "Batch #10\tAverage Generator Loss: 573.894177\tAverage Discriminator Loss: 0.000149\n",
      "\n",
      "Train time for epoch #1447 (step 1447): 1.362508\n",
      "Batch #10\tAverage Generator Loss: 488.879044\tAverage Discriminator Loss: 0.000113\n",
      "\n",
      "Train time for epoch #1448 (step 1448): 1.391458\n",
      "Batch #10\tAverage Generator Loss: 493.459062\tAverage Discriminator Loss: 0.000109\n",
      "\n",
      "Train time for epoch #1449 (step 1449): 1.439247\n",
      "Batch #10\tAverage Generator Loss: 555.208475\tAverage Discriminator Loss: 0.000109\n",
      "\n",
      "Train time for epoch #1450 (step 1450): 1.494918\n",
      "Batch #10\tAverage Generator Loss: 531.381795\tAverage Discriminator Loss: 0.000112\n",
      "\n",
      "Train time for epoch #1451 (step 1451): 1.539968\n",
      "Batch #10\tAverage Generator Loss: 456.830849\tAverage Discriminator Loss: 0.067982\n",
      "\n",
      "Train time for epoch #1452 (step 1452): 1.525637\n",
      "Batch #10\tAverage Generator Loss: 506.447202\tAverage Discriminator Loss: 0.006912\n",
      "\n",
      "Train time for epoch #1453 (step 1453): 1.323305\n",
      "Batch #10\tAverage Generator Loss: 539.975943\tAverage Discriminator Loss: 0.000402\n",
      "\n",
      "Train time for epoch #1454 (step 1454): 1.447672\n",
      "Batch #10\tAverage Generator Loss: 458.875787\tAverage Discriminator Loss: 0.000130\n",
      "\n",
      "Train time for epoch #1455 (step 1455): 1.441037\n",
      "Batch #10\tAverage Generator Loss: 476.902344\tAverage Discriminator Loss: 0.000084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #1456 (step 1456): 1.501215\n",
      "Batch #10\tAverage Generator Loss: 417.390335\tAverage Discriminator Loss: 0.000100\n",
      "\n",
      "Train time for epoch #1457 (step 1457): 1.436619\n",
      "Batch #10\tAverage Generator Loss: 375.518853\tAverage Discriminator Loss: 0.000094\n",
      "\n",
      "Train time for epoch #1458 (step 1458): 1.382045\n",
      "Batch #10\tAverage Generator Loss: 441.242473\tAverage Discriminator Loss: 0.000087\n",
      "\n",
      "Train time for epoch #1459 (step 1459): 1.380758\n",
      "Batch #10\tAverage Generator Loss: 483.949423\tAverage Discriminator Loss: 0.000063\n",
      "\n",
      "Train time for epoch #1460 (step 1460): 1.387395\n",
      "Batch #10\tAverage Generator Loss: 432.508107\tAverage Discriminator Loss: 0.000086\n",
      "\n",
      "Train time for epoch #1461 (step 1461): 1.629894\n",
      "Batch #10\tAverage Generator Loss: 396.765752\tAverage Discriminator Loss: 0.108601\n",
      "\n",
      "Train time for epoch #1462 (step 1462): 1.342837\n",
      "Batch #10\tAverage Generator Loss: 436.455325\tAverage Discriminator Loss: 0.003485\n",
      "\n",
      "Train time for epoch #1463 (step 1463): 1.425835\n",
      "Batch #10\tAverage Generator Loss: 446.931880\tAverage Discriminator Loss: 0.000127\n",
      "\n",
      "Train time for epoch #1464 (step 1464): 1.434815\n",
      "Batch #10\tAverage Generator Loss: 403.481898\tAverage Discriminator Loss: 0.000146\n",
      "\n",
      "Train time for epoch #1465 (step 1465): 1.381038\n",
      "Batch #10\tAverage Generator Loss: 395.824698\tAverage Discriminator Loss: 0.000083\n",
      "\n",
      "Train time for epoch #1466 (step 1466): 1.531614\n",
      "Batch #10\tAverage Generator Loss: 443.139560\tAverage Discriminator Loss: 0.000115\n",
      "\n",
      "Train time for epoch #1467 (step 1467): 1.448595\n",
      "Batch #10\tAverage Generator Loss: 409.986894\tAverage Discriminator Loss: 0.003844\n",
      "\n",
      "Train time for epoch #1468 (step 1468): 1.423975\n",
      "Batch #10\tAverage Generator Loss: 350.317430\tAverage Discriminator Loss: 0.001105\n",
      "\n",
      "Train time for epoch #1469 (step 1469): 1.513280\n",
      "Batch #10\tAverage Generator Loss: 427.958920\tAverage Discriminator Loss: 0.000536\n",
      "\n",
      "Train time for epoch #1470 (step 1470): 1.370754\n",
      "Batch #10\tAverage Generator Loss: 411.293924\tAverage Discriminator Loss: 0.001807\n",
      "\n",
      "Train time for epoch #1471 (step 1471): 1.530466\n",
      "Batch #10\tAverage Generator Loss: 439.038811\tAverage Discriminator Loss: 0.000882\n",
      "\n",
      "Train time for epoch #1472 (step 1472): 1.442043\n",
      "Batch #10\tAverage Generator Loss: 427.597528\tAverage Discriminator Loss: 0.000314\n",
      "\n",
      "Train time for epoch #1473 (step 1473): 1.340117\n",
      "Batch #10\tAverage Generator Loss: 437.422095\tAverage Discriminator Loss: 0.000192\n",
      "\n",
      "Train time for epoch #1474 (step 1474): 1.370043\n",
      "Batch #10\tAverage Generator Loss: 469.959714\tAverage Discriminator Loss: 0.000212\n",
      "\n",
      "Train time for epoch #1475 (step 1475): 1.427260\n",
      "Batch #10\tAverage Generator Loss: 418.151677\tAverage Discriminator Loss: 0.000152\n",
      "\n",
      "Train time for epoch #1476 (step 1476): 1.386916\n",
      "Batch #10\tAverage Generator Loss: 420.582603\tAverage Discriminator Loss: 0.000136\n",
      "\n",
      "Train time for epoch #1477 (step 1477): 1.417257\n",
      "Batch #10\tAverage Generator Loss: 444.178851\tAverage Discriminator Loss: 0.000165\n",
      "\n",
      "Train time for epoch #1478 (step 1478): 1.387126\n",
      "Batch #10\tAverage Generator Loss: 387.779367\tAverage Discriminator Loss: 0.002618\n",
      "\n",
      "Train time for epoch #1479 (step 1479): 1.450863\n",
      "Batch #10\tAverage Generator Loss: 415.245763\tAverage Discriminator Loss: 0.101546\n",
      "\n",
      "Train time for epoch #1480 (step 1480): 1.468371\n",
      "Batch #10\tAverage Generator Loss: 369.619664\tAverage Discriminator Loss: 0.000327\n",
      "\n",
      "Train time for epoch #1481 (step 1481): 1.436773\n",
      "Batch #10\tAverage Generator Loss: 365.680450\tAverage Discriminator Loss: 0.133099\n",
      "\n",
      "Train time for epoch #1482 (step 1482): 1.612259\n",
      "Batch #10\tAverage Generator Loss: 403.819843\tAverage Discriminator Loss: 0.001280\n",
      "\n",
      "Train time for epoch #1483 (step 1483): 1.434922\n",
      "Batch #10\tAverage Generator Loss: 390.007613\tAverage Discriminator Loss: 0.006186\n",
      "\n",
      "Train time for epoch #1484 (step 1484): 1.385162\n",
      "Batch #10\tAverage Generator Loss: 394.363303\tAverage Discriminator Loss: 0.001509\n",
      "\n",
      "Train time for epoch #1485 (step 1485): 1.477278\n",
      "Batch #10\tAverage Generator Loss: 394.063005\tAverage Discriminator Loss: 0.288091\n",
      "\n",
      "Train time for epoch #1486 (step 1486): 1.571656\n",
      "Batch #10\tAverage Generator Loss: 333.339627\tAverage Discriminator Loss: 0.000215\n",
      "\n",
      "Train time for epoch #1487 (step 1487): 1.410577\n",
      "Batch #10\tAverage Generator Loss: 314.602133\tAverage Discriminator Loss: 0.000785\n",
      "\n",
      "Train time for epoch #1488 (step 1488): 1.469193\n",
      "Batch #10\tAverage Generator Loss: 377.156073\tAverage Discriminator Loss: 0.002671\n",
      "\n",
      "Train time for epoch #1489 (step 1489): 1.387706\n",
      "Batch #10\tAverage Generator Loss: 341.241154\tAverage Discriminator Loss: 0.008416\n",
      "\n",
      "Train time for epoch #1490 (step 1490): 1.461644\n",
      "Batch #10\tAverage Generator Loss: 387.637619\tAverage Discriminator Loss: 0.002635\n",
      "\n",
      "Train time for epoch #1491 (step 1491): 1.381589\n",
      "Batch #10\tAverage Generator Loss: 406.569178\tAverage Discriminator Loss: 0.005995\n",
      "\n",
      "Train time for epoch #1492 (step 1492): 1.382669\n",
      "Batch #10\tAverage Generator Loss: 380.317693\tAverage Discriminator Loss: 0.001437\n",
      "\n",
      "Train time for epoch #1493 (step 1493): 1.386966\n",
      "Batch #10\tAverage Generator Loss: 397.392586\tAverage Discriminator Loss: 0.000735\n",
      "\n",
      "Train time for epoch #1494 (step 1494): 1.433957\n",
      "Batch #10\tAverage Generator Loss: 372.344339\tAverage Discriminator Loss: 0.000475\n",
      "\n",
      "Train time for epoch #1495 (step 1495): 1.536763\n",
      "Batch #10\tAverage Generator Loss: 390.267059\tAverage Discriminator Loss: 0.000372\n",
      "\n",
      "Train time for epoch #1496 (step 1496): 1.520816\n",
      "Batch #10\tAverage Generator Loss: 369.971435\tAverage Discriminator Loss: 0.000575\n",
      "\n",
      "Train time for epoch #1497 (step 1497): 1.478767\n",
      "Batch #10\tAverage Generator Loss: 363.937039\tAverage Discriminator Loss: 0.001892\n",
      "\n",
      "Train time for epoch #1498 (step 1498): 1.471611\n",
      "Batch #10\tAverage Generator Loss: 373.351875\tAverage Discriminator Loss: 0.002843\n",
      "\n",
      "Train time for epoch #1499 (step 1499): 1.412483\n",
      "Batch #10\tAverage Generator Loss: 363.575815\tAverage Discriminator Loss: 0.000991\n",
      "\n",
      "Train time for epoch #1500 (step 1500): 1.434274\n",
      "Batch #10\tAverage Generator Loss: 398.773645\tAverage Discriminator Loss: 0.005561\n",
      "\n",
      "Train time for epoch #1501 (step 1501): 1.383900\n",
      "Batch #10\tAverage Generator Loss: 421.003000\tAverage Discriminator Loss: 0.001081\n",
      "\n",
      "Train time for epoch #1502 (step 1502): 1.398543\n",
      "Batch #10\tAverage Generator Loss: 391.422850\tAverage Discriminator Loss: 0.000722\n",
      "\n",
      "Train time for epoch #1503 (step 1503): 1.428693\n",
      "Batch #10\tAverage Generator Loss: 408.495697\tAverage Discriminator Loss: 0.000506\n",
      "\n",
      "Train time for epoch #1504 (step 1504): 1.396585\n",
      "Batch #10\tAverage Generator Loss: 371.383066\tAverage Discriminator Loss: 0.000370\n",
      "\n",
      "Train time for epoch #1505 (step 1505): 1.551079\n",
      "Batch #10\tAverage Generator Loss: 465.804041\tAverage Discriminator Loss: 0.000465\n",
      "\n",
      "Train time for epoch #1506 (step 1506): 1.399801\n",
      "Batch #10\tAverage Generator Loss: 393.181953\tAverage Discriminator Loss: 0.000317\n",
      "\n",
      "Train time for epoch #1507 (step 1507): 1.393641\n",
      "Batch #10\tAverage Generator Loss: 390.813805\tAverage Discriminator Loss: 0.000296\n",
      "\n",
      "Train time for epoch #1508 (step 1508): 1.370222\n",
      "Batch #10\tAverage Generator Loss: 391.384148\tAverage Discriminator Loss: 0.000252\n",
      "\n",
      "Train time for epoch #1509 (step 1509): 1.415916\n",
      "Batch #10\tAverage Generator Loss: 370.923144\tAverage Discriminator Loss: 0.010901\n",
      "\n",
      "Train time for epoch #1510 (step 1510): 1.408462\n",
      "Batch #10\tAverage Generator Loss: 395.996280\tAverage Discriminator Loss: 0.003011\n",
      "\n",
      "Train time for epoch #1511 (step 1511): 1.483197\n",
      "Batch #10\tAverage Generator Loss: 368.121909\tAverage Discriminator Loss: 0.000266\n",
      "\n",
      "Train time for epoch #1512 (step 1512): 1.417938\n",
      "Batch #10\tAverage Generator Loss: 367.737219\tAverage Discriminator Loss: 0.000395\n",
      "\n",
      "Train time for epoch #1513 (step 1513): 1.409858\n",
      "Batch #10\tAverage Generator Loss: 385.269794\tAverage Discriminator Loss: 0.000802\n",
      "\n",
      "Train time for epoch #1514 (step 1514): 1.547672\n",
      "Batch #10\tAverage Generator Loss: 403.429701\tAverage Discriminator Loss: 0.000203\n",
      "\n",
      "Train time for epoch #1515 (step 1515): 1.503316\n",
      "Batch #10\tAverage Generator Loss: 384.627042\tAverage Discriminator Loss: 0.000206\n",
      "\n",
      "Train time for epoch #1516 (step 1516): 1.399046\n",
      "Batch #10\tAverage Generator Loss: 397.384619\tAverage Discriminator Loss: 0.000179\n",
      "\n",
      "Train time for epoch #1517 (step 1517): 1.432819\n",
      "Batch #10\tAverage Generator Loss: 389.291420\tAverage Discriminator Loss: 0.000171\n",
      "\n",
      "Train time for epoch #1518 (step 1518): 1.484175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 343.742299\tAverage Discriminator Loss: 0.046031\n",
      "\n",
      "Train time for epoch #1519 (step 1519): 1.501720\n",
      "Batch #10\tAverage Generator Loss: 460.627177\tAverage Discriminator Loss: 0.001351\n",
      "\n",
      "Train time for epoch #1520 (step 1520): 1.498333\n",
      "Batch #10\tAverage Generator Loss: 375.684085\tAverage Discriminator Loss: 0.000150\n",
      "\n",
      "Train time for epoch #1521 (step 1521): 1.488729\n",
      "Batch #10\tAverage Generator Loss: 398.907147\tAverage Discriminator Loss: 0.006947\n",
      "\n",
      "Train time for epoch #1522 (step 1522): 1.387447\n",
      "Batch #10\tAverage Generator Loss: 446.644473\tAverage Discriminator Loss: 0.002343\n",
      "\n",
      "Train time for epoch #1523 (step 1523): 1.420306\n",
      "Batch #10\tAverage Generator Loss: 407.070195\tAverage Discriminator Loss: 0.001488\n",
      "\n",
      "Train time for epoch #1524 (step 1524): 1.447276\n",
      "Batch #10\tAverage Generator Loss: 393.513980\tAverage Discriminator Loss: 0.000253\n",
      "\n",
      "Train time for epoch #1525 (step 1525): 1.525870\n",
      "Batch #10\tAverage Generator Loss: 432.685190\tAverage Discriminator Loss: 0.000130\n",
      "\n",
      "Train time for epoch #1526 (step 1526): 1.491493\n",
      "Batch #10\tAverage Generator Loss: 409.521475\tAverage Discriminator Loss: 0.000145\n",
      "\n",
      "Train time for epoch #1527 (step 1527): 1.378016\n",
      "Batch #10\tAverage Generator Loss: 393.660445\tAverage Discriminator Loss: 0.000167\n",
      "\n",
      "Train time for epoch #1528 (step 1528): 1.389537\n",
      "Batch #10\tAverage Generator Loss: 400.530437\tAverage Discriminator Loss: 0.000133\n",
      "\n",
      "Train time for epoch #1529 (step 1529): 1.383899\n",
      "Batch #10\tAverage Generator Loss: 435.866705\tAverage Discriminator Loss: 0.000123\n",
      "\n",
      "Train time for epoch #1530 (step 1530): 1.443818\n",
      "Batch #10\tAverage Generator Loss: 433.339049\tAverage Discriminator Loss: 0.000209\n",
      "\n",
      "Train time for epoch #1531 (step 1531): 1.395293\n",
      "Batch #10\tAverage Generator Loss: 448.714255\tAverage Discriminator Loss: 0.000648\n",
      "\n",
      "Train time for epoch #1532 (step 1532): 1.530614\n",
      "Batch #10\tAverage Generator Loss: 399.608195\tAverage Discriminator Loss: 0.000312\n",
      "\n",
      "Train time for epoch #1533 (step 1533): 1.335204\n",
      "Batch #10\tAverage Generator Loss: 366.318666\tAverage Discriminator Loss: 0.000197\n",
      "\n",
      "Train time for epoch #1534 (step 1534): 1.446900\n",
      "Batch #10\tAverage Generator Loss: 370.593318\tAverage Discriminator Loss: 0.000182\n",
      "\n",
      "Train time for epoch #1535 (step 1535): 1.429007\n",
      "Batch #10\tAverage Generator Loss: 436.542270\tAverage Discriminator Loss: 0.000155\n",
      "\n",
      "Train time for epoch #1536 (step 1536): 1.540679\n",
      "Batch #10\tAverage Generator Loss: 385.476559\tAverage Discriminator Loss: 0.000608\n",
      "\n",
      "Train time for epoch #1537 (step 1537): 1.508703\n",
      "Batch #10\tAverage Generator Loss: 461.223645\tAverage Discriminator Loss: 0.001061\n",
      "\n",
      "Train time for epoch #1538 (step 1538): 1.386257\n",
      "Batch #10\tAverage Generator Loss: 410.250090\tAverage Discriminator Loss: 0.000196\n",
      "\n",
      "Train time for epoch #1539 (step 1539): 1.442951\n",
      "Batch #10\tAverage Generator Loss: 395.158073\tAverage Discriminator Loss: 0.000174\n",
      "\n",
      "Train time for epoch #1540 (step 1540): 1.393725\n",
      "Batch #10\tAverage Generator Loss: 401.559000\tAverage Discriminator Loss: 0.000177\n",
      "\n",
      "Train time for epoch #1541 (step 1541): 1.596667\n",
      "Batch #10\tAverage Generator Loss: 391.048301\tAverage Discriminator Loss: 0.000166\n",
      "\n",
      "Train time for epoch #1542 (step 1542): 1.430693\n",
      "Batch #10\tAverage Generator Loss: 365.463959\tAverage Discriminator Loss: 0.000143\n",
      "\n",
      "Train time for epoch #1543 (step 1543): 1.386584\n",
      "Batch #10\tAverage Generator Loss: 387.838986\tAverage Discriminator Loss: 0.000558\n",
      "\n",
      "Train time for epoch #1544 (step 1544): 1.422751\n",
      "Batch #10\tAverage Generator Loss: 450.139658\tAverage Discriminator Loss: 0.000189\n",
      "\n",
      "Train time for epoch #1545 (step 1545): 1.472687\n",
      "Batch #10\tAverage Generator Loss: 418.729965\tAverage Discriminator Loss: 0.000190\n",
      "\n",
      "Train time for epoch #1546 (step 1546): 1.467870\n",
      "Batch #10\tAverage Generator Loss: 455.550613\tAverage Discriminator Loss: 0.000142\n",
      "\n",
      "Train time for epoch #1547 (step 1547): 1.380116\n",
      "Batch #10\tAverage Generator Loss: 455.387692\tAverage Discriminator Loss: 0.000127\n",
      "\n",
      "Train time for epoch #1548 (step 1548): 1.383048\n",
      "Batch #10\tAverage Generator Loss: 378.275604\tAverage Discriminator Loss: 0.000130\n",
      "\n",
      "Train time for epoch #1549 (step 1549): 1.485072\n",
      "Batch #10\tAverage Generator Loss: 433.511966\tAverage Discriminator Loss: 0.011955\n",
      "\n",
      "Train time for epoch #1550 (step 1550): 1.405142\n",
      "Batch #10\tAverage Generator Loss: 446.720216\tAverage Discriminator Loss: 0.001326\n",
      "\n",
      "Train time for epoch #1551 (step 1551): 1.474820\n",
      "Batch #10\tAverage Generator Loss: 459.703271\tAverage Discriminator Loss: 0.000189\n",
      "\n",
      "Train time for epoch #1552 (step 1552): 1.448061\n",
      "Batch #10\tAverage Generator Loss: 360.055521\tAverage Discriminator Loss: 0.000155\n",
      "\n",
      "Train time for epoch #1553 (step 1553): 1.535742\n",
      "Batch #10\tAverage Generator Loss: 431.436066\tAverage Discriminator Loss: 0.000146\n",
      "\n",
      "Train time for epoch #1554 (step 1554): 1.489042\n",
      "Batch #10\tAverage Generator Loss: 420.010286\tAverage Discriminator Loss: 0.000142\n",
      "\n",
      "Train time for epoch #1555 (step 1555): 1.427981\n",
      "Batch #10\tAverage Generator Loss: 440.389209\tAverage Discriminator Loss: 0.000125\n",
      "\n",
      "Train time for epoch #1556 (step 1556): 1.402129\n",
      "Batch #10\tAverage Generator Loss: 343.476041\tAverage Discriminator Loss: 0.000115\n",
      "\n",
      "Train time for epoch #1557 (step 1557): 1.374089\n",
      "Batch #10\tAverage Generator Loss: 391.098656\tAverage Discriminator Loss: 0.006564\n",
      "\n",
      "Train time for epoch #1558 (step 1558): 1.441314\n",
      "Batch #10\tAverage Generator Loss: 399.488055\tAverage Discriminator Loss: 0.000271\n",
      "\n",
      "Train time for epoch #1559 (step 1559): 1.459436\n",
      "Batch #10\tAverage Generator Loss: 478.723236\tAverage Discriminator Loss: 0.000299\n",
      "\n",
      "Train time for epoch #1560 (step 1560): 1.501363\n",
      "Batch #10\tAverage Generator Loss: 445.182997\tAverage Discriminator Loss: 0.000211\n",
      "\n",
      "Train time for epoch #1561 (step 1561): 1.424413\n",
      "Batch #10\tAverage Generator Loss: 407.979483\tAverage Discriminator Loss: 0.000198\n",
      "\n",
      "Train time for epoch #1562 (step 1562): 1.453990\n",
      "Batch #10\tAverage Generator Loss: 445.510361\tAverage Discriminator Loss: 0.000149\n",
      "\n",
      "Train time for epoch #1563 (step 1563): 1.505614\n",
      "Batch #10\tAverage Generator Loss: 354.320564\tAverage Discriminator Loss: 0.000511\n",
      "\n",
      "Train time for epoch #1564 (step 1564): 1.461290\n",
      "Batch #10\tAverage Generator Loss: 432.427725\tAverage Discriminator Loss: 0.000201\n",
      "\n",
      "Train time for epoch #1565 (step 1565): 1.428962\n",
      "Batch #10\tAverage Generator Loss: 391.708012\tAverage Discriminator Loss: 0.000174\n",
      "\n",
      "Train time for epoch #1566 (step 1566): 1.434047\n",
      "Batch #10\tAverage Generator Loss: 391.835852\tAverage Discriminator Loss: 0.000160\n",
      "\n",
      "Train time for epoch #1567 (step 1567): 1.385926\n",
      "Batch #10\tAverage Generator Loss: 411.807027\tAverage Discriminator Loss: 0.000194\n",
      "\n",
      "Train time for epoch #1568 (step 1568): 1.393582\n",
      "Batch #10\tAverage Generator Loss: 401.530337\tAverage Discriminator Loss: 0.000144\n",
      "\n",
      "Train time for epoch #1569 (step 1569): 1.443983\n",
      "Batch #10\tAverage Generator Loss: 474.067049\tAverage Discriminator Loss: 0.000133\n",
      "\n",
      "Train time for epoch #1570 (step 1570): 1.438979\n",
      "Batch #10\tAverage Generator Loss: 423.842245\tAverage Discriminator Loss: 0.065380\n",
      "\n",
      "Train time for epoch #1571 (step 1571): 1.444902\n",
      "Batch #10\tAverage Generator Loss: 414.917346\tAverage Discriminator Loss: 0.000187\n",
      "\n",
      "Train time for epoch #1572 (step 1572): 1.532495\n",
      "Batch #10\tAverage Generator Loss: 412.658195\tAverage Discriminator Loss: 0.000074\n",
      "\n",
      "Train time for epoch #1573 (step 1573): 1.568244\n",
      "Batch #10\tAverage Generator Loss: 406.111800\tAverage Discriminator Loss: 0.000077\n",
      "\n",
      "Train time for epoch #1574 (step 1574): 1.445653\n",
      "Batch #10\tAverage Generator Loss: 383.588087\tAverage Discriminator Loss: 0.000183\n",
      "\n",
      "Train time for epoch #1575 (step 1575): 1.440916\n",
      "Batch #10\tAverage Generator Loss: 475.763730\tAverage Discriminator Loss: 0.000055\n",
      "\n",
      "Train time for epoch #1576 (step 1576): 1.420893\n",
      "Batch #10\tAverage Generator Loss: 389.001263\tAverage Discriminator Loss: 0.000053\n",
      "\n",
      "Train time for epoch #1577 (step 1577): 1.388364\n",
      "Batch #10\tAverage Generator Loss: 436.240073\tAverage Discriminator Loss: 0.000210\n",
      "\n",
      "Train time for epoch #1578 (step 1578): 1.463522\n",
      "Batch #10\tAverage Generator Loss: 429.887637\tAverage Discriminator Loss: 0.000054\n",
      "\n",
      "Train time for epoch #1579 (step 1579): 1.438253\n",
      "Batch #10\tAverage Generator Loss: 391.608365\tAverage Discriminator Loss: 0.000053\n",
      "\n",
      "Train time for epoch #1580 (step 1580): 1.436275\n",
      "Batch #10\tAverage Generator Loss: 382.401425\tAverage Discriminator Loss: 0.002282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #1581 (step 1581): 1.444508\n",
      "Batch #10\tAverage Generator Loss: 434.361089\tAverage Discriminator Loss: 0.000544\n",
      "\n",
      "Train time for epoch #1582 (step 1582): 1.371367\n",
      "Batch #10\tAverage Generator Loss: 406.600566\tAverage Discriminator Loss: 0.000681\n",
      "\n",
      "Train time for epoch #1583 (step 1583): 1.399224\n",
      "Batch #10\tAverage Generator Loss: 419.540390\tAverage Discriminator Loss: 0.000189\n",
      "\n",
      "Train time for epoch #1584 (step 1584): 1.505525\n",
      "Batch #10\tAverage Generator Loss: 377.488086\tAverage Discriminator Loss: 0.000165\n",
      "\n",
      "Train time for epoch #1585 (step 1585): 1.434466\n",
      "Batch #10\tAverage Generator Loss: 433.667036\tAverage Discriminator Loss: 0.000137\n",
      "\n",
      "Train time for epoch #1586 (step 1586): 1.393044\n",
      "Batch #10\tAverage Generator Loss: 431.819864\tAverage Discriminator Loss: 0.000138\n",
      "\n",
      "Train time for epoch #1587 (step 1587): 1.340546\n",
      "Batch #10\tAverage Generator Loss: 469.519354\tAverage Discriminator Loss: 0.000164\n",
      "\n",
      "Train time for epoch #1588 (step 1588): 1.415000\n",
      "Batch #10\tAverage Generator Loss: 454.079857\tAverage Discriminator Loss: 0.000220\n",
      "\n",
      "Train time for epoch #1589 (step 1589): 1.493233\n",
      "Batch #10\tAverage Generator Loss: 422.830930\tAverage Discriminator Loss: 0.000172\n",
      "\n",
      "Train time for epoch #1590 (step 1590): 1.425143\n",
      "Batch #10\tAverage Generator Loss: 433.639787\tAverage Discriminator Loss: 0.000273\n",
      "\n",
      "Train time for epoch #1591 (step 1591): 1.426924\n",
      "Batch #10\tAverage Generator Loss: 379.345030\tAverage Discriminator Loss: 0.000308\n",
      "\n",
      "Train time for epoch #1592 (step 1592): 1.450300\n",
      "Batch #10\tAverage Generator Loss: 352.019989\tAverage Discriminator Loss: 0.000228\n",
      "\n",
      "Train time for epoch #1593 (step 1593): 1.434580\n",
      "Batch #10\tAverage Generator Loss: 430.899722\tAverage Discriminator Loss: 0.000126\n",
      "\n",
      "Train time for epoch #1594 (step 1594): 1.534014\n",
      "Batch #10\tAverage Generator Loss: 427.668594\tAverage Discriminator Loss: 0.000110\n",
      "\n",
      "Train time for epoch #1595 (step 1595): 1.423643\n",
      "Batch #10\tAverage Generator Loss: 447.513624\tAverage Discriminator Loss: 0.000096\n",
      "\n",
      "Train time for epoch #1596 (step 1596): 1.447246\n",
      "Batch #10\tAverage Generator Loss: 392.546149\tAverage Discriminator Loss: 0.000081\n",
      "\n",
      "Train time for epoch #1597 (step 1597): 1.404730\n",
      "Batch #10\tAverage Generator Loss: 449.209068\tAverage Discriminator Loss: 0.000078\n",
      "\n",
      "Train time for epoch #1598 (step 1598): 1.387599\n",
      "Batch #10\tAverage Generator Loss: 419.139098\tAverage Discriminator Loss: 0.000070\n",
      "\n",
      "Train time for epoch #1599 (step 1599): 1.266590\n",
      "Batch #10\tAverage Generator Loss: 445.826144\tAverage Discriminator Loss: 0.000067\n",
      "\n",
      "Train time for epoch #1600 (step 1600): 1.434570\n",
      "Batch #10\tAverage Generator Loss: 454.841959\tAverage Discriminator Loss: 0.000065\n",
      "\n",
      "Train time for epoch #1601 (step 1601): 1.339422\n",
      "Batch #10\tAverage Generator Loss: 416.367075\tAverage Discriminator Loss: 0.000115\n",
      "\n",
      "Train time for epoch #1602 (step 1602): 1.377035\n",
      "Batch #10\tAverage Generator Loss: 410.341045\tAverage Discriminator Loss: 0.000086\n",
      "\n",
      "Train time for epoch #1603 (step 1603): 1.468358\n",
      "Batch #10\tAverage Generator Loss: 502.930687\tAverage Discriminator Loss: 0.000054\n",
      "\n",
      "Train time for epoch #1604 (step 1604): 1.304957\n",
      "Batch #10\tAverage Generator Loss: 420.754623\tAverage Discriminator Loss: 0.011551\n",
      "\n",
      "Train time for epoch #1605 (step 1605): 1.433400\n",
      "Batch #10\tAverage Generator Loss: 416.808606\tAverage Discriminator Loss: 0.001496\n",
      "\n",
      "Train time for epoch #1606 (step 1606): 1.373570\n",
      "Batch #10\tAverage Generator Loss: 456.816655\tAverage Discriminator Loss: 0.000055\n",
      "\n",
      "Train time for epoch #1607 (step 1607): 1.385155\n",
      "Batch #10\tAverage Generator Loss: 359.025273\tAverage Discriminator Loss: 0.000065\n",
      "\n",
      "Train time for epoch #1608 (step 1608): 1.379595\n",
      "Batch #10\tAverage Generator Loss: 489.584387\tAverage Discriminator Loss: 0.000057\n",
      "\n",
      "Train time for epoch #1609 (step 1609): 1.550513\n",
      "Batch #10\tAverage Generator Loss: 411.975752\tAverage Discriminator Loss: 0.000057\n",
      "\n",
      "Train time for epoch #1610 (step 1610): 1.382010\n",
      "Batch #10\tAverage Generator Loss: 456.563765\tAverage Discriminator Loss: 0.000265\n",
      "\n",
      "Train time for epoch #1611 (step 1611): 1.568554\n",
      "Batch #10\tAverage Generator Loss: 409.358432\tAverage Discriminator Loss: 0.001221\n",
      "\n",
      "Train time for epoch #1612 (step 1612): 1.382280\n",
      "Batch #10\tAverage Generator Loss: 504.037390\tAverage Discriminator Loss: 0.000943\n",
      "\n",
      "Train time for epoch #1613 (step 1613): 1.379854\n",
      "Batch #10\tAverage Generator Loss: 471.277129\tAverage Discriminator Loss: 0.000108\n",
      "\n",
      "Train time for epoch #1614 (step 1614): 1.378862\n",
      "Batch #10\tAverage Generator Loss: 461.230450\tAverage Discriminator Loss: 0.000062\n",
      "\n",
      "Train time for epoch #1615 (step 1615): 1.443501\n",
      "Batch #10\tAverage Generator Loss: 466.673106\tAverage Discriminator Loss: 0.000149\n",
      "\n",
      "Train time for epoch #1616 (step 1616): 1.336091\n",
      "Batch #10\tAverage Generator Loss: 442.250960\tAverage Discriminator Loss: 0.061766\n",
      "\n",
      "Train time for epoch #1617 (step 1617): 1.486216\n",
      "Batch #10\tAverage Generator Loss: 410.580345\tAverage Discriminator Loss: 0.000269\n",
      "\n",
      "Train time for epoch #1618 (step 1618): 1.481398\n",
      "Batch #10\tAverage Generator Loss: 398.571039\tAverage Discriminator Loss: 0.000162\n",
      "\n",
      "Train time for epoch #1619 (step 1619): 1.419459\n",
      "Batch #10\tAverage Generator Loss: 400.202606\tAverage Discriminator Loss: 0.001132\n",
      "\n",
      "Train time for epoch #1620 (step 1620): 1.570947\n",
      "Batch #10\tAverage Generator Loss: 373.286075\tAverage Discriminator Loss: 0.000318\n",
      "\n",
      "Train time for epoch #1621 (step 1621): 1.451722\n",
      "Batch #10\tAverage Generator Loss: 331.569772\tAverage Discriminator Loss: 0.004172\n",
      "\n",
      "Train time for epoch #1622 (step 1622): 1.395318\n",
      "Batch #10\tAverage Generator Loss: 407.734201\tAverage Discriminator Loss: 0.002952\n",
      "\n",
      "Train time for epoch #1623 (step 1623): 1.435919\n",
      "Batch #10\tAverage Generator Loss: 362.722887\tAverage Discriminator Loss: 0.002320\n",
      "\n",
      "Train time for epoch #1624 (step 1624): 1.529543\n",
      "Batch #10\tAverage Generator Loss: 425.069759\tAverage Discriminator Loss: 0.000245\n",
      "\n",
      "Train time for epoch #1625 (step 1625): 1.510425\n",
      "Batch #10\tAverage Generator Loss: 372.601770\tAverage Discriminator Loss: 1.510222\n",
      "\n",
      "Train time for epoch #1626 (step 1626): 1.477476\n",
      "Batch #10\tAverage Generator Loss: 490.676799\tAverage Discriminator Loss: 0.328091\n",
      "\n",
      "Train time for epoch #1627 (step 1627): 1.434678\n",
      "Batch #10\tAverage Generator Loss: 294.753541\tAverage Discriminator Loss: 0.491934\n",
      "\n",
      "Train time for epoch #1628 (step 1628): 1.433918\n",
      "Batch #10\tAverage Generator Loss: 445.103690\tAverage Discriminator Loss: 0.031632\n",
      "\n",
      "Train time for epoch #1629 (step 1629): 1.357701\n",
      "Batch #10\tAverage Generator Loss: 616.266852\tAverage Discriminator Loss: 0.014455\n",
      "\n",
      "Train time for epoch #1630 (step 1630): 1.494477\n",
      "Batch #10\tAverage Generator Loss: 733.577446\tAverage Discriminator Loss: 0.138734\n",
      "\n",
      "Train time for epoch #1631 (step 1631): 1.479381\n",
      "Batch #10\tAverage Generator Loss: 759.144962\tAverage Discriminator Loss: 0.001202\n",
      "\n",
      "Train time for epoch #1632 (step 1632): 1.544338\n",
      "Batch #10\tAverage Generator Loss: 634.377388\tAverage Discriminator Loss: 0.000038\n",
      "\n",
      "Train time for epoch #1633 (step 1633): 1.470241\n",
      "Batch #10\tAverage Generator Loss: 1037.711011\tAverage Discriminator Loss: 0.000023\n",
      "\n",
      "Train time for epoch #1634 (step 1634): 1.477708\n",
      "Batch #10\tAverage Generator Loss: 766.186731\tAverage Discriminator Loss: 0.000027\n",
      "\n",
      "Train time for epoch #1635 (step 1635): 1.394743\n",
      "Batch #10\tAverage Generator Loss: 849.215466\tAverage Discriminator Loss: 0.000024\n",
      "\n",
      "Train time for epoch #1636 (step 1636): 1.382179\n",
      "Batch #10\tAverage Generator Loss: 782.844626\tAverage Discriminator Loss: 0.000032\n",
      "\n",
      "Train time for epoch #1637 (step 1637): 1.384077\n",
      "Batch #10\tAverage Generator Loss: 789.752441\tAverage Discriminator Loss: 0.000065\n",
      "\n",
      "Train time for epoch #1638 (step 1638): 1.451326\n",
      "Batch #10\tAverage Generator Loss: 948.596637\tAverage Discriminator Loss: 0.000149\n",
      "\n",
      "Train time for epoch #1639 (step 1639): 1.479932\n",
      "Batch #10\tAverage Generator Loss: 738.202992\tAverage Discriminator Loss: 0.002038\n",
      "\n",
      "Train time for epoch #1640 (step 1640): 1.437965\n",
      "Batch #10\tAverage Generator Loss: 639.715654\tAverage Discriminator Loss: 0.052252\n",
      "\n",
      "Train time for epoch #1641 (step 1641): 1.437682\n",
      "Batch #10\tAverage Generator Loss: 621.494901\tAverage Discriminator Loss: 0.012434\n",
      "\n",
      "Train time for epoch #1642 (step 1642): 1.413340\n",
      "Batch #10\tAverage Generator Loss: 569.080405\tAverage Discriminator Loss: 0.000107\n",
      "\n",
      "Train time for epoch #1643 (step 1643): 1.384058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 584.417238\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #1644 (step 1644): 1.431385\n",
      "Batch #10\tAverage Generator Loss: 534.033426\tAverage Discriminator Loss: 0.007879\n",
      "\n",
      "Train time for epoch #1645 (step 1645): 1.383770\n",
      "Batch #10\tAverage Generator Loss: 556.968494\tAverage Discriminator Loss: 0.000063\n",
      "\n",
      "Train time for epoch #1646 (step 1646): 1.427519\n",
      "Batch #10\tAverage Generator Loss: 480.547804\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #1647 (step 1647): 1.536038\n",
      "Batch #10\tAverage Generator Loss: 530.426166\tAverage Discriminator Loss: 0.000211\n",
      "\n",
      "Train time for epoch #1648 (step 1648): 1.432481\n",
      "Batch #10\tAverage Generator Loss: 463.804349\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #1649 (step 1649): 1.495316\n",
      "Batch #10\tAverage Generator Loss: 436.427582\tAverage Discriminator Loss: 0.013901\n",
      "\n",
      "Train time for epoch #1650 (step 1650): 1.392375\n",
      "Batch #10\tAverage Generator Loss: 521.203990\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #1651 (step 1651): 1.460473\n",
      "Batch #10\tAverage Generator Loss: 656.247833\tAverage Discriminator Loss: 0.000164\n",
      "\n",
      "Train time for epoch #1652 (step 1652): 1.448683\n",
      "Batch #10\tAverage Generator Loss: 464.421748\tAverage Discriminator Loss: 0.000778\n",
      "\n",
      "Train time for epoch #1653 (step 1653): 1.392905\n",
      "Batch #10\tAverage Generator Loss: 415.552211\tAverage Discriminator Loss: 0.002388\n",
      "\n",
      "Train time for epoch #1654 (step 1654): 1.398385\n",
      "Batch #10\tAverage Generator Loss: 475.168646\tAverage Discriminator Loss: 0.001356\n",
      "\n",
      "Train time for epoch #1655 (step 1655): 1.423624\n",
      "Batch #10\tAverage Generator Loss: 453.423083\tAverage Discriminator Loss: 0.000235\n",
      "\n",
      "Train time for epoch #1656 (step 1656): 1.388664\n",
      "Batch #10\tAverage Generator Loss: 452.507542\tAverage Discriminator Loss: 0.000150\n",
      "\n",
      "Train time for epoch #1657 (step 1657): 1.391385\n",
      "Batch #10\tAverage Generator Loss: 543.122452\tAverage Discriminator Loss: 0.000112\n",
      "\n",
      "Train time for epoch #1658 (step 1658): 1.373190\n",
      "Batch #10\tAverage Generator Loss: 551.572488\tAverage Discriminator Loss: 0.000083\n",
      "\n",
      "Train time for epoch #1659 (step 1659): 1.416610\n",
      "Batch #10\tAverage Generator Loss: 527.429090\tAverage Discriminator Loss: 0.000034\n",
      "\n",
      "Train time for epoch #1660 (step 1660): 1.481675\n",
      "Batch #10\tAverage Generator Loss: 512.372742\tAverage Discriminator Loss: 0.000051\n",
      "\n",
      "Train time for epoch #1661 (step 1661): 1.480045\n",
      "Batch #10\tAverage Generator Loss: 526.886993\tAverage Discriminator Loss: 0.000024\n",
      "\n",
      "Train time for epoch #1662 (step 1662): 1.538425\n",
      "Batch #10\tAverage Generator Loss: 459.124771\tAverage Discriminator Loss: 0.000023\n",
      "\n",
      "Train time for epoch #1663 (step 1663): 1.391277\n",
      "Batch #10\tAverage Generator Loss: 505.177356\tAverage Discriminator Loss: 0.000023\n",
      "\n",
      "Train time for epoch #1664 (step 1664): 1.406605\n",
      "Batch #10\tAverage Generator Loss: 409.391751\tAverage Discriminator Loss: 0.000036\n",
      "\n",
      "Train time for epoch #1665 (step 1665): 1.339523\n",
      "Batch #10\tAverage Generator Loss: 516.138080\tAverage Discriminator Loss: 0.000163\n",
      "\n",
      "Train time for epoch #1666 (step 1666): 1.698734\n",
      "Batch #10\tAverage Generator Loss: 503.181146\tAverage Discriminator Loss: 0.000037\n",
      "\n",
      "Train time for epoch #1667 (step 1667): 1.390551\n",
      "Batch #10\tAverage Generator Loss: 424.500204\tAverage Discriminator Loss: 0.000036\n",
      "\n",
      "Train time for epoch #1668 (step 1668): 1.506464\n",
      "Batch #10\tAverage Generator Loss: 411.502495\tAverage Discriminator Loss: 0.000024\n",
      "\n",
      "Train time for epoch #1669 (step 1669): 1.396040\n",
      "Batch #10\tAverage Generator Loss: 486.327834\tAverage Discriminator Loss: 0.000052\n",
      "\n",
      "Train time for epoch #1670 (step 1670): 1.345155\n",
      "Batch #10\tAverage Generator Loss: 349.871102\tAverage Discriminator Loss: 0.007347\n",
      "\n",
      "Train time for epoch #1671 (step 1671): 1.479790\n",
      "Batch #10\tAverage Generator Loss: 523.454175\tAverage Discriminator Loss: 0.006683\n",
      "\n",
      "Train time for epoch #1672 (step 1672): 1.472116\n",
      "Batch #10\tAverage Generator Loss: 476.848904\tAverage Discriminator Loss: 0.000138\n",
      "\n",
      "Train time for epoch #1673 (step 1673): 1.397356\n",
      "Batch #10\tAverage Generator Loss: 500.550876\tAverage Discriminator Loss: 0.000106\n",
      "\n",
      "Train time for epoch #1674 (step 1674): 1.597417\n",
      "Batch #10\tAverage Generator Loss: 470.469037\tAverage Discriminator Loss: 0.000097\n",
      "\n",
      "Train time for epoch #1675 (step 1675): 1.484115\n",
      "Batch #10\tAverage Generator Loss: 451.248776\tAverage Discriminator Loss: 0.000066\n",
      "\n",
      "Train time for epoch #1676 (step 1676): 1.425796\n",
      "Batch #10\tAverage Generator Loss: 528.760161\tAverage Discriminator Loss: 0.000061\n",
      "\n",
      "Train time for epoch #1677 (step 1677): 1.401420\n",
      "Batch #10\tAverage Generator Loss: 430.596317\tAverage Discriminator Loss: 0.033250\n",
      "\n",
      "Train time for epoch #1678 (step 1678): 1.595940\n",
      "Batch #10\tAverage Generator Loss: 432.891684\tAverage Discriminator Loss: 0.001439\n",
      "\n",
      "Train time for epoch #1679 (step 1679): 1.334728\n",
      "Batch #10\tAverage Generator Loss: 436.494992\tAverage Discriminator Loss: 0.000022\n",
      "\n",
      "Train time for epoch #1680 (step 1680): 1.524411\n",
      "Batch #10\tAverage Generator Loss: 416.649799\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #1681 (step 1681): 1.420488\n",
      "Batch #10\tAverage Generator Loss: 419.755844\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #1682 (step 1682): 1.530427\n",
      "Batch #10\tAverage Generator Loss: 392.125928\tAverage Discriminator Loss: 0.000546\n",
      "\n",
      "Train time for epoch #1683 (step 1683): 1.401487\n",
      "Batch #10\tAverage Generator Loss: 462.023474\tAverage Discriminator Loss: 0.000051\n",
      "\n",
      "Train time for epoch #1684 (step 1684): 1.558141\n",
      "Batch #10\tAverage Generator Loss: 451.008130\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #1685 (step 1685): 1.384343\n",
      "Batch #10\tAverage Generator Loss: 454.884647\tAverage Discriminator Loss: 0.000020\n",
      "\n",
      "Train time for epoch #1686 (step 1686): 1.389128\n",
      "Batch #10\tAverage Generator Loss: 497.819662\tAverage Discriminator Loss: 0.000020\n",
      "\n",
      "Train time for epoch #1687 (step 1687): 1.380125\n",
      "Batch #10\tAverage Generator Loss: 537.300677\tAverage Discriminator Loss: 0.000019\n",
      "\n",
      "Train time for epoch #1688 (step 1688): 1.383352\n",
      "Batch #10\tAverage Generator Loss: 418.360674\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #1689 (step 1689): 1.349782\n",
      "Batch #10\tAverage Generator Loss: 413.346672\tAverage Discriminator Loss: 0.072739\n",
      "\n",
      "Train time for epoch #1690 (step 1690): 1.377691\n",
      "Batch #10\tAverage Generator Loss: 461.333331\tAverage Discriminator Loss: 0.065754\n",
      "\n",
      "Train time for epoch #1691 (step 1691): 1.491299\n",
      "Batch #10\tAverage Generator Loss: 459.602878\tAverage Discriminator Loss: 0.000058\n",
      "\n",
      "Train time for epoch #1692 (step 1692): 1.536286\n",
      "Batch #10\tAverage Generator Loss: 343.734453\tAverage Discriminator Loss: 0.005021\n",
      "\n",
      "Train time for epoch #1693 (step 1693): 1.350301\n",
      "Batch #10\tAverage Generator Loss: 400.354318\tAverage Discriminator Loss: 0.013968\n",
      "\n",
      "Train time for epoch #1694 (step 1694): 1.399269\n",
      "Batch #10\tAverage Generator Loss: 370.187022\tAverage Discriminator Loss: 0.000137\n",
      "\n",
      "Train time for epoch #1695 (step 1695): 1.448343\n",
      "Batch #10\tAverage Generator Loss: 446.217616\tAverage Discriminator Loss: 0.007620\n",
      "\n",
      "Train time for epoch #1696 (step 1696): 1.547924\n",
      "Batch #10\tAverage Generator Loss: 364.686229\tAverage Discriminator Loss: 0.000706\n",
      "\n",
      "Train time for epoch #1697 (step 1697): 1.382416\n",
      "Batch #10\tAverage Generator Loss: 411.931528\tAverage Discriminator Loss: 0.000296\n",
      "\n",
      "Train time for epoch #1698 (step 1698): 1.449708\n",
      "Batch #10\tAverage Generator Loss: 358.520703\tAverage Discriminator Loss: 0.000190\n",
      "\n",
      "Train time for epoch #1699 (step 1699): 1.530382\n",
      "Batch #10\tAverage Generator Loss: 432.024493\tAverage Discriminator Loss: 0.000142\n",
      "\n",
      "Train time for epoch #1700 (step 1700): 1.486737\n",
      "Batch #10\tAverage Generator Loss: 440.579227\tAverage Discriminator Loss: 0.000143\n",
      "\n",
      "Train time for epoch #1701 (step 1701): 1.384193\n",
      "Batch #10\tAverage Generator Loss: 399.951204\tAverage Discriminator Loss: 0.000101\n",
      "\n",
      "Train time for epoch #1702 (step 1702): 1.337668\n",
      "Batch #10\tAverage Generator Loss: 387.084171\tAverage Discriminator Loss: 0.000360\n",
      "\n",
      "Train time for epoch #1703 (step 1703): 1.483297\n",
      "Batch #10\tAverage Generator Loss: 309.211134\tAverage Discriminator Loss: 0.002561\n",
      "\n",
      "Train time for epoch #1704 (step 1704): 1.565061\n",
      "Batch #10\tAverage Generator Loss: 429.723260\tAverage Discriminator Loss: 0.015642\n",
      "\n",
      "Train time for epoch #1705 (step 1705): 1.493048\n",
      "Batch #10\tAverage Generator Loss: 381.628040\tAverage Discriminator Loss: 0.040028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #1706 (step 1706): 1.472984\n",
      "Batch #10\tAverage Generator Loss: 406.194748\tAverage Discriminator Loss: 0.002253\n",
      "\n",
      "Train time for epoch #1707 (step 1707): 1.483923\n",
      "Batch #10\tAverage Generator Loss: 412.639474\tAverage Discriminator Loss: 0.000533\n",
      "\n",
      "Train time for epoch #1708 (step 1708): 1.497544\n",
      "Batch #10\tAverage Generator Loss: 395.587157\tAverage Discriminator Loss: 0.108073\n",
      "\n",
      "Train time for epoch #1709 (step 1709): 1.449382\n",
      "Batch #10\tAverage Generator Loss: 408.454089\tAverage Discriminator Loss: 0.008680\n",
      "\n",
      "Train time for epoch #1710 (step 1710): 1.425784\n",
      "Batch #10\tAverage Generator Loss: 360.354062\tAverage Discriminator Loss: 0.000118\n",
      "\n",
      "Train time for epoch #1711 (step 1711): 1.385436\n",
      "Batch #10\tAverage Generator Loss: 385.133380\tAverage Discriminator Loss: 0.000062\n",
      "\n",
      "Train time for epoch #1712 (step 1712): 1.539505\n",
      "Batch #10\tAverage Generator Loss: 401.027724\tAverage Discriminator Loss: 0.013320\n",
      "\n",
      "Train time for epoch #1713 (step 1713): 1.380117\n",
      "Batch #10\tAverage Generator Loss: 384.307330\tAverage Discriminator Loss: 0.000115\n",
      "\n",
      "Train time for epoch #1714 (step 1714): 1.444724\n",
      "Batch #10\tAverage Generator Loss: 395.153612\tAverage Discriminator Loss: 0.000119\n",
      "\n",
      "Train time for epoch #1715 (step 1715): 1.434770\n",
      "Batch #10\tAverage Generator Loss: 420.294370\tAverage Discriminator Loss: 0.000139\n",
      "\n",
      "Train time for epoch #1716 (step 1716): 1.437561\n",
      "Batch #10\tAverage Generator Loss: 450.760495\tAverage Discriminator Loss: 0.000110\n",
      "\n",
      "Train time for epoch #1717 (step 1717): 1.438249\n",
      "Batch #10\tAverage Generator Loss: 341.639095\tAverage Discriminator Loss: 0.000122\n",
      "\n",
      "Train time for epoch #1718 (step 1718): 1.375310\n",
      "Batch #10\tAverage Generator Loss: 392.127621\tAverage Discriminator Loss: 0.005280\n",
      "\n",
      "Train time for epoch #1719 (step 1719): 1.325813\n",
      "Batch #10\tAverage Generator Loss: 458.140353\tAverage Discriminator Loss: 0.000508\n",
      "\n",
      "Train time for epoch #1720 (step 1720): 1.463242\n",
      "Batch #10\tAverage Generator Loss: 446.590273\tAverage Discriminator Loss: 0.000412\n",
      "\n",
      "Train time for epoch #1721 (step 1721): 1.495168\n",
      "Batch #10\tAverage Generator Loss: 433.426215\tAverage Discriminator Loss: 0.000426\n",
      "\n",
      "Train time for epoch #1722 (step 1722): 1.447826\n",
      "Batch #10\tAverage Generator Loss: 481.200900\tAverage Discriminator Loss: 0.000334\n",
      "\n",
      "Train time for epoch #1723 (step 1723): 1.568364\n",
      "Batch #10\tAverage Generator Loss: 414.662355\tAverage Discriminator Loss: 0.000517\n",
      "\n",
      "Train time for epoch #1724 (step 1724): 1.440768\n",
      "Batch #10\tAverage Generator Loss: 373.097522\tAverage Discriminator Loss: 0.000268\n",
      "\n",
      "Train time for epoch #1725 (step 1725): 1.438586\n",
      "Batch #10\tAverage Generator Loss: 386.365977\tAverage Discriminator Loss: 0.000307\n",
      "\n",
      "Train time for epoch #1726 (step 1726): 1.421835\n",
      "Batch #10\tAverage Generator Loss: 340.484354\tAverage Discriminator Loss: 0.000865\n",
      "\n",
      "Train time for epoch #1727 (step 1727): 1.395914\n",
      "Batch #10\tAverage Generator Loss: 433.085670\tAverage Discriminator Loss: 0.000259\n",
      "\n",
      "Train time for epoch #1728 (step 1728): 1.442416\n",
      "Batch #10\tAverage Generator Loss: 410.849428\tAverage Discriminator Loss: 0.000220\n",
      "\n",
      "Train time for epoch #1729 (step 1729): 1.341007\n",
      "Batch #10\tAverage Generator Loss: 407.005004\tAverage Discriminator Loss: 0.000334\n",
      "\n",
      "Train time for epoch #1730 (step 1730): 1.331923\n",
      "Batch #10\tAverage Generator Loss: 377.332629\tAverage Discriminator Loss: 0.000257\n",
      "\n",
      "Train time for epoch #1731 (step 1731): 1.446252\n",
      "Batch #10\tAverage Generator Loss: 388.006844\tAverage Discriminator Loss: 0.000458\n",
      "\n",
      "Train time for epoch #1732 (step 1732): 1.453166\n",
      "Batch #10\tAverage Generator Loss: 473.050908\tAverage Discriminator Loss: 0.000286\n",
      "\n",
      "Train time for epoch #1733 (step 1733): 1.409190\n",
      "Batch #10\tAverage Generator Loss: 444.684265\tAverage Discriminator Loss: 0.000188\n",
      "\n",
      "Train time for epoch #1734 (step 1734): 1.427100\n",
      "Batch #10\tAverage Generator Loss: 429.911061\tAverage Discriminator Loss: 0.000179\n",
      "\n",
      "Train time for epoch #1735 (step 1735): 1.449263\n",
      "Batch #10\tAverage Generator Loss: 419.544324\tAverage Discriminator Loss: 0.004399\n",
      "\n",
      "Train time for epoch #1736 (step 1736): 1.391956\n",
      "Batch #10\tAverage Generator Loss: 516.281830\tAverage Discriminator Loss: 0.000234\n",
      "\n",
      "Train time for epoch #1737 (step 1737): 1.382340\n",
      "Batch #10\tAverage Generator Loss: 474.683328\tAverage Discriminator Loss: 0.000264\n",
      "\n",
      "Train time for epoch #1738 (step 1738): 1.494972\n",
      "Batch #10\tAverage Generator Loss: 413.997606\tAverage Discriminator Loss: 0.000241\n",
      "\n",
      "Train time for epoch #1739 (step 1739): 1.388800\n",
      "Batch #10\tAverage Generator Loss: 433.310957\tAverage Discriminator Loss: 0.000179\n",
      "\n",
      "Train time for epoch #1740 (step 1740): 1.490236\n",
      "Batch #10\tAverage Generator Loss: 457.264020\tAverage Discriminator Loss: 0.000198\n",
      "\n",
      "Train time for epoch #1741 (step 1741): 1.446823\n",
      "Batch #10\tAverage Generator Loss: 424.325311\tAverage Discriminator Loss: 0.000219\n",
      "\n",
      "Train time for epoch #1742 (step 1742): 1.418025\n",
      "Batch #10\tAverage Generator Loss: 445.005087\tAverage Discriminator Loss: 0.000172\n",
      "\n",
      "Train time for epoch #1743 (step 1743): 1.494736\n",
      "Batch #10\tAverage Generator Loss: 460.171417\tAverage Discriminator Loss: 0.000167\n",
      "\n",
      "Train time for epoch #1744 (step 1744): 1.347406\n",
      "Batch #10\tAverage Generator Loss: 419.193423\tAverage Discriminator Loss: 0.000144\n",
      "\n",
      "Train time for epoch #1745 (step 1745): 1.430285\n",
      "Batch #10\tAverage Generator Loss: 407.941864\tAverage Discriminator Loss: 0.000129\n",
      "\n",
      "Train time for epoch #1746 (step 1746): 1.396735\n",
      "Batch #10\tAverage Generator Loss: 438.940919\tAverage Discriminator Loss: 0.000124\n",
      "\n",
      "Train time for epoch #1747 (step 1747): 1.451300\n",
      "Batch #10\tAverage Generator Loss: 438.807332\tAverage Discriminator Loss: 0.000107\n",
      "\n",
      "Train time for epoch #1748 (step 1748): 1.390725\n",
      "Batch #10\tAverage Generator Loss: 495.140958\tAverage Discriminator Loss: 0.030858\n",
      "\n",
      "Train time for epoch #1749 (step 1749): 1.593970\n",
      "Batch #10\tAverage Generator Loss: 467.674425\tAverage Discriminator Loss: 0.000224\n",
      "\n",
      "Train time for epoch #1750 (step 1750): 1.447630\n",
      "Batch #10\tAverage Generator Loss: 390.787140\tAverage Discriminator Loss: 0.000130\n",
      "\n",
      "Train time for epoch #1751 (step 1751): 1.495992\n",
      "Batch #10\tAverage Generator Loss: 443.376157\tAverage Discriminator Loss: 0.000085\n",
      "\n",
      "Train time for epoch #1752 (step 1752): 1.428124\n",
      "Batch #10\tAverage Generator Loss: 416.508954\tAverage Discriminator Loss: 0.000210\n",
      "\n",
      "Train time for epoch #1753 (step 1753): 1.528134\n",
      "Batch #10\tAverage Generator Loss: 442.760016\tAverage Discriminator Loss: 0.000072\n",
      "\n",
      "Train time for epoch #1754 (step 1754): 1.425606\n",
      "Batch #10\tAverage Generator Loss: 463.588194\tAverage Discriminator Loss: 0.001197\n",
      "\n",
      "Train time for epoch #1755 (step 1755): 1.385916\n",
      "Batch #10\tAverage Generator Loss: 458.980034\tAverage Discriminator Loss: 0.000175\n",
      "\n",
      "Train time for epoch #1756 (step 1756): 1.435442\n",
      "Batch #10\tAverage Generator Loss: 435.930148\tAverage Discriminator Loss: 0.006070\n",
      "\n",
      "Train time for epoch #1757 (step 1757): 1.394858\n",
      "Batch #10\tAverage Generator Loss: 403.272427\tAverage Discriminator Loss: 0.000576\n",
      "\n",
      "Train time for epoch #1758 (step 1758): 1.424937\n",
      "Batch #10\tAverage Generator Loss: 422.889653\tAverage Discriminator Loss: 0.001668\n",
      "\n",
      "Train time for epoch #1759 (step 1759): 1.391333\n",
      "Batch #10\tAverage Generator Loss: 419.134012\tAverage Discriminator Loss: 0.000708\n",
      "\n",
      "Train time for epoch #1760 (step 1760): 1.493505\n",
      "Batch #10\tAverage Generator Loss: 396.620845\tAverage Discriminator Loss: 0.000368\n",
      "\n",
      "Train time for epoch #1761 (step 1761): 1.480329\n",
      "Batch #10\tAverage Generator Loss: 362.905328\tAverage Discriminator Loss: 0.000214\n",
      "\n",
      "Train time for epoch #1762 (step 1762): 1.443642\n",
      "Batch #10\tAverage Generator Loss: 419.899959\tAverage Discriminator Loss: 0.000202\n",
      "\n",
      "Train time for epoch #1763 (step 1763): 1.391978\n",
      "Batch #10\tAverage Generator Loss: 480.619058\tAverage Discriminator Loss: 0.000172\n",
      "\n",
      "Train time for epoch #1764 (step 1764): 1.394326\n",
      "Batch #10\tAverage Generator Loss: 419.363815\tAverage Discriminator Loss: 0.000126\n",
      "\n",
      "Train time for epoch #1765 (step 1765): 1.442279\n",
      "Batch #10\tAverage Generator Loss: 439.108536\tAverage Discriminator Loss: 0.000130\n",
      "\n",
      "Train time for epoch #1766 (step 1766): 1.497199\n",
      "Batch #10\tAverage Generator Loss: 445.446432\tAverage Discriminator Loss: 0.000130\n",
      "\n",
      "Train time for epoch #1767 (step 1767): 1.399601\n",
      "Batch #10\tAverage Generator Loss: 400.925989\tAverage Discriminator Loss: 0.000128\n",
      "\n",
      "Train time for epoch #1768 (step 1768): 1.442867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 427.553366\tAverage Discriminator Loss: 0.000289\n",
      "\n",
      "Train time for epoch #1769 (step 1769): 1.482939\n",
      "Batch #10\tAverage Generator Loss: 408.647514\tAverage Discriminator Loss: 0.005951\n",
      "\n",
      "Train time for epoch #1770 (step 1770): 1.392780\n",
      "Batch #10\tAverage Generator Loss: 422.265228\tAverage Discriminator Loss: 0.009618\n",
      "\n",
      "Train time for epoch #1771 (step 1771): 1.439035\n",
      "Batch #10\tAverage Generator Loss: 405.371097\tAverage Discriminator Loss: 0.003167\n",
      "\n",
      "Train time for epoch #1772 (step 1772): 1.488568\n",
      "Batch #10\tAverage Generator Loss: 433.251314\tAverage Discriminator Loss: 0.000339\n",
      "\n",
      "Train time for epoch #1773 (step 1773): 1.420060\n",
      "Batch #10\tAverage Generator Loss: 402.453709\tAverage Discriminator Loss: 0.000204\n",
      "\n",
      "Train time for epoch #1774 (step 1774): 1.455408\n",
      "Batch #10\tAverage Generator Loss: 423.701527\tAverage Discriminator Loss: 0.000166\n",
      "\n",
      "Train time for epoch #1775 (step 1775): 1.501895\n",
      "Batch #10\tAverage Generator Loss: 402.847115\tAverage Discriminator Loss: 0.000155\n",
      "\n",
      "Train time for epoch #1776 (step 1776): 1.443491\n",
      "Batch #10\tAverage Generator Loss: 442.346640\tAverage Discriminator Loss: 0.000124\n",
      "\n",
      "Train time for epoch #1777 (step 1777): 1.453136\n",
      "Batch #10\tAverage Generator Loss: 401.775161\tAverage Discriminator Loss: 0.000108\n",
      "\n",
      "Train time for epoch #1778 (step 1778): 1.426316\n",
      "Batch #10\tAverage Generator Loss: 504.526070\tAverage Discriminator Loss: 0.000204\n",
      "\n",
      "Train time for epoch #1779 (step 1779): 1.446405\n",
      "Batch #10\tAverage Generator Loss: 380.042696\tAverage Discriminator Loss: 0.000116\n",
      "\n",
      "Train time for epoch #1780 (step 1780): 1.446216\n",
      "Batch #10\tAverage Generator Loss: 396.658673\tAverage Discriminator Loss: 0.000292\n",
      "\n",
      "Train time for epoch #1781 (step 1781): 1.387526\n",
      "Batch #10\tAverage Generator Loss: 422.091876\tAverage Discriminator Loss: 0.000202\n",
      "\n",
      "Train time for epoch #1782 (step 1782): 1.435007\n",
      "Batch #10\tAverage Generator Loss: 464.365639\tAverage Discriminator Loss: 0.005818\n",
      "\n",
      "Train time for epoch #1783 (step 1783): 1.384795\n",
      "Batch #10\tAverage Generator Loss: 316.763469\tAverage Discriminator Loss: 0.000288\n",
      "\n",
      "Train time for epoch #1784 (step 1784): 1.480452\n",
      "Batch #10\tAverage Generator Loss: 468.423689\tAverage Discriminator Loss: 0.000218\n",
      "\n",
      "Train time for epoch #1785 (step 1785): 1.537321\n",
      "Batch #10\tAverage Generator Loss: 430.897769\tAverage Discriminator Loss: 0.000190\n",
      "\n",
      "Train time for epoch #1786 (step 1786): 1.393674\n",
      "Batch #10\tAverage Generator Loss: 501.466199\tAverage Discriminator Loss: 0.000204\n",
      "\n",
      "Train time for epoch #1787 (step 1787): 1.432124\n",
      "Batch #10\tAverage Generator Loss: 419.157346\tAverage Discriminator Loss: 0.000133\n",
      "\n",
      "Train time for epoch #1788 (step 1788): 1.434969\n",
      "Batch #10\tAverage Generator Loss: 442.474023\tAverage Discriminator Loss: 0.000135\n",
      "\n",
      "Train time for epoch #1789 (step 1789): 1.440837\n",
      "Batch #10\tAverage Generator Loss: 405.006992\tAverage Discriminator Loss: 0.005629\n",
      "\n",
      "Train time for epoch #1790 (step 1790): 1.381067\n",
      "Batch #10\tAverage Generator Loss: 440.845758\tAverage Discriminator Loss: 0.005081\n",
      "\n",
      "Train time for epoch #1791 (step 1791): 1.473166\n",
      "Batch #10\tAverage Generator Loss: 397.768423\tAverage Discriminator Loss: 0.147059\n",
      "\n",
      "Train time for epoch #1792 (step 1792): 1.379307\n",
      "Batch #10\tAverage Generator Loss: 484.464380\tAverage Discriminator Loss: 0.050446\n",
      "\n",
      "Train time for epoch #1793 (step 1793): 1.517150\n",
      "Batch #10\tAverage Generator Loss: 420.161714\tAverage Discriminator Loss: 0.022438\n",
      "\n",
      "Train time for epoch #1794 (step 1794): 1.341108\n",
      "Batch #10\tAverage Generator Loss: 475.462808\tAverage Discriminator Loss: 0.012402\n",
      "\n",
      "Train time for epoch #1795 (step 1795): 1.454047\n",
      "Batch #10\tAverage Generator Loss: 488.122601\tAverage Discriminator Loss: 0.006740\n",
      "\n",
      "Train time for epoch #1796 (step 1796): 1.392581\n",
      "Batch #10\tAverage Generator Loss: 429.558519\tAverage Discriminator Loss: 0.000611\n",
      "\n",
      "Train time for epoch #1797 (step 1797): 1.391239\n",
      "Batch #10\tAverage Generator Loss: 541.940826\tAverage Discriminator Loss: 0.000238\n",
      "\n",
      "Train time for epoch #1798 (step 1798): 1.444426\n",
      "Batch #10\tAverage Generator Loss: 412.377319\tAverage Discriminator Loss: 0.000243\n",
      "\n",
      "Train time for epoch #1799 (step 1799): 1.494792\n",
      "Batch #10\tAverage Generator Loss: 495.004126\tAverage Discriminator Loss: 0.000183\n",
      "\n",
      "Train time for epoch #1800 (step 1800): 1.440904\n",
      "Batch #10\tAverage Generator Loss: 444.713309\tAverage Discriminator Loss: 0.040796\n",
      "\n",
      "Train time for epoch #1801 (step 1801): 1.430276\n",
      "Batch #10\tAverage Generator Loss: 446.074316\tAverage Discriminator Loss: 0.000875\n",
      "\n",
      "Train time for epoch #1802 (step 1802): 1.393736\n",
      "Batch #10\tAverage Generator Loss: 402.885091\tAverage Discriminator Loss: 0.001828\n",
      "\n",
      "Train time for epoch #1803 (step 1803): 1.417031\n",
      "Batch #10\tAverage Generator Loss: 414.155365\tAverage Discriminator Loss: 0.000022\n",
      "\n",
      "Train time for epoch #1804 (step 1804): 1.329159\n",
      "Batch #10\tAverage Generator Loss: 424.857541\tAverage Discriminator Loss: 0.000023\n",
      "\n",
      "Train time for epoch #1805 (step 1805): 1.454189\n",
      "Batch #10\tAverage Generator Loss: 462.493230\tAverage Discriminator Loss: 0.000024\n",
      "\n",
      "Train time for epoch #1806 (step 1806): 1.490812\n",
      "Batch #10\tAverage Generator Loss: 400.784615\tAverage Discriminator Loss: 0.000535\n",
      "\n",
      "Train time for epoch #1807 (step 1807): 1.342255\n",
      "Batch #10\tAverage Generator Loss: 443.317876\tAverage Discriminator Loss: 0.000070\n",
      "\n",
      "Train time for epoch #1808 (step 1808): 1.498879\n",
      "Batch #10\tAverage Generator Loss: 396.282510\tAverage Discriminator Loss: 0.212570\n",
      "\n",
      "Train time for epoch #1809 (step 1809): 1.472457\n",
      "Batch #10\tAverage Generator Loss: 424.102551\tAverage Discriminator Loss: 0.042377\n",
      "\n",
      "Train time for epoch #1810 (step 1810): 1.565769\n",
      "Batch #10\tAverage Generator Loss: 339.936511\tAverage Discriminator Loss: 0.000096\n",
      "\n",
      "Train time for epoch #1811 (step 1811): 1.423871\n",
      "Batch #10\tAverage Generator Loss: 334.544646\tAverage Discriminator Loss: 0.097655\n",
      "\n",
      "Train time for epoch #1812 (step 1812): 1.389719\n",
      "Batch #10\tAverage Generator Loss: 315.099043\tAverage Discriminator Loss: 0.032637\n",
      "\n",
      "Train time for epoch #1813 (step 1813): 1.455194\n",
      "Batch #10\tAverage Generator Loss: 377.079745\tAverage Discriminator Loss: 0.000091\n",
      "\n",
      "Train time for epoch #1814 (step 1814): 1.389402\n",
      "Batch #10\tAverage Generator Loss: 383.746338\tAverage Discriminator Loss: 0.000073\n",
      "\n",
      "Train time for epoch #1815 (step 1815): 1.451457\n",
      "Batch #10\tAverage Generator Loss: 398.084286\tAverage Discriminator Loss: 0.000073\n",
      "\n",
      "Train time for epoch #1816 (step 1816): 1.458543\n",
      "Batch #10\tAverage Generator Loss: 392.811713\tAverage Discriminator Loss: 0.000067\n",
      "\n",
      "Train time for epoch #1817 (step 1817): 1.395301\n",
      "Batch #10\tAverage Generator Loss: 380.692682\tAverage Discriminator Loss: 0.000224\n",
      "\n",
      "Train time for epoch #1818 (step 1818): 1.510661\n",
      "Batch #10\tAverage Generator Loss: 428.507930\tAverage Discriminator Loss: 0.000067\n",
      "\n",
      "Train time for epoch #1819 (step 1819): 1.456275\n",
      "Batch #10\tAverage Generator Loss: 329.700832\tAverage Discriminator Loss: 0.000287\n",
      "\n",
      "Train time for epoch #1820 (step 1820): 1.456986\n",
      "Batch #10\tAverage Generator Loss: 304.782558\tAverage Discriminator Loss: 0.000258\n",
      "\n",
      "Train time for epoch #1821 (step 1821): 1.333256\n",
      "Batch #10\tAverage Generator Loss: 527.149437\tAverage Discriminator Loss: 0.000055\n",
      "\n",
      "Train time for epoch #1822 (step 1822): 1.499907\n",
      "Batch #10\tAverage Generator Loss: 383.071607\tAverage Discriminator Loss: 0.000052\n",
      "\n",
      "Train time for epoch #1823 (step 1823): 1.500597\n",
      "Batch #10\tAverage Generator Loss: 420.416721\tAverage Discriminator Loss: 0.004670\n",
      "\n",
      "Train time for epoch #1824 (step 1824): 1.530099\n",
      "Batch #10\tAverage Generator Loss: 392.827000\tAverage Discriminator Loss: 0.000798\n",
      "\n",
      "Train time for epoch #1825 (step 1825): 1.419388\n",
      "Batch #10\tAverage Generator Loss: 343.079497\tAverage Discriminator Loss: 0.000096\n",
      "\n",
      "Train time for epoch #1826 (step 1826): 1.464249\n",
      "Batch #10\tAverage Generator Loss: 509.914911\tAverage Discriminator Loss: 0.000090\n",
      "\n",
      "Train time for epoch #1827 (step 1827): 1.381361\n",
      "Batch #10\tAverage Generator Loss: 306.787807\tAverage Discriminator Loss: 0.000093\n",
      "\n",
      "Train time for epoch #1828 (step 1828): 1.445910\n",
      "Batch #10\tAverage Generator Loss: 356.837410\tAverage Discriminator Loss: 0.037165\n",
      "\n",
      "Train time for epoch #1829 (step 1829): 1.484534\n",
      "Batch #10\tAverage Generator Loss: 471.664294\tAverage Discriminator Loss: 0.000085\n",
      "\n",
      "Train time for epoch #1830 (step 1830): 1.482816\n",
      "Batch #10\tAverage Generator Loss: 474.249585\tAverage Discriminator Loss: 0.000037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #1831 (step 1831): 1.362745\n",
      "Batch #10\tAverage Generator Loss: 490.907547\tAverage Discriminator Loss: 0.000033\n",
      "\n",
      "Train time for epoch #1832 (step 1832): 1.453796\n",
      "Batch #10\tAverage Generator Loss: 428.520227\tAverage Discriminator Loss: 0.000025\n",
      "\n",
      "Train time for epoch #1833 (step 1833): 1.284688\n",
      "Batch #10\tAverage Generator Loss: 450.902441\tAverage Discriminator Loss: 0.031501\n",
      "\n",
      "Train time for epoch #1834 (step 1834): 1.387872\n",
      "Batch #10\tAverage Generator Loss: 443.395319\tAverage Discriminator Loss: 0.004395\n",
      "\n",
      "Train time for epoch #1835 (step 1835): 1.476675\n",
      "Batch #10\tAverage Generator Loss: 418.558038\tAverage Discriminator Loss: 0.014041\n",
      "\n",
      "Train time for epoch #1836 (step 1836): 1.350748\n",
      "Batch #10\tAverage Generator Loss: 406.615736\tAverage Discriminator Loss: 0.049371\n",
      "\n",
      "Train time for epoch #1837 (step 1837): 1.515433\n",
      "Batch #10\tAverage Generator Loss: 438.865578\tAverage Discriminator Loss: 0.000207\n",
      "\n",
      "Train time for epoch #1838 (step 1838): 1.468690\n",
      "Batch #10\tAverage Generator Loss: 420.765222\tAverage Discriminator Loss: 0.000215\n",
      "\n",
      "Train time for epoch #1839 (step 1839): 1.388869\n",
      "Batch #10\tAverage Generator Loss: 446.586804\tAverage Discriminator Loss: 0.000187\n",
      "\n",
      "Train time for epoch #1840 (step 1840): 1.457411\n",
      "Batch #10\tAverage Generator Loss: 433.157980\tAverage Discriminator Loss: 0.000167\n",
      "\n",
      "Train time for epoch #1841 (step 1841): 1.445479\n",
      "Batch #10\tAverage Generator Loss: 474.514856\tAverage Discriminator Loss: 0.000141\n",
      "\n",
      "Train time for epoch #1842 (step 1842): 1.514977\n",
      "Batch #10\tAverage Generator Loss: 495.031665\tAverage Discriminator Loss: 0.000145\n",
      "\n",
      "Train time for epoch #1843 (step 1843): 1.576786\n",
      "Batch #10\tAverage Generator Loss: 479.725433\tAverage Discriminator Loss: 0.000133\n",
      "\n",
      "Train time for epoch #1844 (step 1844): 1.409080\n",
      "Batch #10\tAverage Generator Loss: 460.346652\tAverage Discriminator Loss: 0.000165\n",
      "\n",
      "Train time for epoch #1845 (step 1845): 1.430192\n",
      "Batch #10\tAverage Generator Loss: 431.621280\tAverage Discriminator Loss: 0.000179\n",
      "\n",
      "Train time for epoch #1846 (step 1846): 1.399795\n",
      "Batch #10\tAverage Generator Loss: 426.753096\tAverage Discriminator Loss: 0.000155\n",
      "\n",
      "Train time for epoch #1847 (step 1847): 1.501721\n",
      "Batch #10\tAverage Generator Loss: 439.403079\tAverage Discriminator Loss: 0.000354\n",
      "\n",
      "Train time for epoch #1848 (step 1848): 1.399273\n",
      "Batch #10\tAverage Generator Loss: 456.995044\tAverage Discriminator Loss: 0.000144\n",
      "\n",
      "Train time for epoch #1849 (step 1849): 1.382691\n",
      "Batch #10\tAverage Generator Loss: 403.657890\tAverage Discriminator Loss: 0.000139\n",
      "\n",
      "Train time for epoch #1850 (step 1850): 1.341116\n",
      "Batch #10\tAverage Generator Loss: 434.976460\tAverage Discriminator Loss: 0.000152\n",
      "\n",
      "Train time for epoch #1851 (step 1851): 1.513018\n",
      "Batch #10\tAverage Generator Loss: 460.150577\tAverage Discriminator Loss: 0.000116\n",
      "\n",
      "Train time for epoch #1852 (step 1852): 1.408122\n",
      "Batch #10\tAverage Generator Loss: 403.056598\tAverage Discriminator Loss: 0.000117\n",
      "\n",
      "Train time for epoch #1853 (step 1853): 1.397845\n",
      "Batch #10\tAverage Generator Loss: 383.798911\tAverage Discriminator Loss: 0.000793\n",
      "\n",
      "Train time for epoch #1854 (step 1854): 1.435891\n",
      "Batch #10\tAverage Generator Loss: 491.401163\tAverage Discriminator Loss: 0.000152\n",
      "\n",
      "Train time for epoch #1855 (step 1855): 1.387751\n",
      "Batch #10\tAverage Generator Loss: 462.689188\tAverage Discriminator Loss: 0.003637\n",
      "\n",
      "Train time for epoch #1856 (step 1856): 1.432550\n",
      "Batch #10\tAverage Generator Loss: 448.749570\tAverage Discriminator Loss: 0.000229\n",
      "\n",
      "Train time for epoch #1857 (step 1857): 1.392857\n",
      "Batch #10\tAverage Generator Loss: 455.293729\tAverage Discriminator Loss: 0.000248\n",
      "\n",
      "Train time for epoch #1858 (step 1858): 1.494451\n",
      "Batch #10\tAverage Generator Loss: 433.102432\tAverage Discriminator Loss: 0.000200\n",
      "\n",
      "Train time for epoch #1859 (step 1859): 1.395524\n",
      "Batch #10\tAverage Generator Loss: 459.890234\tAverage Discriminator Loss: 0.000186\n",
      "\n",
      "Train time for epoch #1860 (step 1860): 1.398895\n",
      "Batch #10\tAverage Generator Loss: 456.488506\tAverage Discriminator Loss: 0.000146\n",
      "\n",
      "Train time for epoch #1861 (step 1861): 1.367305\n",
      "Batch #10\tAverage Generator Loss: 339.830894\tAverage Discriminator Loss: 0.057382\n",
      "\n",
      "Train time for epoch #1862 (step 1862): 1.461163\n",
      "Batch #10\tAverage Generator Loss: 279.044360\tAverage Discriminator Loss: 0.000170\n",
      "\n",
      "Train time for epoch #1863 (step 1863): 1.430905\n",
      "Batch #10\tAverage Generator Loss: 365.002200\tAverage Discriminator Loss: 0.000067\n",
      "\n",
      "Train time for epoch #1864 (step 1864): 1.351434\n",
      "Batch #10\tAverage Generator Loss: 325.716637\tAverage Discriminator Loss: 0.000107\n",
      "\n",
      "Train time for epoch #1865 (step 1865): 1.418401\n",
      "Batch #10\tAverage Generator Loss: 377.960922\tAverage Discriminator Loss: 0.000211\n",
      "\n",
      "Train time for epoch #1866 (step 1866): 1.495301\n",
      "Batch #10\tAverage Generator Loss: 344.940044\tAverage Discriminator Loss: 0.004193\n",
      "\n",
      "Train time for epoch #1867 (step 1867): 1.401196\n",
      "Batch #10\tAverage Generator Loss: 365.664456\tAverage Discriminator Loss: 0.000151\n",
      "\n",
      "Train time for epoch #1868 (step 1868): 1.444717\n",
      "Batch #10\tAverage Generator Loss: 284.541639\tAverage Discriminator Loss: 0.000091\n",
      "\n",
      "Train time for epoch #1869 (step 1869): 1.404793\n",
      "Batch #10\tAverage Generator Loss: 360.763771\tAverage Discriminator Loss: 0.000093\n",
      "\n",
      "Train time for epoch #1870 (step 1870): 1.364271\n",
      "Batch #10\tAverage Generator Loss: 364.339424\tAverage Discriminator Loss: 0.000106\n",
      "\n",
      "Train time for epoch #1871 (step 1871): 1.591019\n",
      "Batch #10\tAverage Generator Loss: 393.919498\tAverage Discriminator Loss: 0.000075\n",
      "\n",
      "Train time for epoch #1872 (step 1872): 1.453801\n",
      "Batch #10\tAverage Generator Loss: 323.712482\tAverage Discriminator Loss: 0.000098\n",
      "\n",
      "Train time for epoch #1873 (step 1873): 1.340586\n",
      "Batch #10\tAverage Generator Loss: 299.503142\tAverage Discriminator Loss: 0.000091\n",
      "\n",
      "Train time for epoch #1874 (step 1874): 1.396420\n",
      "Batch #10\tAverage Generator Loss: 371.854047\tAverage Discriminator Loss: 0.060247\n",
      "\n",
      "Train time for epoch #1875 (step 1875): 1.426119\n",
      "Batch #10\tAverage Generator Loss: 341.635664\tAverage Discriminator Loss: 0.000250\n",
      "\n",
      "Train time for epoch #1876 (step 1876): 1.430511\n",
      "Batch #10\tAverage Generator Loss: 351.901149\tAverage Discriminator Loss: 0.000151\n",
      "\n",
      "Train time for epoch #1877 (step 1877): 1.386118\n",
      "Batch #10\tAverage Generator Loss: 283.906186\tAverage Discriminator Loss: 0.000102\n",
      "\n",
      "Train time for epoch #1878 (step 1878): 1.461368\n",
      "Batch #10\tAverage Generator Loss: 286.725171\tAverage Discriminator Loss: 0.000077\n",
      "\n",
      "Train time for epoch #1879 (step 1879): 1.385476\n",
      "Batch #10\tAverage Generator Loss: 287.757538\tAverage Discriminator Loss: 0.001134\n",
      "\n",
      "Train time for epoch #1880 (step 1880): 1.445224\n",
      "Batch #10\tAverage Generator Loss: 333.399123\tAverage Discriminator Loss: 0.007244\n",
      "\n",
      "Train time for epoch #1881 (step 1881): 1.469826\n",
      "Batch #10\tAverage Generator Loss: 347.151706\tAverage Discriminator Loss: 0.000109\n",
      "\n",
      "Train time for epoch #1882 (step 1882): 1.531075\n",
      "Batch #10\tAverage Generator Loss: 300.817805\tAverage Discriminator Loss: 0.000100\n",
      "\n",
      "Train time for epoch #1883 (step 1883): 1.392273\n",
      "Batch #10\tAverage Generator Loss: 289.724716\tAverage Discriminator Loss: 0.036614\n",
      "\n",
      "Train time for epoch #1884 (step 1884): 1.452360\n",
      "Batch #10\tAverage Generator Loss: 373.538310\tAverage Discriminator Loss: 0.007115\n",
      "\n",
      "Train time for epoch #1885 (step 1885): 1.431275\n",
      "Batch #10\tAverage Generator Loss: 385.194438\tAverage Discriminator Loss: 0.000791\n",
      "\n",
      "Train time for epoch #1886 (step 1886): 1.429681\n",
      "Batch #10\tAverage Generator Loss: 332.286855\tAverage Discriminator Loss: 0.000339\n",
      "\n",
      "Train time for epoch #1887 (step 1887): 1.419808\n",
      "Batch #10\tAverage Generator Loss: 334.556403\tAverage Discriminator Loss: 0.002172\n",
      "\n",
      "Train time for epoch #1888 (step 1888): 1.349559\n",
      "Batch #10\tAverage Generator Loss: 400.621390\tAverage Discriminator Loss: 0.000557\n",
      "\n",
      "Train time for epoch #1889 (step 1889): 1.394459\n",
      "Batch #10\tAverage Generator Loss: 391.851674\tAverage Discriminator Loss: 0.001063\n",
      "\n",
      "Train time for epoch #1890 (step 1890): 1.385488\n",
      "Batch #10\tAverage Generator Loss: 362.526810\tAverage Discriminator Loss: 0.000875\n",
      "\n",
      "Train time for epoch #1891 (step 1891): 1.391716\n",
      "Batch #10\tAverage Generator Loss: 411.378703\tAverage Discriminator Loss: 0.000499\n",
      "\n",
      "Train time for epoch #1892 (step 1892): 1.473618\n",
      "Batch #10\tAverage Generator Loss: 342.105036\tAverage Discriminator Loss: 0.038151\n",
      "\n",
      "Train time for epoch #1893 (step 1893): 1.434463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 351.577011\tAverage Discriminator Loss: 0.012243\n",
      "\n",
      "Train time for epoch #1894 (step 1894): 1.454535\n",
      "Batch #10\tAverage Generator Loss: 364.420245\tAverage Discriminator Loss: 0.000886\n",
      "\n",
      "Train time for epoch #1895 (step 1895): 1.489115\n",
      "Batch #10\tAverage Generator Loss: 420.998021\tAverage Discriminator Loss: 0.000542\n",
      "\n",
      "Train time for epoch #1896 (step 1896): 1.510002\n",
      "Batch #10\tAverage Generator Loss: 365.823708\tAverage Discriminator Loss: 0.000450\n",
      "\n",
      "Train time for epoch #1897 (step 1897): 1.284863\n",
      "Batch #10\tAverage Generator Loss: 308.519180\tAverage Discriminator Loss: 0.000377\n",
      "\n",
      "Train time for epoch #1898 (step 1898): 1.536892\n",
      "Batch #10\tAverage Generator Loss: 302.083924\tAverage Discriminator Loss: 0.000779\n",
      "\n",
      "Train time for epoch #1899 (step 1899): 1.459883\n",
      "Batch #10\tAverage Generator Loss: 377.786874\tAverage Discriminator Loss: 0.000343\n",
      "\n",
      "Train time for epoch #1900 (step 1900): 1.474115\n",
      "Batch #10\tAverage Generator Loss: 306.144859\tAverage Discriminator Loss: 0.000366\n",
      "\n",
      "Train time for epoch #1901 (step 1901): 1.355798\n",
      "Batch #10\tAverage Generator Loss: 346.786583\tAverage Discriminator Loss: 0.000490\n",
      "\n",
      "Train time for epoch #1902 (step 1902): 1.531246\n",
      "Batch #10\tAverage Generator Loss: 305.568805\tAverage Discriminator Loss: 0.000303\n",
      "\n",
      "Train time for epoch #1903 (step 1903): 1.428845\n",
      "Batch #10\tAverage Generator Loss: 419.647923\tAverage Discriminator Loss: 0.000260\n",
      "\n",
      "Train time for epoch #1904 (step 1904): 1.589439\n",
      "Batch #10\tAverage Generator Loss: 342.058351\tAverage Discriminator Loss: 0.000291\n",
      "\n",
      "Train time for epoch #1905 (step 1905): 1.597516\n",
      "Batch #10\tAverage Generator Loss: 331.333550\tAverage Discriminator Loss: 0.000189\n",
      "\n",
      "Train time for epoch #1906 (step 1906): 1.419681\n",
      "Batch #10\tAverage Generator Loss: 405.572656\tAverage Discriminator Loss: 0.000218\n",
      "\n",
      "Train time for epoch #1907 (step 1907): 1.496842\n",
      "Batch #10\tAverage Generator Loss: 434.900899\tAverage Discriminator Loss: 0.000177\n",
      "\n",
      "Train time for epoch #1908 (step 1908): 1.400501\n",
      "Batch #10\tAverage Generator Loss: 386.094394\tAverage Discriminator Loss: 0.000167\n",
      "\n",
      "Train time for epoch #1909 (step 1909): 1.402919\n",
      "Batch #10\tAverage Generator Loss: 449.290225\tAverage Discriminator Loss: 0.000165\n",
      "\n",
      "Train time for epoch #1910 (step 1910): 1.449828\n",
      "Batch #10\tAverage Generator Loss: 347.160838\tAverage Discriminator Loss: 0.000156\n",
      "\n",
      "Train time for epoch #1911 (step 1911): 1.382353\n",
      "Batch #10\tAverage Generator Loss: 470.197696\tAverage Discriminator Loss: 0.000141\n",
      "\n",
      "Train time for epoch #1912 (step 1912): 1.434032\n",
      "Batch #10\tAverage Generator Loss: 369.537074\tAverage Discriminator Loss: 0.000143\n",
      "\n",
      "Train time for epoch #1913 (step 1913): 1.343892\n",
      "Batch #10\tAverage Generator Loss: 376.058186\tAverage Discriminator Loss: 0.000118\n",
      "\n",
      "Train time for epoch #1914 (step 1914): 1.443427\n",
      "Batch #10\tAverage Generator Loss: 396.497917\tAverage Discriminator Loss: 0.000772\n",
      "\n",
      "Train time for epoch #1915 (step 1915): 1.355131\n",
      "Batch #10\tAverage Generator Loss: 422.944034\tAverage Discriminator Loss: 0.000149\n",
      "\n",
      "Train time for epoch #1916 (step 1916): 1.394950\n",
      "Batch #10\tAverage Generator Loss: 402.476671\tAverage Discriminator Loss: 0.000370\n",
      "\n",
      "Train time for epoch #1917 (step 1917): 1.446589\n",
      "Batch #10\tAverage Generator Loss: 359.904472\tAverage Discriminator Loss: 0.004958\n",
      "\n",
      "Train time for epoch #1918 (step 1918): 1.371030\n",
      "Batch #10\tAverage Generator Loss: 380.347340\tAverage Discriminator Loss: 0.000396\n",
      "\n",
      "Train time for epoch #1919 (step 1919): 1.446485\n",
      "Batch #10\tAverage Generator Loss: 410.471918\tAverage Discriminator Loss: 0.000649\n",
      "\n",
      "Train time for epoch #1920 (step 1920): 1.397882\n",
      "Batch #10\tAverage Generator Loss: 441.480766\tAverage Discriminator Loss: 0.000455\n",
      "\n",
      "Train time for epoch #1921 (step 1921): 1.411175\n",
      "Batch #10\tAverage Generator Loss: 416.608327\tAverage Discriminator Loss: 0.001649\n",
      "\n",
      "Train time for epoch #1922 (step 1922): 1.452722\n",
      "Batch #10\tAverage Generator Loss: 435.277457\tAverage Discriminator Loss: 0.001048\n",
      "\n",
      "Train time for epoch #1923 (step 1923): 1.508874\n",
      "Batch #10\tAverage Generator Loss: 424.042020\tAverage Discriminator Loss: 0.000522\n",
      "\n",
      "Train time for epoch #1924 (step 1924): 1.522529\n",
      "Batch #10\tAverage Generator Loss: 431.447311\tAverage Discriminator Loss: 0.000413\n",
      "\n",
      "Train time for epoch #1925 (step 1925): 1.425582\n",
      "Batch #10\tAverage Generator Loss: 417.334160\tAverage Discriminator Loss: 0.000266\n",
      "\n",
      "Train time for epoch #1926 (step 1926): 1.456598\n",
      "Batch #10\tAverage Generator Loss: 452.436383\tAverage Discriminator Loss: 0.000183\n",
      "\n",
      "Train time for epoch #1927 (step 1927): 1.414958\n",
      "Batch #10\tAverage Generator Loss: 381.287485\tAverage Discriminator Loss: 0.000185\n",
      "\n",
      "Train time for epoch #1928 (step 1928): 1.450662\n",
      "Batch #10\tAverage Generator Loss: 413.648413\tAverage Discriminator Loss: 0.006875\n",
      "\n",
      "Train time for epoch #1929 (step 1929): 1.365392\n",
      "Batch #10\tAverage Generator Loss: 474.936514\tAverage Discriminator Loss: 0.000891\n",
      "\n",
      "Train time for epoch #1930 (step 1930): 1.542747\n",
      "Batch #10\tAverage Generator Loss: 488.085516\tAverage Discriminator Loss: 0.000418\n",
      "\n",
      "Train time for epoch #1931 (step 1931): 1.558111\n",
      "Batch #10\tAverage Generator Loss: 454.133003\tAverage Discriminator Loss: 0.000214\n",
      "\n",
      "Train time for epoch #1932 (step 1932): 1.337472\n",
      "Batch #10\tAverage Generator Loss: 399.756502\tAverage Discriminator Loss: 0.000207\n",
      "\n",
      "Train time for epoch #1933 (step 1933): 1.435899\n",
      "Batch #10\tAverage Generator Loss: 421.309744\tAverage Discriminator Loss: 0.000175\n",
      "\n",
      "Train time for epoch #1934 (step 1934): 1.412979\n",
      "Batch #10\tAverage Generator Loss: 423.512347\tAverage Discriminator Loss: 0.000142\n",
      "\n",
      "Train time for epoch #1935 (step 1935): 1.405698\n",
      "Batch #10\tAverage Generator Loss: 447.657861\tAverage Discriminator Loss: 0.000128\n",
      "\n",
      "Train time for epoch #1936 (step 1936): 1.485219\n",
      "Batch #10\tAverage Generator Loss: 455.524168\tAverage Discriminator Loss: 0.000134\n",
      "\n",
      "Train time for epoch #1937 (step 1937): 1.504124\n",
      "Batch #10\tAverage Generator Loss: 434.489949\tAverage Discriminator Loss: 0.022934\n",
      "\n",
      "Train time for epoch #1938 (step 1938): 1.393907\n",
      "Batch #10\tAverage Generator Loss: 386.494717\tAverage Discriminator Loss: 0.021649\n",
      "\n",
      "Train time for epoch #1939 (step 1939): 1.386090\n",
      "Batch #10\tAverage Generator Loss: 382.505774\tAverage Discriminator Loss: 0.000338\n",
      "\n",
      "Train time for epoch #1940 (step 1940): 1.404077\n",
      "Batch #10\tAverage Generator Loss: 396.938474\tAverage Discriminator Loss: 0.006571\n",
      "\n",
      "Train time for epoch #1941 (step 1941): 1.459521\n",
      "Batch #10\tAverage Generator Loss: 389.771838\tAverage Discriminator Loss: 0.003129\n",
      "\n",
      "Train time for epoch #1942 (step 1942): 1.451043\n",
      "Batch #10\tAverage Generator Loss: 361.104327\tAverage Discriminator Loss: 0.000915\n",
      "\n",
      "Train time for epoch #1943 (step 1943): 1.331485\n",
      "Batch #10\tAverage Generator Loss: 415.729498\tAverage Discriminator Loss: 0.000227\n",
      "\n",
      "Train time for epoch #1944 (step 1944): 1.400448\n",
      "Batch #10\tAverage Generator Loss: 413.232967\tAverage Discriminator Loss: 0.000171\n",
      "\n",
      "Train time for epoch #1945 (step 1945): 1.418858\n",
      "Batch #10\tAverage Generator Loss: 403.755655\tAverage Discriminator Loss: 0.000133\n",
      "\n",
      "Train time for epoch #1946 (step 1946): 1.451288\n",
      "Batch #10\tAverage Generator Loss: 407.601149\tAverage Discriminator Loss: 0.024357\n",
      "\n",
      "Train time for epoch #1947 (step 1947): 1.452151\n",
      "Batch #10\tAverage Generator Loss: 352.305232\tAverage Discriminator Loss: 0.002788\n",
      "\n",
      "Train time for epoch #1948 (step 1948): 1.461477\n",
      "Batch #10\tAverage Generator Loss: 350.564062\tAverage Discriminator Loss: 0.089412\n",
      "\n",
      "Train time for epoch #1949 (step 1949): 1.419260\n",
      "Batch #10\tAverage Generator Loss: 287.187196\tAverage Discriminator Loss: 0.029388\n",
      "\n",
      "Train time for epoch #1950 (step 1950): 1.439417\n",
      "Batch #10\tAverage Generator Loss: 470.097824\tAverage Discriminator Loss: 0.024126\n",
      "\n",
      "Train time for epoch #1951 (step 1951): 1.480438\n",
      "Batch #10\tAverage Generator Loss: 467.369267\tAverage Discriminator Loss: 0.012655\n",
      "\n",
      "Train time for epoch #1952 (step 1952): 1.354222\n",
      "Batch #10\tAverage Generator Loss: 460.401598\tAverage Discriminator Loss: 0.008947\n",
      "\n",
      "Train time for epoch #1953 (step 1953): 1.395748\n",
      "Batch #10\tAverage Generator Loss: 404.934843\tAverage Discriminator Loss: 0.027369\n",
      "\n",
      "Train time for epoch #1954 (step 1954): 1.449902\n",
      "Batch #10\tAverage Generator Loss: 388.597629\tAverage Discriminator Loss: 0.000305\n",
      "\n",
      "Train time for epoch #1955 (step 1955): 1.449782\n",
      "Batch #10\tAverage Generator Loss: 453.814308\tAverage Discriminator Loss: 0.000181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #1956 (step 1956): 1.467242\n",
      "Batch #10\tAverage Generator Loss: 446.965323\tAverage Discriminator Loss: 0.002165\n",
      "\n",
      "Train time for epoch #1957 (step 1957): 1.429420\n",
      "Batch #10\tAverage Generator Loss: 508.760672\tAverage Discriminator Loss: 0.002938\n",
      "\n",
      "Train time for epoch #1958 (step 1958): 1.431260\n",
      "Batch #10\tAverage Generator Loss: 418.103867\tAverage Discriminator Loss: 0.000856\n",
      "\n",
      "Train time for epoch #1959 (step 1959): 1.450505\n",
      "Batch #10\tAverage Generator Loss: 432.581416\tAverage Discriminator Loss: 0.000225\n",
      "\n",
      "Train time for epoch #1960 (step 1960): 1.438047\n",
      "Batch #10\tAverage Generator Loss: 434.262468\tAverage Discriminator Loss: 0.000298\n",
      "\n",
      "Train time for epoch #1961 (step 1961): 1.454925\n",
      "Batch #10\tAverage Generator Loss: 423.904382\tAverage Discriminator Loss: 0.000196\n",
      "\n",
      "Train time for epoch #1962 (step 1962): 1.391210\n",
      "Batch #10\tAverage Generator Loss: 381.324481\tAverage Discriminator Loss: 0.000132\n",
      "\n",
      "Train time for epoch #1963 (step 1963): 1.342973\n",
      "Batch #10\tAverage Generator Loss: 438.981607\tAverage Discriminator Loss: 0.000107\n",
      "\n",
      "Train time for epoch #1964 (step 1964): 1.529544\n",
      "Batch #10\tAverage Generator Loss: 406.345343\tAverage Discriminator Loss: 0.000090\n",
      "\n",
      "Train time for epoch #1965 (step 1965): 1.399273\n",
      "Batch #10\tAverage Generator Loss: 357.448203\tAverage Discriminator Loss: 0.000661\n",
      "\n",
      "Train time for epoch #1966 (step 1966): 1.442767\n",
      "Batch #10\tAverage Generator Loss: 454.631454\tAverage Discriminator Loss: 0.000085\n",
      "\n",
      "Train time for epoch #1967 (step 1967): 1.391776\n",
      "Batch #10\tAverage Generator Loss: 403.399530\tAverage Discriminator Loss: 0.000086\n",
      "\n",
      "Train time for epoch #1968 (step 1968): 1.462060\n",
      "Batch #10\tAverage Generator Loss: 502.985495\tAverage Discriminator Loss: 0.000074\n",
      "\n",
      "Train time for epoch #1969 (step 1969): 1.399712\n",
      "Batch #10\tAverage Generator Loss: 393.849385\tAverage Discriminator Loss: 0.008605\n",
      "\n",
      "Train time for epoch #1970 (step 1970): 1.514410\n",
      "Batch #10\tAverage Generator Loss: 390.264935\tAverage Discriminator Loss: 0.001404\n",
      "\n",
      "Train time for epoch #1971 (step 1971): 1.453698\n",
      "Batch #10\tAverage Generator Loss: 355.340706\tAverage Discriminator Loss: 0.000148\n",
      "\n",
      "Train time for epoch #1972 (step 1972): 1.429681\n",
      "Batch #10\tAverage Generator Loss: 470.812009\tAverage Discriminator Loss: 0.000090\n",
      "\n",
      "Train time for epoch #1973 (step 1973): 1.444319\n",
      "Batch #10\tAverage Generator Loss: 376.437252\tAverage Discriminator Loss: 0.000212\n",
      "\n",
      "Train time for epoch #1974 (step 1974): 1.476424\n",
      "Batch #10\tAverage Generator Loss: 333.900450\tAverage Discriminator Loss: 0.000078\n",
      "\n",
      "Train time for epoch #1975 (step 1975): 1.485623\n",
      "Batch #10\tAverage Generator Loss: 461.947133\tAverage Discriminator Loss: 0.000082\n",
      "\n",
      "Train time for epoch #1976 (step 1976): 1.496131\n",
      "Batch #10\tAverage Generator Loss: 366.174751\tAverage Discriminator Loss: 0.000069\n",
      "\n",
      "Train time for epoch #1977 (step 1977): 1.344299\n",
      "Batch #10\tAverage Generator Loss: 425.964905\tAverage Discriminator Loss: 0.000060\n",
      "\n",
      "Train time for epoch #1978 (step 1978): 1.463324\n",
      "Batch #10\tAverage Generator Loss: 402.263969\tAverage Discriminator Loss: 0.000070\n",
      "\n",
      "Train time for epoch #1979 (step 1979): 1.462146\n",
      "Batch #10\tAverage Generator Loss: 435.772531\tAverage Discriminator Loss: 0.000061\n",
      "\n",
      "Train time for epoch #1980 (step 1980): 1.492125\n",
      "Batch #10\tAverage Generator Loss: 426.228819\tAverage Discriminator Loss: 0.000061\n",
      "\n",
      "Train time for epoch #1981 (step 1981): 1.521437\n",
      "Batch #10\tAverage Generator Loss: 385.074509\tAverage Discriminator Loss: 0.000059\n",
      "\n",
      "Train time for epoch #1982 (step 1982): 1.313137\n",
      "Batch #10\tAverage Generator Loss: 429.577625\tAverage Discriminator Loss: 0.000047\n",
      "\n",
      "Train time for epoch #1983 (step 1983): 1.391444\n",
      "Batch #10\tAverage Generator Loss: 394.829948\tAverage Discriminator Loss: 0.002920\n",
      "\n",
      "Train time for epoch #1984 (step 1984): 1.432711\n",
      "Batch #10\tAverage Generator Loss: 501.788123\tAverage Discriminator Loss: 0.000912\n",
      "\n",
      "Train time for epoch #1985 (step 1985): 1.467664\n",
      "Batch #10\tAverage Generator Loss: 511.646643\tAverage Discriminator Loss: 0.000383\n",
      "\n",
      "Train time for epoch #1986 (step 1986): 1.341298\n",
      "Batch #10\tAverage Generator Loss: 421.481258\tAverage Discriminator Loss: 0.000135\n",
      "\n",
      "Train time for epoch #1987 (step 1987): 1.460325\n",
      "Batch #10\tAverage Generator Loss: 422.706543\tAverage Discriminator Loss: 0.000102\n",
      "\n",
      "Train time for epoch #1988 (step 1988): 1.389336\n",
      "Batch #10\tAverage Generator Loss: 480.697443\tAverage Discriminator Loss: 0.000086\n",
      "\n",
      "Train time for epoch #1989 (step 1989): 1.491044\n",
      "Batch #10\tAverage Generator Loss: 399.921791\tAverage Discriminator Loss: 0.000071\n",
      "\n",
      "Train time for epoch #1990 (step 1990): 1.343461\n",
      "Batch #10\tAverage Generator Loss: 459.213928\tAverage Discriminator Loss: 0.000068\n",
      "\n",
      "Train time for epoch #1991 (step 1991): 1.500518\n",
      "Batch #10\tAverage Generator Loss: 413.689787\tAverage Discriminator Loss: 0.000056\n",
      "\n",
      "Train time for epoch #1992 (step 1992): 1.439716\n",
      "Batch #10\tAverage Generator Loss: 514.219995\tAverage Discriminator Loss: 0.000077\n",
      "\n",
      "Train time for epoch #1993 (step 1993): 1.344883\n",
      "Batch #10\tAverage Generator Loss: 494.763040\tAverage Discriminator Loss: 0.000107\n",
      "\n",
      "Train time for epoch #1994 (step 1994): 1.336476\n",
      "Batch #10\tAverage Generator Loss: 513.316040\tAverage Discriminator Loss: 0.000082\n",
      "\n",
      "Train time for epoch #1995 (step 1995): 1.446212\n",
      "Batch #10\tAverage Generator Loss: 537.198181\tAverage Discriminator Loss: 0.000081\n",
      "\n",
      "Train time for epoch #1996 (step 1996): 1.366113\n",
      "Batch #10\tAverage Generator Loss: 474.489694\tAverage Discriminator Loss: 0.000067\n",
      "\n",
      "Train time for epoch #1997 (step 1997): 1.456131\n",
      "Batch #10\tAverage Generator Loss: 504.530252\tAverage Discriminator Loss: 0.000067\n",
      "\n",
      "Train time for epoch #1998 (step 1998): 1.474912\n",
      "Batch #10\tAverage Generator Loss: 506.190077\tAverage Discriminator Loss: 0.000049\n",
      "\n",
      "Train time for epoch #1999 (step 1999): 1.411066\n",
      "Batch #10\tAverage Generator Loss: 525.241476\tAverage Discriminator Loss: 0.000063\n",
      "\n",
      "Train time for epoch #2000 (step 2000): 1.448777\n",
      "Batch #10\tAverage Generator Loss: 468.266331\tAverage Discriminator Loss: 0.000058\n",
      "\n",
      "Train time for epoch #2001 (step 2001): 1.447058\n",
      "Batch #10\tAverage Generator Loss: 464.242802\tAverage Discriminator Loss: 0.000050\n",
      "\n",
      "Train time for epoch #2002 (step 2002): 1.403177\n",
      "Batch #10\tAverage Generator Loss: 446.475676\tAverage Discriminator Loss: 0.000049\n",
      "\n",
      "Train time for epoch #2003 (step 2003): 1.358938\n",
      "Batch #10\tAverage Generator Loss: 522.303448\tAverage Discriminator Loss: 0.000048\n",
      "\n",
      "Train time for epoch #2004 (step 2004): 1.401645\n",
      "Batch #10\tAverage Generator Loss: 452.010706\tAverage Discriminator Loss: 0.001328\n",
      "\n",
      "Train time for epoch #2005 (step 2005): 1.485491\n",
      "Batch #10\tAverage Generator Loss: 488.492712\tAverage Discriminator Loss: 0.000082\n",
      "\n",
      "Train time for epoch #2006 (step 2006): 1.566197\n",
      "Batch #10\tAverage Generator Loss: 472.087671\tAverage Discriminator Loss: 0.000075\n",
      "\n",
      "Train time for epoch #2007 (step 2007): 1.411973\n",
      "Batch #10\tAverage Generator Loss: 428.992505\tAverage Discriminator Loss: 0.000069\n",
      "\n",
      "Train time for epoch #2008 (step 2008): 1.535933\n",
      "Batch #10\tAverage Generator Loss: 401.774870\tAverage Discriminator Loss: 0.000063\n",
      "\n",
      "Train time for epoch #2009 (step 2009): 1.434808\n",
      "Batch #10\tAverage Generator Loss: 378.850130\tAverage Discriminator Loss: 0.000060\n",
      "\n",
      "Train time for epoch #2010 (step 2010): 1.511675\n",
      "Batch #10\tAverage Generator Loss: 490.411693\tAverage Discriminator Loss: 0.000051\n",
      "\n",
      "Train time for epoch #2011 (step 2011): 1.449206\n",
      "Batch #10\tAverage Generator Loss: 357.012928\tAverage Discriminator Loss: 0.000063\n",
      "\n",
      "Train time for epoch #2012 (step 2012): 1.341197\n",
      "Batch #10\tAverage Generator Loss: 433.051423\tAverage Discriminator Loss: 0.000053\n",
      "\n",
      "Train time for epoch #2013 (step 2013): 1.427031\n",
      "Batch #10\tAverage Generator Loss: 443.113702\tAverage Discriminator Loss: 0.000659\n",
      "\n",
      "Train time for epoch #2014 (step 2014): 1.387776\n",
      "Batch #10\tAverage Generator Loss: 431.997769\tAverage Discriminator Loss: 0.000151\n",
      "\n",
      "Train time for epoch #2015 (step 2015): 1.440991\n",
      "Batch #10\tAverage Generator Loss: 467.209003\tAverage Discriminator Loss: 0.000149\n",
      "\n",
      "Train time for epoch #2016 (step 2016): 1.320186\n",
      "Batch #10\tAverage Generator Loss: 498.405734\tAverage Discriminator Loss: 0.000146\n",
      "\n",
      "Train time for epoch #2017 (step 2017): 1.402073\n",
      "Batch #10\tAverage Generator Loss: 453.196671\tAverage Discriminator Loss: 0.000052\n",
      "\n",
      "Train time for epoch #2018 (step 2018): 1.530707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 408.673593\tAverage Discriminator Loss: 0.000073\n",
      "\n",
      "Train time for epoch #2019 (step 2019): 1.564429\n",
      "Batch #10\tAverage Generator Loss: 477.970630\tAverage Discriminator Loss: 0.000048\n",
      "\n",
      "Train time for epoch #2020 (step 2020): 1.327579\n",
      "Batch #10\tAverage Generator Loss: 456.957933\tAverage Discriminator Loss: 0.000059\n",
      "\n",
      "Train time for epoch #2021 (step 2021): 1.585651\n",
      "Batch #10\tAverage Generator Loss: 425.655182\tAverage Discriminator Loss: 0.000214\n",
      "\n",
      "Train time for epoch #2022 (step 2022): 1.466214\n",
      "Batch #10\tAverage Generator Loss: 449.879697\tAverage Discriminator Loss: 0.000052\n",
      "\n",
      "Train time for epoch #2023 (step 2023): 1.478582\n",
      "Batch #10\tAverage Generator Loss: 496.496202\tAverage Discriminator Loss: 0.001073\n",
      "\n",
      "Train time for epoch #2024 (step 2024): 1.445559\n",
      "Batch #10\tAverage Generator Loss: 453.039494\tAverage Discriminator Loss: 0.000094\n",
      "\n",
      "Train time for epoch #2025 (step 2025): 1.413325\n",
      "Batch #10\tAverage Generator Loss: 471.189455\tAverage Discriminator Loss: 0.021841\n",
      "\n",
      "Train time for epoch #2026 (step 2026): 1.360335\n",
      "Batch #10\tAverage Generator Loss: 518.564909\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #2027 (step 2027): 1.489333\n",
      "Batch #10\tAverage Generator Loss: 413.594594\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #2028 (step 2028): 1.357847\n",
      "Batch #10\tAverage Generator Loss: 446.883304\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #2029 (step 2029): 1.430468\n",
      "Batch #10\tAverage Generator Loss: 396.766200\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #2030 (step 2030): 1.489707\n",
      "Batch #10\tAverage Generator Loss: 496.559384\tAverage Discriminator Loss: 0.000105\n",
      "\n",
      "Train time for epoch #2031 (step 2031): 1.443312\n",
      "Batch #10\tAverage Generator Loss: 523.566830\tAverage Discriminator Loss: 0.001430\n",
      "\n",
      "Train time for epoch #2032 (step 2032): 1.394420\n",
      "Batch #10\tAverage Generator Loss: 524.423825\tAverage Discriminator Loss: 0.000120\n",
      "\n",
      "Train time for epoch #2033 (step 2033): 1.512594\n",
      "Batch #10\tAverage Generator Loss: 475.072104\tAverage Discriminator Loss: 0.000061\n",
      "\n",
      "Train time for epoch #2034 (step 2034): 1.556087\n",
      "Batch #10\tAverage Generator Loss: 438.784393\tAverage Discriminator Loss: 0.000050\n",
      "\n",
      "Train time for epoch #2035 (step 2035): 1.610761\n",
      "Batch #10\tAverage Generator Loss: 445.156381\tAverage Discriminator Loss: 0.000039\n",
      "\n",
      "Train time for epoch #2036 (step 2036): 1.466284\n",
      "Batch #10\tAverage Generator Loss: 407.098616\tAverage Discriminator Loss: 0.000043\n",
      "\n",
      "Train time for epoch #2037 (step 2037): 1.454601\n",
      "Batch #10\tAverage Generator Loss: 485.287576\tAverage Discriminator Loss: 0.000034\n",
      "\n",
      "Train time for epoch #2038 (step 2038): 1.388903\n",
      "Batch #10\tAverage Generator Loss: 429.110661\tAverage Discriminator Loss: 0.003700\n",
      "\n",
      "Train time for epoch #2039 (step 2039): 1.507181\n",
      "Batch #10\tAverage Generator Loss: 513.243924\tAverage Discriminator Loss: 0.001006\n",
      "\n",
      "Train time for epoch #2040 (step 2040): 1.298279\n",
      "Batch #10\tAverage Generator Loss: 517.111974\tAverage Discriminator Loss: 0.000328\n",
      "\n",
      "Train time for epoch #2041 (step 2041): 1.371826\n",
      "Batch #10\tAverage Generator Loss: 503.626538\tAverage Discriminator Loss: 0.000151\n",
      "\n",
      "Train time for epoch #2042 (step 2042): 1.462527\n",
      "Batch #10\tAverage Generator Loss: 482.167693\tAverage Discriminator Loss: 0.000090\n",
      "\n",
      "Train time for epoch #2043 (step 2043): 1.507681\n",
      "Batch #10\tAverage Generator Loss: 532.433273\tAverage Discriminator Loss: 0.000069\n",
      "\n",
      "Train time for epoch #2044 (step 2044): 1.407825\n",
      "Batch #10\tAverage Generator Loss: 418.024435\tAverage Discriminator Loss: 0.000067\n",
      "\n",
      "Train time for epoch #2045 (step 2045): 1.363360\n",
      "Batch #10\tAverage Generator Loss: 496.177509\tAverage Discriminator Loss: 0.000058\n",
      "\n",
      "Train time for epoch #2046 (step 2046): 1.493348\n",
      "Batch #10\tAverage Generator Loss: 439.673854\tAverage Discriminator Loss: 0.000109\n",
      "\n",
      "Train time for epoch #2047 (step 2047): 1.535673\n",
      "Batch #10\tAverage Generator Loss: 523.554312\tAverage Discriminator Loss: 0.001271\n",
      "\n",
      "Train time for epoch #2048 (step 2048): 1.487925\n",
      "Batch #10\tAverage Generator Loss: 444.939175\tAverage Discriminator Loss: 0.001130\n",
      "\n",
      "Train time for epoch #2049 (step 2049): 1.369083\n",
      "Batch #10\tAverage Generator Loss: 519.682269\tAverage Discriminator Loss: 0.000839\n",
      "\n",
      "Train time for epoch #2050 (step 2050): 1.407171\n",
      "Batch #10\tAverage Generator Loss: 544.998297\tAverage Discriminator Loss: 0.000265\n",
      "\n",
      "Train time for epoch #2051 (step 2051): 1.547701\n",
      "Batch #10\tAverage Generator Loss: 521.867819\tAverage Discriminator Loss: 0.000284\n",
      "\n",
      "Train time for epoch #2052 (step 2052): 1.300889\n",
      "Batch #10\tAverage Generator Loss: 445.082605\tAverage Discriminator Loss: 0.000223\n",
      "\n",
      "Train time for epoch #2053 (step 2053): 1.443569\n",
      "Batch #10\tAverage Generator Loss: 441.698114\tAverage Discriminator Loss: 0.000141\n",
      "\n",
      "Train time for epoch #2054 (step 2054): 1.444110\n",
      "Batch #10\tAverage Generator Loss: 476.735710\tAverage Discriminator Loss: 0.000118\n",
      "\n",
      "Train time for epoch #2055 (step 2055): 1.430821\n",
      "Batch #10\tAverage Generator Loss: 483.127321\tAverage Discriminator Loss: 0.000078\n",
      "\n",
      "Train time for epoch #2056 (step 2056): 1.600770\n",
      "Batch #10\tAverage Generator Loss: 375.767067\tAverage Discriminator Loss: 0.000068\n",
      "\n",
      "Train time for epoch #2057 (step 2057): 1.451308\n",
      "Batch #10\tAverage Generator Loss: 503.282153\tAverage Discriminator Loss: 0.000069\n",
      "\n",
      "Train time for epoch #2058 (step 2058): 1.439624\n",
      "Batch #10\tAverage Generator Loss: 486.621115\tAverage Discriminator Loss: 0.000060\n",
      "\n",
      "Train time for epoch #2059 (step 2059): 1.326345\n",
      "Batch #10\tAverage Generator Loss: 437.246259\tAverage Discriminator Loss: 0.005625\n",
      "\n",
      "Train time for epoch #2060 (step 2060): 1.411693\n",
      "Batch #10\tAverage Generator Loss: 427.632848\tAverage Discriminator Loss: 0.000141\n",
      "\n",
      "Train time for epoch #2061 (step 2061): 1.408863\n",
      "Batch #10\tAverage Generator Loss: 515.904260\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #2062 (step 2062): 1.444727\n",
      "Batch #10\tAverage Generator Loss: 481.012750\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #2063 (step 2063): 1.402774\n",
      "Batch #10\tAverage Generator Loss: 413.798419\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #2064 (step 2064): 1.415565\n",
      "Batch #10\tAverage Generator Loss: 465.944559\tAverage Discriminator Loss: 0.007803\n",
      "\n",
      "Train time for epoch #2065 (step 2065): 1.354639\n",
      "Batch #10\tAverage Generator Loss: 438.507946\tAverage Discriminator Loss: 0.000046\n",
      "\n",
      "Train time for epoch #2066 (step 2066): 1.456545\n",
      "Batch #10\tAverage Generator Loss: 391.690871\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #2067 (step 2067): 1.488808\n",
      "Batch #10\tAverage Generator Loss: 531.355301\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #2068 (step 2068): 1.437110\n",
      "Batch #10\tAverage Generator Loss: 454.151193\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #2069 (step 2069): 1.453041\n",
      "Batch #10\tAverage Generator Loss: 482.832720\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #2070 (step 2070): 1.378709\n",
      "Batch #10\tAverage Generator Loss: 446.691391\tAverage Discriminator Loss: 0.000093\n",
      "\n",
      "Train time for epoch #2071 (step 2071): 1.512474\n",
      "Batch #10\tAverage Generator Loss: 503.475662\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #2072 (step 2072): 1.485892\n",
      "Batch #10\tAverage Generator Loss: 507.526294\tAverage Discriminator Loss: 0.000020\n",
      "\n",
      "Train time for epoch #2073 (step 2073): 1.426234\n",
      "Batch #10\tAverage Generator Loss: 453.525735\tAverage Discriminator Loss: 0.001864\n",
      "\n",
      "Train time for epoch #2074 (step 2074): 1.496439\n",
      "Batch #10\tAverage Generator Loss: 546.722696\tAverage Discriminator Loss: 0.000116\n",
      "\n",
      "Train time for epoch #2075 (step 2075): 1.550886\n",
      "Batch #10\tAverage Generator Loss: 427.574348\tAverage Discriminator Loss: 0.000595\n",
      "\n",
      "Train time for epoch #2076 (step 2076): 1.578158\n",
      "Batch #10\tAverage Generator Loss: 517.345486\tAverage Discriminator Loss: 0.000272\n",
      "\n",
      "Train time for epoch #2077 (step 2077): 1.386809\n",
      "Batch #10\tAverage Generator Loss: 503.811279\tAverage Discriminator Loss: 0.000086\n",
      "\n",
      "Train time for epoch #2078 (step 2078): 1.476935\n",
      "Batch #10\tAverage Generator Loss: 515.908850\tAverage Discriminator Loss: 0.000048\n",
      "\n",
      "Train time for epoch #2079 (step 2079): 1.516037\n",
      "Batch #10\tAverage Generator Loss: 480.662299\tAverage Discriminator Loss: 0.000038\n",
      "\n",
      "Train time for epoch #2080 (step 2080): 1.485865\n",
      "Batch #10\tAverage Generator Loss: 503.281329\tAverage Discriminator Loss: 0.000034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #2081 (step 2081): 1.467172\n",
      "Batch #10\tAverage Generator Loss: 502.371768\tAverage Discriminator Loss: 0.000040\n",
      "\n",
      "Train time for epoch #2082 (step 2082): 1.403382\n",
      "Batch #10\tAverage Generator Loss: 510.306197\tAverage Discriminator Loss: 0.000033\n",
      "\n",
      "Train time for epoch #2083 (step 2083): 1.541491\n",
      "Batch #10\tAverage Generator Loss: 443.837067\tAverage Discriminator Loss: 0.000182\n",
      "\n",
      "Train time for epoch #2084 (step 2084): 1.444975\n",
      "Batch #10\tAverage Generator Loss: 575.082089\tAverage Discriminator Loss: 0.000031\n",
      "\n",
      "Train time for epoch #2085 (step 2085): 1.432907\n",
      "Batch #10\tAverage Generator Loss: 411.455222\tAverage Discriminator Loss: 0.000037\n",
      "\n",
      "Train time for epoch #2086 (step 2086): 1.445288\n",
      "Batch #10\tAverage Generator Loss: 477.853424\tAverage Discriminator Loss: 0.082777\n",
      "\n",
      "Train time for epoch #2087 (step 2087): 1.334114\n",
      "Batch #10\tAverage Generator Loss: 425.257870\tAverage Discriminator Loss: 0.000187\n",
      "\n",
      "Train time for epoch #2088 (step 2088): 1.347404\n",
      "Batch #10\tAverage Generator Loss: 411.195589\tAverage Discriminator Loss: 0.001327\n",
      "\n",
      "Train time for epoch #2089 (step 2089): 1.475458\n",
      "Batch #10\tAverage Generator Loss: 439.831030\tAverage Discriminator Loss: 0.001212\n",
      "\n",
      "Train time for epoch #2090 (step 2090): 1.528087\n",
      "Batch #10\tAverage Generator Loss: 449.061221\tAverage Discriminator Loss: 0.000047\n",
      "\n",
      "Train time for epoch #2091 (step 2091): 1.275553\n",
      "Batch #10\tAverage Generator Loss: 416.955065\tAverage Discriminator Loss: 0.087630\n",
      "\n",
      "Train time for epoch #2092 (step 2092): 1.476540\n",
      "Batch #10\tAverage Generator Loss: 483.308594\tAverage Discriminator Loss: 0.000135\n",
      "\n",
      "Train time for epoch #2093 (step 2093): 1.351319\n",
      "Batch #10\tAverage Generator Loss: 493.266533\tAverage Discriminator Loss: 0.066761\n",
      "\n",
      "Train time for epoch #2094 (step 2094): 1.405827\n",
      "Batch #10\tAverage Generator Loss: 540.228391\tAverage Discriminator Loss: 0.000096\n",
      "\n",
      "Train time for epoch #2095 (step 2095): 1.392205\n",
      "Batch #10\tAverage Generator Loss: 540.606743\tAverage Discriminator Loss: 0.000056\n",
      "\n",
      "Train time for epoch #2096 (step 2096): 1.424602\n",
      "Batch #10\tAverage Generator Loss: 508.006149\tAverage Discriminator Loss: 0.000052\n",
      "\n",
      "Train time for epoch #2097 (step 2097): 1.508598\n",
      "Batch #10\tAverage Generator Loss: 564.937360\tAverage Discriminator Loss: 0.000040\n",
      "\n",
      "Train time for epoch #2098 (step 2098): 1.395494\n",
      "Batch #10\tAverage Generator Loss: 642.386688\tAverage Discriminator Loss: 0.000038\n",
      "\n",
      "Train time for epoch #2099 (step 2099): 1.410987\n",
      "Batch #10\tAverage Generator Loss: 546.410205\tAverage Discriminator Loss: 0.000025\n",
      "\n",
      "Train time for epoch #2100 (step 2100): 1.396069\n",
      "Batch #10\tAverage Generator Loss: 560.571815\tAverage Discriminator Loss: 0.000030\n",
      "\n",
      "Train time for epoch #2101 (step 2101): 1.518211\n",
      "Batch #10\tAverage Generator Loss: 582.070401\tAverage Discriminator Loss: 0.000020\n",
      "\n",
      "Train time for epoch #2102 (step 2102): 1.295114\n",
      "Batch #10\tAverage Generator Loss: 640.908185\tAverage Discriminator Loss: 0.000020\n",
      "\n",
      "Train time for epoch #2103 (step 2103): 1.398141\n",
      "Batch #10\tAverage Generator Loss: 530.313803\tAverage Discriminator Loss: 0.000019\n",
      "\n",
      "Train time for epoch #2104 (step 2104): 1.497890\n",
      "Batch #10\tAverage Generator Loss: 664.076019\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #2105 (step 2105): 1.429599\n",
      "Batch #10\tAverage Generator Loss: 464.875204\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #2106 (step 2106): 1.462340\n",
      "Batch #10\tAverage Generator Loss: 543.387231\tAverage Discriminator Loss: 0.000020\n",
      "\n",
      "Train time for epoch #2107 (step 2107): 1.405327\n",
      "Batch #10\tAverage Generator Loss: 599.007529\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #2108 (step 2108): 1.455656\n",
      "Batch #10\tAverage Generator Loss: 535.904536\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #2109 (step 2109): 1.487871\n",
      "Batch #10\tAverage Generator Loss: 636.396521\tAverage Discriminator Loss: 0.021102\n",
      "\n",
      "Train time for epoch #2110 (step 2110): 1.442980\n",
      "Batch #10\tAverage Generator Loss: 566.002248\tAverage Discriminator Loss: 0.000854\n",
      "\n",
      "Train time for epoch #2111 (step 2111): 1.540788\n",
      "Batch #10\tAverage Generator Loss: 626.030475\tAverage Discriminator Loss: 0.000323\n",
      "\n",
      "Train time for epoch #2112 (step 2112): 1.360041\n",
      "Batch #10\tAverage Generator Loss: 578.440454\tAverage Discriminator Loss: 0.000104\n",
      "\n",
      "Train time for epoch #2113 (step 2113): 1.516005\n",
      "Batch #10\tAverage Generator Loss: 541.012112\tAverage Discriminator Loss: 0.000084\n",
      "\n",
      "Train time for epoch #2114 (step 2114): 1.480948\n",
      "Batch #10\tAverage Generator Loss: 505.577020\tAverage Discriminator Loss: 0.003282\n",
      "\n",
      "Train time for epoch #2115 (step 2115): 1.522721\n",
      "Batch #10\tAverage Generator Loss: 571.912326\tAverage Discriminator Loss: 0.000415\n",
      "\n",
      "Train time for epoch #2116 (step 2116): 1.511218\n",
      "Batch #10\tAverage Generator Loss: 576.663498\tAverage Discriminator Loss: 0.000194\n",
      "\n",
      "Train time for epoch #2117 (step 2117): 1.568164\n",
      "Batch #10\tAverage Generator Loss: 559.901205\tAverage Discriminator Loss: 0.000138\n",
      "\n",
      "Train time for epoch #2118 (step 2118): 1.339697\n",
      "Batch #10\tAverage Generator Loss: 626.173035\tAverage Discriminator Loss: 0.000101\n",
      "\n",
      "Train time for epoch #2119 (step 2119): 1.394924\n",
      "Batch #10\tAverage Generator Loss: 590.327621\tAverage Discriminator Loss: 0.020869\n",
      "\n",
      "Train time for epoch #2120 (step 2120): 1.440592\n",
      "Batch #10\tAverage Generator Loss: 639.159000\tAverage Discriminator Loss: 0.000027\n",
      "\n",
      "Train time for epoch #2121 (step 2121): 1.394460\n",
      "Batch #10\tAverage Generator Loss: 604.527560\tAverage Discriminator Loss: 0.060731\n",
      "\n",
      "Train time for epoch #2122 (step 2122): 1.450368\n",
      "Batch #10\tAverage Generator Loss: 429.813184\tAverage Discriminator Loss: 0.000118\n",
      "\n",
      "Train time for epoch #2123 (step 2123): 1.514047\n",
      "Batch #10\tAverage Generator Loss: 396.678062\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #2124 (step 2124): 1.396171\n",
      "Batch #10\tAverage Generator Loss: 422.367496\tAverage Discriminator Loss: 0.022613\n",
      "\n",
      "Train time for epoch #2125 (step 2125): 1.401336\n",
      "Batch #10\tAverage Generator Loss: 501.692397\tAverage Discriminator Loss: 0.004276\n",
      "\n",
      "Train time for epoch #2126 (step 2126): 1.439968\n",
      "Batch #10\tAverage Generator Loss: 492.793256\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #2127 (step 2127): 1.358087\n",
      "Batch #10\tAverage Generator Loss: 449.212629\tAverage Discriminator Loss: 0.000125\n",
      "\n",
      "Train time for epoch #2128 (step 2128): 1.410921\n",
      "Batch #10\tAverage Generator Loss: 394.992853\tAverage Discriminator Loss: 0.000148\n",
      "\n",
      "Train time for epoch #2129 (step 2129): 1.457365\n",
      "Batch #10\tAverage Generator Loss: 500.110339\tAverage Discriminator Loss: 0.000131\n",
      "\n",
      "Train time for epoch #2130 (step 2130): 1.517578\n",
      "Batch #10\tAverage Generator Loss: 460.422430\tAverage Discriminator Loss: 0.000109\n",
      "\n",
      "Train time for epoch #2131 (step 2131): 1.434047\n",
      "Batch #10\tAverage Generator Loss: 544.536111\tAverage Discriminator Loss: 0.000064\n",
      "\n",
      "Train time for epoch #2132 (step 2132): 1.408641\n",
      "Batch #10\tAverage Generator Loss: 420.259071\tAverage Discriminator Loss: 0.000059\n",
      "\n",
      "Train time for epoch #2133 (step 2133): 1.503973\n",
      "Batch #10\tAverage Generator Loss: 469.768011\tAverage Discriminator Loss: 0.000056\n",
      "\n",
      "Train time for epoch #2134 (step 2134): 1.455979\n",
      "Batch #10\tAverage Generator Loss: 422.632637\tAverage Discriminator Loss: 0.000057\n",
      "\n",
      "Train time for epoch #2135 (step 2135): 1.394838\n",
      "Batch #10\tAverage Generator Loss: 390.134966\tAverage Discriminator Loss: 0.000045\n",
      "\n",
      "Train time for epoch #2136 (step 2136): 1.284483\n",
      "Batch #10\tAverage Generator Loss: 391.776784\tAverage Discriminator Loss: 0.000227\n",
      "\n",
      "Train time for epoch #2137 (step 2137): 1.361363\n",
      "Batch #10\tAverage Generator Loss: 379.528871\tAverage Discriminator Loss: 0.001490\n",
      "\n",
      "Train time for epoch #2138 (step 2138): 1.509856\n",
      "Batch #10\tAverage Generator Loss: 435.547502\tAverage Discriminator Loss: 0.000345\n",
      "\n",
      "Train time for epoch #2139 (step 2139): 1.490370\n",
      "Batch #10\tAverage Generator Loss: 472.628433\tAverage Discriminator Loss: 0.000278\n",
      "\n",
      "Train time for epoch #2140 (step 2140): 1.444582\n",
      "Batch #10\tAverage Generator Loss: 461.722522\tAverage Discriminator Loss: 0.000164\n",
      "\n",
      "Train time for epoch #2141 (step 2141): 1.463871\n",
      "Batch #10\tAverage Generator Loss: 354.181232\tAverage Discriminator Loss: 0.000099\n",
      "\n",
      "Train time for epoch #2142 (step 2142): 1.504439\n",
      "Batch #10\tAverage Generator Loss: 467.355431\tAverage Discriminator Loss: 0.000084\n",
      "\n",
      "Train time for epoch #2143 (step 2143): 1.360322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 471.647827\tAverage Discriminator Loss: 0.000056\n",
      "\n",
      "Train time for epoch #2144 (step 2144): 1.451889\n",
      "Batch #10\tAverage Generator Loss: 477.907069\tAverage Discriminator Loss: 0.000059\n",
      "\n",
      "Train time for epoch #2145 (step 2145): 1.557914\n",
      "Batch #10\tAverage Generator Loss: 466.311832\tAverage Discriminator Loss: 0.000058\n",
      "\n",
      "Train time for epoch #2146 (step 2146): 1.435488\n",
      "Batch #10\tAverage Generator Loss: 442.668417\tAverage Discriminator Loss: 0.000052\n",
      "\n",
      "Train time for epoch #2147 (step 2147): 1.475445\n",
      "Batch #10\tAverage Generator Loss: 465.492012\tAverage Discriminator Loss: 0.000041\n",
      "\n",
      "Train time for epoch #2148 (step 2148): 1.514449\n",
      "Batch #10\tAverage Generator Loss: 460.467215\tAverage Discriminator Loss: 0.000037\n",
      "\n",
      "Train time for epoch #2149 (step 2149): 1.447194\n",
      "Batch #10\tAverage Generator Loss: 488.502559\tAverage Discriminator Loss: 0.000086\n",
      "\n",
      "Train time for epoch #2150 (step 2150): 1.357224\n",
      "Batch #10\tAverage Generator Loss: 459.386676\tAverage Discriminator Loss: 0.000040\n",
      "\n",
      "Train time for epoch #2151 (step 2151): 1.447639\n",
      "Batch #10\tAverage Generator Loss: 464.876682\tAverage Discriminator Loss: 0.000030\n",
      "\n",
      "Train time for epoch #2152 (step 2152): 1.551465\n",
      "Batch #10\tAverage Generator Loss: 466.855284\tAverage Discriminator Loss: 0.000032\n",
      "\n",
      "Train time for epoch #2153 (step 2153): 1.557816\n",
      "Batch #10\tAverage Generator Loss: 475.148247\tAverage Discriminator Loss: 0.000029\n",
      "\n",
      "Train time for epoch #2154 (step 2154): 1.478527\n",
      "Batch #10\tAverage Generator Loss: 479.215189\tAverage Discriminator Loss: 0.000031\n",
      "\n",
      "Train time for epoch #2155 (step 2155): 1.394936\n",
      "Batch #10\tAverage Generator Loss: 459.377336\tAverage Discriminator Loss: 0.004346\n",
      "\n",
      "Train time for epoch #2156 (step 2156): 1.467361\n",
      "Batch #10\tAverage Generator Loss: 456.699203\tAverage Discriminator Loss: 0.000033\n",
      "\n",
      "Train time for epoch #2157 (step 2157): 1.365390\n",
      "Batch #10\tAverage Generator Loss: 460.098280\tAverage Discriminator Loss: 0.000022\n",
      "\n",
      "Train time for epoch #2158 (step 2158): 1.457620\n",
      "Batch #10\tAverage Generator Loss: 494.773709\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #2159 (step 2159): 1.504891\n",
      "Batch #10\tAverage Generator Loss: 443.476569\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #2160 (step 2160): 1.362975\n",
      "Batch #10\tAverage Generator Loss: 464.680795\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #2161 (step 2161): 1.408906\n",
      "Batch #10\tAverage Generator Loss: 455.096953\tAverage Discriminator Loss: 0.003918\n",
      "\n",
      "Train time for epoch #2162 (step 2162): 1.541563\n",
      "Batch #10\tAverage Generator Loss: 492.276566\tAverage Discriminator Loss: 0.103701\n",
      "\n",
      "Train time for epoch #2163 (step 2163): 1.374383\n",
      "Batch #10\tAverage Generator Loss: 488.368716\tAverage Discriminator Loss: 0.001133\n",
      "\n",
      "Train time for epoch #2164 (step 2164): 1.531615\n",
      "Batch #10\tAverage Generator Loss: 618.847012\tAverage Discriminator Loss: 0.032531\n",
      "\n",
      "Train time for epoch #2165 (step 2165): 1.452366\n",
      "Batch #10\tAverage Generator Loss: 613.333980\tAverage Discriminator Loss: 0.032731\n",
      "\n",
      "Train time for epoch #2166 (step 2166): 1.414355\n",
      "Batch #10\tAverage Generator Loss: 652.971829\tAverage Discriminator Loss: 0.001090\n",
      "\n",
      "Train time for epoch #2167 (step 2167): 1.448288\n",
      "Batch #10\tAverage Generator Loss: 585.732800\tAverage Discriminator Loss: 0.000220\n",
      "\n",
      "Train time for epoch #2168 (step 2168): 1.338747\n",
      "Batch #10\tAverage Generator Loss: 543.224878\tAverage Discriminator Loss: 0.074351\n",
      "\n",
      "Train time for epoch #2169 (step 2169): 1.511866\n",
      "Batch #10\tAverage Generator Loss: 534.454108\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #2170 (step 2170): 1.460651\n",
      "Batch #10\tAverage Generator Loss: 452.072382\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #2171 (step 2171): 1.430962\n",
      "Batch #10\tAverage Generator Loss: 462.986700\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #2172 (step 2172): 1.397157\n",
      "Batch #10\tAverage Generator Loss: 504.446783\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #2173 (step 2173): 1.411517\n",
      "Batch #10\tAverage Generator Loss: 511.921713\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #2174 (step 2174): 1.464650\n",
      "Batch #10\tAverage Generator Loss: 519.189090\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #2175 (step 2175): 1.397711\n",
      "Batch #10\tAverage Generator Loss: 470.955205\tAverage Discriminator Loss: 0.000370\n",
      "\n",
      "Train time for epoch #2176 (step 2176): 1.417364\n",
      "Batch #10\tAverage Generator Loss: 445.740631\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #2177 (step 2177): 1.451506\n",
      "Batch #10\tAverage Generator Loss: 428.879070\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #2178 (step 2178): 1.516480\n",
      "Batch #10\tAverage Generator Loss: 469.928889\tAverage Discriminator Loss: 0.000027\n",
      "\n",
      "Train time for epoch #2179 (step 2179): 1.462873\n",
      "Batch #10\tAverage Generator Loss: 515.935760\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #2180 (step 2180): 1.612273\n",
      "Batch #10\tAverage Generator Loss: 570.518115\tAverage Discriminator Loss: 0.002530\n",
      "\n",
      "Train time for epoch #2181 (step 2181): 1.432600\n",
      "Batch #10\tAverage Generator Loss: 523.862363\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #2182 (step 2182): 1.540639\n",
      "Batch #10\tAverage Generator Loss: 513.258303\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #2183 (step 2183): 1.392506\n",
      "Batch #10\tAverage Generator Loss: 519.266479\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #2184 (step 2184): 1.399526\n",
      "Batch #10\tAverage Generator Loss: 501.826138\tAverage Discriminator Loss: 0.000102\n",
      "\n",
      "Train time for epoch #2185 (step 2185): 1.572372\n",
      "Batch #10\tAverage Generator Loss: 521.515175\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #2186 (step 2186): 1.509244\n",
      "Batch #10\tAverage Generator Loss: 523.289767\tAverage Discriminator Loss: 0.000020\n",
      "\n",
      "Train time for epoch #2187 (step 2187): 1.360554\n",
      "Batch #10\tAverage Generator Loss: 546.699625\tAverage Discriminator Loss: 0.001483\n",
      "\n",
      "Train time for epoch #2188 (step 2188): 1.391822\n",
      "Batch #10\tAverage Generator Loss: 500.903024\tAverage Discriminator Loss: 0.000155\n",
      "\n",
      "Train time for epoch #2189 (step 2189): 1.441573\n",
      "Batch #10\tAverage Generator Loss: 557.266574\tAverage Discriminator Loss: 0.000077\n",
      "\n",
      "Train time for epoch #2190 (step 2190): 1.407999\n",
      "Batch #10\tAverage Generator Loss: 453.085483\tAverage Discriminator Loss: 0.000052\n",
      "\n",
      "Train time for epoch #2191 (step 2191): 1.494948\n",
      "Batch #10\tAverage Generator Loss: 486.358591\tAverage Discriminator Loss: 0.001083\n",
      "\n",
      "Train time for epoch #2192 (step 2192): 1.401318\n",
      "Batch #10\tAverage Generator Loss: 441.383659\tAverage Discriminator Loss: 0.000195\n",
      "\n",
      "Train time for epoch #2193 (step 2193): 1.511181\n",
      "Batch #10\tAverage Generator Loss: 527.016881\tAverage Discriminator Loss: 0.000117\n",
      "\n",
      "Train time for epoch #2194 (step 2194): 1.441204\n",
      "Batch #10\tAverage Generator Loss: 525.013033\tAverage Discriminator Loss: 0.000050\n",
      "\n",
      "Train time for epoch #2195 (step 2195): 1.468439\n",
      "Batch #10\tAverage Generator Loss: 550.716464\tAverage Discriminator Loss: 0.000039\n",
      "\n",
      "Train time for epoch #2196 (step 2196): 1.436602\n",
      "Batch #10\tAverage Generator Loss: 517.129025\tAverage Discriminator Loss: 0.000039\n",
      "\n",
      "Train time for epoch #2197 (step 2197): 1.450619\n",
      "Batch #10\tAverage Generator Loss: 377.933461\tAverage Discriminator Loss: 0.000038\n",
      "\n",
      "Train time for epoch #2198 (step 2198): 1.492480\n",
      "Batch #10\tAverage Generator Loss: 459.018826\tAverage Discriminator Loss: 0.000032\n",
      "\n",
      "Train time for epoch #2199 (step 2199): 1.353103\n",
      "Batch #10\tAverage Generator Loss: 517.775700\tAverage Discriminator Loss: 0.000028\n",
      "\n",
      "Train time for epoch #2200 (step 2200): 1.356702\n",
      "Batch #10\tAverage Generator Loss: 499.880692\tAverage Discriminator Loss: 0.000026\n",
      "\n",
      "Train time for epoch #2201 (step 2201): 1.405654\n",
      "Batch #10\tAverage Generator Loss: 425.423532\tAverage Discriminator Loss: 0.000030\n",
      "\n",
      "Train time for epoch #2202 (step 2202): 1.452470\n",
      "Batch #10\tAverage Generator Loss: 494.618115\tAverage Discriminator Loss: 0.000027\n",
      "\n",
      "Train time for epoch #2203 (step 2203): 1.506979\n",
      "Batch #10\tAverage Generator Loss: 458.701215\tAverage Discriminator Loss: 0.000043\n",
      "\n",
      "Train time for epoch #2204 (step 2204): 1.422857\n",
      "Batch #10\tAverage Generator Loss: 479.251681\tAverage Discriminator Loss: 0.000024\n",
      "\n",
      "Train time for epoch #2205 (step 2205): 1.403060\n",
      "Batch #10\tAverage Generator Loss: 428.225932\tAverage Discriminator Loss: 0.063811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #2206 (step 2206): 1.397727\n",
      "Batch #10\tAverage Generator Loss: 501.995561\tAverage Discriminator Loss: 0.023730\n",
      "\n",
      "Train time for epoch #2207 (step 2207): 1.255439\n",
      "Batch #10\tAverage Generator Loss: 482.882404\tAverage Discriminator Loss: 0.002205\n",
      "\n",
      "Train time for epoch #2208 (step 2208): 1.484169\n",
      "Batch #10\tAverage Generator Loss: 450.671994\tAverage Discriminator Loss: 0.000158\n",
      "\n",
      "Train time for epoch #2209 (step 2209): 1.396426\n",
      "Batch #10\tAverage Generator Loss: 486.651285\tAverage Discriminator Loss: 0.000102\n",
      "\n",
      "Train time for epoch #2210 (step 2210): 1.411795\n",
      "Batch #10\tAverage Generator Loss: 416.688374\tAverage Discriminator Loss: 0.000614\n",
      "\n",
      "Train time for epoch #2211 (step 2211): 1.535984\n",
      "Batch #10\tAverage Generator Loss: 401.896204\tAverage Discriminator Loss: 0.000996\n",
      "\n",
      "Train time for epoch #2212 (step 2212): 1.458230\n",
      "Batch #10\tAverage Generator Loss: 480.732953\tAverage Discriminator Loss: 0.007869\n",
      "\n",
      "Train time for epoch #2213 (step 2213): 1.498536\n",
      "Batch #10\tAverage Generator Loss: 473.672745\tAverage Discriminator Loss: 0.001066\n",
      "\n",
      "Train time for epoch #2214 (step 2214): 1.402823\n",
      "Batch #10\tAverage Generator Loss: 437.466272\tAverage Discriminator Loss: 0.000050\n",
      "\n",
      "Train time for epoch #2215 (step 2215): 1.414995\n",
      "Batch #10\tAverage Generator Loss: 457.723627\tAverage Discriminator Loss: 0.000048\n",
      "\n",
      "Train time for epoch #2216 (step 2216): 1.446902\n",
      "Batch #10\tAverage Generator Loss: 492.207169\tAverage Discriminator Loss: 0.000044\n",
      "\n",
      "Train time for epoch #2217 (step 2217): 1.486751\n",
      "Batch #10\tAverage Generator Loss: 412.383572\tAverage Discriminator Loss: 0.000044\n",
      "\n",
      "Train time for epoch #2218 (step 2218): 1.462785\n",
      "Batch #10\tAverage Generator Loss: 427.751663\tAverage Discriminator Loss: 0.000038\n",
      "\n",
      "Train time for epoch #2219 (step 2219): 1.326129\n",
      "Batch #10\tAverage Generator Loss: 446.938898\tAverage Discriminator Loss: 0.000039\n",
      "\n",
      "Train time for epoch #2220 (step 2220): 1.447106\n",
      "Batch #10\tAverage Generator Loss: 461.386356\tAverage Discriminator Loss: 0.000035\n",
      "\n",
      "Train time for epoch #2221 (step 2221): 1.435217\n",
      "Batch #10\tAverage Generator Loss: 410.168051\tAverage Discriminator Loss: 0.000040\n",
      "\n",
      "Train time for epoch #2222 (step 2222): 1.455183\n",
      "Batch #10\tAverage Generator Loss: 413.480756\tAverage Discriminator Loss: 0.000161\n",
      "\n",
      "Train time for epoch #2223 (step 2223): 1.408315\n",
      "Batch #10\tAverage Generator Loss: 450.746864\tAverage Discriminator Loss: 0.000043\n",
      "\n",
      "Train time for epoch #2224 (step 2224): 1.447251\n",
      "Batch #10\tAverage Generator Loss: 489.276636\tAverage Discriminator Loss: 0.000040\n",
      "\n",
      "Train time for epoch #2225 (step 2225): 1.391322\n",
      "Batch #10\tAverage Generator Loss: 443.521948\tAverage Discriminator Loss: 0.000035\n",
      "\n",
      "Train time for epoch #2226 (step 2226): 1.501166\n",
      "Batch #10\tAverage Generator Loss: 384.022897\tAverage Discriminator Loss: 0.000035\n",
      "\n",
      "Train time for epoch #2227 (step 2227): 1.443242\n",
      "Batch #10\tAverage Generator Loss: 441.241096\tAverage Discriminator Loss: 0.000046\n",
      "\n",
      "Train time for epoch #2228 (step 2228): 1.543323\n",
      "Batch #10\tAverage Generator Loss: 445.407014\tAverage Discriminator Loss: 0.000034\n",
      "\n",
      "Train time for epoch #2229 (step 2229): 1.429513\n",
      "Batch #10\tAverage Generator Loss: 447.590088\tAverage Discriminator Loss: 0.000031\n",
      "\n",
      "Train time for epoch #2230 (step 2230): 1.465275\n",
      "Batch #10\tAverage Generator Loss: 452.617958\tAverage Discriminator Loss: 0.000080\n",
      "\n",
      "Train time for epoch #2231 (step 2231): 1.481271\n",
      "Batch #10\tAverage Generator Loss: 459.637376\tAverage Discriminator Loss: 0.000043\n",
      "\n",
      "Train time for epoch #2232 (step 2232): 1.440755\n",
      "Batch #10\tAverage Generator Loss: 379.640187\tAverage Discriminator Loss: 0.048734\n",
      "\n",
      "Train time for epoch #2233 (step 2233): 1.534329\n",
      "Batch #10\tAverage Generator Loss: 441.163457\tAverage Discriminator Loss: 0.003855\n",
      "\n",
      "Train time for epoch #2234 (step 2234): 1.403610\n",
      "Batch #10\tAverage Generator Loss: 484.441617\tAverage Discriminator Loss: 0.000067\n",
      "\n",
      "Train time for epoch #2235 (step 2235): 1.399655\n",
      "Batch #10\tAverage Generator Loss: 514.565314\tAverage Discriminator Loss: 0.089778\n",
      "\n",
      "Train time for epoch #2236 (step 2236): 1.399030\n",
      "Batch #10\tAverage Generator Loss: 411.571814\tAverage Discriminator Loss: 0.000043\n",
      "\n",
      "Train time for epoch #2237 (step 2237): 1.334757\n",
      "Batch #10\tAverage Generator Loss: 422.133391\tAverage Discriminator Loss: 0.100728\n",
      "\n",
      "Train time for epoch #2238 (step 2238): 1.446384\n",
      "Batch #10\tAverage Generator Loss: 387.002959\tAverage Discriminator Loss: 0.001145\n",
      "\n",
      "Train time for epoch #2239 (step 2239): 1.455500\n",
      "Batch #10\tAverage Generator Loss: 367.426234\tAverage Discriminator Loss: 0.000264\n",
      "\n",
      "Train time for epoch #2240 (step 2240): 1.503234\n",
      "Batch #10\tAverage Generator Loss: 450.167986\tAverage Discriminator Loss: 0.000088\n",
      "\n",
      "Train time for epoch #2241 (step 2241): 1.499778\n",
      "Batch #10\tAverage Generator Loss: 364.943045\tAverage Discriminator Loss: 0.034606\n",
      "\n",
      "Train time for epoch #2242 (step 2242): 1.399658\n",
      "Batch #10\tAverage Generator Loss: 412.665393\tAverage Discriminator Loss: 0.006976\n",
      "\n",
      "Train time for epoch #2243 (step 2243): 1.407191\n",
      "Batch #10\tAverage Generator Loss: 407.667102\tAverage Discriminator Loss: 0.000024\n",
      "\n",
      "Train time for epoch #2244 (step 2244): 1.418658\n",
      "Batch #10\tAverage Generator Loss: 468.669003\tAverage Discriminator Loss: 0.000089\n",
      "\n",
      "Train time for epoch #2245 (step 2245): 1.501748\n",
      "Batch #10\tAverage Generator Loss: 465.151859\tAverage Discriminator Loss: 0.000089\n",
      "\n",
      "Train time for epoch #2246 (step 2246): 1.481477\n",
      "Batch #10\tAverage Generator Loss: 441.049544\tAverage Discriminator Loss: 0.000065\n",
      "\n",
      "Train time for epoch #2247 (step 2247): 1.502577\n",
      "Batch #10\tAverage Generator Loss: 538.872998\tAverage Discriminator Loss: 0.000273\n",
      "\n",
      "Train time for epoch #2248 (step 2248): 1.529463\n",
      "Batch #10\tAverage Generator Loss: 464.658011\tAverage Discriminator Loss: 0.000080\n",
      "\n",
      "Train time for epoch #2249 (step 2249): 1.451383\n",
      "Batch #10\tAverage Generator Loss: 506.367380\tAverage Discriminator Loss: 0.000066\n",
      "\n",
      "Train time for epoch #2250 (step 2250): 1.407124\n",
      "Batch #10\tAverage Generator Loss: 404.166327\tAverage Discriminator Loss: 0.000138\n",
      "\n",
      "Train time for epoch #2251 (step 2251): 1.342335\n",
      "Batch #10\tAverage Generator Loss: 515.149136\tAverage Discriminator Loss: 0.000054\n",
      "\n",
      "Train time for epoch #2252 (step 2252): 1.404999\n",
      "Batch #10\tAverage Generator Loss: 426.872354\tAverage Discriminator Loss: 0.000046\n",
      "\n",
      "Train time for epoch #2253 (step 2253): 1.421569\n",
      "Batch #10\tAverage Generator Loss: 538.014926\tAverage Discriminator Loss: 0.000095\n",
      "\n",
      "Train time for epoch #2254 (step 2254): 1.402730\n",
      "Batch #10\tAverage Generator Loss: 509.364890\tAverage Discriminator Loss: 0.000023\n",
      "\n",
      "Train time for epoch #2255 (step 2255): 1.466338\n",
      "Batch #10\tAverage Generator Loss: 509.776837\tAverage Discriminator Loss: 0.000042\n",
      "\n",
      "Train time for epoch #2256 (step 2256): 1.482842\n",
      "Batch #10\tAverage Generator Loss: 431.891675\tAverage Discriminator Loss: 0.000101\n",
      "\n",
      "Train time for epoch #2257 (step 2257): 1.407230\n",
      "Batch #10\tAverage Generator Loss: 435.407713\tAverage Discriminator Loss: 0.000036\n",
      "\n",
      "Train time for epoch #2258 (step 2258): 1.408936\n",
      "Batch #10\tAverage Generator Loss: 447.022896\tAverage Discriminator Loss: 0.000034\n",
      "\n",
      "Train time for epoch #2259 (step 2259): 1.287548\n",
      "Batch #10\tAverage Generator Loss: 477.014551\tAverage Discriminator Loss: 0.000359\n",
      "\n",
      "Train time for epoch #2260 (step 2260): 1.537109\n",
      "Batch #10\tAverage Generator Loss: 441.436652\tAverage Discriminator Loss: 0.002427\n",
      "\n",
      "Train time for epoch #2261 (step 2261): 1.364619\n",
      "Batch #10\tAverage Generator Loss: 530.410757\tAverage Discriminator Loss: 0.000510\n",
      "\n",
      "Train time for epoch #2262 (step 2262): 1.414742\n",
      "Batch #10\tAverage Generator Loss: 434.832661\tAverage Discriminator Loss: 0.084314\n",
      "\n",
      "Train time for epoch #2263 (step 2263): 1.596181\n",
      "Batch #10\tAverage Generator Loss: 437.951965\tAverage Discriminator Loss: 0.000095\n",
      "\n",
      "Train time for epoch #2264 (step 2264): 1.546018\n",
      "Batch #10\tAverage Generator Loss: 409.212206\tAverage Discriminator Loss: 0.000248\n",
      "\n",
      "Train time for epoch #2265 (step 2265): 1.411540\n",
      "Batch #10\tAverage Generator Loss: 391.547089\tAverage Discriminator Loss: 0.000371\n",
      "\n",
      "Train time for epoch #2266 (step 2266): 1.428922\n",
      "Batch #10\tAverage Generator Loss: 434.628345\tAverage Discriminator Loss: 0.000559\n",
      "\n",
      "Train time for epoch #2267 (step 2267): 1.471810\n",
      "Batch #10\tAverage Generator Loss: 408.630586\tAverage Discriminator Loss: 0.000192\n",
      "\n",
      "Train time for epoch #2268 (step 2268): 1.420090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 483.487366\tAverage Discriminator Loss: 0.000120\n",
      "\n",
      "Train time for epoch #2269 (step 2269): 1.375116\n",
      "Batch #10\tAverage Generator Loss: 430.623103\tAverage Discriminator Loss: 0.000077\n",
      "\n",
      "Train time for epoch #2270 (step 2270): 1.466376\n",
      "Batch #10\tAverage Generator Loss: 432.633389\tAverage Discriminator Loss: 0.000078\n",
      "\n",
      "Train time for epoch #2271 (step 2271): 1.453135\n",
      "Batch #10\tAverage Generator Loss: 420.962006\tAverage Discriminator Loss: 0.000064\n",
      "\n",
      "Train time for epoch #2272 (step 2272): 1.444643\n",
      "Batch #10\tAverage Generator Loss: 429.193967\tAverage Discriminator Loss: 0.000405\n",
      "\n",
      "Train time for epoch #2273 (step 2273): 1.479422\n",
      "Batch #10\tAverage Generator Loss: 444.733133\tAverage Discriminator Loss: 0.000088\n",
      "\n",
      "Train time for epoch #2274 (step 2274): 1.409155\n",
      "Batch #10\tAverage Generator Loss: 427.348990\tAverage Discriminator Loss: 0.000091\n",
      "\n",
      "Train time for epoch #2275 (step 2275): 1.466191\n",
      "Batch #10\tAverage Generator Loss: 397.331009\tAverage Discriminator Loss: 0.000449\n",
      "\n",
      "Train time for epoch #2276 (step 2276): 1.445514\n",
      "Batch #10\tAverage Generator Loss: 400.362358\tAverage Discriminator Loss: 0.000072\n",
      "\n",
      "Train time for epoch #2277 (step 2277): 1.537757\n",
      "Batch #10\tAverage Generator Loss: 437.607584\tAverage Discriminator Loss: 0.000061\n",
      "\n",
      "Train time for epoch #2278 (step 2278): 1.461361\n",
      "Batch #10\tAverage Generator Loss: 417.446747\tAverage Discriminator Loss: 0.000062\n",
      "\n",
      "Train time for epoch #2279 (step 2279): 1.417282\n",
      "Batch #10\tAverage Generator Loss: 444.099316\tAverage Discriminator Loss: 0.000058\n",
      "\n",
      "Train time for epoch #2280 (step 2280): 1.531888\n",
      "Batch #10\tAverage Generator Loss: 441.948077\tAverage Discriminator Loss: 0.000050\n",
      "\n",
      "Train time for epoch #2281 (step 2281): 1.394088\n",
      "Batch #10\tAverage Generator Loss: 472.023557\tAverage Discriminator Loss: 0.000050\n",
      "\n",
      "Train time for epoch #2282 (step 2282): 1.464360\n",
      "Batch #10\tAverage Generator Loss: 471.305957\tAverage Discriminator Loss: 0.000041\n",
      "\n",
      "Train time for epoch #2283 (step 2283): 1.448974\n",
      "Batch #10\tAverage Generator Loss: 457.949089\tAverage Discriminator Loss: 0.000049\n",
      "\n",
      "Train time for epoch #2284 (step 2284): 1.401980\n",
      "Batch #10\tAverage Generator Loss: 440.891199\tAverage Discriminator Loss: 0.000043\n",
      "\n",
      "Train time for epoch #2285 (step 2285): 1.460718\n",
      "Batch #10\tAverage Generator Loss: 485.431274\tAverage Discriminator Loss: 0.000044\n",
      "\n",
      "Train time for epoch #2286 (step 2286): 1.493120\n",
      "Batch #10\tAverage Generator Loss: 364.376334\tAverage Discriminator Loss: 0.000101\n",
      "\n",
      "Train time for epoch #2287 (step 2287): 1.394856\n",
      "Batch #10\tAverage Generator Loss: 480.732123\tAverage Discriminator Loss: 0.000041\n",
      "\n",
      "Train time for epoch #2288 (step 2288): 1.430473\n",
      "Batch #10\tAverage Generator Loss: 513.809038\tAverage Discriminator Loss: 0.000042\n",
      "\n",
      "Train time for epoch #2289 (step 2289): 1.590155\n",
      "Batch #10\tAverage Generator Loss: 441.734549\tAverage Discriminator Loss: 0.000031\n",
      "\n",
      "Train time for epoch #2290 (step 2290): 1.423993\n",
      "Batch #10\tAverage Generator Loss: 414.360968\tAverage Discriminator Loss: 0.000030\n",
      "\n",
      "Train time for epoch #2291 (step 2291): 1.553451\n",
      "Batch #10\tAverage Generator Loss: 497.900491\tAverage Discriminator Loss: 0.009702\n",
      "\n",
      "Train time for epoch #2292 (step 2292): 1.346879\n",
      "Batch #10\tAverage Generator Loss: 491.140079\tAverage Discriminator Loss: 0.000120\n",
      "\n",
      "Train time for epoch #2293 (step 2293): 1.416313\n",
      "Batch #10\tAverage Generator Loss: 445.490260\tAverage Discriminator Loss: 0.000055\n",
      "\n",
      "Train time for epoch #2294 (step 2294): 1.246204\n",
      "Batch #10\tAverage Generator Loss: 463.981833\tAverage Discriminator Loss: 0.000059\n",
      "\n",
      "Train time for epoch #2295 (step 2295): 1.521170\n",
      "Batch #10\tAverage Generator Loss: 474.840375\tAverage Discriminator Loss: 0.000100\n",
      "\n",
      "Train time for epoch #2296 (step 2296): 1.435305\n",
      "Batch #10\tAverage Generator Loss: 492.276199\tAverage Discriminator Loss: 0.000087\n",
      "\n",
      "Train time for epoch #2297 (step 2297): 1.448933\n",
      "Batch #10\tAverage Generator Loss: 440.377347\tAverage Discriminator Loss: 0.000321\n",
      "\n",
      "Train time for epoch #2298 (step 2298): 1.394118\n",
      "Batch #10\tAverage Generator Loss: 506.812671\tAverage Discriminator Loss: 0.000340\n",
      "\n",
      "Train time for epoch #2299 (step 2299): 1.365361\n",
      "Batch #10\tAverage Generator Loss: 418.836365\tAverage Discriminator Loss: 0.046844\n",
      "\n",
      "Train time for epoch #2300 (step 2300): 1.505781\n",
      "Batch #10\tAverage Generator Loss: 417.282153\tAverage Discriminator Loss: 0.009623\n",
      "\n",
      "Train time for epoch #2301 (step 2301): 1.499665\n",
      "Batch #10\tAverage Generator Loss: 408.570000\tAverage Discriminator Loss: 0.119111\n",
      "\n",
      "Train time for epoch #2302 (step 2302): 1.446468\n",
      "Batch #10\tAverage Generator Loss: 424.488036\tAverage Discriminator Loss: 0.005199\n",
      "\n",
      "Train time for epoch #2303 (step 2303): 1.475796\n",
      "Batch #10\tAverage Generator Loss: 387.125848\tAverage Discriminator Loss: 0.034944\n",
      "\n",
      "Train time for epoch #2304 (step 2304): 1.542938\n",
      "Batch #10\tAverage Generator Loss: 390.839601\tAverage Discriminator Loss: 0.000541\n",
      "\n",
      "Train time for epoch #2305 (step 2305): 1.292942\n",
      "Batch #10\tAverage Generator Loss: 369.075330\tAverage Discriminator Loss: 0.004877\n",
      "\n",
      "Train time for epoch #2306 (step 2306): 1.393389\n",
      "Batch #10\tAverage Generator Loss: 490.555293\tAverage Discriminator Loss: 0.006002\n",
      "\n",
      "Train time for epoch #2307 (step 2307): 1.390887\n",
      "Batch #10\tAverage Generator Loss: 499.485925\tAverage Discriminator Loss: 0.000166\n",
      "\n",
      "Train time for epoch #2308 (step 2308): 1.446352\n",
      "Batch #10\tAverage Generator Loss: 492.451791\tAverage Discriminator Loss: 0.000112\n",
      "\n",
      "Train time for epoch #2309 (step 2309): 1.455001\n",
      "Batch #10\tAverage Generator Loss: 492.952164\tAverage Discriminator Loss: 0.000121\n",
      "\n",
      "Train time for epoch #2310 (step 2310): 1.454067\n",
      "Batch #10\tAverage Generator Loss: 511.766150\tAverage Discriminator Loss: 0.000161\n",
      "\n",
      "Train time for epoch #2311 (step 2311): 1.335100\n",
      "Batch #10\tAverage Generator Loss: 495.729620\tAverage Discriminator Loss: 0.000131\n",
      "\n",
      "Train time for epoch #2312 (step 2312): 1.457717\n",
      "Batch #10\tAverage Generator Loss: 466.624567\tAverage Discriminator Loss: 0.000148\n",
      "\n",
      "Train time for epoch #2313 (step 2313): 1.404043\n",
      "Batch #10\tAverage Generator Loss: 431.996780\tAverage Discriminator Loss: 0.000123\n",
      "\n",
      "Train time for epoch #2314 (step 2314): 1.341931\n",
      "Batch #10\tAverage Generator Loss: 419.213018\tAverage Discriminator Loss: 0.000094\n",
      "\n",
      "Train time for epoch #2315 (step 2315): 1.557980\n",
      "Batch #10\tAverage Generator Loss: 400.313466\tAverage Discriminator Loss: 0.000089\n",
      "\n",
      "Train time for epoch #2316 (step 2316): 1.367290\n",
      "Batch #10\tAverage Generator Loss: 497.080618\tAverage Discriminator Loss: 0.000082\n",
      "\n",
      "Train time for epoch #2317 (step 2317): 1.438937\n",
      "Batch #10\tAverage Generator Loss: 491.281992\tAverage Discriminator Loss: 0.017381\n",
      "\n",
      "Train time for epoch #2318 (step 2318): 1.478326\n",
      "Batch #10\tAverage Generator Loss: 474.545468\tAverage Discriminator Loss: 0.000567\n",
      "\n",
      "Train time for epoch #2319 (step 2319): 1.409328\n",
      "Batch #10\tAverage Generator Loss: 402.702403\tAverage Discriminator Loss: 0.000699\n",
      "\n",
      "Train time for epoch #2320 (step 2320): 1.401241\n",
      "Batch #10\tAverage Generator Loss: 452.792804\tAverage Discriminator Loss: 0.008219\n",
      "\n",
      "Train time for epoch #2321 (step 2321): 1.448824\n",
      "Batch #10\tAverage Generator Loss: 423.705487\tAverage Discriminator Loss: 0.000762\n",
      "\n",
      "Train time for epoch #2322 (step 2322): 1.452358\n",
      "Batch #10\tAverage Generator Loss: 431.169847\tAverage Discriminator Loss: 0.000221\n",
      "\n",
      "Train time for epoch #2323 (step 2323): 1.300012\n",
      "Batch #10\tAverage Generator Loss: 411.085547\tAverage Discriminator Loss: 0.000159\n",
      "\n",
      "Train time for epoch #2324 (step 2324): 1.440412\n",
      "Batch #10\tAverage Generator Loss: 422.981424\tAverage Discriminator Loss: 0.000139\n",
      "\n",
      "Train time for epoch #2325 (step 2325): 1.409446\n",
      "Batch #10\tAverage Generator Loss: 412.291830\tAverage Discriminator Loss: 0.000141\n",
      "\n",
      "Train time for epoch #2326 (step 2326): 1.443951\n",
      "Batch #10\tAverage Generator Loss: 446.112260\tAverage Discriminator Loss: 0.000323\n",
      "\n",
      "Train time for epoch #2327 (step 2327): 1.415601\n",
      "Batch #10\tAverage Generator Loss: 416.696359\tAverage Discriminator Loss: 0.000103\n",
      "\n",
      "Train time for epoch #2328 (step 2328): 1.555605\n",
      "Batch #10\tAverage Generator Loss: 469.192822\tAverage Discriminator Loss: 0.000086\n",
      "\n",
      "Train time for epoch #2329 (step 2329): 1.456066\n",
      "Batch #10\tAverage Generator Loss: 459.457425\tAverage Discriminator Loss: 0.000092\n",
      "\n",
      "Train time for epoch #2330 (step 2330): 1.402918\n",
      "Batch #10\tAverage Generator Loss: 487.635228\tAverage Discriminator Loss: 0.000076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #2331 (step 2331): 1.506524\n",
      "Batch #10\tAverage Generator Loss: 492.775278\tAverage Discriminator Loss: 0.000095\n",
      "\n",
      "Train time for epoch #2332 (step 2332): 1.404585\n",
      "Batch #10\tAverage Generator Loss: 442.101659\tAverage Discriminator Loss: 0.000065\n",
      "\n",
      "Train time for epoch #2333 (step 2333): 1.445023\n",
      "Batch #10\tAverage Generator Loss: 494.457141\tAverage Discriminator Loss: 0.000074\n",
      "\n",
      "Train time for epoch #2334 (step 2334): 1.460022\n",
      "Batch #10\tAverage Generator Loss: 435.280864\tAverage Discriminator Loss: 0.000157\n",
      "\n",
      "Train time for epoch #2335 (step 2335): 1.428609\n",
      "Batch #10\tAverage Generator Loss: 402.806891\tAverage Discriminator Loss: 0.000340\n",
      "\n",
      "Train time for epoch #2336 (step 2336): 1.456668\n",
      "Batch #10\tAverage Generator Loss: 415.369966\tAverage Discriminator Loss: 0.000163\n",
      "\n",
      "Train time for epoch #2337 (step 2337): 1.421368\n",
      "Batch #10\tAverage Generator Loss: 423.231367\tAverage Discriminator Loss: 0.000113\n",
      "\n",
      "Train time for epoch #2338 (step 2338): 1.497710\n",
      "Batch #10\tAverage Generator Loss: 450.336252\tAverage Discriminator Loss: 0.000099\n",
      "\n",
      "Train time for epoch #2339 (step 2339): 1.283588\n",
      "Batch #10\tAverage Generator Loss: 452.140631\tAverage Discriminator Loss: 0.001667\n",
      "\n",
      "Train time for epoch #2340 (step 2340): 1.401584\n",
      "Batch #10\tAverage Generator Loss: 514.347342\tAverage Discriminator Loss: 0.000242\n",
      "\n",
      "Train time for epoch #2341 (step 2341): 1.512574\n",
      "Batch #10\tAverage Generator Loss: 493.868961\tAverage Discriminator Loss: 0.000142\n",
      "\n",
      "Train time for epoch #2342 (step 2342): 1.356480\n",
      "Batch #10\tAverage Generator Loss: 507.394839\tAverage Discriminator Loss: 0.000090\n",
      "\n",
      "Train time for epoch #2343 (step 2343): 1.355459\n",
      "Batch #10\tAverage Generator Loss: 506.162177\tAverage Discriminator Loss: 0.000074\n",
      "\n",
      "Train time for epoch #2344 (step 2344): 1.552088\n",
      "Batch #10\tAverage Generator Loss: 443.188599\tAverage Discriminator Loss: 0.000078\n",
      "\n",
      "Train time for epoch #2345 (step 2345): 1.569512\n",
      "Batch #10\tAverage Generator Loss: 484.648404\tAverage Discriminator Loss: 0.000057\n",
      "\n",
      "Train time for epoch #2346 (step 2346): 1.472214\n",
      "Batch #10\tAverage Generator Loss: 482.192114\tAverage Discriminator Loss: 0.000100\n",
      "\n",
      "Train time for epoch #2347 (step 2347): 1.434884\n",
      "Batch #10\tAverage Generator Loss: 471.394589\tAverage Discriminator Loss: 0.000053\n",
      "\n",
      "Train time for epoch #2348 (step 2348): 1.436980\n",
      "Batch #10\tAverage Generator Loss: 505.660999\tAverage Discriminator Loss: 0.000208\n",
      "\n",
      "Train time for epoch #2349 (step 2349): 1.401858\n",
      "Batch #10\tAverage Generator Loss: 471.627263\tAverage Discriminator Loss: 0.000077\n",
      "\n",
      "Train time for epoch #2350 (step 2350): 1.414116\n",
      "Batch #10\tAverage Generator Loss: 502.740186\tAverage Discriminator Loss: 0.000059\n",
      "\n",
      "Train time for epoch #2351 (step 2351): 1.403422\n",
      "Batch #10\tAverage Generator Loss: 454.351273\tAverage Discriminator Loss: 0.000058\n",
      "\n",
      "Train time for epoch #2352 (step 2352): 1.516869\n",
      "Batch #10\tAverage Generator Loss: 492.130110\tAverage Discriminator Loss: 0.000051\n",
      "\n",
      "Train time for epoch #2353 (step 2353): 1.284159\n",
      "Batch #10\tAverage Generator Loss: 521.881583\tAverage Discriminator Loss: 0.000089\n",
      "\n",
      "Train time for epoch #2354 (step 2354): 1.360118\n",
      "Batch #10\tAverage Generator Loss: 456.744388\tAverage Discriminator Loss: 0.000092\n",
      "\n",
      "Train time for epoch #2355 (step 2355): 1.469253\n",
      "Batch #10\tAverage Generator Loss: 472.235135\tAverage Discriminator Loss: 0.000063\n",
      "\n",
      "Train time for epoch #2356 (step 2356): 1.587939\n",
      "Batch #10\tAverage Generator Loss: 466.998734\tAverage Discriminator Loss: 0.000044\n",
      "\n",
      "Train time for epoch #2357 (step 2357): 1.335937\n",
      "Batch #10\tAverage Generator Loss: 530.860037\tAverage Discriminator Loss: 0.000045\n",
      "\n",
      "Train time for epoch #2358 (step 2358): 1.473308\n",
      "Batch #10\tAverage Generator Loss: 536.626129\tAverage Discriminator Loss: 0.000047\n",
      "\n",
      "Train time for epoch #2359 (step 2359): 1.389879\n",
      "Batch #10\tAverage Generator Loss: 413.575209\tAverage Discriminator Loss: 0.000039\n",
      "\n",
      "Train time for epoch #2360 (step 2360): 1.398986\n",
      "Batch #10\tAverage Generator Loss: 497.187161\tAverage Discriminator Loss: 0.002516\n",
      "\n",
      "Train time for epoch #2361 (step 2361): 1.419835\n",
      "Batch #10\tAverage Generator Loss: 526.634247\tAverage Discriminator Loss: 0.000073\n",
      "\n",
      "Train time for epoch #2362 (step 2362): 1.426874\n",
      "Batch #10\tAverage Generator Loss: 514.359753\tAverage Discriminator Loss: 0.000096\n",
      "\n",
      "Train time for epoch #2363 (step 2363): 1.406191\n",
      "Batch #10\tAverage Generator Loss: 534.730412\tAverage Discriminator Loss: 0.000094\n",
      "\n",
      "Train time for epoch #2364 (step 2364): 1.468156\n",
      "Batch #10\tAverage Generator Loss: 490.684720\tAverage Discriminator Loss: 0.000067\n",
      "\n",
      "Train time for epoch #2365 (step 2365): 1.406061\n",
      "Batch #10\tAverage Generator Loss: 605.991699\tAverage Discriminator Loss: 0.000070\n",
      "\n",
      "Train time for epoch #2366 (step 2366): 1.297846\n",
      "Batch #10\tAverage Generator Loss: 552.021234\tAverage Discriminator Loss: 0.000058\n",
      "\n",
      "Train time for epoch #2367 (step 2367): 1.465532\n",
      "Batch #10\tAverage Generator Loss: 505.313754\tAverage Discriminator Loss: 0.000056\n",
      "\n",
      "Train time for epoch #2368 (step 2368): 1.406690\n",
      "Batch #10\tAverage Generator Loss: 542.742529\tAverage Discriminator Loss: 0.000052\n",
      "\n",
      "Train time for epoch #2369 (step 2369): 1.400770\n",
      "Batch #10\tAverage Generator Loss: 497.686118\tAverage Discriminator Loss: 0.005497\n",
      "\n",
      "Train time for epoch #2370 (step 2370): 1.364835\n",
      "Batch #10\tAverage Generator Loss: 545.186319\tAverage Discriminator Loss: 0.005890\n",
      "\n",
      "Train time for epoch #2371 (step 2371): 1.405094\n",
      "Batch #10\tAverage Generator Loss: 454.824869\tAverage Discriminator Loss: 0.000042\n",
      "\n",
      "Train time for epoch #2372 (step 2372): 1.515953\n",
      "Batch #10\tAverage Generator Loss: 535.346091\tAverage Discriminator Loss: 0.000024\n",
      "\n",
      "Train time for epoch #2373 (step 2373): 1.607694\n",
      "Batch #10\tAverage Generator Loss: 446.995461\tAverage Discriminator Loss: 0.000021\n",
      "\n",
      "Train time for epoch #2374 (step 2374): 1.356210\n",
      "Batch #10\tAverage Generator Loss: 551.382837\tAverage Discriminator Loss: 0.000020\n",
      "\n",
      "Train time for epoch #2375 (step 2375): 1.410964\n",
      "Batch #10\tAverage Generator Loss: 525.097229\tAverage Discriminator Loss: 0.000021\n",
      "\n",
      "Train time for epoch #2376 (step 2376): 1.406532\n",
      "Batch #10\tAverage Generator Loss: 466.420303\tAverage Discriminator Loss: 0.000022\n",
      "\n",
      "Train time for epoch #2377 (step 2377): 1.473519\n",
      "Batch #10\tAverage Generator Loss: 477.022873\tAverage Discriminator Loss: 0.000140\n",
      "\n",
      "Train time for epoch #2378 (step 2378): 1.487491\n",
      "Batch #10\tAverage Generator Loss: 433.933684\tAverage Discriminator Loss: 0.000022\n",
      "\n",
      "Train time for epoch #2379 (step 2379): 1.527650\n",
      "Batch #10\tAverage Generator Loss: 425.004721\tAverage Discriminator Loss: 0.000023\n",
      "\n",
      "Train time for epoch #2380 (step 2380): 1.402600\n",
      "Batch #10\tAverage Generator Loss: 532.187189\tAverage Discriminator Loss: 0.000023\n",
      "\n",
      "Train time for epoch #2381 (step 2381): 1.539752\n",
      "Batch #10\tAverage Generator Loss: 486.599789\tAverage Discriminator Loss: 0.000022\n",
      "\n",
      "Train time for epoch #2382 (step 2382): 1.403263\n",
      "Batch #10\tAverage Generator Loss: 501.314618\tAverage Discriminator Loss: 0.000020\n",
      "\n",
      "Train time for epoch #2383 (step 2383): 1.460991\n",
      "Batch #10\tAverage Generator Loss: 494.743398\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #2384 (step 2384): 1.517888\n",
      "Batch #10\tAverage Generator Loss: 492.790919\tAverage Discriminator Loss: 0.000021\n",
      "\n",
      "Train time for epoch #2385 (step 2385): 1.408449\n",
      "Batch #10\tAverage Generator Loss: 511.550113\tAverage Discriminator Loss: 0.000032\n",
      "\n",
      "Train time for epoch #2386 (step 2386): 1.509910\n",
      "Batch #10\tAverage Generator Loss: 514.619128\tAverage Discriminator Loss: 0.000050\n",
      "\n",
      "Train time for epoch #2387 (step 2387): 1.546864\n",
      "Batch #10\tAverage Generator Loss: 503.189034\tAverage Discriminator Loss: 0.000094\n",
      "\n",
      "Train time for epoch #2388 (step 2388): 1.414611\n",
      "Batch #10\tAverage Generator Loss: 495.182991\tAverage Discriminator Loss: 0.000056\n",
      "\n",
      "Train time for epoch #2389 (step 2389): 1.349206\n",
      "Batch #10\tAverage Generator Loss: 483.900333\tAverage Discriminator Loss: 0.000046\n",
      "\n",
      "Train time for epoch #2390 (step 2390): 1.454876\n",
      "Batch #10\tAverage Generator Loss: 567.161700\tAverage Discriminator Loss: 0.000037\n",
      "\n",
      "Train time for epoch #2391 (step 2391): 1.319996\n",
      "Batch #10\tAverage Generator Loss: 476.256454\tAverage Discriminator Loss: 0.000036\n",
      "\n",
      "Train time for epoch #2392 (step 2392): 1.363239\n",
      "Batch #10\tAverage Generator Loss: 510.175516\tAverage Discriminator Loss: 0.000031\n",
      "\n",
      "Train time for epoch #2393 (step 2393): 1.404339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 522.632265\tAverage Discriminator Loss: 0.000030\n",
      "\n",
      "Train time for epoch #2394 (step 2394): 1.417841\n",
      "Batch #10\tAverage Generator Loss: 457.365717\tAverage Discriminator Loss: 0.000032\n",
      "\n",
      "Train time for epoch #2395 (step 2395): 1.417983\n",
      "Batch #10\tAverage Generator Loss: 469.816531\tAverage Discriminator Loss: 0.000027\n",
      "\n",
      "Train time for epoch #2396 (step 2396): 1.502106\n",
      "Batch #10\tAverage Generator Loss: 547.260095\tAverage Discriminator Loss: 0.000028\n",
      "\n",
      "Train time for epoch #2397 (step 2397): 1.429477\n",
      "Batch #10\tAverage Generator Loss: 543.548041\tAverage Discriminator Loss: 0.000037\n",
      "\n",
      "Train time for epoch #2398 (step 2398): 1.551739\n",
      "Batch #10\tAverage Generator Loss: 465.148802\tAverage Discriminator Loss: 0.000066\n",
      "\n",
      "Train time for epoch #2399 (step 2399): 1.373659\n",
      "Batch #10\tAverage Generator Loss: 478.268068\tAverage Discriminator Loss: 0.000048\n",
      "\n",
      "Train time for epoch #2400 (step 2400): 1.416105\n",
      "Batch #10\tAverage Generator Loss: 502.880156\tAverage Discriminator Loss: 0.000057\n",
      "\n",
      "Train time for epoch #2401 (step 2401): 1.517273\n",
      "Batch #10\tAverage Generator Loss: 479.562650\tAverage Discriminator Loss: 0.000047\n",
      "\n",
      "Train time for epoch #2402 (step 2402): 1.332296\n",
      "Batch #10\tAverage Generator Loss: 577.518262\tAverage Discriminator Loss: 0.000441\n",
      "\n",
      "Train time for epoch #2403 (step 2403): 1.403224\n",
      "Batch #10\tAverage Generator Loss: 528.700452\tAverage Discriminator Loss: 0.000043\n",
      "\n",
      "Train time for epoch #2404 (step 2404): 1.497556\n",
      "Batch #10\tAverage Generator Loss: 477.829224\tAverage Discriminator Loss: 0.000055\n",
      "\n",
      "Train time for epoch #2405 (step 2405): 1.491958\n",
      "Batch #10\tAverage Generator Loss: 480.501085\tAverage Discriminator Loss: 0.000040\n",
      "\n",
      "Train time for epoch #2406 (step 2406): 1.456247\n",
      "Batch #10\tAverage Generator Loss: 532.679002\tAverage Discriminator Loss: 0.000045\n",
      "\n",
      "Train time for epoch #2407 (step 2407): 1.407045\n",
      "Batch #10\tAverage Generator Loss: 482.099771\tAverage Discriminator Loss: 0.000077\n",
      "\n",
      "Train time for epoch #2408 (step 2408): 1.455150\n",
      "Batch #10\tAverage Generator Loss: 531.466769\tAverage Discriminator Loss: 0.000109\n",
      "\n",
      "Train time for epoch #2409 (step 2409): 1.503264\n",
      "Batch #10\tAverage Generator Loss: 548.954288\tAverage Discriminator Loss: 0.000045\n",
      "\n",
      "Train time for epoch #2410 (step 2410): 1.478089\n",
      "Batch #10\tAverage Generator Loss: 497.868913\tAverage Discriminator Loss: 0.000038\n",
      "\n",
      "Train time for epoch #2411 (step 2411): 1.482359\n",
      "Batch #10\tAverage Generator Loss: 565.901404\tAverage Discriminator Loss: 0.000037\n",
      "\n",
      "Train time for epoch #2412 (step 2412): 1.507358\n",
      "Batch #10\tAverage Generator Loss: 471.315083\tAverage Discriminator Loss: 0.000033\n",
      "\n",
      "Train time for epoch #2413 (step 2413): 1.442350\n",
      "Batch #10\tAverage Generator Loss: 518.334448\tAverage Discriminator Loss: 0.000025\n",
      "\n",
      "Train time for epoch #2414 (step 2414): 1.432351\n",
      "Batch #10\tAverage Generator Loss: 532.509174\tAverage Discriminator Loss: 0.000027\n",
      "\n",
      "Train time for epoch #2415 (step 2415): 1.381030\n",
      "Batch #10\tAverage Generator Loss: 527.702414\tAverage Discriminator Loss: 0.000023\n",
      "\n",
      "Train time for epoch #2416 (step 2416): 1.435724\n",
      "Batch #10\tAverage Generator Loss: 476.428632\tAverage Discriminator Loss: 0.000024\n",
      "\n",
      "Train time for epoch #2417 (step 2417): 1.563017\n",
      "Batch #10\tAverage Generator Loss: 498.480807\tAverage Discriminator Loss: 0.000019\n",
      "\n",
      "Train time for epoch #2418 (step 2418): 1.474534\n",
      "Batch #10\tAverage Generator Loss: 541.664743\tAverage Discriminator Loss: 0.000023\n",
      "\n",
      "Train time for epoch #2419 (step 2419): 1.471796\n",
      "Batch #10\tAverage Generator Loss: 521.605920\tAverage Discriminator Loss: 0.000022\n",
      "\n",
      "Train time for epoch #2420 (step 2420): 1.400897\n",
      "Batch #10\tAverage Generator Loss: 538.060382\tAverage Discriminator Loss: 0.000022\n",
      "\n",
      "Train time for epoch #2421 (step 2421): 1.353931\n",
      "Batch #10\tAverage Generator Loss: 454.430350\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #2422 (step 2422): 1.628901\n",
      "Batch #10\tAverage Generator Loss: 520.782401\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #2423 (step 2423): 1.435010\n",
      "Batch #10\tAverage Generator Loss: 484.492004\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #2424 (step 2424): 1.638232\n",
      "Batch #10\tAverage Generator Loss: 424.915538\tAverage Discriminator Loss: 0.079659\n",
      "\n",
      "Train time for epoch #2425 (step 2425): 1.417572\n",
      "Batch #10\tAverage Generator Loss: 384.288124\tAverage Discriminator Loss: 0.010408\n",
      "\n",
      "Train time for epoch #2426 (step 2426): 1.437053\n",
      "Batch #10\tAverage Generator Loss: 472.818764\tAverage Discriminator Loss: 0.093766\n",
      "\n",
      "Train time for epoch #2427 (step 2427): 1.518400\n",
      "Batch #10\tAverage Generator Loss: 585.603806\tAverage Discriminator Loss: 0.001586\n",
      "\n",
      "Train time for epoch #2428 (step 2428): 1.543475\n",
      "Batch #10\tAverage Generator Loss: 391.298566\tAverage Discriminator Loss: 0.035534\n",
      "\n",
      "Train time for epoch #2429 (step 2429): 1.441774\n",
      "Batch #10\tAverage Generator Loss: 474.203323\tAverage Discriminator Loss: 0.012497\n",
      "\n",
      "Train time for epoch #2430 (step 2430): 1.512403\n",
      "Batch #10\tAverage Generator Loss: 590.687386\tAverage Discriminator Loss: 0.000037\n",
      "\n",
      "Train time for epoch #2431 (step 2431): 1.590395\n",
      "Batch #10\tAverage Generator Loss: 557.660236\tAverage Discriminator Loss: 0.000031\n",
      "\n",
      "Train time for epoch #2432 (step 2432): 1.472501\n",
      "Batch #10\tAverage Generator Loss: 632.532516\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #2433 (step 2433): 1.406812\n",
      "Batch #10\tAverage Generator Loss: 668.859021\tAverage Discriminator Loss: 0.000103\n",
      "\n",
      "Train time for epoch #2434 (step 2434): 1.409457\n",
      "Batch #10\tAverage Generator Loss: 612.741322\tAverage Discriminator Loss: 0.000021\n",
      "\n",
      "Train time for epoch #2435 (step 2435): 1.461896\n",
      "Batch #10\tAverage Generator Loss: 599.222385\tAverage Discriminator Loss: 0.000023\n",
      "\n",
      "Train time for epoch #2436 (step 2436): 1.529232\n",
      "Batch #10\tAverage Generator Loss: 578.158762\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #2437 (step 2437): 1.458735\n",
      "Batch #10\tAverage Generator Loss: 479.795355\tAverage Discriminator Loss: 0.089432\n",
      "\n",
      "Train time for epoch #2438 (step 2438): 1.288026\n",
      "Batch #10\tAverage Generator Loss: 497.679549\tAverage Discriminator Loss: 0.001380\n",
      "\n",
      "Train time for epoch #2439 (step 2439): 1.556521\n",
      "Batch #10\tAverage Generator Loss: 527.512817\tAverage Discriminator Loss: 0.000058\n",
      "\n",
      "Train time for epoch #2440 (step 2440): 1.470908\n",
      "Batch #10\tAverage Generator Loss: 484.136252\tAverage Discriminator Loss: 0.000040\n",
      "\n",
      "Train time for epoch #2441 (step 2441): 1.410680\n",
      "Batch #10\tAverage Generator Loss: 534.660150\tAverage Discriminator Loss: 0.036697\n",
      "\n",
      "Train time for epoch #2442 (step 2442): 1.505146\n",
      "Batch #10\tAverage Generator Loss: 515.437210\tAverage Discriminator Loss: 0.000327\n",
      "\n",
      "Train time for epoch #2443 (step 2443): 1.639962\n",
      "Batch #10\tAverage Generator Loss: 509.463863\tAverage Discriminator Loss: 0.000265\n",
      "\n",
      "Train time for epoch #2444 (step 2444): 1.530253\n",
      "Batch #10\tAverage Generator Loss: 590.008435\tAverage Discriminator Loss: 0.000164\n",
      "\n",
      "Train time for epoch #2445 (step 2445): 1.417965\n",
      "Batch #10\tAverage Generator Loss: 523.049854\tAverage Discriminator Loss: 0.007424\n",
      "\n",
      "Train time for epoch #2446 (step 2446): 1.445555\n",
      "Batch #10\tAverage Generator Loss: 488.066286\tAverage Discriminator Loss: 0.000510\n",
      "\n",
      "Train time for epoch #2447 (step 2447): 1.413424\n",
      "Batch #10\tAverage Generator Loss: 525.110337\tAverage Discriminator Loss: 0.052599\n",
      "\n",
      "Train time for epoch #2448 (step 2448): 1.307005\n",
      "Batch #10\tAverage Generator Loss: 542.479951\tAverage Discriminator Loss: 0.001503\n",
      "\n",
      "Train time for epoch #2449 (step 2449): 1.408759\n",
      "Batch #10\tAverage Generator Loss: 576.668658\tAverage Discriminator Loss: 0.000113\n",
      "\n",
      "Train time for epoch #2450 (step 2450): 1.493159\n",
      "Batch #10\tAverage Generator Loss: 467.761992\tAverage Discriminator Loss: 0.000145\n",
      "\n",
      "Train time for epoch #2451 (step 2451): 1.761769\n",
      "Batch #10\tAverage Generator Loss: 505.488846\tAverage Discriminator Loss: 0.000098\n",
      "\n",
      "Train time for epoch #2452 (step 2452): 1.380115\n",
      "Batch #10\tAverage Generator Loss: 506.328014\tAverage Discriminator Loss: 0.000084\n",
      "\n",
      "Train time for epoch #2453 (step 2453): 1.449700\n",
      "Batch #10\tAverage Generator Loss: 536.681934\tAverage Discriminator Loss: 0.000094\n",
      "\n",
      "Train time for epoch #2454 (step 2454): 1.393331\n",
      "Batch #10\tAverage Generator Loss: 554.611856\tAverage Discriminator Loss: 0.000060\n",
      "\n",
      "Train time for epoch #2455 (step 2455): 1.327115\n",
      "Batch #10\tAverage Generator Loss: 513.194176\tAverage Discriminator Loss: 0.000366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #2456 (step 2456): 1.418552\n",
      "Batch #10\tAverage Generator Loss: 486.525011\tAverage Discriminator Loss: 0.002578\n",
      "\n",
      "Train time for epoch #2457 (step 2457): 1.460468\n",
      "Batch #10\tAverage Generator Loss: 597.123724\tAverage Discriminator Loss: 0.000303\n",
      "\n",
      "Train time for epoch #2458 (step 2458): 1.390703\n",
      "Batch #10\tAverage Generator Loss: 528.101840\tAverage Discriminator Loss: 0.000313\n",
      "\n",
      "Train time for epoch #2459 (step 2459): 1.422934\n",
      "Batch #10\tAverage Generator Loss: 435.728838\tAverage Discriminator Loss: 0.000122\n",
      "\n",
      "Train time for epoch #2460 (step 2460): 1.370579\n",
      "Batch #10\tAverage Generator Loss: 536.113852\tAverage Discriminator Loss: 0.000105\n",
      "\n",
      "Train time for epoch #2461 (step 2461): 1.449149\n",
      "Batch #10\tAverage Generator Loss: 520.729175\tAverage Discriminator Loss: 0.000104\n",
      "\n",
      "Train time for epoch #2462 (step 2462): 1.497624\n",
      "Batch #10\tAverage Generator Loss: 513.609320\tAverage Discriminator Loss: 0.000077\n",
      "\n",
      "Train time for epoch #2463 (step 2463): 1.557340\n",
      "Batch #10\tAverage Generator Loss: 531.986508\tAverage Discriminator Loss: 0.000079\n",
      "\n",
      "Train time for epoch #2464 (step 2464): 1.409605\n",
      "Batch #10\tAverage Generator Loss: 538.838708\tAverage Discriminator Loss: 0.000074\n",
      "\n",
      "Train time for epoch #2465 (step 2465): 1.342145\n",
      "Batch #10\tAverage Generator Loss: 519.259549\tAverage Discriminator Loss: 0.000061\n",
      "\n",
      "Train time for epoch #2466 (step 2466): 1.387992\n",
      "Batch #10\tAverage Generator Loss: 461.816241\tAverage Discriminator Loss: 0.000063\n",
      "\n",
      "Train time for epoch #2467 (step 2467): 1.474336\n",
      "Batch #10\tAverage Generator Loss: 516.829863\tAverage Discriminator Loss: 0.000043\n",
      "\n",
      "Train time for epoch #2468 (step 2468): 1.405814\n",
      "Batch #10\tAverage Generator Loss: 512.153886\tAverage Discriminator Loss: 0.000046\n",
      "\n",
      "Train time for epoch #2469 (step 2469): 1.425576\n",
      "Batch #10\tAverage Generator Loss: 541.233649\tAverage Discriminator Loss: 0.000055\n",
      "\n",
      "Train time for epoch #2470 (step 2470): 1.448895\n",
      "Batch #10\tAverage Generator Loss: 525.395581\tAverage Discriminator Loss: 0.000042\n",
      "\n",
      "Train time for epoch #2471 (step 2471): 1.394387\n",
      "Batch #10\tAverage Generator Loss: 475.882504\tAverage Discriminator Loss: 0.000042\n",
      "\n",
      "Train time for epoch #2472 (step 2472): 1.491295\n",
      "Batch #10\tAverage Generator Loss: 475.871240\tAverage Discriminator Loss: 0.000038\n",
      "\n",
      "Train time for epoch #2473 (step 2473): 1.417211\n",
      "Batch #10\tAverage Generator Loss: 506.209555\tAverage Discriminator Loss: 0.000033\n",
      "\n",
      "Train time for epoch #2474 (step 2474): 1.456938\n",
      "Batch #10\tAverage Generator Loss: 467.721915\tAverage Discriminator Loss: 0.000036\n",
      "\n",
      "Train time for epoch #2475 (step 2475): 1.453893\n",
      "Batch #10\tAverage Generator Loss: 554.435452\tAverage Discriminator Loss: 0.000038\n",
      "\n",
      "Train time for epoch #2476 (step 2476): 1.416648\n",
      "Batch #10\tAverage Generator Loss: 429.063412\tAverage Discriminator Loss: 0.000036\n",
      "\n",
      "Train time for epoch #2477 (step 2477): 1.447802\n",
      "Batch #10\tAverage Generator Loss: 511.008392\tAverage Discriminator Loss: 0.000033\n",
      "\n",
      "Train time for epoch #2478 (step 2478): 1.411969\n",
      "Batch #10\tAverage Generator Loss: 520.111838\tAverage Discriminator Loss: 0.000078\n",
      "\n",
      "Train time for epoch #2479 (step 2479): 1.452248\n",
      "Batch #10\tAverage Generator Loss: 427.864987\tAverage Discriminator Loss: 0.000133\n",
      "\n",
      "Train time for epoch #2480 (step 2480): 1.418334\n",
      "Batch #10\tAverage Generator Loss: 463.285016\tAverage Discriminator Loss: 0.000152\n",
      "\n",
      "Train time for epoch #2481 (step 2481): 1.389319\n",
      "Batch #10\tAverage Generator Loss: 544.750024\tAverage Discriminator Loss: 0.001054\n",
      "\n",
      "Train time for epoch #2482 (step 2482): 1.459490\n",
      "Batch #10\tAverage Generator Loss: 592.793597\tAverage Discriminator Loss: 0.002689\n",
      "\n",
      "Train time for epoch #2483 (step 2483): 1.362178\n",
      "Batch #10\tAverage Generator Loss: 560.699786\tAverage Discriminator Loss: 0.000049\n",
      "\n",
      "Train time for epoch #2484 (step 2484): 1.410151\n",
      "Batch #10\tAverage Generator Loss: 580.365039\tAverage Discriminator Loss: 0.000043\n",
      "\n",
      "Train time for epoch #2485 (step 2485): 1.502190\n",
      "Batch #10\tAverage Generator Loss: 557.179276\tAverage Discriminator Loss: 0.003986\n",
      "\n",
      "Train time for epoch #2486 (step 2486): 1.516957\n",
      "Batch #10\tAverage Generator Loss: 559.277740\tAverage Discriminator Loss: 0.002399\n",
      "\n",
      "Train time for epoch #2487 (step 2487): 1.436469\n",
      "Batch #10\tAverage Generator Loss: 514.797516\tAverage Discriminator Loss: 0.000105\n",
      "\n",
      "Train time for epoch #2488 (step 2488): 1.627131\n",
      "Batch #10\tAverage Generator Loss: 530.986258\tAverage Discriminator Loss: 0.000060\n",
      "\n",
      "Train time for epoch #2489 (step 2489): 1.476744\n",
      "Batch #10\tAverage Generator Loss: 590.750278\tAverage Discriminator Loss: 0.003987\n",
      "\n",
      "Train time for epoch #2490 (step 2490): 1.466533\n",
      "Batch #10\tAverage Generator Loss: 614.756461\tAverage Discriminator Loss: 0.000321\n",
      "\n",
      "Train time for epoch #2491 (step 2491): 1.480928\n",
      "Batch #10\tAverage Generator Loss: 532.933481\tAverage Discriminator Loss: 0.000278\n",
      "\n",
      "Train time for epoch #2492 (step 2492): 1.502629\n",
      "Batch #10\tAverage Generator Loss: 592.181671\tAverage Discriminator Loss: 0.000126\n",
      "\n",
      "Train time for epoch #2493 (step 2493): 1.517312\n",
      "Batch #10\tAverage Generator Loss: 559.437585\tAverage Discriminator Loss: 0.000108\n",
      "\n",
      "Train time for epoch #2494 (step 2494): 1.558337\n",
      "Batch #10\tAverage Generator Loss: 582.059821\tAverage Discriminator Loss: 0.000083\n",
      "\n",
      "Train time for epoch #2495 (step 2495): 1.474956\n",
      "Batch #10\tAverage Generator Loss: 536.515372\tAverage Discriminator Loss: 0.000063\n",
      "\n",
      "Train time for epoch #2496 (step 2496): 1.344072\n",
      "Batch #10\tAverage Generator Loss: 454.892616\tAverage Discriminator Loss: 0.000099\n",
      "\n",
      "Train time for epoch #2497 (step 2497): 1.408683\n",
      "Batch #10\tAverage Generator Loss: 579.308093\tAverage Discriminator Loss: 0.000054\n",
      "\n",
      "Train time for epoch #2498 (step 2498): 1.433789\n",
      "Batch #10\tAverage Generator Loss: 528.720920\tAverage Discriminator Loss: 0.000046\n",
      "\n",
      "Train time for epoch #2499 (step 2499): 1.404408\n",
      "Batch #10\tAverage Generator Loss: 544.562434\tAverage Discriminator Loss: 0.000047\n",
      "\n",
      "Train time for epoch #2500 (step 2500): 1.458830\n",
      "Batch #10\tAverage Generator Loss: 578.444675\tAverage Discriminator Loss: 0.000043\n",
      "\n",
      "Train time for epoch #2501 (step 2501): 1.499350\n",
      "Batch #10\tAverage Generator Loss: 617.567612\tAverage Discriminator Loss: 0.001490\n",
      "\n",
      "Train time for epoch #2502 (step 2502): 1.466142\n",
      "Batch #10\tAverage Generator Loss: 549.840277\tAverage Discriminator Loss: 0.000418\n",
      "\n",
      "Train time for epoch #2503 (step 2503): 1.411871\n",
      "Batch #10\tAverage Generator Loss: 484.057915\tAverage Discriminator Loss: 0.000258\n",
      "\n",
      "Train time for epoch #2504 (step 2504): 1.399431\n",
      "Batch #10\tAverage Generator Loss: 602.749164\tAverage Discriminator Loss: 0.000127\n",
      "\n",
      "Train time for epoch #2505 (step 2505): 1.398355\n",
      "Batch #10\tAverage Generator Loss: 567.902942\tAverage Discriminator Loss: 0.000078\n",
      "\n",
      "Train time for epoch #2506 (step 2506): 1.458449\n",
      "Batch #10\tAverage Generator Loss: 576.899557\tAverage Discriminator Loss: 0.000080\n",
      "\n",
      "Train time for epoch #2507 (step 2507): 1.493246\n",
      "Batch #10\tAverage Generator Loss: 528.421707\tAverage Discriminator Loss: 0.000057\n",
      "\n",
      "Train time for epoch #2508 (step 2508): 1.416667\n",
      "Batch #10\tAverage Generator Loss: 515.650809\tAverage Discriminator Loss: 0.000048\n",
      "\n",
      "Train time for epoch #2509 (step 2509): 1.462319\n",
      "Batch #10\tAverage Generator Loss: 584.108444\tAverage Discriminator Loss: 0.000048\n",
      "\n",
      "Train time for epoch #2510 (step 2510): 1.370560\n",
      "Batch #10\tAverage Generator Loss: 580.009610\tAverage Discriminator Loss: 0.000039\n",
      "\n",
      "Train time for epoch #2511 (step 2511): 1.525830\n",
      "Batch #10\tAverage Generator Loss: 469.801537\tAverage Discriminator Loss: 0.244732\n",
      "\n",
      "Train time for epoch #2512 (step 2512): 1.346003\n",
      "Batch #10\tAverage Generator Loss: 561.770801\tAverage Discriminator Loss: 0.041875\n",
      "\n",
      "Train time for epoch #2513 (step 2513): 1.543269\n",
      "Batch #10\tAverage Generator Loss: 457.717976\tAverage Discriminator Loss: 0.000059\n",
      "\n",
      "Train time for epoch #2514 (step 2514): 1.424486\n",
      "Batch #10\tAverage Generator Loss: 557.252820\tAverage Discriminator Loss: 0.000368\n",
      "\n",
      "Train time for epoch #2515 (step 2515): 1.400691\n",
      "Batch #10\tAverage Generator Loss: 558.639278\tAverage Discriminator Loss: 0.000035\n",
      "\n",
      "Train time for epoch #2516 (step 2516): 1.462292\n",
      "Batch #10\tAverage Generator Loss: 606.900790\tAverage Discriminator Loss: 0.000035\n",
      "\n",
      "Train time for epoch #2517 (step 2517): 1.417003\n",
      "Batch #10\tAverage Generator Loss: 596.901447\tAverage Discriminator Loss: 0.000042\n",
      "\n",
      "Train time for epoch #2518 (step 2518): 1.566949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 524.343408\tAverage Discriminator Loss: 0.000697\n",
      "\n",
      "Train time for epoch #2519 (step 2519): 1.507475\n",
      "Batch #10\tAverage Generator Loss: 590.018713\tAverage Discriminator Loss: 0.000057\n",
      "\n",
      "Train time for epoch #2520 (step 2520): 1.327420\n",
      "Batch #10\tAverage Generator Loss: 539.145358\tAverage Discriminator Loss: 0.000597\n",
      "\n",
      "Train time for epoch #2521 (step 2521): 1.403598\n",
      "Batch #10\tAverage Generator Loss: 559.795959\tAverage Discriminator Loss: 0.001282\n",
      "\n",
      "Train time for epoch #2522 (step 2522): 1.360075\n",
      "Batch #10\tAverage Generator Loss: 546.301091\tAverage Discriminator Loss: 0.000064\n",
      "\n",
      "Train time for epoch #2523 (step 2523): 1.488572\n",
      "Batch #10\tAverage Generator Loss: 590.826236\tAverage Discriminator Loss: 0.000047\n",
      "\n",
      "Train time for epoch #2524 (step 2524): 1.411667\n",
      "Batch #10\tAverage Generator Loss: 622.473495\tAverage Discriminator Loss: 0.000038\n",
      "\n",
      "Train time for epoch #2525 (step 2525): 1.467110\n",
      "Batch #10\tAverage Generator Loss: 641.277408\tAverage Discriminator Loss: 0.002795\n",
      "\n",
      "Train time for epoch #2526 (step 2526): 1.407502\n",
      "Batch #10\tAverage Generator Loss: 537.907275\tAverage Discriminator Loss: 0.000082\n",
      "\n",
      "Train time for epoch #2527 (step 2527): 1.528684\n",
      "Batch #10\tAverage Generator Loss: 600.605661\tAverage Discriminator Loss: 0.000123\n",
      "\n",
      "Train time for epoch #2528 (step 2528): 1.471316\n",
      "Batch #10\tAverage Generator Loss: 552.744928\tAverage Discriminator Loss: 0.000089\n",
      "\n",
      "Train time for epoch #2529 (step 2529): 1.426473\n",
      "Batch #10\tAverage Generator Loss: 688.869861\tAverage Discriminator Loss: 0.003885\n",
      "\n",
      "Train time for epoch #2530 (step 2530): 1.396583\n",
      "Batch #10\tAverage Generator Loss: 552.013141\tAverage Discriminator Loss: 0.001532\n",
      "\n",
      "Train time for epoch #2531 (step 2531): 1.442035\n",
      "Batch #10\tAverage Generator Loss: 580.211716\tAverage Discriminator Loss: 0.000119\n",
      "\n",
      "Train time for epoch #2532 (step 2532): 1.468626\n",
      "Batch #10\tAverage Generator Loss: 578.116373\tAverage Discriminator Loss: 0.000060\n",
      "\n",
      "Train time for epoch #2533 (step 2533): 1.420006\n",
      "Batch #10\tAverage Generator Loss: 372.456080\tAverage Discriminator Loss: 0.253901\n",
      "\n",
      "Train time for epoch #2534 (step 2534): 1.423687\n",
      "Batch #10\tAverage Generator Loss: 442.160406\tAverage Discriminator Loss: 0.004030\n",
      "\n",
      "Train time for epoch #2535 (step 2535): 1.557453\n",
      "Batch #10\tAverage Generator Loss: 351.527107\tAverage Discriminator Loss: 0.000119\n",
      "\n",
      "Train time for epoch #2536 (step 2536): 1.402219\n",
      "Batch #10\tAverage Generator Loss: 327.560847\tAverage Discriminator Loss: 0.003331\n",
      "\n",
      "Train time for epoch #2537 (step 2537): 1.290698\n",
      "Batch #10\tAverage Generator Loss: 312.579438\tAverage Discriminator Loss: 0.004645\n",
      "\n",
      "Train time for epoch #2538 (step 2538): 1.438923\n",
      "Batch #10\tAverage Generator Loss: 372.017775\tAverage Discriminator Loss: 0.000437\n",
      "\n",
      "Train time for epoch #2539 (step 2539): 1.429279\n",
      "Batch #10\tAverage Generator Loss: 368.087857\tAverage Discriminator Loss: 0.000322\n",
      "\n",
      "Train time for epoch #2540 (step 2540): 1.590581\n",
      "Batch #10\tAverage Generator Loss: 336.131326\tAverage Discriminator Loss: 0.000188\n",
      "\n",
      "Train time for epoch #2541 (step 2541): 1.412833\n",
      "Batch #10\tAverage Generator Loss: 333.053075\tAverage Discriminator Loss: 0.001595\n",
      "\n",
      "Train time for epoch #2542 (step 2542): 1.414877\n",
      "Batch #10\tAverage Generator Loss: 305.463705\tAverage Discriminator Loss: 0.000257\n",
      "\n",
      "Train time for epoch #2543 (step 2543): 1.442429\n",
      "Batch #10\tAverage Generator Loss: 371.840147\tAverage Discriminator Loss: 0.000227\n",
      "\n",
      "Train time for epoch #2544 (step 2544): 1.570178\n",
      "Batch #10\tAverage Generator Loss: 384.902054\tAverage Discriminator Loss: 0.000187\n",
      "\n",
      "Train time for epoch #2545 (step 2545): 1.284204\n",
      "Batch #10\tAverage Generator Loss: 352.950592\tAverage Discriminator Loss: 0.000149\n",
      "\n",
      "Train time for epoch #2546 (step 2546): 1.447074\n",
      "Batch #10\tAverage Generator Loss: 370.094139\tAverage Discriminator Loss: 0.000151\n",
      "\n",
      "Train time for epoch #2547 (step 2547): 1.509649\n",
      "Batch #10\tAverage Generator Loss: 358.122937\tAverage Discriminator Loss: 0.004547\n",
      "\n",
      "Train time for epoch #2548 (step 2548): 1.373279\n",
      "Batch #10\tAverage Generator Loss: 326.456516\tAverage Discriminator Loss: 0.000246\n",
      "\n",
      "Train time for epoch #2549 (step 2549): 1.427490\n",
      "Batch #10\tAverage Generator Loss: 331.213788\tAverage Discriminator Loss: 0.000239\n",
      "\n",
      "Train time for epoch #2550 (step 2550): 1.416366\n",
      "Batch #10\tAverage Generator Loss: 341.527974\tAverage Discriminator Loss: 0.000179\n",
      "\n",
      "Train time for epoch #2551 (step 2551): 1.422406\n",
      "Batch #10\tAverage Generator Loss: 345.534328\tAverage Discriminator Loss: 0.000170\n",
      "\n",
      "Train time for epoch #2552 (step 2552): 1.445626\n",
      "Batch #10\tAverage Generator Loss: 419.242804\tAverage Discriminator Loss: 0.000146\n",
      "\n",
      "Train time for epoch #2553 (step 2553): 1.283495\n",
      "Batch #10\tAverage Generator Loss: 354.363382\tAverage Discriminator Loss: 0.001297\n",
      "\n",
      "Train time for epoch #2554 (step 2554): 1.495473\n",
      "Batch #10\tAverage Generator Loss: 407.125717\tAverage Discriminator Loss: 0.000592\n",
      "\n",
      "Train time for epoch #2555 (step 2555): 1.536476\n",
      "Batch #10\tAverage Generator Loss: 323.824200\tAverage Discriminator Loss: 0.002698\n",
      "\n",
      "Train time for epoch #2556 (step 2556): 1.415359\n",
      "Batch #10\tAverage Generator Loss: 305.807468\tAverage Discriminator Loss: 0.000994\n",
      "\n",
      "Train time for epoch #2557 (step 2557): 1.409559\n",
      "Batch #10\tAverage Generator Loss: 374.822554\tAverage Discriminator Loss: 0.000549\n",
      "\n",
      "Train time for epoch #2558 (step 2558): 1.457325\n",
      "Batch #10\tAverage Generator Loss: 384.171057\tAverage Discriminator Loss: 0.000175\n",
      "\n",
      "Train time for epoch #2559 (step 2559): 1.405727\n",
      "Batch #10\tAverage Generator Loss: 322.465395\tAverage Discriminator Loss: 0.039717\n",
      "\n",
      "Train time for epoch #2560 (step 2560): 1.402027\n",
      "Batch #10\tAverage Generator Loss: 403.839189\tAverage Discriminator Loss: 0.000318\n",
      "\n",
      "Train time for epoch #2561 (step 2561): 1.587548\n",
      "Batch #10\tAverage Generator Loss: 405.637633\tAverage Discriminator Loss: 0.000293\n",
      "\n",
      "Train time for epoch #2562 (step 2562): 1.384009\n",
      "Batch #10\tAverage Generator Loss: 445.964093\tAverage Discriminator Loss: 0.001544\n",
      "\n",
      "Train time for epoch #2563 (step 2563): 1.539052\n",
      "Batch #10\tAverage Generator Loss: 379.177223\tAverage Discriminator Loss: 0.000158\n",
      "\n",
      "Train time for epoch #2564 (step 2564): 1.483830\n",
      "Batch #10\tAverage Generator Loss: 437.105981\tAverage Discriminator Loss: 0.000080\n",
      "\n",
      "Train time for epoch #2565 (step 2565): 1.479445\n",
      "Batch #10\tAverage Generator Loss: 462.591525\tAverage Discriminator Loss: 0.000072\n",
      "\n",
      "Train time for epoch #2566 (step 2566): 1.416751\n",
      "Batch #10\tAverage Generator Loss: 428.668024\tAverage Discriminator Loss: 0.002874\n",
      "\n",
      "Train time for epoch #2567 (step 2567): 1.563442\n",
      "Batch #10\tAverage Generator Loss: 433.710368\tAverage Discriminator Loss: 0.000930\n",
      "\n",
      "Train time for epoch #2568 (step 2568): 1.460334\n",
      "Batch #10\tAverage Generator Loss: 409.324503\tAverage Discriminator Loss: 0.000210\n",
      "\n",
      "Train time for epoch #2569 (step 2569): 1.447150\n",
      "Batch #10\tAverage Generator Loss: 379.562102\tAverage Discriminator Loss: 0.000294\n",
      "\n",
      "Train time for epoch #2570 (step 2570): 1.453752\n",
      "Batch #10\tAverage Generator Loss: 435.240930\tAverage Discriminator Loss: 0.000174\n",
      "\n",
      "Train time for epoch #2571 (step 2571): 1.469970\n",
      "Batch #10\tAverage Generator Loss: 474.772516\tAverage Discriminator Loss: 0.000809\n",
      "\n",
      "Train time for epoch #2572 (step 2572): 1.477115\n",
      "Batch #10\tAverage Generator Loss: 391.481476\tAverage Discriminator Loss: 0.001109\n",
      "\n",
      "Train time for epoch #2573 (step 2573): 1.420412\n",
      "Batch #10\tAverage Generator Loss: 372.260596\tAverage Discriminator Loss: 0.000262\n",
      "\n",
      "Train time for epoch #2574 (step 2574): 1.492344\n",
      "Batch #10\tAverage Generator Loss: 437.563716\tAverage Discriminator Loss: 0.000103\n",
      "\n",
      "Train time for epoch #2575 (step 2575): 1.469545\n",
      "Batch #10\tAverage Generator Loss: 470.838922\tAverage Discriminator Loss: 0.000132\n",
      "\n",
      "Train time for epoch #2576 (step 2576): 1.421710\n",
      "Batch #10\tAverage Generator Loss: 463.436691\tAverage Discriminator Loss: 0.000128\n",
      "\n",
      "Train time for epoch #2577 (step 2577): 1.420981\n",
      "Batch #10\tAverage Generator Loss: 399.884227\tAverage Discriminator Loss: 0.094045\n",
      "\n",
      "Train time for epoch #2578 (step 2578): 1.354031\n",
      "Batch #10\tAverage Generator Loss: 377.656975\tAverage Discriminator Loss: 0.071841\n",
      "\n",
      "Train time for epoch #2579 (step 2579): 1.564431\n",
      "Batch #10\tAverage Generator Loss: 330.393393\tAverage Discriminator Loss: 0.001579\n",
      "\n",
      "Train time for epoch #2580 (step 2580): 1.497146\n",
      "Batch #10\tAverage Generator Loss: 382.645782\tAverage Discriminator Loss: 0.000324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #2581 (step 2581): 1.448956\n",
      "Batch #10\tAverage Generator Loss: 434.816187\tAverage Discriminator Loss: 0.000293\n",
      "\n",
      "Train time for epoch #2582 (step 2582): 1.445785\n",
      "Batch #10\tAverage Generator Loss: 422.166043\tAverage Discriminator Loss: 0.002727\n",
      "\n",
      "Train time for epoch #2583 (step 2583): 1.513812\n",
      "Batch #10\tAverage Generator Loss: 375.632004\tAverage Discriminator Loss: 0.000686\n",
      "\n",
      "Train time for epoch #2584 (step 2584): 1.626602\n",
      "Batch #10\tAverage Generator Loss: 419.453238\tAverage Discriminator Loss: 0.000537\n",
      "\n",
      "Train time for epoch #2585 (step 2585): 1.488803\n",
      "Batch #10\tAverage Generator Loss: 407.648016\tAverage Discriminator Loss: 0.006455\n",
      "\n",
      "Train time for epoch #2586 (step 2586): 1.393735\n",
      "Batch #10\tAverage Generator Loss: 472.491754\tAverage Discriminator Loss: 0.003454\n",
      "\n",
      "Train time for epoch #2587 (step 2587): 1.561347\n",
      "Batch #10\tAverage Generator Loss: 433.571956\tAverage Discriminator Loss: 0.000132\n",
      "\n",
      "Train time for epoch #2588 (step 2588): 1.513447\n",
      "Batch #10\tAverage Generator Loss: 398.500092\tAverage Discriminator Loss: 0.000102\n",
      "\n",
      "Train time for epoch #2589 (step 2589): 1.466752\n",
      "Batch #10\tAverage Generator Loss: 436.687643\tAverage Discriminator Loss: 0.056560\n",
      "\n",
      "Train time for epoch #2590 (step 2590): 1.412951\n",
      "Batch #10\tAverage Generator Loss: 408.589948\tAverage Discriminator Loss: 0.000209\n",
      "\n",
      "Train time for epoch #2591 (step 2591): 1.498027\n",
      "Batch #10\tAverage Generator Loss: 427.877783\tAverage Discriminator Loss: 0.000090\n",
      "\n",
      "Train time for epoch #2592 (step 2592): 1.378957\n",
      "Batch #10\tAverage Generator Loss: 372.692430\tAverage Discriminator Loss: 0.000133\n",
      "\n",
      "Train time for epoch #2593 (step 2593): 1.341293\n",
      "Batch #10\tAverage Generator Loss: 352.757784\tAverage Discriminator Loss: 0.000074\n",
      "\n",
      "Train time for epoch #2594 (step 2594): 1.423538\n",
      "Batch #10\tAverage Generator Loss: 426.414850\tAverage Discriminator Loss: 0.000071\n",
      "\n",
      "Train time for epoch #2595 (step 2595): 1.543644\n",
      "Batch #10\tAverage Generator Loss: 451.466708\tAverage Discriminator Loss: 0.003381\n",
      "\n",
      "Train time for epoch #2596 (step 2596): 1.458830\n",
      "Batch #10\tAverage Generator Loss: 387.387357\tAverage Discriminator Loss: 0.000792\n",
      "\n",
      "Train time for epoch #2597 (step 2597): 1.361983\n",
      "Batch #10\tAverage Generator Loss: 404.265082\tAverage Discriminator Loss: 0.000358\n",
      "\n",
      "Train time for epoch #2598 (step 2598): 1.492316\n",
      "Batch #10\tAverage Generator Loss: 461.949973\tAverage Discriminator Loss: 0.000179\n",
      "\n",
      "Train time for epoch #2599 (step 2599): 1.428741\n",
      "Batch #10\tAverage Generator Loss: 428.522453\tAverage Discriminator Loss: 0.001563\n",
      "\n",
      "Train time for epoch #2600 (step 2600): 1.503606\n",
      "Batch #10\tAverage Generator Loss: 395.922343\tAverage Discriminator Loss: 0.000694\n",
      "\n",
      "Train time for epoch #2601 (step 2601): 1.416018\n",
      "Batch #10\tAverage Generator Loss: 424.081371\tAverage Discriminator Loss: 0.000848\n",
      "\n",
      "Train time for epoch #2602 (step 2602): 1.464301\n",
      "Batch #10\tAverage Generator Loss: 420.779121\tAverage Discriminator Loss: 0.000203\n",
      "\n",
      "Train time for epoch #2603 (step 2603): 1.277492\n",
      "Batch #10\tAverage Generator Loss: 438.752005\tAverage Discriminator Loss: 0.000161\n",
      "\n",
      "Train time for epoch #2604 (step 2604): 1.417257\n",
      "Batch #10\tAverage Generator Loss: 434.333905\tAverage Discriminator Loss: 0.000281\n",
      "\n",
      "Train time for epoch #2605 (step 2605): 1.457429\n",
      "Batch #10\tAverage Generator Loss: 452.481703\tAverage Discriminator Loss: 0.000133\n",
      "\n",
      "Train time for epoch #2606 (step 2606): 1.469091\n",
      "Batch #10\tAverage Generator Loss: 426.892795\tAverage Discriminator Loss: 0.000135\n",
      "\n",
      "Train time for epoch #2607 (step 2607): 1.512041\n",
      "Batch #10\tAverage Generator Loss: 456.818112\tAverage Discriminator Loss: 0.000118\n",
      "\n",
      "Train time for epoch #2608 (step 2608): 1.561975\n",
      "Batch #10\tAverage Generator Loss: 432.349384\tAverage Discriminator Loss: 0.000110\n",
      "\n",
      "Train time for epoch #2609 (step 2609): 1.340216\n",
      "Batch #10\tAverage Generator Loss: 401.122043\tAverage Discriminator Loss: 0.000111\n",
      "\n",
      "Train time for epoch #2610 (step 2610): 1.460810\n",
      "Batch #10\tAverage Generator Loss: 430.193743\tAverage Discriminator Loss: 0.000474\n",
      "\n",
      "Train time for epoch #2611 (step 2611): 1.406432\n",
      "Batch #10\tAverage Generator Loss: 460.109250\tAverage Discriminator Loss: 0.000105\n",
      "\n",
      "Train time for epoch #2612 (step 2612): 1.414030\n",
      "Batch #10\tAverage Generator Loss: 443.826471\tAverage Discriminator Loss: 0.000099\n",
      "\n",
      "Train time for epoch #2613 (step 2613): 1.467251\n",
      "Batch #10\tAverage Generator Loss: 467.765579\tAverage Discriminator Loss: 0.000096\n",
      "\n",
      "Train time for epoch #2614 (step 2614): 1.423378\n",
      "Batch #10\tAverage Generator Loss: 436.973578\tAverage Discriminator Loss: 0.000099\n",
      "\n",
      "Train time for epoch #2615 (step 2615): 1.285317\n",
      "Batch #10\tAverage Generator Loss: 490.435623\tAverage Discriminator Loss: 0.000089\n",
      "\n",
      "Train time for epoch #2616 (step 2616): 1.405523\n",
      "Batch #10\tAverage Generator Loss: 458.630545\tAverage Discriminator Loss: 0.000086\n",
      "\n",
      "Train time for epoch #2617 (step 2617): 1.487980\n",
      "Batch #10\tAverage Generator Loss: 397.360010\tAverage Discriminator Loss: 0.000078\n",
      "\n",
      "Train time for epoch #2618 (step 2618): 1.448345\n",
      "Batch #10\tAverage Generator Loss: 439.911165\tAverage Discriminator Loss: 0.000077\n",
      "\n",
      "Train time for epoch #2619 (step 2619): 1.416991\n",
      "Batch #10\tAverage Generator Loss: 491.619461\tAverage Discriminator Loss: 0.000071\n",
      "\n",
      "Train time for epoch #2620 (step 2620): 1.423095\n",
      "Batch #10\tAverage Generator Loss: 466.264334\tAverage Discriminator Loss: 0.000070\n",
      "\n",
      "Train time for epoch #2621 (step 2621): 1.599712\n",
      "Batch #10\tAverage Generator Loss: 421.201973\tAverage Discriminator Loss: 0.009277\n",
      "\n",
      "Train time for epoch #2622 (step 2622): 1.464730\n",
      "Batch #10\tAverage Generator Loss: 481.870724\tAverage Discriminator Loss: 0.000208\n",
      "\n",
      "Train time for epoch #2623 (step 2623): 1.488505\n",
      "Batch #10\tAverage Generator Loss: 475.086740\tAverage Discriminator Loss: 0.000350\n",
      "\n",
      "Train time for epoch #2624 (step 2624): 1.274240\n",
      "Batch #10\tAverage Generator Loss: 436.147940\tAverage Discriminator Loss: 0.000223\n",
      "\n",
      "Train time for epoch #2625 (step 2625): 1.470770\n",
      "Batch #10\tAverage Generator Loss: 395.388637\tAverage Discriminator Loss: 0.000230\n",
      "\n",
      "Train time for epoch #2626 (step 2626): 1.471246\n",
      "Batch #10\tAverage Generator Loss: 490.317221\tAverage Discriminator Loss: 0.000136\n",
      "\n",
      "Train time for epoch #2627 (step 2627): 1.484571\n",
      "Batch #10\tAverage Generator Loss: 455.467091\tAverage Discriminator Loss: 0.000356\n",
      "\n",
      "Train time for epoch #2628 (step 2628): 1.660630\n",
      "Batch #10\tAverage Generator Loss: 487.454080\tAverage Discriminator Loss: 0.000532\n",
      "\n",
      "Train time for epoch #2629 (step 2629): 1.436090\n",
      "Batch #10\tAverage Generator Loss: 470.902957\tAverage Discriminator Loss: 0.000291\n",
      "\n",
      "Train time for epoch #2630 (step 2630): 1.575986\n",
      "Batch #10\tAverage Generator Loss: 404.205197\tAverage Discriminator Loss: 0.000194\n",
      "\n",
      "Train time for epoch #2631 (step 2631): 1.378183\n",
      "Batch #10\tAverage Generator Loss: 493.131592\tAverage Discriminator Loss: 0.000294\n",
      "\n",
      "Train time for epoch #2632 (step 2632): 1.408242\n",
      "Batch #10\tAverage Generator Loss: 363.202640\tAverage Discriminator Loss: 0.000331\n",
      "\n",
      "Train time for epoch #2633 (step 2633): 1.405649\n",
      "Batch #10\tAverage Generator Loss: 413.602615\tAverage Discriminator Loss: 0.000246\n",
      "\n",
      "Train time for epoch #2634 (step 2634): 1.590539\n",
      "Batch #10\tAverage Generator Loss: 395.521516\tAverage Discriminator Loss: 0.000162\n",
      "\n",
      "Train time for epoch #2635 (step 2635): 1.473125\n",
      "Batch #10\tAverage Generator Loss: 407.878299\tAverage Discriminator Loss: 0.000140\n",
      "\n",
      "Train time for epoch #2636 (step 2636): 1.510862\n",
      "Batch #10\tAverage Generator Loss: 434.467760\tAverage Discriminator Loss: 0.000133\n",
      "\n",
      "Train time for epoch #2637 (step 2637): 1.306195\n",
      "Batch #10\tAverage Generator Loss: 486.211575\tAverage Discriminator Loss: 0.000114\n",
      "\n",
      "Train time for epoch #2638 (step 2638): 1.372609\n",
      "Batch #10\tAverage Generator Loss: 401.979491\tAverage Discriminator Loss: 0.016712\n",
      "\n",
      "Train time for epoch #2639 (step 2639): 1.458272\n",
      "Batch #10\tAverage Generator Loss: 502.511975\tAverage Discriminator Loss: 0.000080\n",
      "\n",
      "Train time for epoch #2640 (step 2640): 1.515996\n",
      "Batch #10\tAverage Generator Loss: 439.795554\tAverage Discriminator Loss: 0.000072\n",
      "\n",
      "Train time for epoch #2641 (step 2641): 1.471601\n",
      "Batch #10\tAverage Generator Loss: 409.197989\tAverage Discriminator Loss: 0.000074\n",
      "\n",
      "Train time for epoch #2642 (step 2642): 1.498623\n",
      "Batch #10\tAverage Generator Loss: 384.868718\tAverage Discriminator Loss: 0.000070\n",
      "\n",
      "Train time for epoch #2643 (step 2643): 1.354735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 404.257553\tAverage Discriminator Loss: 0.000059\n",
      "\n",
      "Train time for epoch #2644 (step 2644): 1.453400\n",
      "Batch #10\tAverage Generator Loss: 446.694147\tAverage Discriminator Loss: 0.003765\n",
      "\n",
      "Train time for epoch #2645 (step 2645): 1.424541\n",
      "Batch #10\tAverage Generator Loss: 451.756183\tAverage Discriminator Loss: 0.000735\n",
      "\n",
      "Train time for epoch #2646 (step 2646): 1.471060\n",
      "Batch #10\tAverage Generator Loss: 447.652371\tAverage Discriminator Loss: 0.000317\n",
      "\n",
      "Train time for epoch #2647 (step 2647): 1.606603\n",
      "Batch #10\tAverage Generator Loss: 468.583192\tAverage Discriminator Loss: 0.020072\n",
      "\n",
      "Train time for epoch #2648 (step 2648): 1.465765\n",
      "Batch #10\tAverage Generator Loss: 420.543237\tAverage Discriminator Loss: 0.002554\n",
      "\n",
      "Train time for epoch #2649 (step 2649): 1.464302\n",
      "Batch #10\tAverage Generator Loss: 467.499915\tAverage Discriminator Loss: 0.000072\n",
      "\n",
      "Train time for epoch #2650 (step 2650): 1.330909\n",
      "Batch #10\tAverage Generator Loss: 445.582077\tAverage Discriminator Loss: 0.000182\n",
      "\n",
      "Train time for epoch #2651 (step 2651): 1.498937\n",
      "Batch #10\tAverage Generator Loss: 457.664136\tAverage Discriminator Loss: 0.000056\n",
      "\n",
      "Train time for epoch #2652 (step 2652): 1.371461\n",
      "Batch #10\tAverage Generator Loss: 410.674104\tAverage Discriminator Loss: 0.000060\n",
      "\n",
      "Train time for epoch #2653 (step 2653): 1.410026\n",
      "Batch #10\tAverage Generator Loss: 451.154620\tAverage Discriminator Loss: 0.000062\n",
      "\n",
      "Train time for epoch #2654 (step 2654): 1.426480\n",
      "Batch #10\tAverage Generator Loss: 457.505313\tAverage Discriminator Loss: 0.000057\n",
      "\n",
      "Train time for epoch #2655 (step 2655): 1.553931\n",
      "Batch #10\tAverage Generator Loss: 439.340994\tAverage Discriminator Loss: 0.000055\n",
      "\n",
      "Train time for epoch #2656 (step 2656): 1.372055\n",
      "Batch #10\tAverage Generator Loss: 453.067331\tAverage Discriminator Loss: 0.000050\n",
      "\n",
      "Train time for epoch #2657 (step 2657): 1.462717\n",
      "Batch #10\tAverage Generator Loss: 424.768433\tAverage Discriminator Loss: 0.000063\n",
      "\n",
      "Train time for epoch #2658 (step 2658): 1.457281\n",
      "Batch #10\tAverage Generator Loss: 442.971126\tAverage Discriminator Loss: 0.000062\n",
      "\n",
      "Train time for epoch #2659 (step 2659): 1.418074\n",
      "Batch #10\tAverage Generator Loss: 408.280580\tAverage Discriminator Loss: 0.000051\n",
      "\n",
      "Train time for epoch #2660 (step 2660): 1.370165\n",
      "Batch #10\tAverage Generator Loss: 430.470450\tAverage Discriminator Loss: 0.000052\n",
      "\n",
      "Train time for epoch #2661 (step 2661): 1.595998\n",
      "Batch #10\tAverage Generator Loss: 398.624821\tAverage Discriminator Loss: 0.000041\n",
      "\n",
      "Train time for epoch #2662 (step 2662): 1.411033\n",
      "Batch #10\tAverage Generator Loss: 416.015083\tAverage Discriminator Loss: 0.000054\n",
      "\n",
      "Train time for epoch #2663 (step 2663): 1.242445\n",
      "Batch #10\tAverage Generator Loss: 486.003513\tAverage Discriminator Loss: 0.000047\n",
      "\n",
      "Train time for epoch #2664 (step 2664): 1.433196\n",
      "Batch #10\tAverage Generator Loss: 414.972739\tAverage Discriminator Loss: 0.000692\n",
      "\n",
      "Train time for epoch #2665 (step 2665): 1.359590\n",
      "Batch #10\tAverage Generator Loss: 470.602472\tAverage Discriminator Loss: 0.000064\n",
      "\n",
      "Train time for epoch #2666 (step 2666): 1.449541\n",
      "Batch #10\tAverage Generator Loss: 421.681390\tAverage Discriminator Loss: 0.000063\n",
      "\n",
      "Train time for epoch #2667 (step 2667): 1.620617\n",
      "Batch #10\tAverage Generator Loss: 454.473021\tAverage Discriminator Loss: 0.000058\n",
      "\n",
      "Train time for epoch #2668 (step 2668): 1.292075\n",
      "Batch #10\tAverage Generator Loss: 364.949274\tAverage Discriminator Loss: 0.000069\n",
      "\n",
      "Train time for epoch #2669 (step 2669): 1.418604\n",
      "Batch #10\tAverage Generator Loss: 506.543396\tAverage Discriminator Loss: 0.000070\n",
      "\n",
      "Train time for epoch #2670 (step 2670): 1.405347\n",
      "Batch #10\tAverage Generator Loss: 413.609720\tAverage Discriminator Loss: 0.039326\n",
      "\n",
      "Train time for epoch #2671 (step 2671): 1.411875\n",
      "Batch #10\tAverage Generator Loss: 454.152365\tAverage Discriminator Loss: 0.000075\n",
      "\n",
      "Train time for epoch #2672 (step 2672): 2.015256\n",
      "Batch #10\tAverage Generator Loss: 481.342273\tAverage Discriminator Loss: 0.000086\n",
      "\n",
      "Train time for epoch #2673 (step 2673): 1.659391\n",
      "Batch #10\tAverage Generator Loss: 437.111238\tAverage Discriminator Loss: 0.001269\n",
      "\n",
      "Train time for epoch #2674 (step 2674): 1.517727\n",
      "Batch #10\tAverage Generator Loss: 508.202948\tAverage Discriminator Loss: 0.000121\n",
      "\n",
      "Train time for epoch #2675 (step 2675): 1.431375\n",
      "Batch #10\tAverage Generator Loss: 463.184494\tAverage Discriminator Loss: 0.000490\n",
      "\n",
      "Train time for epoch #2676 (step 2676): 1.747062\n",
      "Batch #10\tAverage Generator Loss: 476.496365\tAverage Discriminator Loss: 0.000141\n",
      "\n",
      "Train time for epoch #2677 (step 2677): 1.467825\n",
      "Batch #10\tAverage Generator Loss: 428.387379\tAverage Discriminator Loss: 0.001382\n",
      "\n",
      "Train time for epoch #2678 (step 2678): 5.152744\n",
      "Batch #10\tAverage Generator Loss: 429.367497\tAverage Discriminator Loss: 0.000522\n",
      "\n",
      "Train time for epoch #2679 (step 2679): 1.753775\n",
      "Batch #10\tAverage Generator Loss: 484.990381\tAverage Discriminator Loss: 0.000180\n",
      "\n",
      "Train time for epoch #2680 (step 2680): 1.478722\n",
      "Batch #10\tAverage Generator Loss: 553.088910\tAverage Discriminator Loss: 0.003299\n",
      "\n",
      "Train time for epoch #2681 (step 2681): 1.419163\n",
      "Batch #10\tAverage Generator Loss: 424.223933\tAverage Discriminator Loss: 0.002966\n",
      "\n",
      "Train time for epoch #2682 (step 2682): 1.447102\n",
      "Batch #10\tAverage Generator Loss: 428.400461\tAverage Discriminator Loss: 0.000264\n",
      "\n",
      "Train time for epoch #2683 (step 2683): 1.420528\n",
      "Batch #10\tAverage Generator Loss: 565.243604\tAverage Discriminator Loss: 0.000187\n",
      "\n",
      "Train time for epoch #2684 (step 2684): 1.344431\n",
      "Batch #10\tAverage Generator Loss: 527.384537\tAverage Discriminator Loss: 0.000129\n",
      "\n",
      "Train time for epoch #2685 (step 2685): 1.473647\n",
      "Batch #10\tAverage Generator Loss: 522.574130\tAverage Discriminator Loss: 0.000086\n",
      "\n",
      "Train time for epoch #2686 (step 2686): 1.544750\n",
      "Batch #10\tAverage Generator Loss: 515.777127\tAverage Discriminator Loss: 0.000080\n",
      "\n",
      "Train time for epoch #2687 (step 2687): 1.442401\n",
      "Batch #10\tAverage Generator Loss: 563.687778\tAverage Discriminator Loss: 0.000074\n",
      "\n",
      "Train time for epoch #2688 (step 2688): 1.415082\n",
      "Batch #10\tAverage Generator Loss: 544.011734\tAverage Discriminator Loss: 0.000101\n",
      "\n",
      "Train time for epoch #2689 (step 2689): 1.455582\n",
      "Batch #10\tAverage Generator Loss: 494.790021\tAverage Discriminator Loss: 0.000090\n",
      "\n",
      "Train time for epoch #2690 (step 2690): 1.402755\n",
      "Batch #10\tAverage Generator Loss: 551.778186\tAverage Discriminator Loss: 0.000094\n",
      "\n",
      "Train time for epoch #2691 (step 2691): 1.371760\n",
      "Batch #10\tAverage Generator Loss: 522.298538\tAverage Discriminator Loss: 0.000069\n",
      "\n",
      "Train time for epoch #2692 (step 2692): 1.599140\n",
      "Batch #10\tAverage Generator Loss: 479.675251\tAverage Discriminator Loss: 0.000056\n",
      "\n",
      "Train time for epoch #2693 (step 2693): 1.401335\n",
      "Batch #10\tAverage Generator Loss: 518.521445\tAverage Discriminator Loss: 0.000054\n",
      "\n",
      "Train time for epoch #2694 (step 2694): 1.431797\n",
      "Batch #10\tAverage Generator Loss: 455.059523\tAverage Discriminator Loss: 0.000297\n",
      "\n",
      "Train time for epoch #2695 (step 2695): 1.457803\n",
      "Batch #10\tAverage Generator Loss: 541.827628\tAverage Discriminator Loss: 0.000075\n",
      "\n",
      "Train time for epoch #2696 (step 2696): 1.280071\n",
      "Batch #10\tAverage Generator Loss: 545.675339\tAverage Discriminator Loss: 0.000075\n",
      "\n",
      "Train time for epoch #2697 (step 2697): 1.547179\n",
      "Batch #10\tAverage Generator Loss: 537.508914\tAverage Discriminator Loss: 0.000058\n",
      "\n",
      "Train time for epoch #2698 (step 2698): 1.518272\n",
      "Batch #10\tAverage Generator Loss: 467.506577\tAverage Discriminator Loss: 0.000050\n",
      "\n",
      "Train time for epoch #2699 (step 2699): 1.538618\n",
      "Batch #10\tAverage Generator Loss: 587.611349\tAverage Discriminator Loss: 0.000048\n",
      "\n",
      "Train time for epoch #2700 (step 2700): 1.551458\n",
      "Batch #10\tAverage Generator Loss: 487.340798\tAverage Discriminator Loss: 0.000058\n",
      "\n",
      "Train time for epoch #2701 (step 2701): 1.474341\n",
      "Batch #10\tAverage Generator Loss: 540.438129\tAverage Discriminator Loss: 0.000040\n",
      "\n",
      "Train time for epoch #2702 (step 2702): 1.455389\n",
      "Batch #10\tAverage Generator Loss: 532.263937\tAverage Discriminator Loss: 0.000037\n",
      "\n",
      "Train time for epoch #2703 (step 2703): 1.429736\n",
      "Batch #10\tAverage Generator Loss: 593.954446\tAverage Discriminator Loss: 0.000034\n",
      "\n",
      "Train time for epoch #2704 (step 2704): 1.464886\n",
      "Batch #10\tAverage Generator Loss: 542.273257\tAverage Discriminator Loss: 0.000030\n",
      "\n",
      "Train time for epoch #2705 (step 2705): 1.382205\n",
      "Batch #10\tAverage Generator Loss: 521.276917\tAverage Discriminator Loss: 0.000028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #2706 (step 2706): 1.471361\n",
      "Batch #10\tAverage Generator Loss: 489.082521\tAverage Discriminator Loss: 0.000028\n",
      "\n",
      "Train time for epoch #2707 (step 2707): 1.393996\n",
      "Batch #10\tAverage Generator Loss: 540.803278\tAverage Discriminator Loss: 0.000025\n",
      "\n",
      "Train time for epoch #2708 (step 2708): 1.354699\n",
      "Batch #10\tAverage Generator Loss: 556.576013\tAverage Discriminator Loss: 0.000025\n",
      "\n",
      "Train time for epoch #2709 (step 2709): 1.475957\n",
      "Batch #10\tAverage Generator Loss: 540.305106\tAverage Discriminator Loss: 0.001054\n",
      "\n",
      "Train time for epoch #2710 (step 2710): 1.412783\n",
      "Batch #10\tAverage Generator Loss: 561.200275\tAverage Discriminator Loss: 0.000022\n",
      "\n",
      "Train time for epoch #2711 (step 2711): 1.335777\n",
      "Batch #10\tAverage Generator Loss: 457.521098\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #2712 (step 2712): 1.475954\n",
      "Batch #10\tAverage Generator Loss: 516.802261\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #2713 (step 2713): 1.417882\n",
      "Batch #10\tAverage Generator Loss: 481.701614\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #2714 (step 2714): 1.473676\n",
      "Batch #10\tAverage Generator Loss: 493.609743\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #2715 (step 2715): 1.471865\n",
      "Batch #10\tAverage Generator Loss: 509.557227\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #2716 (step 2716): 1.278439\n",
      "Batch #10\tAverage Generator Loss: 509.925830\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #2717 (step 2717): 1.540334\n",
      "Batch #10\tAverage Generator Loss: 632.228716\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #2718 (step 2718): 1.408797\n",
      "Batch #10\tAverage Generator Loss: 600.856024\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #2719 (step 2719): 1.503115\n",
      "Batch #10\tAverage Generator Loss: 552.454810\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #2720 (step 2720): 1.378698\n",
      "Batch #10\tAverage Generator Loss: 577.653052\tAverage Discriminator Loss: 0.000319\n",
      "\n",
      "Train time for epoch #2721 (step 2721): 1.468171\n",
      "Batch #10\tAverage Generator Loss: 520.311670\tAverage Discriminator Loss: 0.000203\n",
      "\n",
      "Train time for epoch #2722 (step 2722): 1.508553\n",
      "Batch #10\tAverage Generator Loss: 515.762787\tAverage Discriminator Loss: 0.000019\n",
      "\n",
      "Train time for epoch #2723 (step 2723): 1.514010\n",
      "Batch #10\tAverage Generator Loss: 528.603543\tAverage Discriminator Loss: 0.000047\n",
      "\n",
      "Train time for epoch #2724 (step 2724): 1.290364\n",
      "Batch #10\tAverage Generator Loss: 568.917978\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #2725 (step 2725): 1.490732\n",
      "Batch #10\tAverage Generator Loss: 508.257776\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #2726 (step 2726): 1.517653\n",
      "Batch #10\tAverage Generator Loss: 474.393263\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #2727 (step 2727): 1.540146\n",
      "Batch #10\tAverage Generator Loss: 518.124576\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #2728 (step 2728): 1.462882\n",
      "Batch #10\tAverage Generator Loss: 509.089398\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #2729 (step 2729): 1.464064\n",
      "Batch #10\tAverage Generator Loss: 524.177852\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #2730 (step 2730): 1.340555\n",
      "Batch #10\tAverage Generator Loss: 479.725079\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #2731 (step 2731): 1.466765\n",
      "Batch #10\tAverage Generator Loss: 518.608777\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #2732 (step 2732): 1.421379\n",
      "Batch #10\tAverage Generator Loss: 486.334442\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #2733 (step 2733): 1.455497\n",
      "Batch #10\tAverage Generator Loss: 454.406921\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #2734 (step 2734): 1.413115\n",
      "Batch #10\tAverage Generator Loss: 492.401920\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #2735 (step 2735): 1.425397\n",
      "Batch #10\tAverage Generator Loss: 523.258566\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #2736 (step 2736): 1.418649\n",
      "Batch #10\tAverage Generator Loss: 464.787569\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #2737 (step 2737): 1.365014\n",
      "Batch #10\tAverage Generator Loss: 514.113568\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #2738 (step 2738): 1.555961\n",
      "Batch #10\tAverage Generator Loss: 516.071487\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #2739 (step 2739): 1.489292\n",
      "Batch #10\tAverage Generator Loss: 499.612595\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #2740 (step 2740): 1.417937\n",
      "Batch #10\tAverage Generator Loss: 523.511987\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #2741 (step 2741): 1.416324\n",
      "Batch #10\tAverage Generator Loss: 508.157132\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #2742 (step 2742): 1.436235\n",
      "Batch #10\tAverage Generator Loss: 551.567053\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #2743 (step 2743): 1.485118\n",
      "Batch #10\tAverage Generator Loss: 535.343758\tAverage Discriminator Loss: 0.015672\n",
      "\n",
      "Train time for epoch #2744 (step 2744): 1.520902\n",
      "Batch #10\tAverage Generator Loss: 521.311600\tAverage Discriminator Loss: 0.001198\n",
      "\n",
      "Train time for epoch #2745 (step 2745): 1.426033\n",
      "Batch #10\tAverage Generator Loss: 422.904210\tAverage Discriminator Loss: 0.000028\n",
      "\n",
      "Train time for epoch #2746 (step 2746): 1.463411\n",
      "Batch #10\tAverage Generator Loss: 482.268170\tAverage Discriminator Loss: 0.000050\n",
      "\n",
      "Train time for epoch #2747 (step 2747): 1.511131\n",
      "Batch #10\tAverage Generator Loss: 516.672440\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #2748 (step 2748): 1.416381\n",
      "Batch #10\tAverage Generator Loss: 492.417850\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #2749 (step 2749): 1.544611\n",
      "Batch #10\tAverage Generator Loss: 529.069980\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #2750 (step 2750): 1.447648\n",
      "Batch #10\tAverage Generator Loss: 565.945718\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #2751 (step 2751): 1.569553\n",
      "Batch #10\tAverage Generator Loss: 528.657431\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #2752 (step 2752): 1.489856\n",
      "Batch #10\tAverage Generator Loss: 497.069604\tAverage Discriminator Loss: 0.001631\n",
      "\n",
      "Train time for epoch #2753 (step 2753): 1.466563\n",
      "Batch #10\tAverage Generator Loss: 519.897220\tAverage Discriminator Loss: 0.000403\n",
      "\n",
      "Train time for epoch #2754 (step 2754): 1.443125\n",
      "Batch #10\tAverage Generator Loss: 521.328836\tAverage Discriminator Loss: 0.000089\n",
      "\n",
      "Train time for epoch #2755 (step 2755): 1.460918\n",
      "Batch #10\tAverage Generator Loss: 495.684450\tAverage Discriminator Loss: 0.000050\n",
      "\n",
      "Train time for epoch #2756 (step 2756): 1.423078\n",
      "Batch #10\tAverage Generator Loss: 517.383662\tAverage Discriminator Loss: 0.000042\n",
      "\n",
      "Train time for epoch #2757 (step 2757): 1.435952\n",
      "Batch #10\tAverage Generator Loss: 480.690701\tAverage Discriminator Loss: 0.000034\n",
      "\n",
      "Train time for epoch #2758 (step 2758): 1.516834\n",
      "Batch #10\tAverage Generator Loss: 518.452225\tAverage Discriminator Loss: 0.000034\n",
      "\n",
      "Train time for epoch #2759 (step 2759): 1.464940\n",
      "Batch #10\tAverage Generator Loss: 518.335773\tAverage Discriminator Loss: 0.000028\n",
      "\n",
      "Train time for epoch #2760 (step 2760): 1.694478\n",
      "Batch #10\tAverage Generator Loss: 461.018439\tAverage Discriminator Loss: 0.033211\n",
      "\n",
      "Train time for epoch #2761 (step 2761): 1.303187\n",
      "Batch #10\tAverage Generator Loss: 496.286922\tAverage Discriminator Loss: 0.000107\n",
      "\n",
      "Train time for epoch #2762 (step 2762): 1.482638\n",
      "Batch #10\tAverage Generator Loss: 491.916045\tAverage Discriminator Loss: 0.014115\n",
      "\n",
      "Train time for epoch #2763 (step 2763): 1.472769\n",
      "Batch #10\tAverage Generator Loss: 512.665027\tAverage Discriminator Loss: 0.000173\n",
      "\n",
      "Train time for epoch #2764 (step 2764): 1.466849\n",
      "Batch #10\tAverage Generator Loss: 507.075714\tAverage Discriminator Loss: 0.000101\n",
      "\n",
      "Train time for epoch #2765 (step 2765): 1.570451\n",
      "Batch #10\tAverage Generator Loss: 495.341855\tAverage Discriminator Loss: 0.000727\n",
      "\n",
      "Train time for epoch #2766 (step 2766): 1.380558\n",
      "Batch #10\tAverage Generator Loss: 512.754803\tAverage Discriminator Loss: 0.000300\n",
      "\n",
      "Train time for epoch #2767 (step 2767): 1.356233\n",
      "Batch #10\tAverage Generator Loss: 558.511432\tAverage Discriminator Loss: 0.000047\n",
      "\n",
      "Train time for epoch #2768 (step 2768): 1.515985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 455.117114\tAverage Discriminator Loss: 0.000029\n",
      "\n",
      "Train time for epoch #2769 (step 2769): 1.417834\n",
      "Batch #10\tAverage Generator Loss: 560.117047\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #2770 (step 2770): 1.468522\n",
      "Batch #10\tAverage Generator Loss: 553.864786\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #2771 (step 2771): 1.407375\n",
      "Batch #10\tAverage Generator Loss: 542.525272\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #2772 (step 2772): 1.399239\n",
      "Batch #10\tAverage Generator Loss: 416.948869\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #2773 (step 2773): 1.490272\n",
      "Batch #10\tAverage Generator Loss: 496.808020\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #2774 (step 2774): 1.403141\n",
      "Batch #10\tAverage Generator Loss: 554.915378\tAverage Discriminator Loss: 0.000071\n",
      "\n",
      "Train time for epoch #2775 (step 2775): 1.575680\n",
      "Batch #10\tAverage Generator Loss: 564.984827\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #2776 (step 2776): 1.511343\n",
      "Batch #10\tAverage Generator Loss: 508.110106\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #2777 (step 2777): 1.528643\n",
      "Batch #10\tAverage Generator Loss: 516.157109\tAverage Discriminator Loss: 0.004391\n",
      "\n",
      "Train time for epoch #2778 (step 2778): 1.273426\n",
      "Batch #10\tAverage Generator Loss: 514.038422\tAverage Discriminator Loss: 0.000792\n",
      "\n",
      "Train time for epoch #2779 (step 2779): 1.410780\n",
      "Batch #10\tAverage Generator Loss: 547.055688\tAverage Discriminator Loss: 0.000046\n",
      "\n",
      "Train time for epoch #2780 (step 2780): 1.571071\n",
      "Batch #10\tAverage Generator Loss: 488.957474\tAverage Discriminator Loss: 0.000022\n",
      "\n",
      "Train time for epoch #2781 (step 2781): 1.405340\n",
      "Batch #10\tAverage Generator Loss: 475.905008\tAverage Discriminator Loss: 0.000019\n",
      "\n",
      "Train time for epoch #2782 (step 2782): 1.383568\n",
      "Batch #10\tAverage Generator Loss: 504.941066\tAverage Discriminator Loss: 0.002395\n",
      "\n",
      "Train time for epoch #2783 (step 2783): 1.521695\n",
      "Batch #10\tAverage Generator Loss: 421.437796\tAverage Discriminator Loss: 0.006222\n",
      "\n",
      "Train time for epoch #2784 (step 2784): 1.348068\n",
      "Batch #10\tAverage Generator Loss: 408.850320\tAverage Discriminator Loss: 0.005984\n",
      "\n",
      "Train time for epoch #2785 (step 2785): 1.473087\n",
      "Batch #10\tAverage Generator Loss: 399.066809\tAverage Discriminator Loss: 0.000043\n",
      "\n",
      "Train time for epoch #2786 (step 2786): 1.409663\n",
      "Batch #10\tAverage Generator Loss: 393.687897\tAverage Discriminator Loss: 0.000358\n",
      "\n",
      "Train time for epoch #2787 (step 2787): 1.526313\n",
      "Batch #10\tAverage Generator Loss: 402.061932\tAverage Discriminator Loss: 0.000072\n",
      "\n",
      "Train time for epoch #2788 (step 2788): 1.357700\n",
      "Batch #10\tAverage Generator Loss: 514.602823\tAverage Discriminator Loss: 0.000082\n",
      "\n",
      "Train time for epoch #2789 (step 2789): 1.469391\n",
      "Batch #10\tAverage Generator Loss: 429.889539\tAverage Discriminator Loss: 0.000192\n",
      "\n",
      "Train time for epoch #2790 (step 2790): 1.342478\n",
      "Batch #10\tAverage Generator Loss: 435.304657\tAverage Discriminator Loss: 0.000145\n",
      "\n",
      "Train time for epoch #2791 (step 2791): 1.419185\n",
      "Batch #10\tAverage Generator Loss: 417.141684\tAverage Discriminator Loss: 0.000081\n",
      "\n",
      "Train time for epoch #2792 (step 2792): 1.480121\n",
      "Batch #10\tAverage Generator Loss: 424.834433\tAverage Discriminator Loss: 0.000074\n",
      "\n",
      "Train time for epoch #2793 (step 2793): 1.429202\n",
      "Batch #10\tAverage Generator Loss: 462.726407\tAverage Discriminator Loss: 0.000061\n",
      "\n",
      "Train time for epoch #2794 (step 2794): 1.460274\n",
      "Batch #10\tAverage Generator Loss: 505.271704\tAverage Discriminator Loss: 0.000054\n",
      "\n",
      "Train time for epoch #2795 (step 2795): 1.284981\n",
      "Batch #10\tAverage Generator Loss: 471.096841\tAverage Discriminator Loss: 0.000044\n",
      "\n",
      "Train time for epoch #2796 (step 2796): 1.505028\n",
      "Batch #10\tAverage Generator Loss: 453.783279\tAverage Discriminator Loss: 0.000045\n",
      "\n",
      "Train time for epoch #2797 (step 2797): 1.407780\n",
      "Batch #10\tAverage Generator Loss: 461.471317\tAverage Discriminator Loss: 0.000036\n",
      "\n",
      "Train time for epoch #2798 (step 2798): 1.422093\n",
      "Batch #10\tAverage Generator Loss: 471.193802\tAverage Discriminator Loss: 0.000036\n",
      "\n",
      "Train time for epoch #2799 (step 2799): 1.640398\n",
      "Batch #10\tAverage Generator Loss: 431.247134\tAverage Discriminator Loss: 0.000029\n",
      "\n",
      "Train time for epoch #2800 (step 2800): 1.451432\n",
      "Batch #10\tAverage Generator Loss: 499.644775\tAverage Discriminator Loss: 0.000026\n",
      "\n",
      "Train time for epoch #2801 (step 2801): 1.328973\n",
      "Batch #10\tAverage Generator Loss: 453.948817\tAverage Discriminator Loss: 0.000025\n",
      "\n",
      "Train time for epoch #2802 (step 2802): 1.429479\n",
      "Batch #10\tAverage Generator Loss: 402.544040\tAverage Discriminator Loss: 0.000023\n",
      "\n",
      "Train time for epoch #2803 (step 2803): 1.419100\n",
      "Batch #10\tAverage Generator Loss: 495.469025\tAverage Discriminator Loss: 0.000024\n",
      "\n",
      "Train time for epoch #2804 (step 2804): 1.420078\n",
      "Batch #10\tAverage Generator Loss: 451.277109\tAverage Discriminator Loss: 0.000037\n",
      "\n",
      "Train time for epoch #2805 (step 2805): 1.477613\n",
      "Batch #10\tAverage Generator Loss: 449.379138\tAverage Discriminator Loss: 0.000026\n",
      "\n",
      "Train time for epoch #2806 (step 2806): 1.415777\n",
      "Batch #10\tAverage Generator Loss: 409.849011\tAverage Discriminator Loss: 0.000023\n",
      "\n",
      "Train time for epoch #2807 (step 2807): 1.291371\n",
      "Batch #10\tAverage Generator Loss: 417.732605\tAverage Discriminator Loss: 0.005690\n",
      "\n",
      "Train time for epoch #2808 (step 2808): 1.536786\n",
      "Batch #10\tAverage Generator Loss: 426.954065\tAverage Discriminator Loss: 0.000022\n",
      "\n",
      "Train time for epoch #2809 (step 2809): 1.282718\n",
      "Batch #10\tAverage Generator Loss: 407.228798\tAverage Discriminator Loss: 0.033913\n",
      "\n",
      "Train time for epoch #2810 (step 2810): 1.411883\n",
      "Batch #10\tAverage Generator Loss: 499.203931\tAverage Discriminator Loss: 0.000046\n",
      "\n",
      "Train time for epoch #2811 (step 2811): 1.457914\n",
      "Batch #10\tAverage Generator Loss: 465.281215\tAverage Discriminator Loss: 0.000021\n",
      "\n",
      "Train time for epoch #2812 (step 2812): 1.455609\n",
      "Batch #10\tAverage Generator Loss: 392.181917\tAverage Discriminator Loss: 0.567419\n",
      "\n",
      "Train time for epoch #2813 (step 2813): 1.526837\n",
      "Batch #10\tAverage Generator Loss: 450.418988\tAverage Discriminator Loss: 0.005742\n",
      "\n",
      "Train time for epoch #2814 (step 2814): 1.327863\n",
      "Batch #10\tAverage Generator Loss: 362.596996\tAverage Discriminator Loss: 0.036117\n",
      "\n",
      "Train time for epoch #2815 (step 2815): 1.426479\n",
      "Batch #10\tAverage Generator Loss: 401.898785\tAverage Discriminator Loss: 0.013411\n",
      "\n",
      "Train time for epoch #2816 (step 2816): 1.512106\n",
      "Batch #10\tAverage Generator Loss: 350.702579\tAverage Discriminator Loss: 0.000816\n",
      "\n",
      "Train time for epoch #2817 (step 2817): 1.634330\n",
      "Batch #10\tAverage Generator Loss: 521.432018\tAverage Discriminator Loss: 0.309597\n",
      "\n",
      "Train time for epoch #2818 (step 2818): 1.495575\n",
      "Batch #10\tAverage Generator Loss: 830.186328\tAverage Discriminator Loss: 0.015299\n",
      "\n",
      "Train time for epoch #2819 (step 2819): 1.553969\n",
      "Batch #10\tAverage Generator Loss: 699.172942\tAverage Discriminator Loss: 0.144948\n",
      "\n",
      "Train time for epoch #2820 (step 2820): 1.584172\n",
      "Batch #10\tAverage Generator Loss: 924.172049\tAverage Discriminator Loss: 0.446018\n",
      "\n",
      "Train time for epoch #2821 (step 2821): 1.393291\n",
      "Batch #10\tAverage Generator Loss: 898.198303\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #2822 (step 2822): 1.470547\n",
      "Batch #10\tAverage Generator Loss: 766.443706\tAverage Discriminator Loss: 0.535517\n",
      "\n",
      "Train time for epoch #2823 (step 2823): 1.549404\n",
      "Batch #10\tAverage Generator Loss: 783.671341\tAverage Discriminator Loss: 0.048343\n",
      "\n",
      "Train time for epoch #2824 (step 2824): 1.447037\n",
      "Batch #10\tAverage Generator Loss: 672.703122\tAverage Discriminator Loss: 0.000098\n",
      "\n",
      "Train time for epoch #2825 (step 2825): 1.429796\n",
      "Batch #10\tAverage Generator Loss: 873.439194\tAverage Discriminator Loss: 0.072788\n",
      "\n",
      "Train time for epoch #2826 (step 2826): 1.281508\n",
      "Batch #10\tAverage Generator Loss: 846.870175\tAverage Discriminator Loss: 0.028691\n",
      "\n",
      "Train time for epoch #2827 (step 2827): 1.583536\n",
      "Batch #10\tAverage Generator Loss: 782.553244\tAverage Discriminator Loss: 0.000067\n",
      "\n",
      "Train time for epoch #2828 (step 2828): 1.430931\n",
      "Batch #10\tAverage Generator Loss: 807.043628\tAverage Discriminator Loss: 0.000029\n",
      "\n",
      "Train time for epoch #2829 (step 2829): 1.468052\n",
      "Batch #10\tAverage Generator Loss: 768.265832\tAverage Discriminator Loss: 0.000027\n",
      "\n",
      "Train time for epoch #2830 (step 2830): 1.591851\n",
      "Batch #10\tAverage Generator Loss: 648.542181\tAverage Discriminator Loss: 0.003170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #2831 (step 2831): 1.680952\n",
      "Batch #10\tAverage Generator Loss: 717.564600\tAverage Discriminator Loss: 0.000113\n",
      "\n",
      "Train time for epoch #2832 (step 2832): 1.340626\n",
      "Batch #10\tAverage Generator Loss: 743.335941\tAverage Discriminator Loss: 0.000243\n",
      "\n",
      "Train time for epoch #2833 (step 2833): 1.416918\n",
      "Batch #10\tAverage Generator Loss: 792.457645\tAverage Discriminator Loss: 0.000257\n",
      "\n",
      "Train time for epoch #2834 (step 2834): 1.558048\n",
      "Batch #10\tAverage Generator Loss: 775.860461\tAverage Discriminator Loss: 0.000146\n",
      "\n",
      "Train time for epoch #2835 (step 2835): 1.421277\n",
      "Batch #10\tAverage Generator Loss: 750.905182\tAverage Discriminator Loss: 0.000140\n",
      "\n",
      "Train time for epoch #2836 (step 2836): 1.506665\n",
      "Batch #10\tAverage Generator Loss: 686.256207\tAverage Discriminator Loss: 0.000099\n",
      "\n",
      "Train time for epoch #2837 (step 2837): 1.511920\n",
      "Batch #10\tAverage Generator Loss: 701.404944\tAverage Discriminator Loss: 0.000109\n",
      "\n",
      "Train time for epoch #2838 (step 2838): 1.345039\n",
      "Batch #10\tAverage Generator Loss: 756.089929\tAverage Discriminator Loss: 0.000087\n",
      "\n",
      "Train time for epoch #2839 (step 2839): 1.452830\n",
      "Batch #10\tAverage Generator Loss: 824.424083\tAverage Discriminator Loss: 0.000087\n",
      "\n",
      "Train time for epoch #2840 (step 2840): 1.360333\n",
      "Batch #10\tAverage Generator Loss: 817.371564\tAverage Discriminator Loss: 0.000074\n",
      "\n",
      "Train time for epoch #2841 (step 2841): 1.624272\n",
      "Batch #10\tAverage Generator Loss: 733.749908\tAverage Discriminator Loss: 0.000074\n",
      "\n",
      "Train time for epoch #2842 (step 2842): 1.410586\n",
      "Batch #10\tAverage Generator Loss: 713.591464\tAverage Discriminator Loss: 0.000058\n",
      "\n",
      "Train time for epoch #2843 (step 2843): 1.473184\n",
      "Batch #10\tAverage Generator Loss: 717.197940\tAverage Discriminator Loss: 0.000063\n",
      "\n",
      "Train time for epoch #2844 (step 2844): 1.506598\n",
      "Batch #10\tAverage Generator Loss: 746.236311\tAverage Discriminator Loss: 0.055574\n",
      "\n",
      "Train time for epoch #2845 (step 2845): 1.284899\n",
      "Batch #10\tAverage Generator Loss: 776.689667\tAverage Discriminator Loss: 0.000357\n",
      "\n",
      "Train time for epoch #2846 (step 2846): 1.496056\n",
      "Batch #10\tAverage Generator Loss: 692.725220\tAverage Discriminator Loss: 0.000073\n",
      "\n",
      "Train time for epoch #2847 (step 2847): 1.506708\n",
      "Batch #10\tAverage Generator Loss: 880.965125\tAverage Discriminator Loss: 0.000052\n",
      "\n",
      "Train time for epoch #2848 (step 2848): 1.423141\n",
      "Batch #10\tAverage Generator Loss: 856.549709\tAverage Discriminator Loss: 0.000041\n",
      "\n",
      "Train time for epoch #2849 (step 2849): 1.412752\n",
      "Batch #10\tAverage Generator Loss: 807.970749\tAverage Discriminator Loss: 0.000045\n",
      "\n",
      "Train time for epoch #2850 (step 2850): 1.467322\n",
      "Batch #10\tAverage Generator Loss: 839.222662\tAverage Discriminator Loss: 0.000042\n",
      "\n",
      "Train time for epoch #2851 (step 2851): 1.409419\n",
      "Batch #10\tAverage Generator Loss: 818.934360\tAverage Discriminator Loss: 0.000039\n",
      "\n",
      "Train time for epoch #2852 (step 2852): 1.332102\n",
      "Batch #10\tAverage Generator Loss: 916.155408\tAverage Discriminator Loss: 0.000038\n",
      "\n",
      "Train time for epoch #2853 (step 2853): 1.518872\n",
      "Batch #10\tAverage Generator Loss: 760.321011\tAverage Discriminator Loss: 0.000028\n",
      "\n",
      "Train time for epoch #2854 (step 2854): 1.504928\n",
      "Batch #10\tAverage Generator Loss: 822.225781\tAverage Discriminator Loss: 0.000029\n",
      "\n",
      "Train time for epoch #2855 (step 2855): 1.478910\n",
      "Batch #10\tAverage Generator Loss: 685.565387\tAverage Discriminator Loss: 0.000024\n",
      "\n",
      "Train time for epoch #2856 (step 2856): 1.455751\n",
      "Batch #10\tAverage Generator Loss: 751.773935\tAverage Discriminator Loss: 0.000030\n",
      "\n",
      "Train time for epoch #2857 (step 2857): 1.429214\n",
      "Batch #10\tAverage Generator Loss: 696.448743\tAverage Discriminator Loss: 0.000031\n",
      "\n",
      "Train time for epoch #2858 (step 2858): 1.373193\n",
      "Batch #10\tAverage Generator Loss: 799.240959\tAverage Discriminator Loss: 0.000039\n",
      "\n",
      "Train time for epoch #2859 (step 2859): 1.369964\n",
      "Batch #10\tAverage Generator Loss: 764.011880\tAverage Discriminator Loss: 0.000033\n",
      "\n",
      "Train time for epoch #2860 (step 2860): 1.410107\n",
      "Batch #10\tAverage Generator Loss: 731.533562\tAverage Discriminator Loss: 0.000038\n",
      "\n",
      "Train time for epoch #2861 (step 2861): 1.496874\n",
      "Batch #10\tAverage Generator Loss: 850.116681\tAverage Discriminator Loss: 0.000034\n",
      "\n",
      "Train time for epoch #2862 (step 2862): 1.412499\n",
      "Batch #10\tAverage Generator Loss: 817.909003\tAverage Discriminator Loss: 0.000030\n",
      "\n",
      "Train time for epoch #2863 (step 2863): 1.506948\n",
      "Batch #10\tAverage Generator Loss: 706.757889\tAverage Discriminator Loss: 0.000031\n",
      "\n",
      "Train time for epoch #2864 (step 2864): 1.469523\n",
      "Batch #10\tAverage Generator Loss: 687.463904\tAverage Discriminator Loss: 0.000028\n",
      "\n",
      "Train time for epoch #2865 (step 2865): 1.394002\n",
      "Batch #10\tAverage Generator Loss: 695.019272\tAverage Discriminator Loss: 0.018658\n",
      "\n",
      "Train time for epoch #2866 (step 2866): 1.412284\n",
      "Batch #10\tAverage Generator Loss: 828.426770\tAverage Discriminator Loss: 0.000137\n",
      "\n",
      "Train time for epoch #2867 (step 2867): 1.416718\n",
      "Batch #10\tAverage Generator Loss: 818.174130\tAverage Discriminator Loss: 0.000043\n",
      "\n",
      "Train time for epoch #2868 (step 2868): 1.437137\n",
      "Batch #10\tAverage Generator Loss: 907.049548\tAverage Discriminator Loss: 0.000300\n",
      "\n",
      "Train time for epoch #2869 (step 2869): 1.508461\n",
      "Batch #10\tAverage Generator Loss: 754.316098\tAverage Discriminator Loss: 0.000046\n",
      "\n",
      "Train time for epoch #2870 (step 2870): 1.464578\n",
      "Batch #10\tAverage Generator Loss: 813.965692\tAverage Discriminator Loss: 0.000040\n",
      "\n",
      "Train time for epoch #2871 (step 2871): 1.484600\n",
      "Batch #10\tAverage Generator Loss: 820.516434\tAverage Discriminator Loss: 0.000039\n",
      "\n",
      "Train time for epoch #2872 (step 2872): 1.463278\n",
      "Batch #10\tAverage Generator Loss: 768.142194\tAverage Discriminator Loss: 0.000041\n",
      "\n",
      "Train time for epoch #2873 (step 2873): 1.448491\n",
      "Batch #10\tAverage Generator Loss: 816.399405\tAverage Discriminator Loss: 0.000045\n",
      "\n",
      "Train time for epoch #2874 (step 2874): 1.407793\n",
      "Batch #10\tAverage Generator Loss: 736.344482\tAverage Discriminator Loss: 0.012157\n",
      "\n",
      "Train time for epoch #2875 (step 2875): 1.422682\n",
      "Batch #10\tAverage Generator Loss: 755.511311\tAverage Discriminator Loss: 0.000154\n",
      "\n",
      "Train time for epoch #2876 (step 2876): 1.528279\n",
      "Batch #10\tAverage Generator Loss: 822.589569\tAverage Discriminator Loss: 0.000041\n",
      "\n",
      "Train time for epoch #2877 (step 2877): 1.420508\n",
      "Batch #10\tAverage Generator Loss: 830.070032\tAverage Discriminator Loss: 0.000036\n",
      "\n",
      "Train time for epoch #2878 (step 2878): 1.460390\n",
      "Batch #10\tAverage Generator Loss: 846.183350\tAverage Discriminator Loss: 0.000031\n",
      "\n",
      "Train time for epoch #2879 (step 2879): 1.274619\n",
      "Batch #10\tAverage Generator Loss: 769.645020\tAverage Discriminator Loss: 0.000033\n",
      "\n",
      "Train time for epoch #2880 (step 2880): 1.465044\n",
      "Batch #10\tAverage Generator Loss: 733.542903\tAverage Discriminator Loss: 0.001710\n",
      "\n",
      "Train time for epoch #2881 (step 2881): 1.525696\n",
      "Batch #10\tAverage Generator Loss: 897.123688\tAverage Discriminator Loss: 0.000046\n",
      "\n",
      "Train time for epoch #2882 (step 2882): 1.440657\n",
      "Batch #10\tAverage Generator Loss: 738.520117\tAverage Discriminator Loss: 0.000046\n",
      "\n",
      "Train time for epoch #2883 (step 2883): 1.427141\n",
      "Batch #10\tAverage Generator Loss: 700.328882\tAverage Discriminator Loss: 0.000055\n",
      "\n",
      "Train time for epoch #2884 (step 2884): 1.520505\n",
      "Batch #10\tAverage Generator Loss: 666.968842\tAverage Discriminator Loss: 0.000053\n",
      "\n",
      "Train time for epoch #2885 (step 2885): 1.335857\n",
      "Batch #10\tAverage Generator Loss: 776.951129\tAverage Discriminator Loss: 0.000071\n",
      "\n",
      "Train time for epoch #2886 (step 2886): 1.511455\n",
      "Batch #10\tAverage Generator Loss: 743.804413\tAverage Discriminator Loss: 0.000045\n",
      "\n",
      "Train time for epoch #2887 (step 2887): 1.507427\n",
      "Batch #10\tAverage Generator Loss: 778.320355\tAverage Discriminator Loss: 0.000036\n",
      "\n",
      "Train time for epoch #2888 (step 2888): 1.451125\n",
      "Batch #10\tAverage Generator Loss: 869.005621\tAverage Discriminator Loss: 0.000044\n",
      "\n",
      "Train time for epoch #2889 (step 2889): 1.444758\n",
      "Batch #10\tAverage Generator Loss: 834.447318\tAverage Discriminator Loss: 0.000035\n",
      "\n",
      "Train time for epoch #2890 (step 2890): 1.462983\n",
      "Batch #10\tAverage Generator Loss: 663.775906\tAverage Discriminator Loss: 0.000038\n",
      "\n",
      "Train time for epoch #2891 (step 2891): 1.485877\n",
      "Batch #10\tAverage Generator Loss: 727.269568\tAverage Discriminator Loss: 0.000039\n",
      "\n",
      "Train time for epoch #2892 (step 2892): 1.339863\n",
      "Batch #10\tAverage Generator Loss: 738.178122\tAverage Discriminator Loss: 0.000083\n",
      "\n",
      "Train time for epoch #2893 (step 2893): 1.419948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 773.206976\tAverage Discriminator Loss: 0.000033\n",
      "\n",
      "Train time for epoch #2894 (step 2894): 1.389767\n",
      "Batch #10\tAverage Generator Loss: 704.291849\tAverage Discriminator Loss: 0.000034\n",
      "\n",
      "Train time for epoch #2895 (step 2895): 1.424860\n",
      "Batch #10\tAverage Generator Loss: 798.925208\tAverage Discriminator Loss: 0.000040\n",
      "\n",
      "Train time for epoch #2896 (step 2896): 1.633271\n",
      "Batch #10\tAverage Generator Loss: 737.719794\tAverage Discriminator Loss: 0.000044\n",
      "\n",
      "Train time for epoch #2897 (step 2897): 1.294589\n",
      "Batch #10\tAverage Generator Loss: 871.783630\tAverage Discriminator Loss: 0.000052\n",
      "\n",
      "Train time for epoch #2898 (step 2898): 1.471086\n",
      "Batch #10\tAverage Generator Loss: 774.562396\tAverage Discriminator Loss: 0.000042\n",
      "\n",
      "Train time for epoch #2899 (step 2899): 1.408562\n",
      "Batch #10\tAverage Generator Loss: 709.803836\tAverage Discriminator Loss: 0.000061\n",
      "\n",
      "Train time for epoch #2900 (step 2900): 1.443759\n",
      "Batch #10\tAverage Generator Loss: 759.467010\tAverage Discriminator Loss: 0.000043\n",
      "\n",
      "Train time for epoch #2901 (step 2901): 1.474834\n",
      "Batch #10\tAverage Generator Loss: 700.212933\tAverage Discriminator Loss: 0.000062\n",
      "\n",
      "Train time for epoch #2902 (step 2902): 1.423457\n",
      "Batch #10\tAverage Generator Loss: 803.365393\tAverage Discriminator Loss: 0.011685\n",
      "\n",
      "Train time for epoch #2903 (step 2903): 1.469108\n",
      "Batch #10\tAverage Generator Loss: 752.278537\tAverage Discriminator Loss: 0.001492\n",
      "\n",
      "Train time for epoch #2904 (step 2904): 1.458956\n",
      "Batch #10\tAverage Generator Loss: 724.176474\tAverage Discriminator Loss: 0.000131\n",
      "\n",
      "Train time for epoch #2905 (step 2905): 1.424691\n",
      "Batch #10\tAverage Generator Loss: 957.946484\tAverage Discriminator Loss: 0.000074\n",
      "\n",
      "Train time for epoch #2906 (step 2906): 1.425486\n",
      "Batch #10\tAverage Generator Loss: 648.781650\tAverage Discriminator Loss: 0.000065\n",
      "\n",
      "Train time for epoch #2907 (step 2907): 1.342974\n",
      "Batch #10\tAverage Generator Loss: 769.858926\tAverage Discriminator Loss: 0.000046\n",
      "\n",
      "Train time for epoch #2908 (step 2908): 1.470838\n",
      "Batch #10\tAverage Generator Loss: 719.739502\tAverage Discriminator Loss: 0.000051\n",
      "\n",
      "Train time for epoch #2909 (step 2909): 1.527787\n",
      "Batch #10\tAverage Generator Loss: 798.054840\tAverage Discriminator Loss: 0.000045\n",
      "\n",
      "Train time for epoch #2910 (step 2910): 1.434954\n",
      "Batch #10\tAverage Generator Loss: 782.515784\tAverage Discriminator Loss: 0.000042\n",
      "\n",
      "Train time for epoch #2911 (step 2911): 1.441448\n",
      "Batch #10\tAverage Generator Loss: 829.633478\tAverage Discriminator Loss: 0.000041\n",
      "\n",
      "Train time for epoch #2912 (step 2912): 1.372941\n",
      "Batch #10\tAverage Generator Loss: 832.849619\tAverage Discriminator Loss: 0.000035\n",
      "\n",
      "Train time for epoch #2913 (step 2913): 1.472103\n",
      "Batch #10\tAverage Generator Loss: 692.191876\tAverage Discriminator Loss: 0.000036\n",
      "\n",
      "Train time for epoch #2914 (step 2914): 1.441540\n",
      "Batch #10\tAverage Generator Loss: 700.321994\tAverage Discriminator Loss: 0.000042\n",
      "\n",
      "Train time for epoch #2915 (step 2915): 1.527268\n",
      "Batch #10\tAverage Generator Loss: 693.794760\tAverage Discriminator Loss: 0.000036\n",
      "\n",
      "Train time for epoch #2916 (step 2916): 1.522702\n",
      "Batch #10\tAverage Generator Loss: 688.395016\tAverage Discriminator Loss: 0.000045\n",
      "\n",
      "Train time for epoch #2917 (step 2917): 1.440407\n",
      "Batch #10\tAverage Generator Loss: 715.202982\tAverage Discriminator Loss: 0.000035\n",
      "\n",
      "Train time for epoch #2918 (step 2918): 1.431114\n",
      "Batch #10\tAverage Generator Loss: 782.073950\tAverage Discriminator Loss: 0.000035\n",
      "\n",
      "Train time for epoch #2919 (step 2919): 1.413823\n",
      "Batch #10\tAverage Generator Loss: 721.054449\tAverage Discriminator Loss: 0.000036\n",
      "\n",
      "Train time for epoch #2920 (step 2920): 1.411806\n",
      "Batch #10\tAverage Generator Loss: 814.332614\tAverage Discriminator Loss: 0.000032\n",
      "\n",
      "Train time for epoch #2921 (step 2921): 1.426021\n",
      "Batch #10\tAverage Generator Loss: 863.001849\tAverage Discriminator Loss: 0.000032\n",
      "\n",
      "Train time for epoch #2922 (step 2922): 1.414024\n",
      "Batch #10\tAverage Generator Loss: 779.057513\tAverage Discriminator Loss: 0.000028\n",
      "\n",
      "Train time for epoch #2923 (step 2923): 1.322956\n",
      "Batch #10\tAverage Generator Loss: 766.997385\tAverage Discriminator Loss: 0.000030\n",
      "\n",
      "Train time for epoch #2924 (step 2924): 1.527052\n",
      "Batch #10\tAverage Generator Loss: 717.976993\tAverage Discriminator Loss: 0.000031\n",
      "\n",
      "Train time for epoch #2925 (step 2925): 1.410514\n",
      "Batch #10\tAverage Generator Loss: 828.498132\tAverage Discriminator Loss: 0.000029\n",
      "\n",
      "Train time for epoch #2926 (step 2926): 1.488664\n",
      "Batch #10\tAverage Generator Loss: 701.107602\tAverage Discriminator Loss: 0.000028\n",
      "\n",
      "Train time for epoch #2927 (step 2927): 1.477666\n",
      "Batch #10\tAverage Generator Loss: 742.546564\tAverage Discriminator Loss: 0.000042\n",
      "\n",
      "Train time for epoch #2928 (step 2928): 1.511115\n",
      "Batch #10\tAverage Generator Loss: 708.690518\tAverage Discriminator Loss: 0.000059\n",
      "\n",
      "Train time for epoch #2929 (step 2929): 1.465827\n",
      "Batch #10\tAverage Generator Loss: 724.919647\tAverage Discriminator Loss: 0.000081\n",
      "\n",
      "Train time for epoch #2930 (step 2930): 1.421614\n",
      "Batch #10\tAverage Generator Loss: 683.659698\tAverage Discriminator Loss: 0.261062\n",
      "\n",
      "Train time for epoch #2931 (step 2931): 1.290613\n",
      "Batch #10\tAverage Generator Loss: 619.478561\tAverage Discriminator Loss: 0.000602\n",
      "\n",
      "Train time for epoch #2932 (step 2932): 1.402775\n",
      "Batch #10\tAverage Generator Loss: 641.086520\tAverage Discriminator Loss: 0.279509\n",
      "\n",
      "Train time for epoch #2933 (step 2933): 1.470713\n",
      "Batch #10\tAverage Generator Loss: 728.760849\tAverage Discriminator Loss: 0.037407\n",
      "\n",
      "Train time for epoch #2934 (step 2934): 1.484024\n",
      "Batch #10\tAverage Generator Loss: 583.610248\tAverage Discriminator Loss: 0.000022\n",
      "\n",
      "Train time for epoch #2935 (step 2935): 1.476596\n",
      "Batch #10\tAverage Generator Loss: 604.242371\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #2936 (step 2936): 1.282458\n",
      "Batch #10\tAverage Generator Loss: 536.574582\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #2937 (step 2937): 1.465823\n",
      "Batch #10\tAverage Generator Loss: 521.057538\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #2938 (step 2938): 1.636398\n",
      "Batch #10\tAverage Generator Loss: 559.560638\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #2939 (step 2939): 1.532006\n",
      "Batch #10\tAverage Generator Loss: 698.765991\tAverage Discriminator Loss: 0.025827\n",
      "\n",
      "Train time for epoch #2940 (step 2940): 1.532341\n",
      "Batch #10\tAverage Generator Loss: 532.136943\tAverage Discriminator Loss: 0.000243\n",
      "\n",
      "Train time for epoch #2941 (step 2941): 1.405876\n",
      "Batch #10\tAverage Generator Loss: 566.558109\tAverage Discriminator Loss: 0.000817\n",
      "\n",
      "Train time for epoch #2942 (step 2942): 1.474381\n",
      "Batch #10\tAverage Generator Loss: 567.943115\tAverage Discriminator Loss: 0.000059\n",
      "\n",
      "Train time for epoch #2943 (step 2943): 1.532086\n",
      "Batch #10\tAverage Generator Loss: 694.938098\tAverage Discriminator Loss: 0.000089\n",
      "\n",
      "Train time for epoch #2944 (step 2944): 1.415067\n",
      "Batch #10\tAverage Generator Loss: 578.107388\tAverage Discriminator Loss: 0.000077\n",
      "\n",
      "Train time for epoch #2945 (step 2945): 1.499738\n",
      "Batch #10\tAverage Generator Loss: 555.709346\tAverage Discriminator Loss: 0.000076\n",
      "\n",
      "Train time for epoch #2946 (step 2946): 1.469602\n",
      "Batch #10\tAverage Generator Loss: 480.603743\tAverage Discriminator Loss: 0.000097\n",
      "\n",
      "Train time for epoch #2947 (step 2947): 1.317511\n",
      "Batch #10\tAverage Generator Loss: 562.084662\tAverage Discriminator Loss: 0.000054\n",
      "\n",
      "Train time for epoch #2948 (step 2948): 1.461049\n",
      "Batch #10\tAverage Generator Loss: 617.498532\tAverage Discriminator Loss: 0.000053\n",
      "\n",
      "Train time for epoch #2949 (step 2949): 1.422797\n",
      "Batch #10\tAverage Generator Loss: 624.632483\tAverage Discriminator Loss: 0.000099\n",
      "\n",
      "Train time for epoch #2950 (step 2950): 1.493217\n",
      "Batch #10\tAverage Generator Loss: 563.861829\tAverage Discriminator Loss: 0.000054\n",
      "\n",
      "Train time for epoch #2951 (step 2951): 1.518225\n",
      "Batch #10\tAverage Generator Loss: 604.896854\tAverage Discriminator Loss: 0.000048\n",
      "\n",
      "Train time for epoch #2952 (step 2952): 1.282195\n",
      "Batch #10\tAverage Generator Loss: 585.031897\tAverage Discriminator Loss: 0.000063\n",
      "\n",
      "Train time for epoch #2953 (step 2953): 1.420969\n",
      "Batch #10\tAverage Generator Loss: 542.560623\tAverage Discriminator Loss: 0.000055\n",
      "\n",
      "Train time for epoch #2954 (step 2954): 1.418134\n",
      "Batch #10\tAverage Generator Loss: 581.282083\tAverage Discriminator Loss: 0.000048\n",
      "\n",
      "Train time for epoch #2955 (step 2955): 1.514436\n",
      "Batch #10\tAverage Generator Loss: 612.494318\tAverage Discriminator Loss: 0.000053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #2956 (step 2956): 1.458291\n",
      "Batch #10\tAverage Generator Loss: 623.356042\tAverage Discriminator Loss: 0.000052\n",
      "\n",
      "Train time for epoch #2957 (step 2957): 1.477232\n",
      "Batch #10\tAverage Generator Loss: 560.027420\tAverage Discriminator Loss: 0.000037\n",
      "\n",
      "Train time for epoch #2958 (step 2958): 1.425878\n",
      "Batch #10\tAverage Generator Loss: 522.679141\tAverage Discriminator Loss: 0.001707\n",
      "\n",
      "Train time for epoch #2959 (step 2959): 1.285767\n",
      "Batch #10\tAverage Generator Loss: 526.529228\tAverage Discriminator Loss: 0.000084\n",
      "\n",
      "Train time for epoch #2960 (step 2960): 1.420661\n",
      "Batch #10\tAverage Generator Loss: 585.119873\tAverage Discriminator Loss: 0.000089\n",
      "\n",
      "Train time for epoch #2961 (step 2961): 1.568254\n",
      "Batch #10\tAverage Generator Loss: 532.486124\tAverage Discriminator Loss: 0.000074\n",
      "\n",
      "Train time for epoch #2962 (step 2962): 1.467519\n",
      "Batch #10\tAverage Generator Loss: 601.956189\tAverage Discriminator Loss: 0.000080\n",
      "\n",
      "Train time for epoch #2963 (step 2963): 1.469237\n",
      "Batch #10\tAverage Generator Loss: 549.690250\tAverage Discriminator Loss: 0.000068\n",
      "\n",
      "Train time for epoch #2964 (step 2964): 1.480421\n",
      "Batch #10\tAverage Generator Loss: 588.291428\tAverage Discriminator Loss: 0.000053\n",
      "\n",
      "Train time for epoch #2965 (step 2965): 1.345368\n",
      "Batch #10\tAverage Generator Loss: 610.892874\tAverage Discriminator Loss: 0.000070\n",
      "\n",
      "Train time for epoch #2966 (step 2966): 1.472342\n",
      "Batch #10\tAverage Generator Loss: 605.444971\tAverage Discriminator Loss: 0.000067\n",
      "\n",
      "Train time for epoch #2967 (step 2967): 1.405567\n",
      "Batch #10\tAverage Generator Loss: 625.648303\tAverage Discriminator Loss: 0.000057\n",
      "\n",
      "Train time for epoch #2968 (step 2968): 1.457925\n",
      "Batch #10\tAverage Generator Loss: 584.786420\tAverage Discriminator Loss: 0.000054\n",
      "\n",
      "Train time for epoch #2969 (step 2969): 1.469565\n",
      "Batch #10\tAverage Generator Loss: 563.948550\tAverage Discriminator Loss: 0.000057\n",
      "\n",
      "Train time for epoch #2970 (step 2970): 1.430670\n",
      "Batch #10\tAverage Generator Loss: 569.446674\tAverage Discriminator Loss: 0.000057\n",
      "\n",
      "Train time for epoch #2971 (step 2971): 1.577264\n",
      "Batch #10\tAverage Generator Loss: 603.561859\tAverage Discriminator Loss: 0.000046\n",
      "\n",
      "Train time for epoch #2972 (step 2972): 1.471796\n",
      "Batch #10\tAverage Generator Loss: 607.310686\tAverage Discriminator Loss: 0.000242\n",
      "\n",
      "Train time for epoch #2973 (step 2973): 1.422613\n",
      "Batch #10\tAverage Generator Loss: 587.765283\tAverage Discriminator Loss: 0.000055\n",
      "\n",
      "Train time for epoch #2974 (step 2974): 1.616108\n",
      "Batch #10\tAverage Generator Loss: 608.318533\tAverage Discriminator Loss: 0.000053\n",
      "\n",
      "Train time for epoch #2975 (step 2975): 1.422585\n",
      "Batch #10\tAverage Generator Loss: 569.999753\tAverage Discriminator Loss: 0.000051\n",
      "\n",
      "Train time for epoch #2976 (step 2976): 1.375799\n",
      "Batch #10\tAverage Generator Loss: 634.614484\tAverage Discriminator Loss: 0.000054\n",
      "\n",
      "Train time for epoch #2977 (step 2977): 1.428987\n",
      "Batch #10\tAverage Generator Loss: 616.698990\tAverage Discriminator Loss: 0.003418\n",
      "\n",
      "Train time for epoch #2978 (step 2978): 1.528452\n",
      "Batch #10\tAverage Generator Loss: 653.777548\tAverage Discriminator Loss: 0.000466\n",
      "\n",
      "Train time for epoch #2979 (step 2979): 1.412705\n",
      "Batch #10\tAverage Generator Loss: 568.997287\tAverage Discriminator Loss: 0.000211\n",
      "\n",
      "Train time for epoch #2980 (step 2980): 1.442228\n",
      "Batch #10\tAverage Generator Loss: 593.326123\tAverage Discriminator Loss: 0.000118\n",
      "\n",
      "Train time for epoch #2981 (step 2981): 1.466817\n",
      "Batch #10\tAverage Generator Loss: 547.724927\tAverage Discriminator Loss: 0.000091\n",
      "\n",
      "Train time for epoch #2982 (step 2982): 1.291545\n",
      "Batch #10\tAverage Generator Loss: 640.610510\tAverage Discriminator Loss: 0.000081\n",
      "\n",
      "Train time for epoch #2983 (step 2983): 1.475694\n",
      "Batch #10\tAverage Generator Loss: 557.350192\tAverage Discriminator Loss: 0.000077\n",
      "\n",
      "Train time for epoch #2984 (step 2984): 1.503873\n",
      "Batch #10\tAverage Generator Loss: 644.278076\tAverage Discriminator Loss: 0.000054\n",
      "\n",
      "Train time for epoch #2985 (step 2985): 1.479565\n",
      "Batch #10\tAverage Generator Loss: 541.639726\tAverage Discriminator Loss: 0.000074\n",
      "\n",
      "Train time for epoch #2986 (step 2986): 1.464456\n",
      "Batch #10\tAverage Generator Loss: 568.682834\tAverage Discriminator Loss: 0.000054\n",
      "\n",
      "Train time for epoch #2987 (step 2987): 1.435860\n",
      "Batch #10\tAverage Generator Loss: 571.473260\tAverage Discriminator Loss: 0.000084\n",
      "\n",
      "Train time for epoch #2988 (step 2988): 1.475598\n",
      "Batch #10\tAverage Generator Loss: 651.278748\tAverage Discriminator Loss: 0.003646\n",
      "\n",
      "Train time for epoch #2989 (step 2989): 1.485088\n",
      "Batch #10\tAverage Generator Loss: 603.516614\tAverage Discriminator Loss: 0.003587\n",
      "\n",
      "Train time for epoch #2990 (step 2990): 1.425439\n",
      "Batch #10\tAverage Generator Loss: 542.065332\tAverage Discriminator Loss: 0.000024\n",
      "\n",
      "Train time for epoch #2991 (step 2991): 1.501087\n",
      "Batch #10\tAverage Generator Loss: 583.930408\tAverage Discriminator Loss: 0.000021\n",
      "\n",
      "Train time for epoch #2992 (step 2992): 1.568165\n",
      "Batch #10\tAverage Generator Loss: 560.345671\tAverage Discriminator Loss: 0.041398\n",
      "\n",
      "Train time for epoch #2993 (step 2993): 1.449367\n",
      "Batch #10\tAverage Generator Loss: 545.775090\tAverage Discriminator Loss: 0.021436\n",
      "\n",
      "Train time for epoch #2994 (step 2994): 1.416777\n",
      "Batch #10\tAverage Generator Loss: 579.640689\tAverage Discriminator Loss: 0.000544\n",
      "\n",
      "Train time for epoch #2995 (step 2995): 1.348655\n",
      "Batch #10\tAverage Generator Loss: 565.936859\tAverage Discriminator Loss: 0.000168\n",
      "\n",
      "Train time for epoch #2996 (step 2996): 1.483289\n",
      "Batch #10\tAverage Generator Loss: 508.670519\tAverage Discriminator Loss: 0.000126\n",
      "\n",
      "Train time for epoch #2997 (step 2997): 1.490940\n",
      "Batch #10\tAverage Generator Loss: 630.911472\tAverage Discriminator Loss: 0.000088\n",
      "\n",
      "Train time for epoch #2998 (step 2998): 1.509957\n",
      "Batch #10\tAverage Generator Loss: 570.906351\tAverage Discriminator Loss: 0.000091\n",
      "\n",
      "Train time for epoch #2999 (step 2999): 1.425090\n",
      "Batch #10\tAverage Generator Loss: 572.350453\tAverage Discriminator Loss: 0.000060\n",
      "\n",
      "Train time for epoch #3000 (step 3000): 1.427293\n",
      "Batch #10\tAverage Generator Loss: 585.673578\tAverage Discriminator Loss: 0.000051\n",
      "\n",
      "Train time for epoch #3001 (step 3001): 1.464718\n",
      "Batch #10\tAverage Generator Loss: 634.352771\tAverage Discriminator Loss: 0.000056\n",
      "\n",
      "Train time for epoch #3002 (step 3002): 1.418240\n",
      "Batch #10\tAverage Generator Loss: 625.816989\tAverage Discriminator Loss: 0.000046\n",
      "\n",
      "Train time for epoch #3003 (step 3003): 1.548322\n",
      "Batch #10\tAverage Generator Loss: 647.432391\tAverage Discriminator Loss: 0.000036\n",
      "\n",
      "Train time for epoch #3004 (step 3004): 1.369740\n",
      "Batch #10\tAverage Generator Loss: 644.781213\tAverage Discriminator Loss: 0.000039\n",
      "\n",
      "Train time for epoch #3005 (step 3005): 1.477136\n",
      "Batch #10\tAverage Generator Loss: 566.325653\tAverage Discriminator Loss: 0.000045\n",
      "\n",
      "Train time for epoch #3006 (step 3006): 1.481153\n",
      "Batch #10\tAverage Generator Loss: 562.232898\tAverage Discriminator Loss: 0.000037\n",
      "\n",
      "Train time for epoch #3007 (step 3007): 1.447773\n",
      "Batch #10\tAverage Generator Loss: 557.715924\tAverage Discriminator Loss: 0.001908\n",
      "\n",
      "Train time for epoch #3008 (step 3008): 1.517260\n",
      "Batch #10\tAverage Generator Loss: 508.475507\tAverage Discriminator Loss: 0.000604\n",
      "\n",
      "Train time for epoch #3009 (step 3009): 1.483772\n",
      "Batch #10\tAverage Generator Loss: 539.941492\tAverage Discriminator Loss: 0.000064\n",
      "\n",
      "Train time for epoch #3010 (step 3010): 1.312112\n",
      "Batch #10\tAverage Generator Loss: 514.914825\tAverage Discriminator Loss: 0.000051\n",
      "\n",
      "Train time for epoch #3011 (step 3011): 1.482563\n",
      "Batch #10\tAverage Generator Loss: 582.927251\tAverage Discriminator Loss: 0.000055\n",
      "\n",
      "Train time for epoch #3012 (step 3012): 1.496850\n",
      "Batch #10\tAverage Generator Loss: 533.337312\tAverage Discriminator Loss: 0.000055\n",
      "\n",
      "Train time for epoch #3013 (step 3013): 1.455368\n",
      "Batch #10\tAverage Generator Loss: 554.839014\tAverage Discriminator Loss: 0.000047\n",
      "\n",
      "Train time for epoch #3014 (step 3014): 1.523953\n",
      "Batch #10\tAverage Generator Loss: 511.765933\tAverage Discriminator Loss: 0.000045\n",
      "\n",
      "Train time for epoch #3015 (step 3015): 1.242889\n",
      "Batch #10\tAverage Generator Loss: 537.986765\tAverage Discriminator Loss: 0.000049\n",
      "\n",
      "Train time for epoch #3016 (step 3016): 1.532501\n",
      "Batch #10\tAverage Generator Loss: 555.908975\tAverage Discriminator Loss: 0.000041\n",
      "\n",
      "Train time for epoch #3017 (step 3017): 1.481606\n",
      "Batch #10\tAverage Generator Loss: 585.869983\tAverage Discriminator Loss: 0.000040\n",
      "\n",
      "Train time for epoch #3018 (step 3018): 1.479782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 542.305646\tAverage Discriminator Loss: 0.000041\n",
      "\n",
      "Train time for epoch #3019 (step 3019): 1.420749\n",
      "Batch #10\tAverage Generator Loss: 609.430197\tAverage Discriminator Loss: 0.000042\n",
      "\n",
      "Train time for epoch #3020 (step 3020): 1.525353\n",
      "Batch #10\tAverage Generator Loss: 552.805887\tAverage Discriminator Loss: 0.000039\n",
      "\n",
      "Train time for epoch #3021 (step 3021): 1.329744\n",
      "Batch #10\tAverage Generator Loss: 545.105231\tAverage Discriminator Loss: 0.000039\n",
      "\n",
      "Train time for epoch #3022 (step 3022): 1.364928\n",
      "Batch #10\tAverage Generator Loss: 528.468095\tAverage Discriminator Loss: 0.000032\n",
      "\n",
      "Train time for epoch #3023 (step 3023): 1.587050\n",
      "Batch #10\tAverage Generator Loss: 556.399762\tAverage Discriminator Loss: 0.000031\n",
      "\n",
      "Train time for epoch #3024 (step 3024): 1.446032\n",
      "Batch #10\tAverage Generator Loss: 547.148227\tAverage Discriminator Loss: 0.000030\n",
      "\n",
      "Train time for epoch #3025 (step 3025): 1.425368\n",
      "Batch #10\tAverage Generator Loss: 591.850345\tAverage Discriminator Loss: 0.000031\n",
      "\n",
      "Train time for epoch #3026 (step 3026): 1.401486\n",
      "Batch #10\tAverage Generator Loss: 609.750366\tAverage Discriminator Loss: 0.000031\n",
      "\n",
      "Train time for epoch #3027 (step 3027): 1.248085\n",
      "Batch #10\tAverage Generator Loss: 471.338199\tAverage Discriminator Loss: 0.000028\n",
      "\n",
      "Train time for epoch #3028 (step 3028): 1.599442\n",
      "Batch #10\tAverage Generator Loss: 449.244339\tAverage Discriminator Loss: 0.000070\n",
      "\n",
      "Train time for epoch #3029 (step 3029): 1.436126\n",
      "Batch #10\tAverage Generator Loss: 580.869431\tAverage Discriminator Loss: 0.000031\n",
      "\n",
      "Train time for epoch #3030 (step 3030): 1.707544\n",
      "Batch #10\tAverage Generator Loss: 552.591428\tAverage Discriminator Loss: 0.000034\n",
      "\n",
      "Train time for epoch #3031 (step 3031): 1.416453\n",
      "Batch #10\tAverage Generator Loss: 518.341048\tAverage Discriminator Loss: 0.000025\n",
      "\n",
      "Train time for epoch #3032 (step 3032): 1.471341\n",
      "Batch #10\tAverage Generator Loss: 583.236139\tAverage Discriminator Loss: 0.000030\n",
      "\n",
      "Train time for epoch #3033 (step 3033): 1.346829\n",
      "Batch #10\tAverage Generator Loss: 556.425446\tAverage Discriminator Loss: 0.000030\n",
      "\n",
      "Train time for epoch #3034 (step 3034): 1.410902\n",
      "Batch #10\tAverage Generator Loss: 516.360646\tAverage Discriminator Loss: 0.000026\n",
      "\n",
      "Train time for epoch #3035 (step 3035): 1.469998\n",
      "Batch #10\tAverage Generator Loss: 556.017462\tAverage Discriminator Loss: 0.000026\n",
      "\n",
      "Train time for epoch #3036 (step 3036): 1.499505\n",
      "Batch #10\tAverage Generator Loss: 563.410596\tAverage Discriminator Loss: 0.000028\n",
      "\n",
      "Train time for epoch #3037 (step 3037): 1.493925\n",
      "Batch #10\tAverage Generator Loss: 589.789932\tAverage Discriminator Loss: 0.003619\n",
      "\n",
      "Train time for epoch #3038 (step 3038): 1.575038\n",
      "Batch #10\tAverage Generator Loss: 459.191606\tAverage Discriminator Loss: 0.000418\n",
      "\n",
      "Train time for epoch #3039 (step 3039): 1.355129\n",
      "Batch #10\tAverage Generator Loss: 569.356622\tAverage Discriminator Loss: 0.005802\n",
      "\n",
      "Train time for epoch #3040 (step 3040): 1.477409\n",
      "Batch #10\tAverage Generator Loss: 645.390900\tAverage Discriminator Loss: 0.000524\n",
      "\n",
      "Train time for epoch #3041 (step 3041): 1.477281\n",
      "Batch #10\tAverage Generator Loss: 591.979947\tAverage Discriminator Loss: 0.000262\n",
      "\n",
      "Train time for epoch #3042 (step 3042): 1.468902\n",
      "Batch #10\tAverage Generator Loss: 617.226065\tAverage Discriminator Loss: 0.000177\n",
      "\n",
      "Train time for epoch #3043 (step 3043): 1.426887\n",
      "Batch #10\tAverage Generator Loss: 618.416714\tAverage Discriminator Loss: 0.000139\n",
      "\n",
      "Train time for epoch #3044 (step 3044): 1.394926\n",
      "Batch #10\tAverage Generator Loss: 638.267157\tAverage Discriminator Loss: 0.000131\n",
      "\n",
      "Train time for epoch #3045 (step 3045): 1.470801\n",
      "Batch #10\tAverage Generator Loss: 561.581750\tAverage Discriminator Loss: 0.000099\n",
      "\n",
      "Train time for epoch #3046 (step 3046): 1.474964\n",
      "Batch #10\tAverage Generator Loss: 575.480902\tAverage Discriminator Loss: 0.000092\n",
      "\n",
      "Train time for epoch #3047 (step 3047): 1.287654\n",
      "Batch #10\tAverage Generator Loss: 513.103564\tAverage Discriminator Loss: 0.000085\n",
      "\n",
      "Train time for epoch #3048 (step 3048): 1.412999\n",
      "Batch #10\tAverage Generator Loss: 620.150330\tAverage Discriminator Loss: 0.000087\n",
      "\n",
      "Train time for epoch #3049 (step 3049): 1.412965\n",
      "Batch #10\tAverage Generator Loss: 639.784058\tAverage Discriminator Loss: 0.000070\n",
      "\n",
      "Train time for epoch #3050 (step 3050): 1.557950\n",
      "Batch #10\tAverage Generator Loss: 573.101477\tAverage Discriminator Loss: 0.013552\n",
      "\n",
      "Train time for epoch #3051 (step 3051): 1.425074\n",
      "Batch #10\tAverage Generator Loss: 578.913370\tAverage Discriminator Loss: 0.000513\n",
      "\n",
      "Train time for epoch #3052 (step 3052): 1.375443\n",
      "Batch #10\tAverage Generator Loss: 597.181973\tAverage Discriminator Loss: 0.000171\n",
      "\n",
      "Train time for epoch #3053 (step 3053): 1.559211\n",
      "Batch #10\tAverage Generator Loss: 540.604634\tAverage Discriminator Loss: 0.000175\n",
      "\n",
      "Train time for epoch #3054 (step 3054): 1.364032\n",
      "Batch #10\tAverage Generator Loss: 585.480072\tAverage Discriminator Loss: 0.000072\n",
      "\n",
      "Train time for epoch #3055 (step 3055): 1.450968\n",
      "Batch #10\tAverage Generator Loss: 540.993068\tAverage Discriminator Loss: 0.000054\n",
      "\n",
      "Train time for epoch #3056 (step 3056): 1.565094\n",
      "Batch #10\tAverage Generator Loss: 544.297662\tAverage Discriminator Loss: 0.000048\n",
      "\n",
      "Train time for epoch #3057 (step 3057): 1.566941\n",
      "Batch #10\tAverage Generator Loss: 548.054050\tAverage Discriminator Loss: 0.000144\n",
      "\n",
      "Train time for epoch #3058 (step 3058): 1.436788\n",
      "Batch #10\tAverage Generator Loss: 571.038702\tAverage Discriminator Loss: 0.000046\n",
      "\n",
      "Train time for epoch #3059 (step 3059): 1.297366\n",
      "Batch #10\tAverage Generator Loss: 611.335443\tAverage Discriminator Loss: 0.000037\n",
      "\n",
      "Train time for epoch #3060 (step 3060): 1.551446\n",
      "Batch #10\tAverage Generator Loss: 466.196893\tAverage Discriminator Loss: 0.000077\n",
      "\n",
      "Train time for epoch #3061 (step 3061): 1.417686\n",
      "Batch #10\tAverage Generator Loss: 466.831067\tAverage Discriminator Loss: 0.000035\n",
      "\n",
      "Train time for epoch #3062 (step 3062): 1.428617\n",
      "Batch #10\tAverage Generator Loss: 576.150388\tAverage Discriminator Loss: 0.000032\n",
      "\n",
      "Train time for epoch #3063 (step 3063): 1.465324\n",
      "Batch #10\tAverage Generator Loss: 517.389261\tAverage Discriminator Loss: 0.000029\n",
      "\n",
      "Train time for epoch #3064 (step 3064): 1.482104\n",
      "Batch #10\tAverage Generator Loss: 539.308076\tAverage Discriminator Loss: 0.000026\n",
      "\n",
      "Train time for epoch #3065 (step 3065): 1.278450\n",
      "Batch #10\tAverage Generator Loss: 451.649451\tAverage Discriminator Loss: 0.000272\n",
      "\n",
      "Train time for epoch #3066 (step 3066): 1.461335\n",
      "Batch #10\tAverage Generator Loss: 575.711319\tAverage Discriminator Loss: 0.000428\n",
      "\n",
      "Train time for epoch #3067 (step 3067): 1.470272\n",
      "Batch #10\tAverage Generator Loss: 561.097971\tAverage Discriminator Loss: 0.000126\n",
      "\n",
      "Train time for epoch #3068 (step 3068): 1.415469\n",
      "Batch #10\tAverage Generator Loss: 615.877737\tAverage Discriminator Loss: 0.000053\n",
      "\n",
      "Train time for epoch #3069 (step 3069): 1.389221\n",
      "Batch #10\tAverage Generator Loss: 535.625867\tAverage Discriminator Loss: 0.000039\n",
      "\n",
      "Train time for epoch #3070 (step 3070): 1.430766\n",
      "Batch #10\tAverage Generator Loss: 570.937079\tAverage Discriminator Loss: 0.000036\n",
      "\n",
      "Train time for epoch #3071 (step 3071): 1.509300\n",
      "Batch #10\tAverage Generator Loss: 534.645261\tAverage Discriminator Loss: 0.000030\n",
      "\n",
      "Train time for epoch #3072 (step 3072): 1.430809\n",
      "Batch #10\tAverage Generator Loss: 559.568909\tAverage Discriminator Loss: 0.000029\n",
      "\n",
      "Train time for epoch #3073 (step 3073): 1.476047\n",
      "Batch #10\tAverage Generator Loss: 546.752570\tAverage Discriminator Loss: 0.000027\n",
      "\n",
      "Train time for epoch #3074 (step 3074): 1.469187\n",
      "Batch #10\tAverage Generator Loss: 536.711530\tAverage Discriminator Loss: 0.000025\n",
      "\n",
      "Train time for epoch #3075 (step 3075): 1.609521\n",
      "Batch #10\tAverage Generator Loss: 556.067950\tAverage Discriminator Loss: 0.000023\n",
      "\n",
      "Train time for epoch #3076 (step 3076): 1.328547\n",
      "Batch #10\tAverage Generator Loss: 615.061612\tAverage Discriminator Loss: 0.000021\n",
      "\n",
      "Train time for epoch #3077 (step 3077): 1.432014\n",
      "Batch #10\tAverage Generator Loss: 580.219797\tAverage Discriminator Loss: 0.000022\n",
      "\n",
      "Train time for epoch #3078 (step 3078): 1.643590\n",
      "Batch #10\tAverage Generator Loss: 578.413321\tAverage Discriminator Loss: 0.000022\n",
      "\n",
      "Train time for epoch #3079 (step 3079): 1.431290\n",
      "Batch #10\tAverage Generator Loss: 613.336481\tAverage Discriminator Loss: 0.000019\n",
      "\n",
      "Train time for epoch #3080 (step 3080): 1.425929\n",
      "Batch #10\tAverage Generator Loss: 581.915073\tAverage Discriminator Loss: 0.000019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #3081 (step 3081): 1.362472\n",
      "Batch #10\tAverage Generator Loss: 590.844522\tAverage Discriminator Loss: 0.000037\n",
      "\n",
      "Train time for epoch #3082 (step 3082): 1.380238\n",
      "Batch #10\tAverage Generator Loss: 489.602815\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #3083 (step 3083): 1.479372\n",
      "Batch #10\tAverage Generator Loss: 556.516016\tAverage Discriminator Loss: 0.079727\n",
      "\n",
      "Train time for epoch #3084 (step 3084): 1.571471\n",
      "Batch #10\tAverage Generator Loss: 544.719864\tAverage Discriminator Loss: 0.006174\n",
      "\n",
      "Train time for epoch #3085 (step 3085): 1.675359\n",
      "Batch #10\tAverage Generator Loss: 563.122740\tAverage Discriminator Loss: 0.003025\n",
      "\n",
      "Train time for epoch #3086 (step 3086): 1.430832\n",
      "Batch #10\tAverage Generator Loss: 564.669331\tAverage Discriminator Loss: 0.000041\n",
      "\n",
      "Train time for epoch #3087 (step 3087): 1.297672\n",
      "Batch #10\tAverage Generator Loss: 525.256146\tAverage Discriminator Loss: 0.000024\n",
      "\n",
      "Train time for epoch #3088 (step 3088): 1.561750\n",
      "Batch #10\tAverage Generator Loss: 492.413643\tAverage Discriminator Loss: 0.000019\n",
      "\n",
      "Train time for epoch #3089 (step 3089): 1.512402\n",
      "Batch #10\tAverage Generator Loss: 440.134908\tAverage Discriminator Loss: 0.000019\n",
      "\n",
      "Train time for epoch #3090 (step 3090): 1.455423\n",
      "Batch #10\tAverage Generator Loss: 531.216998\tAverage Discriminator Loss: 0.012740\n",
      "\n",
      "Train time for epoch #3091 (step 3091): 1.726568\n",
      "Batch #10\tAverage Generator Loss: 510.590735\tAverage Discriminator Loss: 0.000749\n",
      "\n",
      "Train time for epoch #3092 (step 3092): 1.491162\n",
      "Batch #10\tAverage Generator Loss: 552.242590\tAverage Discriminator Loss: 0.000067\n",
      "\n",
      "Train time for epoch #3093 (step 3093): 1.391503\n",
      "Batch #10\tAverage Generator Loss: 585.250549\tAverage Discriminator Loss: 0.000027\n",
      "\n",
      "Train time for epoch #3094 (step 3094): 1.467436\n",
      "Batch #10\tAverage Generator Loss: 529.117978\tAverage Discriminator Loss: 0.000023\n",
      "\n",
      "Train time for epoch #3095 (step 3095): 1.437763\n",
      "Batch #10\tAverage Generator Loss: 542.043546\tAverage Discriminator Loss: 0.000023\n",
      "\n",
      "Train time for epoch #3096 (step 3096): 1.554312\n",
      "Batch #10\tAverage Generator Loss: 493.663490\tAverage Discriminator Loss: 0.000020\n",
      "\n",
      "Train time for epoch #3097 (step 3097): 1.424692\n",
      "Batch #10\tAverage Generator Loss: 576.771472\tAverage Discriminator Loss: 0.000020\n",
      "\n",
      "Train time for epoch #3098 (step 3098): 1.463877\n",
      "Batch #10\tAverage Generator Loss: 552.938406\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #3099 (step 3099): 1.270941\n",
      "Batch #10\tAverage Generator Loss: 494.422076\tAverage Discriminator Loss: 0.000027\n",
      "\n",
      "Train time for epoch #3100 (step 3100): 1.418958\n",
      "Batch #10\tAverage Generator Loss: 545.395960\tAverage Discriminator Loss: 0.000042\n",
      "\n",
      "Train time for epoch #3101 (step 3101): 1.450342\n",
      "Batch #10\tAverage Generator Loss: 533.575362\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #3102 (step 3102): 1.575235\n",
      "Batch #10\tAverage Generator Loss: 583.343747\tAverage Discriminator Loss: 0.000284\n",
      "\n",
      "Train time for epoch #3103 (step 3103): 1.435420\n",
      "Batch #10\tAverage Generator Loss: 500.571803\tAverage Discriminator Loss: 0.041622\n",
      "\n",
      "Train time for epoch #3104 (step 3104): 1.473301\n",
      "Batch #10\tAverage Generator Loss: 425.235364\tAverage Discriminator Loss: 0.000399\n",
      "\n",
      "Train time for epoch #3105 (step 3105): 1.466224\n",
      "Batch #10\tAverage Generator Loss: 410.196442\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #3106 (step 3106): 1.576335\n",
      "Batch #10\tAverage Generator Loss: 526.449347\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #3107 (step 3107): 1.230622\n",
      "Batch #10\tAverage Generator Loss: 467.682143\tAverage Discriminator Loss: 0.000083\n",
      "\n",
      "Train time for epoch #3108 (step 3108): 1.424958\n",
      "Batch #10\tAverage Generator Loss: 513.616750\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #3109 (step 3109): 1.433121\n",
      "Batch #10\tAverage Generator Loss: 494.823817\tAverage Discriminator Loss: 0.132739\n",
      "\n",
      "Train time for epoch #3110 (step 3110): 1.375295\n",
      "Batch #10\tAverage Generator Loss: 413.798038\tAverage Discriminator Loss: 0.000028\n",
      "\n",
      "Train time for epoch #3111 (step 3111): 1.432724\n",
      "Batch #10\tAverage Generator Loss: 480.876184\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #3112 (step 3112): 1.265770\n",
      "Batch #10\tAverage Generator Loss: 435.603525\tAverage Discriminator Loss: 0.003683\n",
      "\n",
      "Train time for epoch #3113 (step 3113): 1.477128\n",
      "Batch #10\tAverage Generator Loss: 447.457190\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #3114 (step 3114): 1.533737\n",
      "Batch #10\tAverage Generator Loss: 485.578128\tAverage Discriminator Loss: 0.000023\n",
      "\n",
      "Train time for epoch #3115 (step 3115): 1.421547\n",
      "Batch #10\tAverage Generator Loss: 486.221295\tAverage Discriminator Loss: 0.213180\n",
      "\n",
      "Train time for epoch #3116 (step 3116): 1.371494\n",
      "Batch #10\tAverage Generator Loss: 484.373721\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #3117 (step 3117): 1.389638\n",
      "Batch #10\tAverage Generator Loss: 450.984192\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #3118 (step 3118): 1.491067\n",
      "Batch #10\tAverage Generator Loss: 427.710779\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #3119 (step 3119): 1.475334\n",
      "Batch #10\tAverage Generator Loss: 426.552814\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #3120 (step 3120): 1.471591\n",
      "Batch #10\tAverage Generator Loss: 475.250021\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #3121 (step 3121): 1.477916\n",
      "Batch #10\tAverage Generator Loss: 500.255905\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #3122 (step 3122): 1.336220\n",
      "Batch #10\tAverage Generator Loss: 457.681226\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #3123 (step 3123): 1.404472\n",
      "Batch #10\tAverage Generator Loss: 483.713324\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #3124 (step 3124): 1.462364\n",
      "Batch #10\tAverage Generator Loss: 428.828281\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #3125 (step 3125): 1.466068\n",
      "Batch #10\tAverage Generator Loss: 476.819897\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #3126 (step 3126): 1.443053\n",
      "Batch #10\tAverage Generator Loss: 544.792389\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #3127 (step 3127): 1.291701\n",
      "Batch #10\tAverage Generator Loss: 456.420847\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #3128 (step 3128): 1.482057\n",
      "Batch #10\tAverage Generator Loss: 515.972644\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #3129 (step 3129): 1.499793\n",
      "Batch #10\tAverage Generator Loss: 425.062303\tAverage Discriminator Loss: 0.007342\n",
      "\n",
      "Train time for epoch #3130 (step 3130): 1.521949\n",
      "Batch #10\tAverage Generator Loss: 407.228506\tAverage Discriminator Loss: 0.003208\n",
      "\n",
      "Train time for epoch #3131 (step 3131): 1.535648\n",
      "Batch #10\tAverage Generator Loss: 440.238455\tAverage Discriminator Loss: 0.000031\n",
      "\n",
      "Train time for epoch #3132 (step 3132): 1.526695\n",
      "Batch #10\tAverage Generator Loss: 524.914377\tAverage Discriminator Loss: 0.000072\n",
      "\n",
      "Train time for epoch #3133 (step 3133): 1.344914\n",
      "Batch #10\tAverage Generator Loss: 447.822592\tAverage Discriminator Loss: 0.000068\n",
      "\n",
      "Train time for epoch #3134 (step 3134): 1.405640\n",
      "Batch #10\tAverage Generator Loss: 446.531500\tAverage Discriminator Loss: 0.000052\n",
      "\n",
      "Train time for epoch #3135 (step 3135): 1.471246\n",
      "Batch #10\tAverage Generator Loss: 413.393881\tAverage Discriminator Loss: 0.000045\n",
      "\n",
      "Train time for epoch #3136 (step 3136): 1.422113\n",
      "Batch #10\tAverage Generator Loss: 497.242575\tAverage Discriminator Loss: 0.000039\n",
      "\n",
      "Train time for epoch #3137 (step 3137): 1.491102\n",
      "Batch #10\tAverage Generator Loss: 451.104672\tAverage Discriminator Loss: 0.000031\n",
      "\n",
      "Train time for epoch #3138 (step 3138): 1.378800\n",
      "Batch #10\tAverage Generator Loss: 408.295724\tAverage Discriminator Loss: 0.000020\n",
      "\n",
      "Train time for epoch #3139 (step 3139): 1.416185\n",
      "Batch #10\tAverage Generator Loss: 404.040425\tAverage Discriminator Loss: 0.150396\n",
      "\n",
      "Train time for epoch #3140 (step 3140): 1.420006\n",
      "Batch #10\tAverage Generator Loss: 614.698511\tAverage Discriminator Loss: 0.000942\n",
      "\n",
      "Train time for epoch #3141 (step 3141): 1.472734\n",
      "Batch #10\tAverage Generator Loss: 659.998129\tAverage Discriminator Loss: 0.000318\n",
      "\n",
      "Train time for epoch #3142 (step 3142): 1.432416\n",
      "Batch #10\tAverage Generator Loss: 575.581793\tAverage Discriminator Loss: 0.000186\n",
      "\n",
      "Train time for epoch #3143 (step 3143): 1.476246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 643.658795\tAverage Discriminator Loss: 0.000104\n",
      "\n",
      "Train time for epoch #3144 (step 3144): 1.546515\n",
      "Batch #10\tAverage Generator Loss: 680.245355\tAverage Discriminator Loss: 0.000067\n",
      "\n",
      "Train time for epoch #3145 (step 3145): 1.291393\n",
      "Batch #10\tAverage Generator Loss: 596.106433\tAverage Discriminator Loss: 0.000099\n",
      "\n",
      "Train time for epoch #3146 (step 3146): 1.410621\n",
      "Batch #10\tAverage Generator Loss: 626.617017\tAverage Discriminator Loss: 0.000061\n",
      "\n",
      "Train time for epoch #3147 (step 3147): 1.430485\n",
      "Batch #10\tAverage Generator Loss: 674.970041\tAverage Discriminator Loss: 0.000033\n",
      "\n",
      "Train time for epoch #3148 (step 3148): 1.518376\n",
      "Batch #10\tAverage Generator Loss: 572.562160\tAverage Discriminator Loss: 0.000038\n",
      "\n",
      "Train time for epoch #3149 (step 3149): 1.530928\n",
      "Batch #10\tAverage Generator Loss: 617.503992\tAverage Discriminator Loss: 0.000571\n",
      "\n",
      "Train time for epoch #3150 (step 3150): 1.486617\n",
      "Batch #10\tAverage Generator Loss: 626.295065\tAverage Discriminator Loss: 0.000330\n",
      "\n",
      "Train time for epoch #3151 (step 3151): 1.442073\n",
      "Batch #10\tAverage Generator Loss: 619.480301\tAverage Discriminator Loss: 0.000096\n",
      "\n",
      "Train time for epoch #3152 (step 3152): 1.498589\n",
      "Batch #10\tAverage Generator Loss: 615.964661\tAverage Discriminator Loss: 0.000058\n",
      "\n",
      "Train time for epoch #3153 (step 3153): 1.433665\n",
      "Batch #10\tAverage Generator Loss: 702.702478\tAverage Discriminator Loss: 0.000040\n",
      "\n",
      "Train time for epoch #3154 (step 3154): 1.501661\n",
      "Batch #10\tAverage Generator Loss: 578.684143\tAverage Discriminator Loss: 0.000046\n",
      "\n",
      "Train time for epoch #3155 (step 3155): 1.471539\n",
      "Batch #10\tAverage Generator Loss: 621.265204\tAverage Discriminator Loss: 0.000042\n",
      "\n",
      "Train time for epoch #3156 (step 3156): 1.293278\n",
      "Batch #10\tAverage Generator Loss: 625.038425\tAverage Discriminator Loss: 0.000048\n",
      "\n",
      "Train time for epoch #3157 (step 3157): 1.488442\n",
      "Batch #10\tAverage Generator Loss: 697.722070\tAverage Discriminator Loss: 0.002101\n",
      "\n",
      "Train time for epoch #3158 (step 3158): 1.488235\n",
      "Batch #10\tAverage Generator Loss: 693.382962\tAverage Discriminator Loss: 0.000225\n",
      "\n",
      "Train time for epoch #3159 (step 3159): 1.467110\n",
      "Batch #10\tAverage Generator Loss: 690.472601\tAverage Discriminator Loss: 0.000092\n",
      "\n",
      "Train time for epoch #3160 (step 3160): 1.518595\n",
      "Batch #10\tAverage Generator Loss: 578.946399\tAverage Discriminator Loss: 0.000145\n",
      "\n",
      "Train time for epoch #3161 (step 3161): 1.381308\n",
      "Batch #10\tAverage Generator Loss: 629.923993\tAverage Discriminator Loss: 0.000070\n",
      "\n",
      "Train time for epoch #3162 (step 3162): 1.496138\n",
      "Batch #10\tAverage Generator Loss: 563.294931\tAverage Discriminator Loss: 0.000223\n",
      "\n",
      "Train time for epoch #3163 (step 3163): 1.410802\n",
      "Batch #10\tAverage Generator Loss: 573.966888\tAverage Discriminator Loss: 0.000082\n",
      "\n",
      "Train time for epoch #3164 (step 3164): 1.426433\n",
      "Batch #10\tAverage Generator Loss: 585.962839\tAverage Discriminator Loss: 0.000077\n",
      "\n",
      "Train time for epoch #3165 (step 3165): 1.520142\n",
      "Batch #10\tAverage Generator Loss: 583.699796\tAverage Discriminator Loss: 0.000071\n",
      "\n",
      "Train time for epoch #3166 (step 3166): 1.481197\n",
      "Batch #10\tAverage Generator Loss: 628.508804\tAverage Discriminator Loss: 0.000060\n",
      "\n",
      "Train time for epoch #3167 (step 3167): 1.302346\n",
      "Batch #10\tAverage Generator Loss: 563.007281\tAverage Discriminator Loss: 0.000042\n",
      "\n",
      "Train time for epoch #3168 (step 3168): 1.430364\n",
      "Batch #10\tAverage Generator Loss: 505.330557\tAverage Discriminator Loss: 0.000051\n",
      "\n",
      "Train time for epoch #3169 (step 3169): 1.470049\n",
      "Batch #10\tAverage Generator Loss: 610.523737\tAverage Discriminator Loss: 0.000044\n",
      "\n",
      "Train time for epoch #3170 (step 3170): 1.382718\n",
      "Batch #10\tAverage Generator Loss: 599.862366\tAverage Discriminator Loss: 0.000050\n",
      "\n",
      "Train time for epoch #3171 (step 3171): 1.474542\n",
      "Batch #10\tAverage Generator Loss: 577.797824\tAverage Discriminator Loss: 0.000046\n",
      "\n",
      "Train time for epoch #3172 (step 3172): 1.324556\n",
      "Batch #10\tAverage Generator Loss: 625.014655\tAverage Discriminator Loss: 0.000040\n",
      "\n",
      "Train time for epoch #3173 (step 3173): 1.542955\n",
      "Batch #10\tAverage Generator Loss: 657.163260\tAverage Discriminator Loss: 0.000036\n",
      "\n",
      "Train time for epoch #3174 (step 3174): 1.430197\n",
      "Batch #10\tAverage Generator Loss: 646.911148\tAverage Discriminator Loss: 0.000037\n",
      "\n",
      "Train time for epoch #3175 (step 3175): 1.414162\n",
      "Batch #10\tAverage Generator Loss: 578.623853\tAverage Discriminator Loss: 0.000036\n",
      "\n",
      "Train time for epoch #3176 (step 3176): 1.278366\n",
      "Batch #10\tAverage Generator Loss: 587.465443\tAverage Discriminator Loss: 0.000034\n",
      "\n",
      "Train time for epoch #3177 (step 3177): 1.471264\n",
      "Batch #10\tAverage Generator Loss: 652.582529\tAverage Discriminator Loss: 0.000033\n",
      "\n",
      "Train time for epoch #3178 (step 3178): 1.535215\n",
      "Batch #10\tAverage Generator Loss: 641.113943\tAverage Discriminator Loss: 0.004380\n",
      "\n",
      "Train time for epoch #3179 (step 3179): 1.377882\n",
      "Batch #10\tAverage Generator Loss: 623.897870\tAverage Discriminator Loss: 0.000062\n",
      "\n",
      "Train time for epoch #3180 (step 3180): 1.424433\n",
      "Batch #10\tAverage Generator Loss: 566.299480\tAverage Discriminator Loss: 0.000068\n",
      "\n",
      "Train time for epoch #3181 (step 3181): 1.341147\n",
      "Batch #10\tAverage Generator Loss: 612.264093\tAverage Discriminator Loss: 0.000071\n",
      "\n",
      "Train time for epoch #3182 (step 3182): 1.483549\n",
      "Batch #10\tAverage Generator Loss: 599.782797\tAverage Discriminator Loss: 0.000062\n",
      "\n",
      "Train time for epoch #3183 (step 3183): 1.427166\n",
      "Batch #10\tAverage Generator Loss: 537.328827\tAverage Discriminator Loss: 0.002372\n",
      "\n",
      "Train time for epoch #3184 (step 3184): 1.424665\n",
      "Batch #10\tAverage Generator Loss: 618.357947\tAverage Discriminator Loss: 0.000148\n",
      "\n",
      "Train time for epoch #3185 (step 3185): 1.362988\n",
      "Batch #10\tAverage Generator Loss: 620.944336\tAverage Discriminator Loss: 0.000146\n",
      "\n",
      "Train time for epoch #3186 (step 3186): 1.422089\n",
      "Batch #10\tAverage Generator Loss: 645.908698\tAverage Discriminator Loss: 0.000105\n",
      "\n",
      "Train time for epoch #3187 (step 3187): 1.471378\n",
      "Batch #10\tAverage Generator Loss: 638.389932\tAverage Discriminator Loss: 0.000217\n",
      "\n",
      "Train time for epoch #3188 (step 3188): 1.427663\n",
      "Batch #10\tAverage Generator Loss: 621.790488\tAverage Discriminator Loss: 0.000076\n",
      "\n",
      "Train time for epoch #3189 (step 3189): 1.468892\n",
      "Batch #10\tAverage Generator Loss: 623.476105\tAverage Discriminator Loss: 0.000077\n",
      "\n",
      "Train time for epoch #3190 (step 3190): 1.481215\n",
      "Batch #10\tAverage Generator Loss: 510.670708\tAverage Discriminator Loss: 0.000058\n",
      "\n",
      "Train time for epoch #3191 (step 3191): 1.289693\n",
      "Batch #10\tAverage Generator Loss: 611.115533\tAverage Discriminator Loss: 0.000054\n",
      "\n",
      "Train time for epoch #3192 (step 3192): 1.474153\n",
      "Batch #10\tAverage Generator Loss: 628.169360\tAverage Discriminator Loss: 0.000051\n",
      "\n",
      "Train time for epoch #3193 (step 3193): 1.440823\n",
      "Batch #10\tAverage Generator Loss: 641.264490\tAverage Discriminator Loss: 0.000042\n",
      "\n",
      "Train time for epoch #3194 (step 3194): 1.486413\n",
      "Batch #10\tAverage Generator Loss: 662.333463\tAverage Discriminator Loss: 0.000047\n",
      "\n",
      "Train time for epoch #3195 (step 3195): 1.598534\n",
      "Batch #10\tAverage Generator Loss: 600.987756\tAverage Discriminator Loss: 0.000455\n",
      "\n",
      "Train time for epoch #3196 (step 3196): 1.483952\n",
      "Batch #10\tAverage Generator Loss: 590.896024\tAverage Discriminator Loss: 0.000059\n",
      "\n",
      "Train time for epoch #3197 (step 3197): 1.282245\n",
      "Batch #10\tAverage Generator Loss: 594.975616\tAverage Discriminator Loss: 0.000059\n",
      "\n",
      "Train time for epoch #3198 (step 3198): 1.413228\n",
      "Batch #10\tAverage Generator Loss: 606.484341\tAverage Discriminator Loss: 0.005006\n",
      "\n",
      "Train time for epoch #3199 (step 3199): 1.546465\n",
      "Batch #10\tAverage Generator Loss: 612.240173\tAverage Discriminator Loss: 0.000280\n",
      "\n",
      "Train time for epoch #3200 (step 3200): 1.433404\n",
      "Batch #10\tAverage Generator Loss: 638.255133\tAverage Discriminator Loss: 0.000179\n",
      "\n",
      "Train time for epoch #3201 (step 3201): 1.513436\n",
      "Batch #10\tAverage Generator Loss: 638.814297\tAverage Discriminator Loss: 0.000159\n",
      "\n",
      "Train time for epoch #3202 (step 3202): 1.233175\n",
      "Batch #10\tAverage Generator Loss: 558.320447\tAverage Discriminator Loss: 0.000185\n",
      "\n",
      "Train time for epoch #3203 (step 3203): 1.507990\n",
      "Batch #10\tAverage Generator Loss: 613.150073\tAverage Discriminator Loss: 0.000113\n",
      "\n",
      "Train time for epoch #3204 (step 3204): 1.435079\n",
      "Batch #10\tAverage Generator Loss: 588.184412\tAverage Discriminator Loss: 0.000087\n",
      "\n",
      "Train time for epoch #3205 (step 3205): 1.468984\n",
      "Batch #10\tAverage Generator Loss: 586.291019\tAverage Discriminator Loss: 0.198064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #3206 (step 3206): 1.479003\n",
      "Batch #10\tAverage Generator Loss: 619.553629\tAverage Discriminator Loss: 0.029944\n",
      "\n",
      "Train time for epoch #3207 (step 3207): 1.286646\n",
      "Batch #10\tAverage Generator Loss: 551.733722\tAverage Discriminator Loss: 0.000649\n",
      "\n",
      "Train time for epoch #3208 (step 3208): 1.441586\n",
      "Batch #10\tAverage Generator Loss: 555.966025\tAverage Discriminator Loss: 0.000371\n",
      "\n",
      "Train time for epoch #3209 (step 3209): 1.420766\n",
      "Batch #10\tAverage Generator Loss: 565.911555\tAverage Discriminator Loss: 0.000116\n",
      "\n",
      "Train time for epoch #3210 (step 3210): 1.480384\n",
      "Batch #10\tAverage Generator Loss: 530.420541\tAverage Discriminator Loss: 0.000073\n",
      "\n",
      "Train time for epoch #3211 (step 3211): 1.439056\n",
      "Batch #10\tAverage Generator Loss: 631.533408\tAverage Discriminator Loss: 0.000114\n",
      "\n",
      "Train time for epoch #3212 (step 3212): 1.409364\n",
      "Batch #10\tAverage Generator Loss: 465.010602\tAverage Discriminator Loss: 0.000173\n",
      "\n",
      "Train time for epoch #3213 (step 3213): 1.424181\n",
      "Batch #10\tAverage Generator Loss: 549.827527\tAverage Discriminator Loss: 0.000150\n",
      "\n",
      "Train time for epoch #3214 (step 3214): 1.648200\n",
      "Batch #10\tAverage Generator Loss: 525.139468\tAverage Discriminator Loss: 0.001739\n",
      "\n",
      "Train time for epoch #3215 (step 3215): 1.412049\n",
      "Batch #10\tAverage Generator Loss: 599.805530\tAverage Discriminator Loss: 0.000103\n",
      "\n",
      "Train time for epoch #3216 (step 3216): 1.388619\n",
      "Batch #10\tAverage Generator Loss: 589.195645\tAverage Discriminator Loss: 0.000103\n",
      "\n",
      "Train time for epoch #3217 (step 3217): 1.430761\n",
      "Batch #10\tAverage Generator Loss: 634.135818\tAverage Discriminator Loss: 0.000084\n",
      "\n",
      "Train time for epoch #3218 (step 3218): 1.387609\n",
      "Batch #10\tAverage Generator Loss: 606.428937\tAverage Discriminator Loss: 0.000083\n",
      "\n",
      "Train time for epoch #3219 (step 3219): 1.616693\n",
      "Batch #10\tAverage Generator Loss: 555.739609\tAverage Discriminator Loss: 0.000065\n",
      "\n",
      "Train time for epoch #3220 (step 3220): 1.427174\n",
      "Batch #10\tAverage Generator Loss: 622.413879\tAverage Discriminator Loss: 0.000063\n",
      "\n",
      "Train time for epoch #3221 (step 3221): 1.616177\n",
      "Batch #10\tAverage Generator Loss: 536.812900\tAverage Discriminator Loss: 0.000106\n",
      "\n",
      "Train time for epoch #3222 (step 3222): 1.425162\n",
      "Batch #10\tAverage Generator Loss: 529.590221\tAverage Discriminator Loss: 0.000050\n",
      "\n",
      "Train time for epoch #3223 (step 3223): 1.308112\n",
      "Batch #10\tAverage Generator Loss: 621.934122\tAverage Discriminator Loss: 0.000049\n",
      "\n",
      "Train time for epoch #3224 (step 3224): 1.516663\n",
      "Batch #10\tAverage Generator Loss: 590.510797\tAverage Discriminator Loss: 0.000046\n",
      "\n",
      "Train time for epoch #3225 (step 3225): 1.480280\n",
      "Batch #10\tAverage Generator Loss: 484.870210\tAverage Discriminator Loss: 0.000044\n",
      "\n",
      "Train time for epoch #3226 (step 3226): 1.378795\n",
      "Batch #10\tAverage Generator Loss: 617.887415\tAverage Discriminator Loss: 0.000038\n",
      "\n",
      "Train time for epoch #3227 (step 3227): 1.508105\n",
      "Batch #10\tAverage Generator Loss: 667.378824\tAverage Discriminator Loss: 0.000031\n",
      "\n",
      "Train time for epoch #3228 (step 3228): 1.301440\n",
      "Batch #10\tAverage Generator Loss: 558.518988\tAverage Discriminator Loss: 0.000037\n",
      "\n",
      "Train time for epoch #3229 (step 3229): 1.458247\n",
      "Batch #10\tAverage Generator Loss: 585.236792\tAverage Discriminator Loss: 0.000034\n",
      "\n",
      "Train time for epoch #3230 (step 3230): 1.476148\n",
      "Batch #10\tAverage Generator Loss: 572.500555\tAverage Discriminator Loss: 0.000028\n",
      "\n",
      "Train time for epoch #3231 (step 3231): 1.469279\n",
      "Batch #10\tAverage Generator Loss: 517.707156\tAverage Discriminator Loss: 0.000029\n",
      "\n",
      "Train time for epoch #3232 (step 3232): 1.298431\n",
      "Batch #10\tAverage Generator Loss: 548.905014\tAverage Discriminator Loss: 0.000027\n",
      "\n",
      "Train time for epoch #3233 (step 3233): 1.476138\n",
      "Batch #10\tAverage Generator Loss: 619.957062\tAverage Discriminator Loss: 0.000027\n",
      "\n",
      "Train time for epoch #3234 (step 3234): 1.559837\n",
      "Batch #10\tAverage Generator Loss: 622.966003\tAverage Discriminator Loss: 0.000031\n",
      "\n",
      "Train time for epoch #3235 (step 3235): 1.479476\n",
      "Batch #10\tAverage Generator Loss: 611.275662\tAverage Discriminator Loss: 0.000030\n",
      "\n",
      "Train time for epoch #3236 (step 3236): 1.433470\n",
      "Batch #10\tAverage Generator Loss: 664.440829\tAverage Discriminator Loss: 0.000029\n",
      "\n",
      "Train time for epoch #3237 (step 3237): 1.442525\n",
      "Batch #10\tAverage Generator Loss: 638.604211\tAverage Discriminator Loss: 0.000025\n",
      "\n",
      "Train time for epoch #3238 (step 3238): 1.441612\n",
      "Batch #10\tAverage Generator Loss: 554.598917\tAverage Discriminator Loss: 0.000024\n",
      "\n",
      "Train time for epoch #3239 (step 3239): 1.467680\n",
      "Batch #10\tAverage Generator Loss: 563.054651\tAverage Discriminator Loss: 0.000024\n",
      "\n",
      "Train time for epoch #3240 (step 3240): 1.559886\n",
      "Batch #10\tAverage Generator Loss: 590.081973\tAverage Discriminator Loss: 0.000023\n",
      "\n",
      "Train time for epoch #3241 (step 3241): 1.439686\n",
      "Batch #10\tAverage Generator Loss: 554.974588\tAverage Discriminator Loss: 0.000020\n",
      "\n",
      "Train time for epoch #3242 (step 3242): 1.440296\n",
      "Batch #10\tAverage Generator Loss: 482.747047\tAverage Discriminator Loss: 0.000023\n",
      "\n",
      "Train time for epoch #3243 (step 3243): 1.340194\n",
      "Batch #10\tAverage Generator Loss: 617.016608\tAverage Discriminator Loss: 0.000028\n",
      "\n",
      "Train time for epoch #3244 (step 3244): 1.432761\n",
      "Batch #10\tAverage Generator Loss: 609.838690\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #3245 (step 3245): 1.434995\n",
      "Batch #10\tAverage Generator Loss: 653.319302\tAverage Discriminator Loss: 0.000020\n",
      "\n",
      "Train time for epoch #3246 (step 3246): 1.429884\n",
      "Batch #10\tAverage Generator Loss: 569.856287\tAverage Discriminator Loss: 0.000020\n",
      "\n",
      "Train time for epoch #3247 (step 3247): 1.419749\n",
      "Batch #10\tAverage Generator Loss: 632.302933\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #3248 (step 3248): 1.285855\n",
      "Batch #10\tAverage Generator Loss: 618.812677\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #3249 (step 3249): 1.513132\n",
      "Batch #10\tAverage Generator Loss: 512.877972\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #3250 (step 3250): 1.521677\n",
      "Batch #10\tAverage Generator Loss: 606.181494\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #3251 (step 3251): 1.488662\n",
      "Batch #10\tAverage Generator Loss: 593.339319\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #3252 (step 3252): 1.513399\n",
      "Batch #10\tAverage Generator Loss: 596.635013\tAverage Discriminator Loss: 0.000042\n",
      "\n",
      "Train time for epoch #3253 (step 3253): 1.513801\n",
      "Batch #10\tAverage Generator Loss: 600.816446\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #3254 (step 3254): 1.406140\n",
      "Batch #10\tAverage Generator Loss: 674.450204\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #3255 (step 3255): 1.539911\n",
      "Batch #10\tAverage Generator Loss: 625.577841\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #3256 (step 3256): 1.415947\n",
      "Batch #10\tAverage Generator Loss: 529.813722\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #3257 (step 3257): 1.514674\n",
      "Batch #10\tAverage Generator Loss: 583.409613\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #3258 (step 3258): 1.508085\n",
      "Batch #10\tAverage Generator Loss: 674.998407\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #3259 (step 3259): 1.381098\n",
      "Batch #10\tAverage Generator Loss: 639.159113\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #3260 (step 3260): 1.282133\n",
      "Batch #10\tAverage Generator Loss: 676.538525\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #3261 (step 3261): 1.641178\n",
      "Batch #10\tAverage Generator Loss: 616.620441\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #3262 (step 3262): 1.385805\n",
      "Batch #10\tAverage Generator Loss: 594.460791\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #3263 (step 3263): 1.376495\n",
      "Batch #10\tAverage Generator Loss: 557.842056\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #3264 (step 3264): 1.440737\n",
      "Batch #10\tAverage Generator Loss: 552.860495\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #3265 (step 3265): 1.479056\n",
      "Batch #10\tAverage Generator Loss: 570.310074\tAverage Discriminator Loss: 0.003680\n",
      "\n",
      "Train time for epoch #3266 (step 3266): 1.502806\n",
      "Batch #10\tAverage Generator Loss: 571.907635\tAverage Discriminator Loss: 0.000049\n",
      "\n",
      "Train time for epoch #3267 (step 3267): 1.527490\n",
      "Batch #10\tAverage Generator Loss: 487.602628\tAverage Discriminator Loss: 0.000063\n",
      "\n",
      "Train time for epoch #3268 (step 3268): 1.427792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 617.139763\tAverage Discriminator Loss: 0.000052\n",
      "\n",
      "Train time for epoch #3269 (step 3269): 1.292290\n",
      "Batch #10\tAverage Generator Loss: 596.457410\tAverage Discriminator Loss: 0.000054\n",
      "\n",
      "Train time for epoch #3270 (step 3270): 1.475103\n",
      "Batch #10\tAverage Generator Loss: 515.570349\tAverage Discriminator Loss: 0.000047\n",
      "\n",
      "Train time for epoch #3271 (step 3271): 1.419985\n",
      "Batch #10\tAverage Generator Loss: 629.862930\tAverage Discriminator Loss: 0.000038\n",
      "\n",
      "Train time for epoch #3272 (step 3272): 1.496180\n",
      "Batch #10\tAverage Generator Loss: 578.806726\tAverage Discriminator Loss: 0.000037\n",
      "\n",
      "Train time for epoch #3273 (step 3273): 1.469268\n",
      "Batch #10\tAverage Generator Loss: 528.571327\tAverage Discriminator Loss: 0.000034\n",
      "\n",
      "Train time for epoch #3274 (step 3274): 1.454134\n",
      "Batch #10\tAverage Generator Loss: 656.038995\tAverage Discriminator Loss: 0.000026\n",
      "\n",
      "Train time for epoch #3275 (step 3275): 1.440623\n",
      "Batch #10\tAverage Generator Loss: 595.659961\tAverage Discriminator Loss: 0.000026\n",
      "\n",
      "Train time for epoch #3276 (step 3276): 1.612830\n",
      "Batch #10\tAverage Generator Loss: 646.754730\tAverage Discriminator Loss: 0.000026\n",
      "\n",
      "Train time for epoch #3277 (step 3277): 1.477874\n",
      "Batch #10\tAverage Generator Loss: 609.151321\tAverage Discriminator Loss: 0.000025\n",
      "\n",
      "Train time for epoch #3278 (step 3278): 1.460901\n",
      "Batch #10\tAverage Generator Loss: 605.788049\tAverage Discriminator Loss: 0.000477\n",
      "\n",
      "Train time for epoch #3279 (step 3279): 1.490013\n",
      "Batch #10\tAverage Generator Loss: 559.848416\tAverage Discriminator Loss: 0.000831\n",
      "\n",
      "Train time for epoch #3280 (step 3280): 1.378406\n",
      "Batch #10\tAverage Generator Loss: 591.912898\tAverage Discriminator Loss: 0.000078\n",
      "\n",
      "Train time for epoch #3281 (step 3281): 1.451336\n",
      "Batch #10\tAverage Generator Loss: 567.494720\tAverage Discriminator Loss: 0.000058\n",
      "\n",
      "Train time for epoch #3282 (step 3282): 1.428899\n",
      "Batch #10\tAverage Generator Loss: 560.245129\tAverage Discriminator Loss: 0.000044\n",
      "\n",
      "Train time for epoch #3283 (step 3283): 1.506062\n",
      "Batch #10\tAverage Generator Loss: 549.430273\tAverage Discriminator Loss: 0.000042\n",
      "\n",
      "Train time for epoch #3284 (step 3284): 1.280662\n",
      "Batch #10\tAverage Generator Loss: 597.620020\tAverage Discriminator Loss: 0.000039\n",
      "\n",
      "Train time for epoch #3285 (step 3285): 1.518062\n",
      "Batch #10\tAverage Generator Loss: 645.499646\tAverage Discriminator Loss: 0.000033\n",
      "\n",
      "Train time for epoch #3286 (step 3286): 1.508875\n",
      "Batch #10\tAverage Generator Loss: 554.721799\tAverage Discriminator Loss: 0.000032\n",
      "\n",
      "Train time for epoch #3287 (step 3287): 1.489868\n",
      "Batch #10\tAverage Generator Loss: 501.505737\tAverage Discriminator Loss: 0.000033\n",
      "\n",
      "Train time for epoch #3288 (step 3288): 1.439649\n",
      "Batch #10\tAverage Generator Loss: 582.029929\tAverage Discriminator Loss: 0.000137\n",
      "\n",
      "Train time for epoch #3289 (step 3289): 1.420233\n",
      "Batch #10\tAverage Generator Loss: 536.841266\tAverage Discriminator Loss: 0.000209\n",
      "\n",
      "Train time for epoch #3290 (step 3290): 1.476313\n",
      "Batch #10\tAverage Generator Loss: 577.895874\tAverage Discriminator Loss: 0.000135\n",
      "\n",
      "Train time for epoch #3291 (step 3291): 1.285478\n",
      "Batch #10\tAverage Generator Loss: 559.398495\tAverage Discriminator Loss: 0.000088\n",
      "\n",
      "Train time for epoch #3292 (step 3292): 1.441895\n",
      "Batch #10\tAverage Generator Loss: 464.609668\tAverage Discriminator Loss: 0.000061\n",
      "\n",
      "Train time for epoch #3293 (step 3293): 1.492501\n",
      "Batch #10\tAverage Generator Loss: 560.286874\tAverage Discriminator Loss: 0.000059\n",
      "\n",
      "Train time for epoch #3294 (step 3294): 1.429970\n",
      "Batch #10\tAverage Generator Loss: 559.988522\tAverage Discriminator Loss: 0.000041\n",
      "\n",
      "Train time for epoch #3295 (step 3295): 1.626504\n",
      "Batch #10\tAverage Generator Loss: 540.074800\tAverage Discriminator Loss: 0.000040\n",
      "\n",
      "Train time for epoch #3296 (step 3296): 1.292636\n",
      "Batch #10\tAverage Generator Loss: 489.326398\tAverage Discriminator Loss: 0.004110\n",
      "\n",
      "Train time for epoch #3297 (step 3297): 1.659424\n",
      "Batch #10\tAverage Generator Loss: 644.031219\tAverage Discriminator Loss: 0.001723\n",
      "\n",
      "Train time for epoch #3298 (step 3298): 1.485487\n",
      "Batch #10\tAverage Generator Loss: 561.202997\tAverage Discriminator Loss: 0.000043\n",
      "\n",
      "Train time for epoch #3299 (step 3299): 1.535146\n",
      "Batch #10\tAverage Generator Loss: 605.081219\tAverage Discriminator Loss: 0.000028\n",
      "\n",
      "Train time for epoch #3300 (step 3300): 1.394412\n",
      "Batch #10\tAverage Generator Loss: 600.072855\tAverage Discriminator Loss: 0.000024\n",
      "\n",
      "Train time for epoch #3301 (step 3301): 1.322733\n",
      "Batch #10\tAverage Generator Loss: 601.656979\tAverage Discriminator Loss: 0.000019\n",
      "\n",
      "Train time for epoch #3302 (step 3302): 1.509574\n",
      "Batch #10\tAverage Generator Loss: 519.412323\tAverage Discriminator Loss: 0.000019\n",
      "\n",
      "Train time for epoch #3303 (step 3303): 1.527525\n",
      "Batch #10\tAverage Generator Loss: 594.127667\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #3304 (step 3304): 1.490587\n",
      "Batch #10\tAverage Generator Loss: 485.196466\tAverage Discriminator Loss: 0.003005\n",
      "\n",
      "Train time for epoch #3305 (step 3305): 1.328136\n",
      "Batch #10\tAverage Generator Loss: 614.942502\tAverage Discriminator Loss: 0.000244\n",
      "\n",
      "Train time for epoch #3306 (step 3306): 1.546811\n",
      "Batch #10\tAverage Generator Loss: 547.764005\tAverage Discriminator Loss: 0.000367\n",
      "\n",
      "Train time for epoch #3307 (step 3307): 1.422503\n",
      "Batch #10\tAverage Generator Loss: 572.633124\tAverage Discriminator Loss: 0.000110\n",
      "\n",
      "Train time for epoch #3308 (step 3308): 1.478765\n",
      "Batch #10\tAverage Generator Loss: 528.318093\tAverage Discriminator Loss: 0.000064\n",
      "\n",
      "Train time for epoch #3309 (step 3309): 1.431506\n",
      "Batch #10\tAverage Generator Loss: 601.795819\tAverage Discriminator Loss: 0.000045\n",
      "\n",
      "Train time for epoch #3310 (step 3310): 1.353284\n",
      "Batch #10\tAverage Generator Loss: 590.888257\tAverage Discriminator Loss: 0.000039\n",
      "\n",
      "Train time for epoch #3311 (step 3311): 1.438010\n",
      "Batch #10\tAverage Generator Loss: 645.321097\tAverage Discriminator Loss: 0.000036\n",
      "\n",
      "Train time for epoch #3312 (step 3312): 1.513066\n",
      "Batch #10\tAverage Generator Loss: 611.229965\tAverage Discriminator Loss: 0.000033\n",
      "\n",
      "Train time for epoch #3313 (step 3313): 1.436252\n",
      "Batch #10\tAverage Generator Loss: 586.830060\tAverage Discriminator Loss: 0.000031\n",
      "\n",
      "Train time for epoch #3314 (step 3314): 1.510171\n",
      "Batch #10\tAverage Generator Loss: 593.494809\tAverage Discriminator Loss: 0.000026\n",
      "\n",
      "Train time for epoch #3315 (step 3315): 1.522487\n",
      "Batch #10\tAverage Generator Loss: 506.874438\tAverage Discriminator Loss: 0.000026\n",
      "\n",
      "Train time for epoch #3316 (step 3316): 1.413049\n",
      "Batch #10\tAverage Generator Loss: 631.547638\tAverage Discriminator Loss: 0.000023\n",
      "\n",
      "Train time for epoch #3317 (step 3317): 1.424417\n",
      "Batch #10\tAverage Generator Loss: 530.911700\tAverage Discriminator Loss: 0.000023\n",
      "\n",
      "Train time for epoch #3318 (step 3318): 1.480692\n",
      "Batch #10\tAverage Generator Loss: 606.353311\tAverage Discriminator Loss: 0.000019\n",
      "\n",
      "Train time for epoch #3319 (step 3319): 1.531632\n",
      "Batch #10\tAverage Generator Loss: 619.014990\tAverage Discriminator Loss: 0.000022\n",
      "\n",
      "Train time for epoch #3320 (step 3320): 1.483734\n",
      "Batch #10\tAverage Generator Loss: 621.686453\tAverage Discriminator Loss: 0.000019\n",
      "\n",
      "Train time for epoch #3321 (step 3321): 1.347207\n",
      "Batch #10\tAverage Generator Loss: 679.731384\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #3322 (step 3322): 1.484142\n",
      "Batch #10\tAverage Generator Loss: 581.583643\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #3323 (step 3323): 1.437834\n",
      "Batch #10\tAverage Generator Loss: 601.553088\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #3324 (step 3324): 1.429067\n",
      "Batch #10\tAverage Generator Loss: 540.084398\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #3325 (step 3325): 1.328256\n",
      "Batch #10\tAverage Generator Loss: 532.015520\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #3326 (step 3326): 1.504419\n",
      "Batch #10\tAverage Generator Loss: 575.781403\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #3327 (step 3327): 1.434869\n",
      "Batch #10\tAverage Generator Loss: 626.385355\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #3328 (step 3328): 1.425446\n",
      "Batch #10\tAverage Generator Loss: 594.230313\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #3329 (step 3329): 1.526777\n",
      "Batch #10\tAverage Generator Loss: 541.520483\tAverage Discriminator Loss: 0.000019\n",
      "\n",
      "Train time for epoch #3330 (step 3330): 1.353546\n",
      "Batch #10\tAverage Generator Loss: 621.165750\tAverage Discriminator Loss: 0.001856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #3331 (step 3331): 1.487434\n",
      "Batch #10\tAverage Generator Loss: 550.316446\tAverage Discriminator Loss: 0.000183\n",
      "\n",
      "Train time for epoch #3332 (step 3332): 1.531119\n",
      "Batch #10\tAverage Generator Loss: 596.184406\tAverage Discriminator Loss: 0.000139\n",
      "\n",
      "Train time for epoch #3333 (step 3333): 1.485101\n",
      "Batch #10\tAverage Generator Loss: 560.939642\tAverage Discriminator Loss: 0.000070\n",
      "\n",
      "Train time for epoch #3334 (step 3334): 1.425455\n",
      "Batch #10\tAverage Generator Loss: 554.226822\tAverage Discriminator Loss: 0.042668\n",
      "\n",
      "Train time for epoch #3335 (step 3335): 1.490310\n",
      "Batch #10\tAverage Generator Loss: 507.518161\tAverage Discriminator Loss: 0.230215\n",
      "\n",
      "Train time for epoch #3336 (step 3336): 1.516359\n",
      "Batch #10\tAverage Generator Loss: 446.933725\tAverage Discriminator Loss: 0.000172\n",
      "\n",
      "Train time for epoch #3337 (step 3337): 1.535594\n",
      "Batch #10\tAverage Generator Loss: 386.988701\tAverage Discriminator Loss: 0.987545\n",
      "\n",
      "Train time for epoch #3338 (step 3338): 1.294405\n",
      "Batch #10\tAverage Generator Loss: 314.666131\tAverage Discriminator Loss: 0.087565\n",
      "\n",
      "Train time for epoch #3339 (step 3339): 1.476216\n",
      "Batch #10\tAverage Generator Loss: 502.082285\tAverage Discriminator Loss: 0.308637\n",
      "\n",
      "Train time for epoch #3340 (step 3340): 1.476701\n",
      "Batch #10\tAverage Generator Loss: 507.550093\tAverage Discriminator Loss: 0.004620\n",
      "\n",
      "Train time for epoch #3341 (step 3341): 1.488900\n",
      "Batch #10\tAverage Generator Loss: 499.105312\tAverage Discriminator Loss: 0.028950\n",
      "\n",
      "Train time for epoch #3342 (step 3342): 1.434185\n",
      "Batch #10\tAverage Generator Loss: 422.052668\tAverage Discriminator Loss: 0.847922\n",
      "\n",
      "Train time for epoch #3343 (step 3343): 1.395972\n",
      "Batch #10\tAverage Generator Loss: 443.092603\tAverage Discriminator Loss: 0.005932\n",
      "\n",
      "Train time for epoch #3344 (step 3344): 1.415303\n",
      "Batch #10\tAverage Generator Loss: 433.772510\tAverage Discriminator Loss: 0.000425\n",
      "\n",
      "Train time for epoch #3345 (step 3345): 1.526740\n",
      "Batch #10\tAverage Generator Loss: 370.692934\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #3346 (step 3346): 1.428246\n",
      "Batch #10\tAverage Generator Loss: 337.364893\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #3347 (step 3347): 1.475602\n",
      "Batch #10\tAverage Generator Loss: 352.461443\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #3348 (step 3348): 1.332899\n",
      "Batch #10\tAverage Generator Loss: 370.793710\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #3349 (step 3349): 1.475820\n",
      "Batch #10\tAverage Generator Loss: 402.527829\tAverage Discriminator Loss: 0.000053\n",
      "\n",
      "Train time for epoch #3350 (step 3350): 1.523889\n",
      "Batch #10\tAverage Generator Loss: 378.347812\tAverage Discriminator Loss: 0.000167\n",
      "\n",
      "Train time for epoch #3351 (step 3351): 1.430510\n",
      "Batch #10\tAverage Generator Loss: 427.306000\tAverage Discriminator Loss: 0.000298\n",
      "\n",
      "Train time for epoch #3352 (step 3352): 1.441443\n",
      "Batch #10\tAverage Generator Loss: 371.143138\tAverage Discriminator Loss: 0.000192\n",
      "\n",
      "Train time for epoch #3353 (step 3353): 1.430762\n",
      "Batch #10\tAverage Generator Loss: 404.150336\tAverage Discriminator Loss: 0.000144\n",
      "\n",
      "Train time for epoch #3354 (step 3354): 1.436571\n",
      "Batch #10\tAverage Generator Loss: 408.779311\tAverage Discriminator Loss: 0.000625\n",
      "\n",
      "Train time for epoch #3355 (step 3355): 1.496642\n",
      "Batch #10\tAverage Generator Loss: 460.069894\tAverage Discriminator Loss: 0.000148\n",
      "\n",
      "Train time for epoch #3356 (step 3356): 1.481317\n",
      "Batch #10\tAverage Generator Loss: 445.037643\tAverage Discriminator Loss: 0.000333\n",
      "\n",
      "Train time for epoch #3357 (step 3357): 1.285382\n",
      "Batch #10\tAverage Generator Loss: 480.674234\tAverage Discriminator Loss: 0.000227\n",
      "\n",
      "Train time for epoch #3358 (step 3358): 1.436025\n",
      "Batch #10\tAverage Generator Loss: 383.562238\tAverage Discriminator Loss: 0.000133\n",
      "\n",
      "Train time for epoch #3359 (step 3359): 1.491522\n",
      "Batch #10\tAverage Generator Loss: 374.988629\tAverage Discriminator Loss: 0.000119\n",
      "\n",
      "Train time for epoch #3360 (step 3360): 1.500108\n",
      "Batch #10\tAverage Generator Loss: 471.412344\tAverage Discriminator Loss: 0.000406\n",
      "\n",
      "Train time for epoch #3361 (step 3361): 1.340283\n",
      "Batch #10\tAverage Generator Loss: 439.917770\tAverage Discriminator Loss: 0.007598\n",
      "\n",
      "Train time for epoch #3362 (step 3362): 1.478336\n",
      "Batch #10\tAverage Generator Loss: 488.329779\tAverage Discriminator Loss: 0.000041\n",
      "\n",
      "Train time for epoch #3363 (step 3363): 1.448197\n",
      "Batch #10\tAverage Generator Loss: 400.576225\tAverage Discriminator Loss: 0.000033\n",
      "\n",
      "Train time for epoch #3364 (step 3364): 1.452794\n",
      "Batch #10\tAverage Generator Loss: 397.017334\tAverage Discriminator Loss: 0.000041\n",
      "\n",
      "Train time for epoch #3365 (step 3365): 1.294074\n",
      "Batch #10\tAverage Generator Loss: 448.944238\tAverage Discriminator Loss: 0.000038\n",
      "\n",
      "Train time for epoch #3366 (step 3366): 1.439521\n",
      "Batch #10\tAverage Generator Loss: 405.130190\tAverage Discriminator Loss: 0.000030\n",
      "\n",
      "Train time for epoch #3367 (step 3367): 1.500793\n",
      "Batch #10\tAverage Generator Loss: 410.681236\tAverage Discriminator Loss: 0.000027\n",
      "\n",
      "Train time for epoch #3368 (step 3368): 1.472037\n",
      "Batch #10\tAverage Generator Loss: 451.282013\tAverage Discriminator Loss: 0.000043\n",
      "\n",
      "Train time for epoch #3369 (step 3369): 1.444087\n",
      "Batch #10\tAverage Generator Loss: 422.850528\tAverage Discriminator Loss: 0.000035\n",
      "\n",
      "Train time for epoch #3370 (step 3370): 1.627715\n",
      "Batch #10\tAverage Generator Loss: 419.890646\tAverage Discriminator Loss: 0.000037\n",
      "\n",
      "Train time for epoch #3371 (step 3371): 1.500065\n",
      "Batch #10\tAverage Generator Loss: 395.376651\tAverage Discriminator Loss: 0.000029\n",
      "\n",
      "Train time for epoch #3372 (step 3372): 1.416422\n",
      "Batch #10\tAverage Generator Loss: 474.034428\tAverage Discriminator Loss: 0.000026\n",
      "\n",
      "Train time for epoch #3373 (step 3373): 1.459838\n",
      "Batch #10\tAverage Generator Loss: 463.765588\tAverage Discriminator Loss: 0.078390\n",
      "\n",
      "Train time for epoch #3374 (step 3374): 1.542551\n",
      "Batch #10\tAverage Generator Loss: 428.085257\tAverage Discriminator Loss: 0.000033\n",
      "\n",
      "Train time for epoch #3375 (step 3375): 1.401564\n",
      "Batch #10\tAverage Generator Loss: 392.013844\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #3376 (step 3376): 1.487696\n",
      "Batch #10\tAverage Generator Loss: 390.688861\tAverage Discriminator Loss: 0.003728\n",
      "\n",
      "Train time for epoch #3377 (step 3377): 1.495689\n",
      "Batch #10\tAverage Generator Loss: 463.569975\tAverage Discriminator Loss: 0.000065\n",
      "\n",
      "Train time for epoch #3378 (step 3378): 1.434080\n",
      "Batch #10\tAverage Generator Loss: 442.439896\tAverage Discriminator Loss: 0.000160\n",
      "\n",
      "Train time for epoch #3379 (step 3379): 1.277020\n",
      "Batch #10\tAverage Generator Loss: 481.599811\tAverage Discriminator Loss: 0.000177\n",
      "\n",
      "Train time for epoch #3380 (step 3380): 1.478275\n",
      "Batch #10\tAverage Generator Loss: 498.945160\tAverage Discriminator Loss: 0.000149\n",
      "\n",
      "Train time for epoch #3381 (step 3381): 1.414415\n",
      "Batch #10\tAverage Generator Loss: 419.445413\tAverage Discriminator Loss: 0.000120\n",
      "\n",
      "Train time for epoch #3382 (step 3382): 1.434580\n",
      "Batch #10\tAverage Generator Loss: 428.768255\tAverage Discriminator Loss: 0.169752\n",
      "\n",
      "Train time for epoch #3383 (step 3383): 1.364853\n",
      "Batch #10\tAverage Generator Loss: 444.885999\tAverage Discriminator Loss: 0.179283\n",
      "\n",
      "Train time for epoch #3384 (step 3384): 1.433567\n",
      "Batch #10\tAverage Generator Loss: 549.284183\tAverage Discriminator Loss: 0.000072\n",
      "\n",
      "Train time for epoch #3385 (step 3385): 1.517391\n",
      "Batch #10\tAverage Generator Loss: 502.399875\tAverage Discriminator Loss: 0.000534\n",
      "\n",
      "Train time for epoch #3386 (step 3386): 1.490560\n",
      "Batch #10\tAverage Generator Loss: 498.042323\tAverage Discriminator Loss: 0.066921\n",
      "\n",
      "Train time for epoch #3387 (step 3387): 1.301507\n",
      "Batch #10\tAverage Generator Loss: 476.079378\tAverage Discriminator Loss: 0.009114\n",
      "\n",
      "Train time for epoch #3388 (step 3388): 1.521452\n",
      "Batch #10\tAverage Generator Loss: 457.382217\tAverage Discriminator Loss: 0.000174\n",
      "\n",
      "Train time for epoch #3389 (step 3389): 1.542949\n",
      "Batch #10\tAverage Generator Loss: 425.674660\tAverage Discriminator Loss: 0.000581\n",
      "\n",
      "Train time for epoch #3390 (step 3390): 1.437495\n",
      "Batch #10\tAverage Generator Loss: 459.370775\tAverage Discriminator Loss: 0.000076\n",
      "\n",
      "Train time for epoch #3391 (step 3391): 1.345544\n",
      "Batch #10\tAverage Generator Loss: 447.096133\tAverage Discriminator Loss: 0.080436\n",
      "\n",
      "Train time for epoch #3392 (step 3392): 1.590803\n",
      "Batch #10\tAverage Generator Loss: 473.672212\tAverage Discriminator Loss: 0.004944\n",
      "\n",
      "Train time for epoch #3393 (step 3393): 1.649699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 507.005814\tAverage Discriminator Loss: 0.000130\n",
      "\n",
      "Train time for epoch #3394 (step 3394): 1.432549\n",
      "Batch #10\tAverage Generator Loss: 437.744466\tAverage Discriminator Loss: 0.000030\n",
      "\n",
      "Train time for epoch #3395 (step 3395): 1.454501\n",
      "Batch #10\tAverage Generator Loss: 619.807932\tAverage Discriminator Loss: 0.000056\n",
      "\n",
      "Train time for epoch #3396 (step 3396): 1.289700\n",
      "Batch #10\tAverage Generator Loss: 580.792612\tAverage Discriminator Loss: 0.000054\n",
      "\n",
      "Train time for epoch #3397 (step 3397): 1.508761\n",
      "Batch #10\tAverage Generator Loss: 572.913936\tAverage Discriminator Loss: 0.000046\n",
      "\n",
      "Train time for epoch #3398 (step 3398): 1.490658\n",
      "Batch #10\tAverage Generator Loss: 446.631427\tAverage Discriminator Loss: 0.000042\n",
      "\n",
      "Train time for epoch #3399 (step 3399): 1.272856\n",
      "Batch #10\tAverage Generator Loss: 546.895947\tAverage Discriminator Loss: 0.000045\n",
      "\n",
      "Train time for epoch #3400 (step 3400): 1.479072\n",
      "Batch #10\tAverage Generator Loss: 437.112216\tAverage Discriminator Loss: 0.006830\n",
      "\n",
      "Train time for epoch #3401 (step 3401): 1.546134\n",
      "Batch #10\tAverage Generator Loss: 571.956833\tAverage Discriminator Loss: 0.000052\n",
      "\n",
      "Train time for epoch #3402 (step 3402): 1.460170\n",
      "Batch #10\tAverage Generator Loss: 493.043262\tAverage Discriminator Loss: 0.000251\n",
      "\n",
      "Train time for epoch #3403 (step 3403): 1.286319\n",
      "Batch #10\tAverage Generator Loss: 547.444086\tAverage Discriminator Loss: 0.000982\n",
      "\n",
      "Train time for epoch #3404 (step 3404): 1.531122\n",
      "Batch #10\tAverage Generator Loss: 520.577686\tAverage Discriminator Loss: 0.000156\n",
      "\n",
      "Train time for epoch #3405 (step 3405): 1.487412\n",
      "Batch #10\tAverage Generator Loss: 521.765263\tAverage Discriminator Loss: 0.000143\n",
      "\n",
      "Train time for epoch #3406 (step 3406): 1.330656\n",
      "Batch #10\tAverage Generator Loss: 505.195555\tAverage Discriminator Loss: 0.000792\n",
      "\n",
      "Train time for epoch #3407 (step 3407): 1.448315\n",
      "Batch #10\tAverage Generator Loss: 512.771182\tAverage Discriminator Loss: 0.000131\n",
      "\n",
      "Train time for epoch #3408 (step 3408): 1.440460\n",
      "Batch #10\tAverage Generator Loss: 507.001138\tAverage Discriminator Loss: 0.000361\n",
      "\n",
      "Train time for epoch #3409 (step 3409): 1.523649\n",
      "Batch #10\tAverage Generator Loss: 559.547441\tAverage Discriminator Loss: 0.000086\n",
      "\n",
      "Train time for epoch #3410 (step 3410): 1.446087\n",
      "Batch #10\tAverage Generator Loss: 513.995012\tAverage Discriminator Loss: 0.000082\n",
      "\n",
      "Train time for epoch #3411 (step 3411): 1.423747\n",
      "Batch #10\tAverage Generator Loss: 528.832590\tAverage Discriminator Loss: 0.000098\n",
      "\n",
      "Train time for epoch #3412 (step 3412): 1.435226\n",
      "Batch #10\tAverage Generator Loss: 542.587782\tAverage Discriminator Loss: 0.000067\n",
      "\n",
      "Train time for epoch #3413 (step 3413): 1.489804\n",
      "Batch #10\tAverage Generator Loss: 524.513227\tAverage Discriminator Loss: 0.030283\n",
      "\n",
      "Train time for epoch #3414 (step 3414): 1.461355\n",
      "Batch #10\tAverage Generator Loss: 623.613806\tAverage Discriminator Loss: 0.000090\n",
      "\n",
      "Train time for epoch #3415 (step 3415): 1.378612\n",
      "Batch #10\tAverage Generator Loss: 547.896759\tAverage Discriminator Loss: 0.000076\n",
      "\n",
      "Train time for epoch #3416 (step 3416): 1.434049\n",
      "Batch #10\tAverage Generator Loss: 553.450064\tAverage Discriminator Loss: 0.000176\n",
      "\n",
      "Train time for epoch #3417 (step 3417): 1.462845\n",
      "Batch #10\tAverage Generator Loss: 560.763435\tAverage Discriminator Loss: 0.000039\n",
      "\n",
      "Train time for epoch #3418 (step 3418): 1.427368\n",
      "Batch #10\tAverage Generator Loss: 578.045523\tAverage Discriminator Loss: 0.000235\n",
      "\n",
      "Train time for epoch #3419 (step 3419): 1.435941\n",
      "Batch #10\tAverage Generator Loss: 600.849335\tAverage Discriminator Loss: 0.000030\n",
      "\n",
      "Train time for epoch #3420 (step 3420): 1.305830\n",
      "Batch #10\tAverage Generator Loss: 532.639539\tAverage Discriminator Loss: 0.000029\n",
      "\n",
      "Train time for epoch #3421 (step 3421): 1.419166\n",
      "Batch #10\tAverage Generator Loss: 620.244150\tAverage Discriminator Loss: 0.000037\n",
      "\n",
      "Train time for epoch #3422 (step 3422): 1.443873\n",
      "Batch #10\tAverage Generator Loss: 555.160851\tAverage Discriminator Loss: 0.000021\n",
      "\n",
      "Train time for epoch #3423 (step 3423): 1.537703\n",
      "Batch #10\tAverage Generator Loss: 545.748309\tAverage Discriminator Loss: 0.000032\n",
      "\n",
      "Train time for epoch #3424 (step 3424): 1.298710\n",
      "Batch #10\tAverage Generator Loss: 586.892664\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #3425 (step 3425): 1.491583\n",
      "Batch #10\tAverage Generator Loss: 590.998695\tAverage Discriminator Loss: 0.000029\n",
      "\n",
      "Train time for epoch #3426 (step 3426): 1.499110\n",
      "Batch #10\tAverage Generator Loss: 627.808252\tAverage Discriminator Loss: 0.014749\n",
      "\n",
      "Train time for epoch #3427 (step 3427): 1.422862\n",
      "Batch #10\tAverage Generator Loss: 620.219147\tAverage Discriminator Loss: 0.000081\n",
      "\n",
      "Train time for epoch #3428 (step 3428): 1.515433\n",
      "Batch #10\tAverage Generator Loss: 621.969476\tAverage Discriminator Loss: 0.000090\n",
      "\n",
      "Train time for epoch #3429 (step 3429): 1.436695\n",
      "Batch #10\tAverage Generator Loss: 595.741360\tAverage Discriminator Loss: 0.144292\n",
      "\n",
      "Train time for epoch #3430 (step 3430): 1.298621\n",
      "Batch #10\tAverage Generator Loss: 587.798547\tAverage Discriminator Loss: 0.063085\n",
      "\n",
      "Train time for epoch #3431 (step 3431): 1.449552\n",
      "Batch #10\tAverage Generator Loss: 641.706094\tAverage Discriminator Loss: 0.000071\n",
      "\n",
      "Train time for epoch #3432 (step 3432): 1.492142\n",
      "Batch #10\tAverage Generator Loss: 540.086153\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #3433 (step 3433): 1.493866\n",
      "Batch #10\tAverage Generator Loss: 568.144589\tAverage Discriminator Loss: 0.275787\n",
      "\n",
      "Train time for epoch #3434 (step 3434): 1.435282\n",
      "Batch #10\tAverage Generator Loss: 620.347900\tAverage Discriminator Loss: 0.036975\n",
      "\n",
      "Train time for epoch #3435 (step 3435): 1.398441\n",
      "Batch #10\tAverage Generator Loss: 561.016272\tAverage Discriminator Loss: 0.000757\n",
      "\n",
      "Train time for epoch #3436 (step 3436): 1.522592\n",
      "Batch #10\tAverage Generator Loss: 563.145853\tAverage Discriminator Loss: 0.000145\n",
      "\n",
      "Train time for epoch #3437 (step 3437): 1.520817\n",
      "Batch #10\tAverage Generator Loss: 496.631796\tAverage Discriminator Loss: 0.000111\n",
      "\n",
      "Train time for epoch #3438 (step 3438): 1.525329\n",
      "Batch #10\tAverage Generator Loss: 459.808456\tAverage Discriminator Loss: 0.000111\n",
      "\n",
      "Train time for epoch #3439 (step 3439): 1.473478\n",
      "Batch #10\tAverage Generator Loss: 474.002834\tAverage Discriminator Loss: 0.000104\n",
      "\n",
      "Train time for epoch #3440 (step 3440): 1.539040\n",
      "Batch #10\tAverage Generator Loss: 548.511591\tAverage Discriminator Loss: 0.000077\n",
      "\n",
      "Train time for epoch #3441 (step 3441): 1.387766\n",
      "Batch #10\tAverage Generator Loss: 481.695526\tAverage Discriminator Loss: 0.000094\n",
      "\n",
      "Train time for epoch #3442 (step 3442): 1.546172\n",
      "Batch #10\tAverage Generator Loss: 485.843109\tAverage Discriminator Loss: 0.000088\n",
      "\n",
      "Train time for epoch #3443 (step 3443): 1.496756\n",
      "Batch #10\tAverage Generator Loss: 524.487982\tAverage Discriminator Loss: 0.000065\n",
      "\n",
      "Train time for epoch #3444 (step 3444): 1.300931\n",
      "Batch #10\tAverage Generator Loss: 495.556982\tAverage Discriminator Loss: 0.036553\n",
      "\n",
      "Train time for epoch #3445 (step 3445): 1.531881\n",
      "Batch #10\tAverage Generator Loss: 480.401590\tAverage Discriminator Loss: 0.004711\n",
      "\n",
      "Train time for epoch #3446 (step 3446): 1.588322\n",
      "Batch #10\tAverage Generator Loss: 473.255939\tAverage Discriminator Loss: 0.002279\n",
      "\n",
      "Train time for epoch #3447 (step 3447): 1.540733\n",
      "Batch #10\tAverage Generator Loss: 532.638251\tAverage Discriminator Loss: 0.000617\n",
      "\n",
      "Train time for epoch #3448 (step 3448): 1.481661\n",
      "Batch #10\tAverage Generator Loss: 435.393597\tAverage Discriminator Loss: 0.000250\n",
      "\n",
      "Train time for epoch #3449 (step 3449): 1.441261\n",
      "Batch #10\tAverage Generator Loss: 508.785031\tAverage Discriminator Loss: 0.000212\n",
      "\n",
      "Train time for epoch #3450 (step 3450): 1.449558\n",
      "Batch #10\tAverage Generator Loss: 491.211761\tAverage Discriminator Loss: 0.000234\n",
      "\n",
      "Train time for epoch #3451 (step 3451): 1.427865\n",
      "Batch #10\tAverage Generator Loss: 447.172676\tAverage Discriminator Loss: 0.000191\n",
      "\n",
      "Train time for epoch #3452 (step 3452): 1.439103\n",
      "Batch #10\tAverage Generator Loss: 512.490616\tAverage Discriminator Loss: 0.000190\n",
      "\n",
      "Train time for epoch #3453 (step 3453): 1.286446\n",
      "Batch #10\tAverage Generator Loss: 493.246457\tAverage Discriminator Loss: 0.000131\n",
      "\n",
      "Train time for epoch #3454 (step 3454): 1.476690\n",
      "Batch #10\tAverage Generator Loss: 479.306750\tAverage Discriminator Loss: 0.000148\n",
      "\n",
      "Train time for epoch #3455 (step 3455): 1.528588\n",
      "Batch #10\tAverage Generator Loss: 485.934824\tAverage Discriminator Loss: 0.000157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #3456 (step 3456): 1.444086\n",
      "Batch #10\tAverage Generator Loss: 463.321548\tAverage Discriminator Loss: 0.000114\n",
      "\n",
      "Train time for epoch #3457 (step 3457): 1.530619\n",
      "Batch #10\tAverage Generator Loss: 435.136037\tAverage Discriminator Loss: 0.000178\n",
      "\n",
      "Train time for epoch #3458 (step 3458): 1.415331\n",
      "Batch #10\tAverage Generator Loss: 526.037222\tAverage Discriminator Loss: 0.000112\n",
      "\n",
      "Train time for epoch #3459 (step 3459): 1.580060\n",
      "Batch #10\tAverage Generator Loss: 515.732275\tAverage Discriminator Loss: 0.000108\n",
      "\n",
      "Train time for epoch #3460 (step 3460): 1.441307\n",
      "Batch #10\tAverage Generator Loss: 458.748718\tAverage Discriminator Loss: 0.000106\n",
      "\n",
      "Train time for epoch #3461 (step 3461): 1.484868\n",
      "Batch #10\tAverage Generator Loss: 422.725322\tAverage Discriminator Loss: 0.002390\n",
      "\n",
      "Train time for epoch #3462 (step 3462): 1.568133\n",
      "Batch #10\tAverage Generator Loss: 498.267723\tAverage Discriminator Loss: 0.000239\n",
      "\n",
      "Train time for epoch #3463 (step 3463): 1.282312\n",
      "Batch #10\tAverage Generator Loss: 456.725174\tAverage Discriminator Loss: 0.000216\n",
      "\n",
      "Train time for epoch #3464 (step 3464): 1.639897\n",
      "Batch #10\tAverage Generator Loss: 539.367517\tAverage Discriminator Loss: 0.000255\n",
      "\n",
      "Train time for epoch #3465 (step 3465): 1.435699\n",
      "Batch #10\tAverage Generator Loss: 509.336073\tAverage Discriminator Loss: 0.000191\n",
      "\n",
      "Train time for epoch #3466 (step 3466): 1.591019\n",
      "Batch #10\tAverage Generator Loss: 544.814594\tAverage Discriminator Loss: 0.000162\n",
      "\n",
      "Train time for epoch #3467 (step 3467): 1.545485\n",
      "Batch #10\tAverage Generator Loss: 524.411720\tAverage Discriminator Loss: 0.000122\n",
      "\n",
      "Train time for epoch #3468 (step 3468): 1.283909\n",
      "Batch #10\tAverage Generator Loss: 642.245004\tAverage Discriminator Loss: 0.000173\n",
      "\n",
      "Train time for epoch #3469 (step 3469): 1.494732\n",
      "Batch #10\tAverage Generator Loss: 463.576852\tAverage Discriminator Loss: 0.009811\n",
      "\n",
      "Train time for epoch #3470 (step 3470): 1.473519\n",
      "Batch #10\tAverage Generator Loss: 597.373625\tAverage Discriminator Loss: 0.003754\n",
      "\n",
      "Train time for epoch #3471 (step 3471): 1.582411\n",
      "Batch #10\tAverage Generator Loss: 447.689279\tAverage Discriminator Loss: 0.001011\n",
      "\n",
      "Train time for epoch #3472 (step 3472): 1.476895\n",
      "Batch #10\tAverage Generator Loss: 466.084174\tAverage Discriminator Loss: 0.000396\n",
      "\n",
      "Train time for epoch #3473 (step 3473): 1.341285\n",
      "Batch #10\tAverage Generator Loss: 518.861432\tAverage Discriminator Loss: 0.000248\n",
      "\n",
      "Train time for epoch #3474 (step 3474): 1.529278\n",
      "Batch #10\tAverage Generator Loss: 500.192383\tAverage Discriminator Loss: 0.000229\n",
      "\n",
      "Train time for epoch #3475 (step 3475): 1.501115\n",
      "Batch #10\tAverage Generator Loss: 552.020911\tAverage Discriminator Loss: 0.000201\n",
      "\n",
      "Train time for epoch #3476 (step 3476): 1.454853\n",
      "Batch #10\tAverage Generator Loss: 534.075943\tAverage Discriminator Loss: 0.000145\n",
      "\n",
      "Train time for epoch #3477 (step 3477): 1.545756\n",
      "Batch #10\tAverage Generator Loss: 480.522218\tAverage Discriminator Loss: 0.000148\n",
      "\n",
      "Train time for epoch #3478 (step 3478): 1.403121\n",
      "Batch #10\tAverage Generator Loss: 532.740680\tAverage Discriminator Loss: 0.000099\n",
      "\n",
      "Train time for epoch #3479 (step 3479): 1.416598\n",
      "Batch #10\tAverage Generator Loss: 564.602551\tAverage Discriminator Loss: 0.002867\n",
      "\n",
      "Train time for epoch #3480 (step 3480): 1.617946\n",
      "Batch #10\tAverage Generator Loss: 476.924414\tAverage Discriminator Loss: 0.000344\n",
      "\n",
      "Train time for epoch #3481 (step 3481): 1.514262\n",
      "Batch #10\tAverage Generator Loss: 593.385519\tAverage Discriminator Loss: 0.000363\n",
      "\n",
      "Train time for epoch #3482 (step 3482): 1.295434\n",
      "Batch #10\tAverage Generator Loss: 746.793271\tAverage Discriminator Loss: 0.000247\n",
      "\n",
      "Train time for epoch #3483 (step 3483): 1.437083\n",
      "Batch #10\tAverage Generator Loss: 559.298679\tAverage Discriminator Loss: 0.000190\n",
      "\n",
      "Train time for epoch #3484 (step 3484): 1.446736\n",
      "Batch #10\tAverage Generator Loss: 573.496701\tAverage Discriminator Loss: 0.000185\n",
      "\n",
      "Train time for epoch #3485 (step 3485): 1.448988\n",
      "Batch #10\tAverage Generator Loss: 504.398642\tAverage Discriminator Loss: 0.000156\n",
      "\n",
      "Train time for epoch #3486 (step 3486): 1.337816\n",
      "Batch #10\tAverage Generator Loss: 607.065268\tAverage Discriminator Loss: 0.000106\n",
      "\n",
      "Train time for epoch #3487 (step 3487): 1.490996\n",
      "Batch #10\tAverage Generator Loss: 601.481024\tAverage Discriminator Loss: 0.000118\n",
      "\n",
      "Train time for epoch #3488 (step 3488): 1.576395\n",
      "Batch #10\tAverage Generator Loss: 629.419003\tAverage Discriminator Loss: 0.000106\n",
      "\n",
      "Train time for epoch #3489 (step 3489): 1.452794\n",
      "Batch #10\tAverage Generator Loss: 539.014935\tAverage Discriminator Loss: 0.000087\n",
      "\n",
      "Train time for epoch #3490 (step 3490): 1.283057\n",
      "Batch #10\tAverage Generator Loss: 588.745016\tAverage Discriminator Loss: 0.000094\n",
      "\n",
      "Train time for epoch #3491 (step 3491): 1.432948\n",
      "Batch #10\tAverage Generator Loss: 480.924768\tAverage Discriminator Loss: 0.000071\n",
      "\n",
      "Train time for epoch #3492 (step 3492): 1.493675\n",
      "Batch #10\tAverage Generator Loss: 561.384915\tAverage Discriminator Loss: 0.000090\n",
      "\n",
      "Train time for epoch #3493 (step 3493): 1.482293\n",
      "Batch #10\tAverage Generator Loss: 533.902792\tAverage Discriminator Loss: 0.000086\n",
      "\n",
      "Train time for epoch #3494 (step 3494): 1.360032\n",
      "Batch #10\tAverage Generator Loss: 537.916586\tAverage Discriminator Loss: 0.000070\n",
      "\n",
      "Train time for epoch #3495 (step 3495): 1.481147\n",
      "Batch #10\tAverage Generator Loss: 549.294012\tAverage Discriminator Loss: 0.000073\n",
      "\n",
      "Train time for epoch #3496 (step 3496): 1.516663\n",
      "Batch #10\tAverage Generator Loss: 546.991171\tAverage Discriminator Loss: 0.000070\n",
      "\n",
      "Train time for epoch #3497 (step 3497): 1.539929\n",
      "Batch #10\tAverage Generator Loss: 536.095682\tAverage Discriminator Loss: 0.000061\n",
      "\n",
      "Train time for epoch #3498 (step 3498): 1.674360\n",
      "Batch #10\tAverage Generator Loss: 586.676340\tAverage Discriminator Loss: 0.006967\n",
      "\n",
      "Train time for epoch #3499 (step 3499): 1.330288\n",
      "Batch #10\tAverage Generator Loss: 561.946191\tAverage Discriminator Loss: 0.003068\n",
      "\n",
      "Train time for epoch #3500 (step 3500): 1.427294\n",
      "Batch #10\tAverage Generator Loss: 584.937665\tAverage Discriminator Loss: 0.000374\n",
      "\n",
      "Train time for epoch #3501 (step 3501): 1.418384\n",
      "Batch #10\tAverage Generator Loss: 563.823419\tAverage Discriminator Loss: 0.005657\n",
      "\n",
      "Train time for epoch #3502 (step 3502): 1.434485\n",
      "Batch #10\tAverage Generator Loss: 577.115646\tAverage Discriminator Loss: 0.000119\n",
      "\n",
      "Train time for epoch #3503 (step 3503): 1.390451\n",
      "Batch #10\tAverage Generator Loss: 581.059357\tAverage Discriminator Loss: 0.000103\n",
      "\n",
      "Train time for epoch #3504 (step 3504): 1.499518\n",
      "Batch #10\tAverage Generator Loss: 543.059995\tAverage Discriminator Loss: 0.000111\n",
      "\n",
      "Train time for epoch #3505 (step 3505): 1.492357\n",
      "Batch #10\tAverage Generator Loss: 546.326779\tAverage Discriminator Loss: 0.000104\n",
      "\n",
      "Train time for epoch #3506 (step 3506): 1.430281\n",
      "Batch #10\tAverage Generator Loss: 553.378632\tAverage Discriminator Loss: 0.000091\n",
      "\n",
      "Train time for epoch #3507 (step 3507): 1.555508\n",
      "Batch #10\tAverage Generator Loss: 468.437454\tAverage Discriminator Loss: 0.000096\n",
      "\n",
      "Train time for epoch #3508 (step 3508): 1.611283\n",
      "Batch #10\tAverage Generator Loss: 588.239975\tAverage Discriminator Loss: 0.000074\n",
      "\n",
      "Train time for epoch #3509 (step 3509): 1.437828\n",
      "Batch #10\tAverage Generator Loss: 501.247685\tAverage Discriminator Loss: 0.000067\n",
      "\n",
      "Train time for epoch #3510 (step 3510): 1.345760\n",
      "Batch #10\tAverage Generator Loss: 538.279860\tAverage Discriminator Loss: 0.000081\n",
      "\n",
      "Train time for epoch #3511 (step 3511): 1.445975\n",
      "Batch #10\tAverage Generator Loss: 531.893698\tAverage Discriminator Loss: 0.000072\n",
      "\n",
      "Train time for epoch #3512 (step 3512): 1.424756\n",
      "Batch #10\tAverage Generator Loss: 621.316687\tAverage Discriminator Loss: 0.000062\n",
      "\n",
      "Train time for epoch #3513 (step 3513): 1.460190\n",
      "Batch #10\tAverage Generator Loss: 573.243091\tAverage Discriminator Loss: 0.000062\n",
      "\n",
      "Train time for epoch #3514 (step 3514): 1.342470\n",
      "Batch #10\tAverage Generator Loss: 489.636484\tAverage Discriminator Loss: 0.000060\n",
      "\n",
      "Train time for epoch #3515 (step 3515): 1.507745\n",
      "Batch #10\tAverage Generator Loss: 525.568683\tAverage Discriminator Loss: 0.000059\n",
      "\n",
      "Train time for epoch #3516 (step 3516): 1.435966\n",
      "Batch #10\tAverage Generator Loss: 618.407047\tAverage Discriminator Loss: 0.000052\n",
      "\n",
      "Train time for epoch #3517 (step 3517): 1.564430\n",
      "Batch #10\tAverage Generator Loss: 518.391711\tAverage Discriminator Loss: 0.000050\n",
      "\n",
      "Train time for epoch #3518 (step 3518): 1.278732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 529.928998\tAverage Discriminator Loss: 0.000053\n",
      "\n",
      "Train time for epoch #3519 (step 3519): 1.464900\n",
      "Batch #10\tAverage Generator Loss: 553.747437\tAverage Discriminator Loss: 0.000052\n",
      "\n",
      "Train time for epoch #3520 (step 3520): 1.502261\n",
      "Batch #10\tAverage Generator Loss: 544.967627\tAverage Discriminator Loss: 0.000047\n",
      "\n",
      "Train time for epoch #3521 (step 3521): 1.471681\n",
      "Batch #10\tAverage Generator Loss: 466.063258\tAverage Discriminator Loss: 0.000045\n",
      "\n",
      "Train time for epoch #3522 (step 3522): 1.322091\n",
      "Batch #10\tAverage Generator Loss: 505.975700\tAverage Discriminator Loss: 0.000046\n",
      "\n",
      "Train time for epoch #3523 (step 3523): 1.590005\n",
      "Batch #10\tAverage Generator Loss: 535.765332\tAverage Discriminator Loss: 0.000039\n",
      "\n",
      "Train time for epoch #3524 (step 3524): 1.542549\n",
      "Batch #10\tAverage Generator Loss: 551.776401\tAverage Discriminator Loss: 0.000044\n",
      "\n",
      "Train time for epoch #3525 (step 3525): 1.341056\n",
      "Batch #10\tAverage Generator Loss: 533.779625\tAverage Discriminator Loss: 0.000048\n",
      "\n",
      "Train time for epoch #3526 (step 3526): 1.446054\n",
      "Batch #10\tAverage Generator Loss: 449.839917\tAverage Discriminator Loss: 0.000041\n",
      "\n",
      "Train time for epoch #3527 (step 3527): 1.596298\n",
      "Batch #10\tAverage Generator Loss: 520.870097\tAverage Discriminator Loss: 0.000042\n",
      "\n",
      "Train time for epoch #3528 (step 3528): 1.432740\n",
      "Batch #10\tAverage Generator Loss: 510.729974\tAverage Discriminator Loss: 0.000041\n",
      "\n",
      "Train time for epoch #3529 (step 3529): 1.390449\n",
      "Batch #10\tAverage Generator Loss: 481.013483\tAverage Discriminator Loss: 0.000106\n",
      "\n",
      "Train time for epoch #3530 (step 3530): 1.436946\n",
      "Batch #10\tAverage Generator Loss: 464.949481\tAverage Discriminator Loss: 0.000041\n",
      "\n",
      "Train time for epoch #3531 (step 3531): 1.249423\n",
      "Batch #10\tAverage Generator Loss: 517.358594\tAverage Discriminator Loss: 0.000037\n",
      "\n",
      "Train time for epoch #3532 (step 3532): 1.429415\n",
      "Batch #10\tAverage Generator Loss: 569.277109\tAverage Discriminator Loss: 0.000034\n",
      "\n",
      "Train time for epoch #3533 (step 3533): 1.444826\n",
      "Batch #10\tAverage Generator Loss: 546.341846\tAverage Discriminator Loss: 0.000035\n",
      "\n",
      "Train time for epoch #3534 (step 3534): 1.443204\n",
      "Batch #10\tAverage Generator Loss: 566.694965\tAverage Discriminator Loss: 0.000035\n",
      "\n",
      "Train time for epoch #3535 (step 3535): 1.331179\n",
      "Batch #10\tAverage Generator Loss: 491.403000\tAverage Discriminator Loss: 0.000031\n",
      "\n",
      "Train time for epoch #3536 (step 3536): 1.491867\n",
      "Batch #10\tAverage Generator Loss: 490.836032\tAverage Discriminator Loss: 0.000028\n",
      "\n",
      "Train time for epoch #3537 (step 3537): 1.534827\n",
      "Batch #10\tAverage Generator Loss: 518.922477\tAverage Discriminator Loss: 0.000033\n",
      "\n",
      "Train time for epoch #3538 (step 3538): 1.453633\n",
      "Batch #10\tAverage Generator Loss: 489.260640\tAverage Discriminator Loss: 0.000030\n",
      "\n",
      "Train time for epoch #3539 (step 3539): 1.526309\n",
      "Batch #10\tAverage Generator Loss: 626.389105\tAverage Discriminator Loss: 0.000030\n",
      "\n",
      "Train time for epoch #3540 (step 3540): 1.427095\n",
      "Batch #10\tAverage Generator Loss: 513.936844\tAverage Discriminator Loss: 0.000105\n",
      "\n",
      "Train time for epoch #3541 (step 3541): 1.509267\n",
      "Batch #10\tAverage Generator Loss: 523.058124\tAverage Discriminator Loss: 0.000032\n",
      "\n",
      "Train time for epoch #3542 (step 3542): 1.427720\n",
      "Batch #10\tAverage Generator Loss: 514.310211\tAverage Discriminator Loss: 0.000216\n",
      "\n",
      "Train time for epoch #3543 (step 3543): 1.632185\n",
      "Batch #10\tAverage Generator Loss: 514.381196\tAverage Discriminator Loss: 0.000031\n",
      "\n",
      "Train time for epoch #3544 (step 3544): 1.486591\n",
      "Batch #10\tAverage Generator Loss: 528.407159\tAverage Discriminator Loss: 0.000034\n",
      "\n",
      "Train time for epoch #3545 (step 3545): 1.537556\n",
      "Batch #10\tAverage Generator Loss: 515.689877\tAverage Discriminator Loss: 0.000036\n",
      "\n",
      "Train time for epoch #3546 (step 3546): 1.289943\n",
      "Batch #10\tAverage Generator Loss: 523.536005\tAverage Discriminator Loss: 0.000030\n",
      "\n",
      "Train time for epoch #3547 (step 3547): 1.524790\n",
      "Batch #10\tAverage Generator Loss: 516.935124\tAverage Discriminator Loss: 0.000031\n",
      "\n",
      "Train time for epoch #3548 (step 3548): 1.457449\n",
      "Batch #10\tAverage Generator Loss: 453.962840\tAverage Discriminator Loss: 0.000029\n",
      "\n",
      "Train time for epoch #3549 (step 3549): 1.380857\n",
      "Batch #10\tAverage Generator Loss: 593.499106\tAverage Discriminator Loss: 0.000031\n",
      "\n",
      "Train time for epoch #3550 (step 3550): 1.410017\n",
      "Batch #10\tAverage Generator Loss: 529.648199\tAverage Discriminator Loss: 0.000030\n",
      "\n",
      "Train time for epoch #3551 (step 3551): 1.614531\n",
      "Batch #10\tAverage Generator Loss: 574.309839\tAverage Discriminator Loss: 0.000027\n",
      "\n",
      "Train time for epoch #3552 (step 3552): 1.301599\n",
      "Batch #10\tAverage Generator Loss: 471.619720\tAverage Discriminator Loss: 0.000065\n",
      "\n",
      "Train time for epoch #3553 (step 3553): 1.491580\n",
      "Batch #10\tAverage Generator Loss: 539.996901\tAverage Discriminator Loss: 0.000038\n",
      "\n",
      "Train time for epoch #3554 (step 3554): 1.475862\n",
      "Batch #10\tAverage Generator Loss: 497.107770\tAverage Discriminator Loss: 0.000029\n",
      "\n",
      "Train time for epoch #3555 (step 3555): 1.427045\n",
      "Batch #10\tAverage Generator Loss: 506.281409\tAverage Discriminator Loss: 0.000030\n",
      "\n",
      "Train time for epoch #3556 (step 3556): 1.645070\n",
      "Batch #10\tAverage Generator Loss: 613.574353\tAverage Discriminator Loss: 0.000031\n",
      "\n",
      "Train time for epoch #3557 (step 3557): 1.300664\n",
      "Batch #10\tAverage Generator Loss: 538.663748\tAverage Discriminator Loss: 0.000031\n",
      "\n",
      "Train time for epoch #3558 (step 3558): 1.484243\n",
      "Batch #10\tAverage Generator Loss: 517.903937\tAverage Discriminator Loss: 0.000028\n",
      "\n",
      "Train time for epoch #3559 (step 3559): 1.453318\n",
      "Batch #10\tAverage Generator Loss: 531.640512\tAverage Discriminator Loss: 0.000025\n",
      "\n",
      "Train time for epoch #3560 (step 3560): 1.486802\n",
      "Batch #10\tAverage Generator Loss: 505.531641\tAverage Discriminator Loss: 0.000024\n",
      "\n",
      "Train time for epoch #3561 (step 3561): 1.312557\n",
      "Batch #10\tAverage Generator Loss: 564.449380\tAverage Discriminator Loss: 0.005931\n",
      "\n",
      "Train time for epoch #3562 (step 3562): 1.435097\n",
      "Batch #10\tAverage Generator Loss: 539.183438\tAverage Discriminator Loss: 0.000026\n",
      "\n",
      "Train time for epoch #3563 (step 3563): 1.498774\n",
      "Batch #10\tAverage Generator Loss: 518.808418\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #3564 (step 3564): 1.405033\n",
      "Batch #10\tAverage Generator Loss: 580.312775\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #3565 (step 3565): 1.395513\n",
      "Batch #10\tAverage Generator Loss: 612.445941\tAverage Discriminator Loss: 0.000023\n",
      "\n",
      "Train time for epoch #3566 (step 3566): 1.485525\n",
      "Batch #10\tAverage Generator Loss: 620.175421\tAverage Discriminator Loss: 0.000097\n",
      "\n",
      "Train time for epoch #3567 (step 3567): 1.439472\n",
      "Batch #10\tAverage Generator Loss: 523.112753\tAverage Discriminator Loss: 0.007399\n",
      "\n",
      "Train time for epoch #3568 (step 3568): 1.347295\n",
      "Batch #10\tAverage Generator Loss: 492.691571\tAverage Discriminator Loss: 0.000670\n",
      "\n",
      "Train time for epoch #3569 (step 3569): 1.495095\n",
      "Batch #10\tAverage Generator Loss: 518.471951\tAverage Discriminator Loss: 0.000088\n",
      "\n",
      "Train time for epoch #3570 (step 3570): 1.450893\n",
      "Batch #10\tAverage Generator Loss: 559.639041\tAverage Discriminator Loss: 0.000190\n",
      "\n",
      "Train time for epoch #3571 (step 3571): 1.488273\n",
      "Batch #10\tAverage Generator Loss: 620.592105\tAverage Discriminator Loss: 0.000059\n",
      "\n",
      "Train time for epoch #3572 (step 3572): 1.470225\n",
      "Batch #10\tAverage Generator Loss: 537.918842\tAverage Discriminator Loss: 0.000068\n",
      "\n",
      "Train time for epoch #3573 (step 3573): 1.444503\n",
      "Batch #10\tAverage Generator Loss: 561.326416\tAverage Discriminator Loss: 0.000049\n",
      "\n",
      "Train time for epoch #3574 (step 3574): 1.410933\n",
      "Batch #10\tAverage Generator Loss: 541.913956\tAverage Discriminator Loss: 0.000059\n",
      "\n",
      "Train time for epoch #3575 (step 3575): 1.515169\n",
      "Batch #10\tAverage Generator Loss: 547.377887\tAverage Discriminator Loss: 0.023830\n",
      "\n",
      "Train time for epoch #3576 (step 3576): 1.486606\n",
      "Batch #10\tAverage Generator Loss: 567.462573\tAverage Discriminator Loss: 0.000875\n",
      "\n",
      "Train time for epoch #3577 (step 3577): 1.447001\n",
      "Batch #10\tAverage Generator Loss: 566.266881\tAverage Discriminator Loss: 0.000045\n",
      "\n",
      "Train time for epoch #3578 (step 3578): 1.418545\n",
      "Batch #10\tAverage Generator Loss: 572.507794\tAverage Discriminator Loss: 0.000032\n",
      "\n",
      "Train time for epoch #3579 (step 3579): 1.488314\n",
      "Batch #10\tAverage Generator Loss: 561.944458\tAverage Discriminator Loss: 0.000027\n",
      "\n",
      "Train time for epoch #3580 (step 3580): 1.478984\n",
      "Batch #10\tAverage Generator Loss: 573.097501\tAverage Discriminator Loss: 0.000019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #3581 (step 3581): 1.299000\n",
      "Batch #10\tAverage Generator Loss: 568.955829\tAverage Discriminator Loss: 0.000026\n",
      "\n",
      "Train time for epoch #3582 (step 3582): 1.484772\n",
      "Batch #10\tAverage Generator Loss: 520.836887\tAverage Discriminator Loss: 0.000027\n",
      "\n",
      "Train time for epoch #3583 (step 3583): 1.465180\n",
      "Batch #10\tAverage Generator Loss: 482.410684\tAverage Discriminator Loss: 0.000023\n",
      "\n",
      "Train time for epoch #3584 (step 3584): 1.437826\n",
      "Batch #10\tAverage Generator Loss: 585.753897\tAverage Discriminator Loss: 0.000021\n",
      "\n",
      "Train time for epoch #3585 (step 3585): 1.437944\n",
      "Batch #10\tAverage Generator Loss: 523.434848\tAverage Discriminator Loss: 0.000021\n",
      "\n",
      "Train time for epoch #3586 (step 3586): 1.392402\n",
      "Batch #10\tAverage Generator Loss: 559.055966\tAverage Discriminator Loss: 0.000022\n",
      "\n",
      "Train time for epoch #3587 (step 3587): 1.579126\n",
      "Batch #10\tAverage Generator Loss: 613.859302\tAverage Discriminator Loss: 0.000022\n",
      "\n",
      "Train time for epoch #3588 (step 3588): 1.492656\n",
      "Batch #10\tAverage Generator Loss: 466.563911\tAverage Discriminator Loss: 0.000021\n",
      "\n",
      "Train time for epoch #3589 (step 3589): 1.283356\n",
      "Batch #10\tAverage Generator Loss: 510.574715\tAverage Discriminator Loss: 0.000062\n",
      "\n",
      "Train time for epoch #3590 (step 3590): 1.426019\n",
      "Batch #10\tAverage Generator Loss: 494.377737\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #3591 (step 3591): 1.493585\n",
      "Batch #10\tAverage Generator Loss: 618.752075\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #3592 (step 3592): 1.624705\n",
      "Batch #10\tAverage Generator Loss: 589.800888\tAverage Discriminator Loss: 0.000021\n",
      "\n",
      "Train time for epoch #3593 (step 3593): 1.569689\n",
      "Batch #10\tAverage Generator Loss: 612.793665\tAverage Discriminator Loss: 0.000019\n",
      "\n",
      "Train time for epoch #3594 (step 3594): 1.596241\n",
      "Batch #10\tAverage Generator Loss: 592.070819\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #3595 (step 3595): 1.283537\n",
      "Batch #10\tAverage Generator Loss: 552.631183\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #3596 (step 3596): 1.594561\n",
      "Batch #10\tAverage Generator Loss: 563.902808\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #3597 (step 3597): 1.402568\n",
      "Batch #10\tAverage Generator Loss: 556.666501\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #3598 (step 3598): 1.290649\n",
      "Batch #10\tAverage Generator Loss: 468.124557\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #3599 (step 3599): 1.495062\n",
      "Batch #10\tAverage Generator Loss: 527.927213\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #3600 (step 3600): 1.584008\n",
      "Batch #10\tAverage Generator Loss: 492.656297\tAverage Discriminator Loss: 0.000025\n",
      "\n",
      "Train time for epoch #3601 (step 3601): 1.337177\n",
      "Batch #10\tAverage Generator Loss: 576.680551\tAverage Discriminator Loss: 0.000033\n",
      "\n",
      "Train time for epoch #3602 (step 3602): 1.403030\n",
      "Batch #10\tAverage Generator Loss: 543.862534\tAverage Discriminator Loss: 0.000031\n",
      "\n",
      "Train time for epoch #3603 (step 3603): 1.499071\n",
      "Batch #10\tAverage Generator Loss: 611.966241\tAverage Discriminator Loss: 0.000035\n",
      "\n",
      "Train time for epoch #3604 (step 3604): 1.496567\n",
      "Batch #10\tAverage Generator Loss: 568.548282\tAverage Discriminator Loss: 0.000027\n",
      "\n",
      "Train time for epoch #3605 (step 3605): 1.501930\n",
      "Batch #10\tAverage Generator Loss: 458.852673\tAverage Discriminator Loss: 0.000071\n",
      "\n",
      "Train time for epoch #3606 (step 3606): 1.353922\n",
      "Batch #10\tAverage Generator Loss: 519.943768\tAverage Discriminator Loss: 0.000060\n",
      "\n",
      "Train time for epoch #3607 (step 3607): 1.428245\n",
      "Batch #10\tAverage Generator Loss: 506.668802\tAverage Discriminator Loss: 0.000081\n",
      "\n",
      "Train time for epoch #3608 (step 3608): 1.488603\n",
      "Batch #10\tAverage Generator Loss: 548.685278\tAverage Discriminator Loss: 0.000099\n",
      "\n",
      "Train time for epoch #3609 (step 3609): 1.438307\n",
      "Batch #10\tAverage Generator Loss: 543.711424\tAverage Discriminator Loss: 0.000097\n",
      "\n",
      "Train time for epoch #3610 (step 3610): 1.482278\n",
      "Batch #10\tAverage Generator Loss: 510.667422\tAverage Discriminator Loss: 0.000072\n",
      "\n",
      "Train time for epoch #3611 (step 3611): 1.444179\n",
      "Batch #10\tAverage Generator Loss: 556.733057\tAverage Discriminator Loss: 0.000061\n",
      "\n",
      "Train time for epoch #3612 (step 3612): 1.488122\n",
      "Batch #10\tAverage Generator Loss: 524.579871\tAverage Discriminator Loss: 0.000047\n",
      "\n",
      "Train time for epoch #3613 (step 3613): 1.290566\n",
      "Batch #10\tAverage Generator Loss: 522.059335\tAverage Discriminator Loss: 0.000054\n",
      "\n",
      "Train time for epoch #3614 (step 3614): 1.472384\n",
      "Batch #10\tAverage Generator Loss: 504.961902\tAverage Discriminator Loss: 0.000042\n",
      "\n",
      "Train time for epoch #3615 (step 3615): 1.431943\n",
      "Batch #10\tAverage Generator Loss: 556.020261\tAverage Discriminator Loss: 0.000032\n",
      "\n",
      "Train time for epoch #3616 (step 3616): 1.470438\n",
      "Batch #10\tAverage Generator Loss: 511.062134\tAverage Discriminator Loss: 0.000030\n",
      "\n",
      "Train time for epoch #3617 (step 3617): 1.433549\n",
      "Batch #10\tAverage Generator Loss: 520.200499\tAverage Discriminator Loss: 0.000037\n",
      "\n",
      "Train time for epoch #3618 (step 3618): 1.451497\n",
      "Batch #10\tAverage Generator Loss: 500.455408\tAverage Discriminator Loss: 0.000030\n",
      "\n",
      "Train time for epoch #3619 (step 3619): 1.362206\n",
      "Batch #10\tAverage Generator Loss: 511.183954\tAverage Discriminator Loss: 0.000028\n",
      "\n",
      "Train time for epoch #3620 (step 3620): 1.475214\n",
      "Batch #10\tAverage Generator Loss: 559.777435\tAverage Discriminator Loss: 0.000030\n",
      "\n",
      "Train time for epoch #3621 (step 3621): 1.425352\n",
      "Batch #10\tAverage Generator Loss: 509.875641\tAverage Discriminator Loss: 0.000026\n",
      "\n",
      "Train time for epoch #3622 (step 3622): 1.476643\n",
      "Batch #10\tAverage Generator Loss: 597.474661\tAverage Discriminator Loss: 0.000023\n",
      "\n",
      "Train time for epoch #3623 (step 3623): 1.394625\n",
      "Batch #10\tAverage Generator Loss: 452.437279\tAverage Discriminator Loss: 0.000026\n",
      "\n",
      "Train time for epoch #3624 (step 3624): 1.531268\n",
      "Batch #10\tAverage Generator Loss: 491.453455\tAverage Discriminator Loss: 0.000032\n",
      "\n",
      "Train time for epoch #3625 (step 3625): 1.483775\n",
      "Batch #10\tAverage Generator Loss: 528.946701\tAverage Discriminator Loss: 0.000029\n",
      "\n",
      "Train time for epoch #3626 (step 3626): 1.439205\n",
      "Batch #10\tAverage Generator Loss: 500.092688\tAverage Discriminator Loss: 0.000023\n",
      "\n",
      "Train time for epoch #3627 (step 3627): 1.292756\n",
      "Batch #10\tAverage Generator Loss: 534.246878\tAverage Discriminator Loss: 0.000019\n",
      "\n",
      "Train time for epoch #3628 (step 3628): 1.427433\n",
      "Batch #10\tAverage Generator Loss: 507.561002\tAverage Discriminator Loss: 0.000023\n",
      "\n",
      "Train time for epoch #3629 (step 3629): 1.447009\n",
      "Batch #10\tAverage Generator Loss: 612.090369\tAverage Discriminator Loss: 0.000024\n",
      "\n",
      "Train time for epoch #3630 (step 3630): 1.637288\n",
      "Batch #10\tAverage Generator Loss: 516.722870\tAverage Discriminator Loss: 0.000514\n",
      "\n",
      "Train time for epoch #3631 (step 3631): 1.344095\n",
      "Batch #10\tAverage Generator Loss: 544.264890\tAverage Discriminator Loss: 0.000048\n",
      "\n",
      "Train time for epoch #3632 (step 3632): 1.606002\n",
      "Batch #10\tAverage Generator Loss: 531.163828\tAverage Discriminator Loss: 0.000096\n",
      "\n",
      "Train time for epoch #3633 (step 3633): 1.653815\n",
      "Batch #10\tAverage Generator Loss: 520.095132\tAverage Discriminator Loss: 0.005178\n",
      "\n",
      "Train time for epoch #3634 (step 3634): 1.451946\n",
      "Batch #10\tAverage Generator Loss: 542.275087\tAverage Discriminator Loss: 0.015857\n",
      "\n",
      "Train time for epoch #3635 (step 3635): 1.430372\n",
      "Batch #10\tAverage Generator Loss: 660.969782\tAverage Discriminator Loss: 0.400524\n",
      "\n",
      "Train time for epoch #3636 (step 3636): 1.539812\n",
      "Batch #10\tAverage Generator Loss: 647.604199\tAverage Discriminator Loss: 0.002045\n",
      "\n",
      "Train time for epoch #3637 (step 3637): 1.547876\n",
      "Batch #10\tAverage Generator Loss: 615.424222\tAverage Discriminator Loss: 0.006518\n",
      "\n",
      "Train time for epoch #3638 (step 3638): 1.519712\n",
      "Batch #10\tAverage Generator Loss: 654.525327\tAverage Discriminator Loss: 0.000082\n",
      "\n",
      "Train time for epoch #3639 (step 3639): 1.499511\n",
      "Batch #10\tAverage Generator Loss: 628.718018\tAverage Discriminator Loss: 0.000032\n",
      "\n",
      "Train time for epoch #3640 (step 3640): 1.499797\n",
      "Batch #10\tAverage Generator Loss: 654.829434\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #3641 (step 3641): 1.517074\n",
      "Batch #10\tAverage Generator Loss: 732.895105\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #3642 (step 3642): 1.289563\n",
      "Batch #10\tAverage Generator Loss: 685.790802\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #3643 (step 3643): 1.433260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 673.983186\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #3644 (step 3644): 1.669931\n",
      "Batch #10\tAverage Generator Loss: 586.265771\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #3645 (step 3645): 1.480339\n",
      "Batch #10\tAverage Generator Loss: 579.659882\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #3646 (step 3646): 1.498671\n",
      "Batch #10\tAverage Generator Loss: 708.146829\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #3647 (step 3647): 1.235162\n",
      "Batch #10\tAverage Generator Loss: 706.830130\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #3648 (step 3648): 1.492899\n",
      "Batch #10\tAverage Generator Loss: 692.744427\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #3649 (step 3649): 1.503922\n",
      "Batch #10\tAverage Generator Loss: 637.725778\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #3650 (step 3650): 1.488527\n",
      "Batch #10\tAverage Generator Loss: 652.445105\tAverage Discriminator Loss: 0.005266\n",
      "\n",
      "Train time for epoch #3651 (step 3651): 1.340602\n",
      "Batch #10\tAverage Generator Loss: 611.172870\tAverage Discriminator Loss: 0.000089\n",
      "\n",
      "Train time for epoch #3652 (step 3652): 1.579353\n",
      "Batch #10\tAverage Generator Loss: 617.046188\tAverage Discriminator Loss: 0.000080\n",
      "\n",
      "Train time for epoch #3653 (step 3653): 1.496819\n",
      "Batch #10\tAverage Generator Loss: 659.253125\tAverage Discriminator Loss: 0.000394\n",
      "\n",
      "Train time for epoch #3654 (step 3654): 1.574989\n",
      "Batch #10\tAverage Generator Loss: 593.217181\tAverage Discriminator Loss: 0.000100\n",
      "\n",
      "Train time for epoch #3655 (step 3655): 1.588741\n",
      "Batch #10\tAverage Generator Loss: 678.378287\tAverage Discriminator Loss: 0.000040\n",
      "\n",
      "Train time for epoch #3656 (step 3656): 1.292087\n",
      "Batch #10\tAverage Generator Loss: 618.426868\tAverage Discriminator Loss: 0.000024\n",
      "\n",
      "Train time for epoch #3657 (step 3657): 1.488539\n",
      "Batch #10\tAverage Generator Loss: 576.973618\tAverage Discriminator Loss: 0.065405\n",
      "\n",
      "Train time for epoch #3658 (step 3658): 1.404226\n",
      "Batch #10\tAverage Generator Loss: 509.752704\tAverage Discriminator Loss: 0.031609\n",
      "\n",
      "Train time for epoch #3659 (step 3659): 1.596036\n",
      "Batch #10\tAverage Generator Loss: 503.639960\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #3660 (step 3660): 1.361895\n",
      "Batch #10\tAverage Generator Loss: 558.353250\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #3661 (step 3661): 1.486708\n",
      "Batch #10\tAverage Generator Loss: 543.011249\tAverage Discriminator Loss: 0.011222\n",
      "\n",
      "Train time for epoch #3662 (step 3662): 1.501142\n",
      "Batch #10\tAverage Generator Loss: 614.578088\tAverage Discriminator Loss: 0.007031\n",
      "\n",
      "Train time for epoch #3663 (step 3663): 1.479174\n",
      "Batch #10\tAverage Generator Loss: 551.020685\tAverage Discriminator Loss: 0.003248\n",
      "\n",
      "Train time for epoch #3664 (step 3664): 1.374193\n",
      "Batch #10\tAverage Generator Loss: 627.915628\tAverage Discriminator Loss: 0.000059\n",
      "\n",
      "Train time for epoch #3665 (step 3665): 1.402188\n",
      "Batch #10\tAverage Generator Loss: 530.321848\tAverage Discriminator Loss: 0.000044\n",
      "\n",
      "Train time for epoch #3666 (step 3666): 1.586232\n",
      "Batch #10\tAverage Generator Loss: 561.311594\tAverage Discriminator Loss: 0.015077\n",
      "\n",
      "Train time for epoch #3667 (step 3667): 1.446029\n",
      "Batch #10\tAverage Generator Loss: 550.062570\tAverage Discriminator Loss: 0.004303\n",
      "\n",
      "Train time for epoch #3668 (step 3668): 1.355644\n",
      "Batch #10\tAverage Generator Loss: 550.788617\tAverage Discriminator Loss: 0.000328\n",
      "\n",
      "Train time for epoch #3669 (step 3669): 1.414755\n",
      "Batch #10\tAverage Generator Loss: 544.424417\tAverage Discriminator Loss: 0.000096\n",
      "\n",
      "Train time for epoch #3670 (step 3670): 1.648316\n",
      "Batch #10\tAverage Generator Loss: 461.773157\tAverage Discriminator Loss: 0.000059\n",
      "\n",
      "Train time for epoch #3671 (step 3671): 1.485761\n",
      "Batch #10\tAverage Generator Loss: 516.227628\tAverage Discriminator Loss: 0.000052\n",
      "\n",
      "Train time for epoch #3672 (step 3672): 1.346915\n",
      "Batch #10\tAverage Generator Loss: 514.445624\tAverage Discriminator Loss: 0.001469\n",
      "\n",
      "Train time for epoch #3673 (step 3673): 1.566674\n",
      "Batch #10\tAverage Generator Loss: 539.793234\tAverage Discriminator Loss: 0.000481\n",
      "\n",
      "Train time for epoch #3674 (step 3674): 1.466842\n",
      "Batch #10\tAverage Generator Loss: 538.959634\tAverage Discriminator Loss: 0.001372\n",
      "\n",
      "Train time for epoch #3675 (step 3675): 1.601297\n",
      "Batch #10\tAverage Generator Loss: 570.395953\tAverage Discriminator Loss: 0.000114\n",
      "\n",
      "Train time for epoch #3676 (step 3676): 1.402658\n",
      "Batch #10\tAverage Generator Loss: 496.903574\tAverage Discriminator Loss: 0.000080\n",
      "\n",
      "Train time for epoch #3677 (step 3677): 1.514955\n",
      "Batch #10\tAverage Generator Loss: 506.148935\tAverage Discriminator Loss: 0.000050\n",
      "\n",
      "Train time for epoch #3678 (step 3678): 1.531136\n",
      "Batch #10\tAverage Generator Loss: 556.076453\tAverage Discriminator Loss: 0.000036\n",
      "\n",
      "Train time for epoch #3679 (step 3679): 1.449305\n",
      "Batch #10\tAverage Generator Loss: 560.614764\tAverage Discriminator Loss: 0.000031\n",
      "\n",
      "Train time for epoch #3680 (step 3680): 1.297893\n",
      "Batch #10\tAverage Generator Loss: 585.729410\tAverage Discriminator Loss: 0.000028\n",
      "\n",
      "Train time for epoch #3681 (step 3681): 1.409992\n",
      "Batch #10\tAverage Generator Loss: 474.372433\tAverage Discriminator Loss: 0.002493\n",
      "\n",
      "Train time for epoch #3682 (step 3682): 1.462480\n",
      "Batch #10\tAverage Generator Loss: 579.930887\tAverage Discriminator Loss: 0.000630\n",
      "\n",
      "Train time for epoch #3683 (step 3683): 1.484411\n",
      "Batch #10\tAverage Generator Loss: 609.538181\tAverage Discriminator Loss: 0.000224\n",
      "\n",
      "Train time for epoch #3684 (step 3684): 1.451868\n",
      "Batch #10\tAverage Generator Loss: 506.708569\tAverage Discriminator Loss: 0.000486\n",
      "\n",
      "Train time for epoch #3685 (step 3685): 1.512795\n",
      "Batch #10\tAverage Generator Loss: 660.398849\tAverage Discriminator Loss: 0.011165\n",
      "\n",
      "Train time for epoch #3686 (step 3686): 1.566430\n",
      "Batch #10\tAverage Generator Loss: 554.122362\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #3687 (step 3687): 1.451121\n",
      "Batch #10\tAverage Generator Loss: 584.260382\tAverage Discriminator Loss: 0.050808\n",
      "\n",
      "Train time for epoch #3688 (step 3688): 1.472859\n",
      "Batch #10\tAverage Generator Loss: 702.631439\tAverage Discriminator Loss: 0.024654\n",
      "\n",
      "Train time for epoch #3689 (step 3689): 1.545840\n",
      "Batch #10\tAverage Generator Loss: 636.337955\tAverage Discriminator Loss: 0.000036\n",
      "\n",
      "Train time for epoch #3690 (step 3690): 1.523464\n",
      "Batch #10\tAverage Generator Loss: 541.450105\tAverage Discriminator Loss: 0.000029\n",
      "\n",
      "Train time for epoch #3691 (step 3691): 1.447002\n",
      "Batch #10\tAverage Generator Loss: 596.423022\tAverage Discriminator Loss: 0.000030\n",
      "\n",
      "Train time for epoch #3692 (step 3692): 1.333592\n",
      "Batch #10\tAverage Generator Loss: 542.712677\tAverage Discriminator Loss: 0.000073\n",
      "\n",
      "Train time for epoch #3693 (step 3693): 1.490672\n",
      "Batch #10\tAverage Generator Loss: 598.098137\tAverage Discriminator Loss: 0.000024\n",
      "\n",
      "Train time for epoch #3694 (step 3694): 1.532655\n",
      "Batch #10\tAverage Generator Loss: 621.061761\tAverage Discriminator Loss: 0.000023\n",
      "\n",
      "Train time for epoch #3695 (step 3695): 1.339549\n",
      "Batch #10\tAverage Generator Loss: 630.672568\tAverage Discriminator Loss: 0.051154\n",
      "\n",
      "Train time for epoch #3696 (step 3696): 1.479360\n",
      "Batch #10\tAverage Generator Loss: 641.472690\tAverage Discriminator Loss: 0.050482\n",
      "\n",
      "Train time for epoch #3697 (step 3697): 1.548205\n",
      "Batch #10\tAverage Generator Loss: 674.783691\tAverage Discriminator Loss: 0.000159\n",
      "\n",
      "Train time for epoch #3698 (step 3698): 1.616383\n",
      "Batch #10\tAverage Generator Loss: 683.034155\tAverage Discriminator Loss: 0.000117\n",
      "\n",
      "Train time for epoch #3699 (step 3699): 1.350316\n",
      "Batch #10\tAverage Generator Loss: 630.426602\tAverage Discriminator Loss: 0.000099\n",
      "\n",
      "Train time for epoch #3700 (step 3700): 1.701443\n",
      "Batch #10\tAverage Generator Loss: 608.991522\tAverage Discriminator Loss: 0.000069\n",
      "\n",
      "Train time for epoch #3701 (step 3701): 1.571720\n",
      "Batch #10\tAverage Generator Loss: 627.685382\tAverage Discriminator Loss: 0.000071\n",
      "\n",
      "Train time for epoch #3702 (step 3702): 1.496759\n",
      "Batch #10\tAverage Generator Loss: 617.094228\tAverage Discriminator Loss: 0.000065\n",
      "\n",
      "Train time for epoch #3703 (step 3703): 1.506554\n",
      "Batch #10\tAverage Generator Loss: 752.099173\tAverage Discriminator Loss: 0.000059\n",
      "\n",
      "Train time for epoch #3704 (step 3704): 1.323181\n",
      "Batch #10\tAverage Generator Loss: 623.301302\tAverage Discriminator Loss: 0.024686\n",
      "\n",
      "Train time for epoch #3705 (step 3705): 1.486866\n",
      "Batch #10\tAverage Generator Loss: 659.075610\tAverage Discriminator Loss: 0.009054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #3706 (step 3706): 1.495301\n",
      "Batch #10\tAverage Generator Loss: 653.661316\tAverage Discriminator Loss: 0.000057\n",
      "\n",
      "Train time for epoch #3707 (step 3707): 1.430247\n",
      "Batch #10\tAverage Generator Loss: 678.166891\tAverage Discriminator Loss: 0.000572\n",
      "\n",
      "Train time for epoch #3708 (step 3708): 1.360206\n",
      "Batch #10\tAverage Generator Loss: 664.085818\tAverage Discriminator Loss: 0.000091\n",
      "\n",
      "Train time for epoch #3709 (step 3709): 1.489271\n",
      "Batch #10\tAverage Generator Loss: 675.640704\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #3710 (step 3710): 1.393276\n",
      "Batch #10\tAverage Generator Loss: 600.148721\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #3711 (step 3711): 1.547760\n",
      "Batch #10\tAverage Generator Loss: 593.112347\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #3712 (step 3712): 1.291630\n",
      "Batch #10\tAverage Generator Loss: 698.334247\tAverage Discriminator Loss: 0.000157\n",
      "\n",
      "Train time for epoch #3713 (step 3713): 1.506880\n",
      "Batch #10\tAverage Generator Loss: 598.314407\tAverage Discriminator Loss: 0.000259\n",
      "\n",
      "Train time for epoch #3714 (step 3714): 1.541099\n",
      "Batch #10\tAverage Generator Loss: 558.948125\tAverage Discriminator Loss: 0.000532\n",
      "\n",
      "Train time for epoch #3715 (step 3715): 1.434484\n",
      "Batch #10\tAverage Generator Loss: 649.806274\tAverage Discriminator Loss: 0.000222\n",
      "\n",
      "Train time for epoch #3716 (step 3716): 1.437359\n",
      "Batch #10\tAverage Generator Loss: 632.898947\tAverage Discriminator Loss: 0.000100\n",
      "\n",
      "Train time for epoch #3717 (step 3717): 1.432298\n",
      "Batch #10\tAverage Generator Loss: 603.813507\tAverage Discriminator Loss: 0.000073\n",
      "\n",
      "Train time for epoch #3718 (step 3718): 1.440125\n",
      "Batch #10\tAverage Generator Loss: 607.264310\tAverage Discriminator Loss: 0.000287\n",
      "\n",
      "Train time for epoch #3719 (step 3719): 1.544398\n",
      "Batch #10\tAverage Generator Loss: 595.138718\tAverage Discriminator Loss: 0.000141\n",
      "\n",
      "Train time for epoch #3720 (step 3720): 1.322580\n",
      "Batch #10\tAverage Generator Loss: 616.619176\tAverage Discriminator Loss: 0.000146\n",
      "\n",
      "Train time for epoch #3721 (step 3721): 1.500240\n",
      "Batch #10\tAverage Generator Loss: 588.781238\tAverage Discriminator Loss: 0.000057\n",
      "\n",
      "Train time for epoch #3722 (step 3722): 1.554241\n",
      "Batch #10\tAverage Generator Loss: 554.752316\tAverage Discriminator Loss: 0.000054\n",
      "\n",
      "Train time for epoch #3723 (step 3723): 1.439596\n",
      "Batch #10\tAverage Generator Loss: 629.072580\tAverage Discriminator Loss: 0.000032\n",
      "\n",
      "Train time for epoch #3724 (step 3724): 1.480850\n",
      "Batch #10\tAverage Generator Loss: 581.686440\tAverage Discriminator Loss: 0.127582\n",
      "\n",
      "Train time for epoch #3725 (step 3725): 1.503755\n",
      "Batch #10\tAverage Generator Loss: 562.044354\tAverage Discriminator Loss: 0.004702\n",
      "\n",
      "Train time for epoch #3726 (step 3726): 1.414713\n",
      "Batch #10\tAverage Generator Loss: 544.360156\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #3727 (step 3727): 1.482228\n",
      "Batch #10\tAverage Generator Loss: 624.674353\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #3728 (step 3728): 1.482328\n",
      "Batch #10\tAverage Generator Loss: 613.938229\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #3729 (step 3729): 1.333298\n",
      "Batch #10\tAverage Generator Loss: 556.753802\tAverage Discriminator Loss: 0.051498\n",
      "\n",
      "Train time for epoch #3730 (step 3730): 1.534913\n",
      "Batch #10\tAverage Generator Loss: 509.344229\tAverage Discriminator Loss: 0.016613\n",
      "\n",
      "Train time for epoch #3731 (step 3731): 1.478092\n",
      "Batch #10\tAverage Generator Loss: 500.001666\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #3732 (step 3732): 1.544383\n",
      "Batch #10\tAverage Generator Loss: 502.252036\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #3733 (step 3733): 1.363781\n",
      "Batch #10\tAverage Generator Loss: 475.132077\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #3734 (step 3734): 1.438796\n",
      "Batch #10\tAverage Generator Loss: 476.532294\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #3735 (step 3735): 1.540194\n",
      "Batch #10\tAverage Generator Loss: 533.060596\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #3736 (step 3736): 1.291700\n",
      "Batch #10\tAverage Generator Loss: 467.073969\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #3737 (step 3737): 1.464693\n",
      "Batch #10\tAverage Generator Loss: 495.339624\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #3738 (step 3738): 1.488429\n",
      "Batch #10\tAverage Generator Loss: 498.237357\tAverage Discriminator Loss: 0.000019\n",
      "\n",
      "Train time for epoch #3739 (step 3739): 1.448421\n",
      "Batch #10\tAverage Generator Loss: 422.103413\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #3740 (step 3740): 1.501151\n",
      "Batch #10\tAverage Generator Loss: 514.048596\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #3741 (step 3741): 1.406671\n",
      "Batch #10\tAverage Generator Loss: 477.476590\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #3742 (step 3742): 1.430627\n",
      "Batch #10\tAverage Generator Loss: 478.456537\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #3743 (step 3743): 1.447259\n",
      "Batch #10\tAverage Generator Loss: 491.858206\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #3744 (step 3744): 1.478412\n",
      "Batch #10\tAverage Generator Loss: 498.538098\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #3745 (step 3745): 1.350969\n",
      "Batch #10\tAverage Generator Loss: 474.471304\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #3746 (step 3746): 1.444436\n",
      "Batch #10\tAverage Generator Loss: 465.317677\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #3747 (step 3747): 1.534049\n",
      "Batch #10\tAverage Generator Loss: 469.194397\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #3748 (step 3748): 1.587194\n",
      "Batch #10\tAverage Generator Loss: 469.843353\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #3749 (step 3749): 1.341690\n",
      "Batch #10\tAverage Generator Loss: 456.683652\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #3750 (step 3750): 1.444792\n",
      "Batch #10\tAverage Generator Loss: 488.888858\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #3751 (step 3751): 1.444439\n",
      "Batch #10\tAverage Generator Loss: 498.988821\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #3752 (step 3752): 1.425266\n",
      "Batch #10\tAverage Generator Loss: 477.039447\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #3753 (step 3753): 1.302619\n",
      "Batch #10\tAverage Generator Loss: 450.287891\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #3754 (step 3754): 1.610857\n",
      "Batch #10\tAverage Generator Loss: 472.438849\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #3755 (step 3755): 1.495824\n",
      "Batch #10\tAverage Generator Loss: 453.155188\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #3756 (step 3756): 1.535868\n",
      "Batch #10\tAverage Generator Loss: 512.136023\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #3757 (step 3757): 1.327540\n",
      "Batch #10\tAverage Generator Loss: 452.575674\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #3758 (step 3758): 1.637079\n",
      "Batch #10\tAverage Generator Loss: 475.940131\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #3759 (step 3759): 1.437397\n",
      "Batch #10\tAverage Generator Loss: 495.972803\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #3760 (step 3760): 1.332680\n",
      "Batch #10\tAverage Generator Loss: 506.635562\tAverage Discriminator Loss: 0.005190\n",
      "\n",
      "Train time for epoch #3761 (step 3761): 1.698048\n",
      "Batch #10\tAverage Generator Loss: 504.686926\tAverage Discriminator Loss: 0.000104\n",
      "\n",
      "Train time for epoch #3762 (step 3762): 1.437763\n",
      "Batch #10\tAverage Generator Loss: 498.107935\tAverage Discriminator Loss: 0.000067\n",
      "\n",
      "Train time for epoch #3763 (step 3763): 1.505615\n",
      "Batch #10\tAverage Generator Loss: 478.257126\tAverage Discriminator Loss: 0.000020\n",
      "\n",
      "Train time for epoch #3764 (step 3764): 1.283458\n",
      "Batch #10\tAverage Generator Loss: 448.588159\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #3765 (step 3765): 1.603798\n",
      "Batch #10\tAverage Generator Loss: 483.799915\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #3766 (step 3766): 1.447406\n",
      "Batch #10\tAverage Generator Loss: 473.035233\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #3767 (step 3767): 1.567200\n",
      "Batch #10\tAverage Generator Loss: 475.235339\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #3768 (step 3768): 1.305094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 469.981293\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #3769 (step 3769): 1.434990\n",
      "Batch #10\tAverage Generator Loss: 468.519785\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #3770 (step 3770): 1.401819\n",
      "Batch #10\tAverage Generator Loss: 479.511215\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #3771 (step 3771): 1.341508\n",
      "Batch #10\tAverage Generator Loss: 429.940187\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #3772 (step 3772): 1.440478\n",
      "Batch #10\tAverage Generator Loss: 500.505539\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #3773 (step 3773): 1.518076\n",
      "Batch #10\tAverage Generator Loss: 453.217929\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #3774 (step 3774): 1.335073\n",
      "Batch #10\tAverage Generator Loss: 425.299445\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #3775 (step 3775): 1.487900\n",
      "Batch #10\tAverage Generator Loss: 485.012172\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #3776 (step 3776): 1.535999\n",
      "Batch #10\tAverage Generator Loss: 514.481027\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #3777 (step 3777): 1.451492\n",
      "Batch #10\tAverage Generator Loss: 453.504164\tAverage Discriminator Loss: 0.000148\n",
      "\n",
      "Train time for epoch #3778 (step 3778): 1.289234\n",
      "Batch #10\tAverage Generator Loss: 473.256845\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #3779 (step 3779): 1.436749\n",
      "Batch #10\tAverage Generator Loss: 489.244875\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #3780 (step 3780): 1.460107\n",
      "Batch #10\tAverage Generator Loss: 512.291077\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #3781 (step 3781): 1.530435\n",
      "Batch #10\tAverage Generator Loss: 494.505377\tAverage Discriminator Loss: 0.000023\n",
      "\n",
      "Train time for epoch #3782 (step 3782): 1.328353\n",
      "Batch #10\tAverage Generator Loss: 486.643948\tAverage Discriminator Loss: 0.000108\n",
      "\n",
      "Train time for epoch #3783 (step 3783): 1.503618\n",
      "Batch #10\tAverage Generator Loss: 488.759225\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #3784 (step 3784): 1.491087\n",
      "Batch #10\tAverage Generator Loss: 493.153687\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #3785 (step 3785): 1.546019\n",
      "Batch #10\tAverage Generator Loss: 439.637285\tAverage Discriminator Loss: 0.003157\n",
      "\n",
      "Train time for epoch #3786 (step 3786): 1.452221\n",
      "Batch #10\tAverage Generator Loss: 478.188554\tAverage Discriminator Loss: 0.000138\n",
      "\n",
      "Train time for epoch #3787 (step 3787): 1.506886\n",
      "Batch #10\tAverage Generator Loss: 430.479706\tAverage Discriminator Loss: 0.000088\n",
      "\n",
      "Train time for epoch #3788 (step 3788): 1.555878\n",
      "Batch #10\tAverage Generator Loss: 476.087552\tAverage Discriminator Loss: 0.000062\n",
      "\n",
      "Train time for epoch #3789 (step 3789): 1.567736\n",
      "Batch #10\tAverage Generator Loss: 422.757242\tAverage Discriminator Loss: 0.000037\n",
      "\n",
      "Train time for epoch #3790 (step 3790): 1.275487\n",
      "Batch #10\tAverage Generator Loss: 497.643143\tAverage Discriminator Loss: 0.000033\n",
      "\n",
      "Train time for epoch #3791 (step 3791): 1.441393\n",
      "Batch #10\tAverage Generator Loss: 487.366348\tAverage Discriminator Loss: 0.000028\n",
      "\n",
      "Train time for epoch #3792 (step 3792): 1.551104\n",
      "Batch #10\tAverage Generator Loss: 482.219754\tAverage Discriminator Loss: 0.000026\n",
      "\n",
      "Train time for epoch #3793 (step 3793): 1.319205\n",
      "Batch #10\tAverage Generator Loss: 492.696097\tAverage Discriminator Loss: 0.000022\n",
      "\n",
      "Train time for epoch #3794 (step 3794): 1.549493\n",
      "Batch #10\tAverage Generator Loss: 513.754718\tAverage Discriminator Loss: 0.000021\n",
      "\n",
      "Train time for epoch #3795 (step 3795): 1.508467\n",
      "Batch #10\tAverage Generator Loss: 486.787115\tAverage Discriminator Loss: 0.222101\n",
      "\n",
      "Train time for epoch #3796 (step 3796): 1.322120\n",
      "Batch #10\tAverage Generator Loss: 506.865640\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #3797 (step 3797): 1.586874\n",
      "Batch #10\tAverage Generator Loss: 519.385406\tAverage Discriminator Loss: 0.000111\n",
      "\n",
      "Train time for epoch #3798 (step 3798): 1.546890\n",
      "Batch #10\tAverage Generator Loss: 539.479691\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #3799 (step 3799): 1.449855\n",
      "Batch #10\tAverage Generator Loss: 497.214993\tAverage Discriminator Loss: 0.000024\n",
      "\n",
      "Train time for epoch #3800 (step 3800): 1.314093\n",
      "Batch #10\tAverage Generator Loss: 480.401927\tAverage Discriminator Loss: 0.000030\n",
      "\n",
      "Train time for epoch #3801 (step 3801): 1.623946\n",
      "Batch #10\tAverage Generator Loss: 495.202512\tAverage Discriminator Loss: 0.000646\n",
      "\n",
      "Train time for epoch #3802 (step 3802): 1.433318\n",
      "Batch #10\tAverage Generator Loss: 464.035159\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #3803 (step 3803): 1.437225\n",
      "Batch #10\tAverage Generator Loss: 448.376404\tAverage Discriminator Loss: 0.000029\n",
      "\n",
      "Train time for epoch #3804 (step 3804): 1.331397\n",
      "Batch #10\tAverage Generator Loss: 530.750272\tAverage Discriminator Loss: 0.000078\n",
      "\n",
      "Train time for epoch #3805 (step 3805): 1.619045\n",
      "Batch #10\tAverage Generator Loss: 549.858890\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #3806 (step 3806): 1.556695\n",
      "Batch #10\tAverage Generator Loss: 518.981883\tAverage Discriminator Loss: 0.168610\n",
      "\n",
      "Train time for epoch #3807 (step 3807): 1.486923\n",
      "Batch #10\tAverage Generator Loss: 509.229297\tAverage Discriminator Loss: 0.048714\n",
      "\n",
      "Train time for epoch #3808 (step 3808): 1.333650\n",
      "Batch #10\tAverage Generator Loss: 536.854742\tAverage Discriminator Loss: 0.001671\n",
      "\n",
      "Train time for epoch #3809 (step 3809): 1.464612\n",
      "Batch #10\tAverage Generator Loss: 456.222154\tAverage Discriminator Loss: 0.000441\n",
      "\n",
      "Train time for epoch #3810 (step 3810): 1.410070\n",
      "Batch #10\tAverage Generator Loss: 394.475885\tAverage Discriminator Loss: 0.000123\n",
      "\n",
      "Train time for epoch #3811 (step 3811): 1.410063\n",
      "Batch #10\tAverage Generator Loss: 505.962727\tAverage Discriminator Loss: 0.000061\n",
      "\n",
      "Train time for epoch #3812 (step 3812): 1.578332\n",
      "Batch #10\tAverage Generator Loss: 519.666953\tAverage Discriminator Loss: 0.000101\n",
      "\n",
      "Train time for epoch #3813 (step 3813): 1.499386\n",
      "Batch #10\tAverage Generator Loss: 497.334662\tAverage Discriminator Loss: 0.000085\n",
      "\n",
      "Train time for epoch #3814 (step 3814): 1.325222\n",
      "Batch #10\tAverage Generator Loss: 529.043500\tAverage Discriminator Loss: 0.000081\n",
      "\n",
      "Train time for epoch #3815 (step 3815): 1.508577\n",
      "Batch #10\tAverage Generator Loss: 523.186108\tAverage Discriminator Loss: 0.000070\n",
      "\n",
      "Train time for epoch #3816 (step 3816): 1.438996\n",
      "Batch #10\tAverage Generator Loss: 455.569682\tAverage Discriminator Loss: 0.000053\n",
      "\n",
      "Train time for epoch #3817 (step 3817): 1.449537\n",
      "Batch #10\tAverage Generator Loss: 447.890973\tAverage Discriminator Loss: 0.000028\n",
      "\n",
      "Train time for epoch #3818 (step 3818): 1.296852\n",
      "Batch #10\tAverage Generator Loss: 397.177229\tAverage Discriminator Loss: 0.000035\n",
      "\n",
      "Train time for epoch #3819 (step 3819): 1.540906\n",
      "Batch #10\tAverage Generator Loss: 466.891022\tAverage Discriminator Loss: 0.000058\n",
      "\n",
      "Train time for epoch #3820 (step 3820): 1.440734\n",
      "Batch #10\tAverage Generator Loss: 474.993143\tAverage Discriminator Loss: 0.000055\n",
      "\n",
      "Train time for epoch #3821 (step 3821): 1.315635\n",
      "Batch #10\tAverage Generator Loss: 432.699310\tAverage Discriminator Loss: 0.000052\n",
      "\n",
      "Train time for epoch #3822 (step 3822): 1.540824\n",
      "Batch #10\tAverage Generator Loss: 484.528387\tAverage Discriminator Loss: 0.000042\n",
      "\n",
      "Train time for epoch #3823 (step 3823): 1.455797\n",
      "Batch #10\tAverage Generator Loss: 457.238551\tAverage Discriminator Loss: 0.000033\n",
      "\n",
      "Train time for epoch #3824 (step 3824): 1.416478\n",
      "Batch #10\tAverage Generator Loss: 466.935306\tAverage Discriminator Loss: 0.000039\n",
      "\n",
      "Train time for epoch #3825 (step 3825): 1.436235\n",
      "Batch #10\tAverage Generator Loss: 461.432085\tAverage Discriminator Loss: 0.000037\n",
      "\n",
      "Train time for epoch #3826 (step 3826): 1.365109\n",
      "Batch #10\tAverage Generator Loss: 514.425212\tAverage Discriminator Loss: 0.000028\n",
      "\n",
      "Train time for epoch #3827 (step 3827): 1.448897\n",
      "Batch #10\tAverage Generator Loss: 522.524359\tAverage Discriminator Loss: 0.000030\n",
      "\n",
      "Train time for epoch #3828 (step 3828): 1.491538\n",
      "Batch #10\tAverage Generator Loss: 571.356985\tAverage Discriminator Loss: 0.020794\n",
      "\n",
      "Train time for epoch #3829 (step 3829): 1.300383\n",
      "Batch #10\tAverage Generator Loss: 623.083099\tAverage Discriminator Loss: 0.015726\n",
      "\n",
      "Train time for epoch #3830 (step 3830): 1.554962\n",
      "Batch #10\tAverage Generator Loss: 638.156296\tAverage Discriminator Loss: 0.000002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #3831 (step 3831): 1.539346\n",
      "Batch #10\tAverage Generator Loss: 661.715065\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #3832 (step 3832): 1.456932\n",
      "Batch #10\tAverage Generator Loss: 571.636511\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #3833 (step 3833): 1.490325\n",
      "Batch #10\tAverage Generator Loss: 671.136844\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #3834 (step 3834): 1.499654\n",
      "Batch #10\tAverage Generator Loss: 692.370264\tAverage Discriminator Loss: 0.000365\n",
      "\n",
      "Train time for epoch #3835 (step 3835): 1.575883\n",
      "Batch #10\tAverage Generator Loss: 563.916208\tAverage Discriminator Loss: 0.127824\n",
      "\n",
      "Train time for epoch #3836 (step 3836): 1.456524\n",
      "Batch #10\tAverage Generator Loss: 601.520276\tAverage Discriminator Loss: 0.000538\n",
      "\n",
      "Train time for epoch #3837 (step 3837): 1.290320\n",
      "Batch #10\tAverage Generator Loss: 486.708633\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #3838 (step 3838): 1.447652\n",
      "Batch #10\tAverage Generator Loss: 532.775665\tAverage Discriminator Loss: 0.000051\n",
      "\n",
      "Train time for epoch #3839 (step 3839): 1.446603\n",
      "Batch #10\tAverage Generator Loss: 602.185706\tAverage Discriminator Loss: 0.000202\n",
      "\n",
      "Train time for epoch #3840 (step 3840): 1.696165\n",
      "Batch #10\tAverage Generator Loss: 514.262589\tAverage Discriminator Loss: 0.000626\n",
      "\n",
      "Train time for epoch #3841 (step 3841): 1.355866\n",
      "Batch #10\tAverage Generator Loss: 482.726776\tAverage Discriminator Loss: 0.000071\n",
      "\n",
      "Train time for epoch #3842 (step 3842): 1.507253\n",
      "Batch #10\tAverage Generator Loss: 586.637885\tAverage Discriminator Loss: 0.000113\n",
      "\n",
      "Train time for epoch #3843 (step 3843): 1.459742\n",
      "Batch #10\tAverage Generator Loss: 605.461499\tAverage Discriminator Loss: 0.000047\n",
      "\n",
      "Train time for epoch #3844 (step 3844): 1.396610\n",
      "Batch #10\tAverage Generator Loss: 534.798334\tAverage Discriminator Loss: 0.000754\n",
      "\n",
      "Train time for epoch #3845 (step 3845): 1.452909\n",
      "Batch #10\tAverage Generator Loss: 546.634579\tAverage Discriminator Loss: 0.000573\n",
      "\n",
      "Train time for epoch #3846 (step 3846): 1.444811\n",
      "Batch #10\tAverage Generator Loss: 572.263199\tAverage Discriminator Loss: 0.000065\n",
      "\n",
      "Train time for epoch #3847 (step 3847): 1.565378\n",
      "Batch #10\tAverage Generator Loss: 549.115445\tAverage Discriminator Loss: 0.000032\n",
      "\n",
      "Train time for epoch #3848 (step 3848): 1.345665\n",
      "Batch #10\tAverage Generator Loss: 576.741525\tAverage Discriminator Loss: 0.000028\n",
      "\n",
      "Train time for epoch #3849 (step 3849): 1.451784\n",
      "Batch #10\tAverage Generator Loss: 541.407214\tAverage Discriminator Loss: 0.000028\n",
      "\n",
      "Train time for epoch #3850 (step 3850): 1.543292\n",
      "Batch #10\tAverage Generator Loss: 550.214253\tAverage Discriminator Loss: 0.000023\n",
      "\n",
      "Train time for epoch #3851 (step 3851): 1.513480\n",
      "Batch #10\tAverage Generator Loss: 528.853300\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #3852 (step 3852): 1.294031\n",
      "Batch #10\tAverage Generator Loss: 530.194348\tAverage Discriminator Loss: 0.000025\n",
      "\n",
      "Train time for epoch #3853 (step 3853): 1.458229\n",
      "Batch #10\tAverage Generator Loss: 598.412120\tAverage Discriminator Loss: 0.000024\n",
      "\n",
      "Train time for epoch #3854 (step 3854): 1.461790\n",
      "Batch #10\tAverage Generator Loss: 537.083157\tAverage Discriminator Loss: 0.000026\n",
      "\n",
      "Train time for epoch #3855 (step 3855): 1.554522\n",
      "Batch #10\tAverage Generator Loss: 587.068378\tAverage Discriminator Loss: 0.000024\n",
      "\n",
      "Train time for epoch #3856 (step 3856): 1.396152\n",
      "Batch #10\tAverage Generator Loss: 537.792535\tAverage Discriminator Loss: 0.000023\n",
      "\n",
      "Train time for epoch #3857 (step 3857): 1.507686\n",
      "Batch #10\tAverage Generator Loss: 528.586517\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #3858 (step 3858): 1.503905\n",
      "Batch #10\tAverage Generator Loss: 517.351115\tAverage Discriminator Loss: 0.000022\n",
      "\n",
      "Train time for epoch #3859 (step 3859): 1.507374\n",
      "Batch #10\tAverage Generator Loss: 513.792429\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #3860 (step 3860): 1.409410\n",
      "Batch #10\tAverage Generator Loss: 533.543262\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #3861 (step 3861): 1.596076\n",
      "Batch #10\tAverage Generator Loss: 673.836523\tAverage Discriminator Loss: 0.000019\n",
      "\n",
      "Train time for epoch #3862 (step 3862): 1.603568\n",
      "Batch #10\tAverage Generator Loss: 563.145532\tAverage Discriminator Loss: 0.000021\n",
      "\n",
      "Train time for epoch #3863 (step 3863): 1.459789\n",
      "Batch #10\tAverage Generator Loss: 602.150356\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #3864 (step 3864): 1.334506\n",
      "Batch #10\tAverage Generator Loss: 553.715552\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #3865 (step 3865): 1.451605\n",
      "Batch #10\tAverage Generator Loss: 605.600203\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #3866 (step 3866): 1.448553\n",
      "Batch #10\tAverage Generator Loss: 597.643680\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #3867 (step 3867): 1.352989\n",
      "Batch #10\tAverage Generator Loss: 509.565816\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #3868 (step 3868): 1.553023\n",
      "Batch #10\tAverage Generator Loss: 566.990897\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #3869 (step 3869): 1.557379\n",
      "Batch #10\tAverage Generator Loss: 461.617952\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #3870 (step 3870): 1.491085\n",
      "Batch #10\tAverage Generator Loss: 531.612637\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #3871 (step 3871): 1.381313\n",
      "Batch #10\tAverage Generator Loss: 554.332898\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #3872 (step 3872): 1.448663\n",
      "Batch #10\tAverage Generator Loss: 515.464771\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #3873 (step 3873): 1.535454\n",
      "Batch #10\tAverage Generator Loss: 464.269257\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #3874 (step 3874): 1.440316\n",
      "Batch #10\tAverage Generator Loss: 621.174316\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #3875 (step 3875): 1.482536\n",
      "Batch #10\tAverage Generator Loss: 536.945511\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #3876 (step 3876): 1.488919\n",
      "Batch #10\tAverage Generator Loss: 487.633859\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #3877 (step 3877): 1.562117\n",
      "Batch #10\tAverage Generator Loss: 542.972842\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #3878 (step 3878): 1.367973\n",
      "Batch #10\tAverage Generator Loss: 588.738046\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #3879 (step 3879): 1.495586\n",
      "Batch #10\tAverage Generator Loss: 578.702090\tAverage Discriminator Loss: 0.000024\n",
      "\n",
      "Train time for epoch #3880 (step 3880): 1.439529\n",
      "Batch #10\tAverage Generator Loss: 548.557291\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #3881 (step 3881): 1.330020\n",
      "Batch #10\tAverage Generator Loss: 536.252414\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #3882 (step 3882): 1.560769\n",
      "Batch #10\tAverage Generator Loss: 536.951724\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #3883 (step 3883): 1.504116\n",
      "Batch #10\tAverage Generator Loss: 507.078700\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #3884 (step 3884): 1.452117\n",
      "Batch #10\tAverage Generator Loss: 553.234308\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #3885 (step 3885): 1.566434\n",
      "Batch #10\tAverage Generator Loss: 599.867776\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #3886 (step 3886): 1.439279\n",
      "Batch #10\tAverage Generator Loss: 569.091309\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #3887 (step 3887): 1.487399\n",
      "Batch #10\tAverage Generator Loss: 554.430298\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #3888 (step 3888): 1.452906\n",
      "Batch #10\tAverage Generator Loss: 491.816533\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #3889 (step 3889): 1.502960\n",
      "Batch #10\tAverage Generator Loss: 566.193948\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #3890 (step 3890): 1.282308\n",
      "Batch #10\tAverage Generator Loss: 553.276651\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #3891 (step 3891): 1.498322\n",
      "Batch #10\tAverage Generator Loss: 432.796225\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #3892 (step 3892): 1.453427\n",
      "Batch #10\tAverage Generator Loss: 553.241821\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #3893 (step 3893): 1.377015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 630.106680\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #3894 (step 3894): 1.547457\n",
      "Batch #10\tAverage Generator Loss: 553.569522\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #3895 (step 3895): 1.494697\n",
      "Batch #10\tAverage Generator Loss: 462.354999\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #3896 (step 3896): 1.507651\n",
      "Batch #10\tAverage Generator Loss: 532.336322\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #3897 (step 3897): 1.453533\n",
      "Batch #10\tAverage Generator Loss: 517.690176\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #3898 (step 3898): 1.492045\n",
      "Batch #10\tAverage Generator Loss: 560.976114\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #3899 (step 3899): 1.500054\n",
      "Batch #10\tAverage Generator Loss: 463.470871\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #3900 (step 3900): 1.381709\n",
      "Batch #10\tAverage Generator Loss: 444.766144\tAverage Discriminator Loss: 0.025186\n",
      "\n",
      "Train time for epoch #3901 (step 3901): 1.596537\n",
      "Batch #10\tAverage Generator Loss: 494.009634\tAverage Discriminator Loss: 0.000422\n",
      "\n",
      "Train time for epoch #3902 (step 3902): 1.620209\n",
      "Batch #10\tAverage Generator Loss: 393.554082\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #3903 (step 3903): 1.335720\n",
      "Batch #10\tAverage Generator Loss: 439.369139\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #3904 (step 3904): 1.495569\n",
      "Batch #10\tAverage Generator Loss: 464.856754\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #3905 (step 3905): 1.494624\n",
      "Batch #10\tAverage Generator Loss: 482.905667\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #3906 (step 3906): 1.500773\n",
      "Batch #10\tAverage Generator Loss: 453.756680\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #3907 (step 3907): 1.302989\n",
      "Batch #10\tAverage Generator Loss: 472.241364\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #3908 (step 3908): 1.448814\n",
      "Batch #10\tAverage Generator Loss: 471.057501\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #3909 (step 3909): 1.549938\n",
      "Batch #10\tAverage Generator Loss: 399.531860\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #3910 (step 3910): 1.462187\n",
      "Batch #10\tAverage Generator Loss: 452.314429\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #3911 (step 3911): 1.446487\n",
      "Batch #10\tAverage Generator Loss: 426.013583\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #3912 (step 3912): 1.575614\n",
      "Batch #10\tAverage Generator Loss: 434.220021\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #3913 (step 3913): 1.380941\n",
      "Batch #10\tAverage Generator Loss: 456.985583\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #3914 (step 3914): 1.539121\n",
      "Batch #10\tAverage Generator Loss: 444.642624\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #3915 (step 3915): 1.546321\n",
      "Batch #10\tAverage Generator Loss: 417.790228\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #3916 (step 3916): 1.494630\n",
      "Batch #10\tAverage Generator Loss: 445.703629\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #3917 (step 3917): 1.656355\n",
      "Batch #10\tAverage Generator Loss: 421.893576\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #3918 (step 3918): 1.285869\n",
      "Batch #10\tAverage Generator Loss: 379.244678\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #3919 (step 3919): 1.492804\n",
      "Batch #10\tAverage Generator Loss: 443.170885\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #3920 (step 3920): 1.452908\n",
      "Batch #10\tAverage Generator Loss: 460.161475\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #3921 (step 3921): 1.363792\n",
      "Batch #10\tAverage Generator Loss: 430.062436\tAverage Discriminator Loss: 0.028996\n",
      "\n",
      "Train time for epoch #3922 (step 3922): 1.472628\n",
      "Batch #10\tAverage Generator Loss: 412.516699\tAverage Discriminator Loss: 0.000040\n",
      "\n",
      "Train time for epoch #3923 (step 3923): 1.503405\n",
      "Batch #10\tAverage Generator Loss: 392.777605\tAverage Discriminator Loss: 0.000022\n",
      "\n",
      "Train time for epoch #3924 (step 3924): 1.448037\n",
      "Batch #10\tAverage Generator Loss: 382.689124\tAverage Discriminator Loss: 0.000022\n",
      "\n",
      "Train time for epoch #3925 (step 3925): 1.294418\n",
      "Batch #10\tAverage Generator Loss: 365.354088\tAverage Discriminator Loss: 0.000020\n",
      "\n",
      "Train time for epoch #3926 (step 3926): 1.497012\n",
      "Batch #10\tAverage Generator Loss: 384.888950\tAverage Discriminator Loss: 0.000019\n",
      "\n",
      "Train time for epoch #3927 (step 3927): 1.485708\n",
      "Batch #10\tAverage Generator Loss: 398.123314\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #3928 (step 3928): 1.530519\n",
      "Batch #10\tAverage Generator Loss: 384.826472\tAverage Discriminator Loss: 0.020582\n",
      "\n",
      "Train time for epoch #3929 (step 3929): 1.397642\n",
      "Batch #10\tAverage Generator Loss: 388.236248\tAverage Discriminator Loss: 0.078051\n",
      "\n",
      "Train time for epoch #3930 (step 3930): 1.483804\n",
      "Batch #10\tAverage Generator Loss: 460.316507\tAverage Discriminator Loss: 0.000409\n",
      "\n",
      "Train time for epoch #3931 (step 3931): 1.485253\n",
      "Batch #10\tAverage Generator Loss: 436.586546\tAverage Discriminator Loss: 0.009090\n",
      "\n",
      "Train time for epoch #3932 (step 3932): 1.502183\n",
      "Batch #10\tAverage Generator Loss: 518.566159\tAverage Discriminator Loss: 0.000076\n",
      "\n",
      "Train time for epoch #3933 (step 3933): 1.335220\n",
      "Batch #10\tAverage Generator Loss: 485.837274\tAverage Discriminator Loss: 0.000086\n",
      "\n",
      "Train time for epoch #3934 (step 3934): 1.536615\n",
      "Batch #10\tAverage Generator Loss: 445.537146\tAverage Discriminator Loss: 0.000100\n",
      "\n",
      "Train time for epoch #3935 (step 3935): 1.444381\n",
      "Batch #10\tAverage Generator Loss: 438.595001\tAverage Discriminator Loss: 0.000475\n",
      "\n",
      "Train time for epoch #3936 (step 3936): 1.439312\n",
      "Batch #10\tAverage Generator Loss: 443.984140\tAverage Discriminator Loss: 0.000131\n",
      "\n",
      "Train time for epoch #3937 (step 3937): 1.432153\n",
      "Batch #10\tAverage Generator Loss: 460.650281\tAverage Discriminator Loss: 0.000110\n",
      "\n",
      "Train time for epoch #3938 (step 3938): 1.549166\n",
      "Batch #10\tAverage Generator Loss: 489.216498\tAverage Discriminator Loss: 0.000093\n",
      "\n",
      "Train time for epoch #3939 (step 3939): 1.594038\n",
      "Batch #10\tAverage Generator Loss: 449.105089\tAverage Discriminator Loss: 0.000074\n",
      "\n",
      "Train time for epoch #3940 (step 3940): 1.378161\n",
      "Batch #10\tAverage Generator Loss: 497.902649\tAverage Discriminator Loss: 0.000072\n",
      "\n",
      "Train time for epoch #3941 (step 3941): 1.565024\n",
      "Batch #10\tAverage Generator Loss: 468.818527\tAverage Discriminator Loss: 0.000066\n",
      "\n",
      "Train time for epoch #3942 (step 3942): 1.603596\n",
      "Batch #10\tAverage Generator Loss: 474.082846\tAverage Discriminator Loss: 0.011533\n",
      "\n",
      "Train time for epoch #3943 (step 3943): 1.543164\n",
      "Batch #10\tAverage Generator Loss: 509.533429\tAverage Discriminator Loss: 0.000068\n",
      "\n",
      "Train time for epoch #3944 (step 3944): 1.336071\n",
      "Batch #10\tAverage Generator Loss: 411.550334\tAverage Discriminator Loss: 0.000047\n",
      "\n",
      "Train time for epoch #3945 (step 3945): 1.586656\n",
      "Batch #10\tAverage Generator Loss: 433.454703\tAverage Discriminator Loss: 0.000119\n",
      "\n",
      "Train time for epoch #3946 (step 3946): 1.505074\n",
      "Batch #10\tAverage Generator Loss: 429.653949\tAverage Discriminator Loss: 0.000038\n",
      "\n",
      "Train time for epoch #3947 (step 3947): 1.283056\n",
      "Batch #10\tAverage Generator Loss: 501.258368\tAverage Discriminator Loss: 0.011060\n",
      "\n",
      "Train time for epoch #3948 (step 3948): 1.453717\n",
      "Batch #10\tAverage Generator Loss: 509.964645\tAverage Discriminator Loss: 0.000095\n",
      "\n",
      "Train time for epoch #3949 (step 3949): 1.507336\n",
      "Batch #10\tAverage Generator Loss: 449.259531\tAverage Discriminator Loss: 0.000130\n",
      "\n",
      "Train time for epoch #3950 (step 3950): 1.380575\n",
      "Batch #10\tAverage Generator Loss: 425.320920\tAverage Discriminator Loss: 0.000270\n",
      "\n",
      "Train time for epoch #3951 (step 3951): 1.517026\n",
      "Batch #10\tAverage Generator Loss: 521.523932\tAverage Discriminator Loss: 0.000108\n",
      "\n",
      "Train time for epoch #3952 (step 3952): 1.588075\n",
      "Batch #10\tAverage Generator Loss: 452.980971\tAverage Discriminator Loss: 0.000096\n",
      "\n",
      "Train time for epoch #3953 (step 3953): 1.291111\n",
      "Batch #10\tAverage Generator Loss: 528.557379\tAverage Discriminator Loss: 0.000109\n",
      "\n",
      "Train time for epoch #3954 (step 3954): 1.566367\n",
      "Batch #10\tAverage Generator Loss: 483.004820\tAverage Discriminator Loss: 0.000130\n",
      "\n",
      "Train time for epoch #3955 (step 3955): 1.534258\n",
      "Batch #10\tAverage Generator Loss: 454.545414\tAverage Discriminator Loss: 0.000118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #3956 (step 3956): 1.446289\n",
      "Batch #10\tAverage Generator Loss: 515.332977\tAverage Discriminator Loss: 0.000085\n",
      "\n",
      "Train time for epoch #3957 (step 3957): 1.298767\n",
      "Batch #10\tAverage Generator Loss: 455.137542\tAverage Discriminator Loss: 0.000080\n",
      "\n",
      "Train time for epoch #3958 (step 3958): 1.460253\n",
      "Batch #10\tAverage Generator Loss: 508.962262\tAverage Discriminator Loss: 0.000074\n",
      "\n",
      "Train time for epoch #3959 (step 3959): 1.504419\n",
      "Batch #10\tAverage Generator Loss: 546.218561\tAverage Discriminator Loss: 0.000069\n",
      "\n",
      "Train time for epoch #3960 (step 3960): 1.495980\n",
      "Batch #10\tAverage Generator Loss: 475.567403\tAverage Discriminator Loss: 0.000051\n",
      "\n",
      "Train time for epoch #3961 (step 3961): 1.303015\n",
      "Batch #10\tAverage Generator Loss: 518.521921\tAverage Discriminator Loss: 0.000053\n",
      "\n",
      "Train time for epoch #3962 (step 3962): 1.408389\n",
      "Batch #10\tAverage Generator Loss: 484.090715\tAverage Discriminator Loss: 0.010096\n",
      "\n",
      "Train time for epoch #3963 (step 3963): 1.599915\n",
      "Batch #10\tAverage Generator Loss: 522.127536\tAverage Discriminator Loss: 0.000305\n",
      "\n",
      "Train time for epoch #3964 (step 3964): 1.420184\n",
      "Batch #10\tAverage Generator Loss: 508.430698\tAverage Discriminator Loss: 0.000429\n",
      "\n",
      "Train time for epoch #3965 (step 3965): 1.613241\n",
      "Batch #10\tAverage Generator Loss: 562.562686\tAverage Discriminator Loss: 0.000070\n",
      "\n",
      "Train time for epoch #3966 (step 3966): 1.700038\n",
      "Batch #10\tAverage Generator Loss: 509.866565\tAverage Discriminator Loss: 0.000042\n",
      "\n",
      "Train time for epoch #3967 (step 3967): 1.559651\n",
      "Batch #10\tAverage Generator Loss: 570.015067\tAverage Discriminator Loss: 0.000037\n",
      "\n",
      "Train time for epoch #3968 (step 3968): 1.285774\n",
      "Batch #10\tAverage Generator Loss: 564.557639\tAverage Discriminator Loss: 0.000040\n",
      "\n",
      "Train time for epoch #3969 (step 3969): 1.543061\n",
      "Batch #10\tAverage Generator Loss: 541.383664\tAverage Discriminator Loss: 0.000039\n",
      "\n",
      "Train time for epoch #3970 (step 3970): 1.592512\n",
      "Batch #10\tAverage Generator Loss: 491.909747\tAverage Discriminator Loss: 0.000034\n",
      "\n",
      "Train time for epoch #3971 (step 3971): 1.475638\n",
      "Batch #10\tAverage Generator Loss: 529.676227\tAverage Discriminator Loss: 0.000036\n",
      "\n",
      "Train time for epoch #3972 (step 3972): 1.375300\n",
      "Batch #10\tAverage Generator Loss: 598.705612\tAverage Discriminator Loss: 0.000033\n",
      "\n",
      "Train time for epoch #3973 (step 3973): 1.495154\n",
      "Batch #10\tAverage Generator Loss: 423.695319\tAverage Discriminator Loss: 0.001796\n",
      "\n",
      "Train time for epoch #3974 (step 3974): 1.496574\n",
      "Batch #10\tAverage Generator Loss: 535.006345\tAverage Discriminator Loss: 0.000117\n",
      "\n",
      "Train time for epoch #3975 (step 3975): 1.323574\n",
      "Batch #10\tAverage Generator Loss: 535.006107\tAverage Discriminator Loss: 0.000317\n",
      "\n",
      "Train time for epoch #3976 (step 3976): 1.514699\n",
      "Batch #10\tAverage Generator Loss: 523.806995\tAverage Discriminator Loss: 0.000058\n",
      "\n",
      "Train time for epoch #3977 (step 3977): 1.457854\n",
      "Batch #10\tAverage Generator Loss: 486.250421\tAverage Discriminator Loss: 0.000064\n",
      "\n",
      "Train time for epoch #3978 (step 3978): 1.427769\n",
      "Batch #10\tAverage Generator Loss: 481.230603\tAverage Discriminator Loss: 0.000054\n",
      "\n",
      "Train time for epoch #3979 (step 3979): 1.681473\n",
      "Batch #10\tAverage Generator Loss: 529.911533\tAverage Discriminator Loss: 0.000069\n",
      "\n",
      "Train time for epoch #3980 (step 3980): 1.504594\n",
      "Batch #10\tAverage Generator Loss: 475.773618\tAverage Discriminator Loss: 0.000066\n",
      "\n",
      "Train time for epoch #3981 (step 3981): 1.551815\n",
      "Batch #10\tAverage Generator Loss: 497.591913\tAverage Discriminator Loss: 0.000037\n",
      "\n",
      "Train time for epoch #3982 (step 3982): 1.444028\n",
      "Batch #10\tAverage Generator Loss: 458.204535\tAverage Discriminator Loss: 0.000052\n",
      "\n",
      "Train time for epoch #3983 (step 3983): 1.447321\n",
      "Batch #10\tAverage Generator Loss: 525.143454\tAverage Discriminator Loss: 0.000051\n",
      "\n",
      "Train time for epoch #3984 (step 3984): 1.532832\n",
      "Batch #10\tAverage Generator Loss: 498.676231\tAverage Discriminator Loss: 0.000046\n",
      "\n",
      "Train time for epoch #3985 (step 3985): 1.328323\n",
      "Batch #10\tAverage Generator Loss: 454.579254\tAverage Discriminator Loss: 0.000045\n",
      "\n",
      "Train time for epoch #3986 (step 3986): 1.442625\n",
      "Batch #10\tAverage Generator Loss: 525.606848\tAverage Discriminator Loss: 0.000047\n",
      "\n",
      "Train time for epoch #3987 (step 3987): 1.460705\n",
      "Batch #10\tAverage Generator Loss: 481.175754\tAverage Discriminator Loss: 0.002549\n",
      "\n",
      "Train time for epoch #3988 (step 3988): 1.599307\n",
      "Batch #10\tAverage Generator Loss: 507.512375\tAverage Discriminator Loss: 0.000067\n",
      "\n",
      "Train time for epoch #3989 (step 3989): 1.446930\n",
      "Batch #10\tAverage Generator Loss: 524.066519\tAverage Discriminator Loss: 0.000040\n",
      "\n",
      "Train time for epoch #3990 (step 3990): 1.456024\n",
      "Batch #10\tAverage Generator Loss: 496.628677\tAverage Discriminator Loss: 0.000030\n",
      "\n",
      "Train time for epoch #3991 (step 3991): 1.504685\n",
      "Batch #10\tAverage Generator Loss: 578.219821\tAverage Discriminator Loss: 0.000027\n",
      "\n",
      "Train time for epoch #3992 (step 3992): 1.443336\n",
      "Batch #10\tAverage Generator Loss: 559.781583\tAverage Discriminator Loss: 0.000061\n",
      "\n",
      "Train time for epoch #3993 (step 3993): 1.341078\n",
      "Batch #10\tAverage Generator Loss: 525.461121\tAverage Discriminator Loss: 0.000030\n",
      "\n",
      "Train time for epoch #3994 (step 3994): 1.559865\n",
      "Batch #10\tAverage Generator Loss: 521.472971\tAverage Discriminator Loss: 0.000853\n",
      "\n",
      "Train time for epoch #3995 (step 3995): 1.529024\n",
      "Batch #10\tAverage Generator Loss: 557.281680\tAverage Discriminator Loss: 0.000042\n",
      "\n",
      "Train time for epoch #3996 (step 3996): 1.474638\n",
      "Batch #10\tAverage Generator Loss: 468.715326\tAverage Discriminator Loss: 0.000068\n",
      "\n",
      "Train time for epoch #3997 (step 3997): 1.419482\n",
      "Batch #10\tAverage Generator Loss: 479.992560\tAverage Discriminator Loss: 0.000109\n",
      "\n",
      "Train time for epoch #3998 (step 3998): 1.491608\n",
      "Batch #10\tAverage Generator Loss: 537.915823\tAverage Discriminator Loss: 0.000060\n",
      "\n",
      "Train time for epoch #3999 (step 3999): 1.522910\n",
      "Batch #10\tAverage Generator Loss: 590.507492\tAverage Discriminator Loss: 0.000103\n",
      "\n",
      "Train time for epoch #4000 (step 4000): 1.482009\n",
      "Batch #10\tAverage Generator Loss: 523.595718\tAverage Discriminator Loss: 0.000058\n",
      "\n",
      "Train time for epoch #4001 (step 4001): 1.520620\n",
      "Batch #10\tAverage Generator Loss: 490.560858\tAverage Discriminator Loss: 0.000041\n",
      "\n",
      "Train time for epoch #4002 (step 4002): 1.451032\n",
      "Batch #10\tAverage Generator Loss: 435.071906\tAverage Discriminator Loss: 0.000052\n",
      "\n",
      "Train time for epoch #4003 (step 4003): 1.458481\n",
      "Batch #10\tAverage Generator Loss: 492.463672\tAverage Discriminator Loss: 0.000047\n",
      "\n",
      "Train time for epoch #4004 (step 4004): 1.342085\n",
      "Batch #10\tAverage Generator Loss: 540.191104\tAverage Discriminator Loss: 0.000040\n",
      "\n",
      "Train time for epoch #4005 (step 4005): 1.593099\n",
      "Batch #10\tAverage Generator Loss: 559.104340\tAverage Discriminator Loss: 0.000039\n",
      "\n",
      "Train time for epoch #4006 (step 4006): 1.502882\n",
      "Batch #10\tAverage Generator Loss: 569.951218\tAverage Discriminator Loss: 0.000036\n",
      "\n",
      "Train time for epoch #4007 (step 4007): 1.452172\n",
      "Batch #10\tAverage Generator Loss: 558.234390\tAverage Discriminator Loss: 0.000034\n",
      "\n",
      "Train time for epoch #4008 (step 4008): 1.392817\n",
      "Batch #10\tAverage Generator Loss: 523.936876\tAverage Discriminator Loss: 0.000034\n",
      "\n",
      "Train time for epoch #4009 (step 4009): 1.437365\n",
      "Batch #10\tAverage Generator Loss: 510.525275\tAverage Discriminator Loss: 0.000032\n",
      "\n",
      "Train time for epoch #4010 (step 4010): 1.461630\n",
      "Batch #10\tAverage Generator Loss: 513.050972\tAverage Discriminator Loss: 0.000029\n",
      "\n",
      "Train time for epoch #4011 (step 4011): 1.293900\n",
      "Batch #10\tAverage Generator Loss: 476.800850\tAverage Discriminator Loss: 0.000027\n",
      "\n",
      "Train time for epoch #4012 (step 4012): 1.613045\n",
      "Batch #10\tAverage Generator Loss: 540.699197\tAverage Discriminator Loss: 0.000027\n",
      "\n",
      "Train time for epoch #4013 (step 4013): 1.542671\n",
      "Batch #10\tAverage Generator Loss: 491.321802\tAverage Discriminator Loss: 0.000026\n",
      "\n",
      "Train time for epoch #4014 (step 4014): 1.451082\n",
      "Batch #10\tAverage Generator Loss: 566.001431\tAverage Discriminator Loss: 0.000026\n",
      "\n",
      "Train time for epoch #4015 (step 4015): 1.293600\n",
      "Batch #10\tAverage Generator Loss: 470.448648\tAverage Discriminator Loss: 0.000027\n",
      "\n",
      "Train time for epoch #4016 (step 4016): 1.456653\n",
      "Batch #10\tAverage Generator Loss: 456.167659\tAverage Discriminator Loss: 0.000032\n",
      "\n",
      "Train time for epoch #4017 (step 4017): 1.519816\n",
      "Batch #10\tAverage Generator Loss: 502.660718\tAverage Discriminator Loss: 0.000025\n",
      "\n",
      "Train time for epoch #4018 (step 4018): 1.310767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 537.481328\tAverage Discriminator Loss: 0.000020\n",
      "\n",
      "Train time for epoch #4019 (step 4019): 1.483922\n",
      "Batch #10\tAverage Generator Loss: 582.690009\tAverage Discriminator Loss: 0.000023\n",
      "\n",
      "Train time for epoch #4020 (step 4020): 1.559930\n",
      "Batch #10\tAverage Generator Loss: 460.460620\tAverage Discriminator Loss: 0.000021\n",
      "\n",
      "Train time for epoch #4021 (step 4021): 1.583189\n",
      "Batch #10\tAverage Generator Loss: 580.690274\tAverage Discriminator Loss: 0.000019\n",
      "\n",
      "Train time for epoch #4022 (step 4022): 1.389138\n",
      "Batch #10\tAverage Generator Loss: 521.848447\tAverage Discriminator Loss: 0.000021\n",
      "\n",
      "Train time for epoch #4023 (step 4023): 1.485464\n",
      "Batch #10\tAverage Generator Loss: 524.623801\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #4024 (step 4024): 1.508605\n",
      "Batch #10\tAverage Generator Loss: 501.144745\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #4025 (step 4025): 1.386364\n",
      "Batch #10\tAverage Generator Loss: 577.710602\tAverage Discriminator Loss: 0.000020\n",
      "\n",
      "Train time for epoch #4026 (step 4026): 1.531611\n",
      "Batch #10\tAverage Generator Loss: 537.339322\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #4027 (step 4027): 1.453200\n",
      "Batch #10\tAverage Generator Loss: 568.984921\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #4028 (step 4028): 1.601726\n",
      "Batch #10\tAverage Generator Loss: 549.842499\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #4029 (step 4029): 1.359359\n",
      "Batch #10\tAverage Generator Loss: 505.583176\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #4030 (step 4030): 1.507788\n",
      "Batch #10\tAverage Generator Loss: 477.029173\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #4031 (step 4031): 1.621884\n",
      "Batch #10\tAverage Generator Loss: 504.926409\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #4032 (step 4032): 1.396770\n",
      "Batch #10\tAverage Generator Loss: 550.812045\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #4033 (step 4033): 1.442072\n",
      "Batch #10\tAverage Generator Loss: 560.404715\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #4034 (step 4034): 1.526416\n",
      "Batch #10\tAverage Generator Loss: 528.112195\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #4035 (step 4035): 1.557445\n",
      "Batch #10\tAverage Generator Loss: 526.000098\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #4036 (step 4036): 1.303804\n",
      "Batch #10\tAverage Generator Loss: 535.731378\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #4037 (step 4037): 1.571633\n",
      "Batch #10\tAverage Generator Loss: 498.816460\tAverage Discriminator Loss: 0.078126\n",
      "\n",
      "Train time for epoch #4038 (step 4038): 1.569586\n",
      "Batch #10\tAverage Generator Loss: 405.902563\tAverage Discriminator Loss: 0.008526\n",
      "\n",
      "Train time for epoch #4039 (step 4039): 1.446145\n",
      "Batch #10\tAverage Generator Loss: 382.965076\tAverage Discriminator Loss: 0.001795\n",
      "\n",
      "Train time for epoch #4040 (step 4040): 1.312625\n",
      "Batch #10\tAverage Generator Loss: 426.905457\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #4041 (step 4041): 1.457832\n",
      "Batch #10\tAverage Generator Loss: 465.631683\tAverage Discriminator Loss: 0.000133\n",
      "\n",
      "Train time for epoch #4042 (step 4042): 1.520073\n",
      "Batch #10\tAverage Generator Loss: 466.537804\tAverage Discriminator Loss: 0.005893\n",
      "\n",
      "Train time for epoch #4043 (step 4043): 1.573112\n",
      "Batch #10\tAverage Generator Loss: 442.085387\tAverage Discriminator Loss: 0.017211\n",
      "\n",
      "Train time for epoch #4044 (step 4044): 1.280031\n",
      "Batch #10\tAverage Generator Loss: 499.345139\tAverage Discriminator Loss: 0.007818\n",
      "\n",
      "Train time for epoch #4045 (step 4045): 1.459064\n",
      "Batch #10\tAverage Generator Loss: 694.994255\tAverage Discriminator Loss: 0.000779\n",
      "\n",
      "Train time for epoch #4046 (step 4046): 1.602458\n",
      "Batch #10\tAverage Generator Loss: 732.895758\tAverage Discriminator Loss: 0.000028\n",
      "\n",
      "Train time for epoch #4047 (step 4047): 1.500808\n",
      "Batch #10\tAverage Generator Loss: 660.065588\tAverage Discriminator Loss: 0.000028\n",
      "\n",
      "Train time for epoch #4048 (step 4048): 1.398249\n",
      "Batch #10\tAverage Generator Loss: 698.006296\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #4049 (step 4049): 1.429422\n",
      "Batch #10\tAverage Generator Loss: 712.338834\tAverage Discriminator Loss: 0.000019\n",
      "\n",
      "Train time for epoch #4050 (step 4050): 1.454221\n",
      "Batch #10\tAverage Generator Loss: 666.243622\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #4051 (step 4051): 1.378052\n",
      "Batch #10\tAverage Generator Loss: 705.442084\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #4052 (step 4052): 1.510427\n",
      "Batch #10\tAverage Generator Loss: 698.877344\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #4053 (step 4053): 1.492604\n",
      "Batch #10\tAverage Generator Loss: 757.438361\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #4054 (step 4054): 1.383030\n",
      "Batch #10\tAverage Generator Loss: 727.346988\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #4055 (step 4055): 1.488818\n",
      "Batch #10\tAverage Generator Loss: 719.188531\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #4056 (step 4056): 1.451516\n",
      "Batch #10\tAverage Generator Loss: 690.521173\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #4057 (step 4057): 1.498936\n",
      "Batch #10\tAverage Generator Loss: 801.946246\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #4058 (step 4058): 1.308233\n",
      "Batch #10\tAverage Generator Loss: 604.957533\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #4059 (step 4059): 1.479633\n",
      "Batch #10\tAverage Generator Loss: 613.842966\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #4060 (step 4060): 1.539652\n",
      "Batch #10\tAverage Generator Loss: 560.194681\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #4061 (step 4061): 1.459780\n",
      "Batch #10\tAverage Generator Loss: 645.283643\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #4062 (step 4062): 1.452650\n",
      "Batch #10\tAverage Generator Loss: 769.817792\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #4063 (step 4063): 1.607884\n",
      "Batch #10\tAverage Generator Loss: 546.937909\tAverage Discriminator Loss: 0.089439\n",
      "\n",
      "Train time for epoch #4064 (step 4064): 1.456616\n",
      "Batch #10\tAverage Generator Loss: 607.853067\tAverage Discriminator Loss: 0.000036\n",
      "\n",
      "Train time for epoch #4065 (step 4065): 1.544216\n",
      "Batch #10\tAverage Generator Loss: 737.936496\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #4066 (step 4066): 1.340300\n",
      "Batch #10\tAverage Generator Loss: 524.788342\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #4067 (step 4067): 1.495286\n",
      "Batch #10\tAverage Generator Loss: 635.559521\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #4068 (step 4068): 1.470053\n",
      "Batch #10\tAverage Generator Loss: 681.008279\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #4069 (step 4069): 1.468880\n",
      "Batch #10\tAverage Generator Loss: 645.714508\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #4070 (step 4070): 1.568438\n",
      "Batch #10\tAverage Generator Loss: 625.489984\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #4071 (step 4071): 1.456060\n",
      "Batch #10\tAverage Generator Loss: 660.590118\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #4072 (step 4072): 1.356507\n",
      "Batch #10\tAverage Generator Loss: 591.969989\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #4073 (step 4073): 1.449405\n",
      "Batch #10\tAverage Generator Loss: 678.037665\tAverage Discriminator Loss: 0.006147\n",
      "\n",
      "Train time for epoch #4074 (step 4074): 1.513096\n",
      "Batch #10\tAverage Generator Loss: 590.442383\tAverage Discriminator Loss: 0.000606\n",
      "\n",
      "Train time for epoch #4075 (step 4075): 1.549322\n",
      "Batch #10\tAverage Generator Loss: 605.246353\tAverage Discriminator Loss: 0.000064\n",
      "\n",
      "Train time for epoch #4076 (step 4076): 1.430234\n",
      "Batch #10\tAverage Generator Loss: 716.179315\tAverage Discriminator Loss: 0.000022\n",
      "\n",
      "Train time for epoch #4077 (step 4077): 1.549884\n",
      "Batch #10\tAverage Generator Loss: 647.084438\tAverage Discriminator Loss: 0.000025\n",
      "\n",
      "Train time for epoch #4078 (step 4078): 1.596226\n",
      "Batch #10\tAverage Generator Loss: 621.637625\tAverage Discriminator Loss: 0.000021\n",
      "\n",
      "Train time for epoch #4079 (step 4079): 1.330860\n",
      "Batch #10\tAverage Generator Loss: 622.562750\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #4080 (step 4080): 1.619349\n",
      "Batch #10\tAverage Generator Loss: 619.660516\tAverage Discriminator Loss: 0.000017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #4081 (step 4081): 1.511795\n",
      "Batch #10\tAverage Generator Loss: 577.930554\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #4082 (step 4082): 1.451884\n",
      "Batch #10\tAverage Generator Loss: 645.578699\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #4083 (step 4083): 1.383835\n",
      "Batch #10\tAverage Generator Loss: 622.031950\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #4084 (step 4084): 1.507615\n",
      "Batch #10\tAverage Generator Loss: 625.617685\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #4085 (step 4085): 1.559142\n",
      "Batch #10\tAverage Generator Loss: 649.059485\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #4086 (step 4086): 1.377506\n",
      "Batch #10\tAverage Generator Loss: 611.634998\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #4087 (step 4087): 1.531020\n",
      "Batch #10\tAverage Generator Loss: 574.670961\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #4088 (step 4088): 1.552838\n",
      "Batch #10\tAverage Generator Loss: 632.894762\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #4089 (step 4089): 1.441650\n",
      "Batch #10\tAverage Generator Loss: 537.744809\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #4090 (step 4090): 1.343323\n",
      "Batch #10\tAverage Generator Loss: 634.934851\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #4091 (step 4091): 1.669534\n",
      "Batch #10\tAverage Generator Loss: 534.656062\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #4092 (step 4092): 1.466067\n",
      "Batch #10\tAverage Generator Loss: 563.306799\tAverage Discriminator Loss: 0.015631\n",
      "\n",
      "Train time for epoch #4093 (step 4093): 1.343415\n",
      "Batch #10\tAverage Generator Loss: 718.856155\tAverage Discriminator Loss: 0.005185\n",
      "\n",
      "Train time for epoch #4094 (step 4094): 1.502152\n",
      "Batch #10\tAverage Generator Loss: 591.643280\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4095 (step 4095): 1.456908\n",
      "Batch #10\tAverage Generator Loss: 558.822287\tAverage Discriminator Loss: 0.000020\n",
      "\n",
      "Train time for epoch #4096 (step 4096): 1.497638\n",
      "Batch #10\tAverage Generator Loss: 687.628629\tAverage Discriminator Loss: 0.008947\n",
      "\n",
      "Train time for epoch #4097 (step 4097): 1.345356\n",
      "Batch #10\tAverage Generator Loss: 877.507114\tAverage Discriminator Loss: 0.002151\n",
      "\n",
      "Train time for epoch #4098 (step 4098): 1.452285\n",
      "Batch #10\tAverage Generator Loss: 779.446124\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #4099 (step 4099): 1.514829\n",
      "Batch #10\tAverage Generator Loss: 1004.946454\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4100 (step 4100): 1.471243\n",
      "Batch #10\tAverage Generator Loss: 915.719226\tAverage Discriminator Loss: 0.000084\n",
      "\n",
      "Train time for epoch #4101 (step 4101): 1.518351\n",
      "Batch #10\tAverage Generator Loss: 817.461230\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4102 (step 4102): 1.563375\n",
      "Batch #10\tAverage Generator Loss: 979.459760\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #4103 (step 4103): 1.536029\n",
      "Batch #10\tAverage Generator Loss: 877.536208\tAverage Discriminator Loss: 0.000039\n",
      "\n",
      "Train time for epoch #4104 (step 4104): 1.332085\n",
      "Batch #10\tAverage Generator Loss: 915.569232\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4105 (step 4105): 1.451099\n",
      "Batch #10\tAverage Generator Loss: 1078.851556\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4106 (step 4106): 1.452741\n",
      "Batch #10\tAverage Generator Loss: 902.733676\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #4107 (step 4107): 1.390466\n",
      "Batch #10\tAverage Generator Loss: 918.491571\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4108 (step 4108): 1.619094\n",
      "Batch #10\tAverage Generator Loss: 851.709021\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #4109 (step 4109): 1.467889\n",
      "Batch #10\tAverage Generator Loss: 981.495206\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4110 (step 4110): 1.395578\n",
      "Batch #10\tAverage Generator Loss: 983.968323\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #4111 (step 4111): 1.461027\n",
      "Batch #10\tAverage Generator Loss: 1036.330731\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #4112 (step 4112): 1.485900\n",
      "Batch #10\tAverage Generator Loss: 894.779538\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #4113 (step 4113): 1.420317\n",
      "Batch #10\tAverage Generator Loss: 1015.560968\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #4114 (step 4114): 1.392468\n",
      "Batch #10\tAverage Generator Loss: 974.032272\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #4115 (step 4115): 1.551701\n",
      "Batch #10\tAverage Generator Loss: 997.772382\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #4116 (step 4116): 1.568515\n",
      "Batch #10\tAverage Generator Loss: 965.951111\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #4117 (step 4117): 1.473739\n",
      "Batch #10\tAverage Generator Loss: 832.668640\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #4118 (step 4118): 1.333016\n",
      "Batch #10\tAverage Generator Loss: 921.920920\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4119 (step 4119): 1.541296\n",
      "Batch #10\tAverage Generator Loss: 835.336298\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #4120 (step 4120): 1.470800\n",
      "Batch #10\tAverage Generator Loss: 981.759225\tAverage Discriminator Loss: 0.284337\n",
      "\n",
      "Train time for epoch #4121 (step 4121): 1.532357\n",
      "Batch #10\tAverage Generator Loss: 838.475687\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4122 (step 4122): 1.336587\n",
      "Batch #10\tAverage Generator Loss: 719.903580\tAverage Discriminator Loss: 0.017302\n",
      "\n",
      "Train time for epoch #4123 (step 4123): 1.418444\n",
      "Batch #10\tAverage Generator Loss: 762.076233\tAverage Discriminator Loss: 0.000272\n",
      "\n",
      "Train time for epoch #4124 (step 4124): 1.465937\n",
      "Batch #10\tAverage Generator Loss: 794.141043\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #4125 (step 4125): 1.325023\n",
      "Batch #10\tAverage Generator Loss: 925.474500\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #4126 (step 4126): 1.502310\n",
      "Batch #10\tAverage Generator Loss: 867.707861\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #4127 (step 4127): 1.487976\n",
      "Batch #10\tAverage Generator Loss: 821.317374\tAverage Discriminator Loss: 0.000128\n",
      "\n",
      "Train time for epoch #4128 (step 4128): 1.506603\n",
      "Batch #10\tAverage Generator Loss: 838.641614\tAverage Discriminator Loss: 0.000205\n",
      "\n",
      "Train time for epoch #4129 (step 4129): 1.439861\n",
      "Batch #10\tAverage Generator Loss: 867.908618\tAverage Discriminator Loss: 0.000255\n",
      "\n",
      "Train time for epoch #4130 (step 4130): 1.463390\n",
      "Batch #10\tAverage Generator Loss: 903.428369\tAverage Discriminator Loss: 0.000688\n",
      "\n",
      "Train time for epoch #4131 (step 4131): 1.507970\n",
      "Batch #10\tAverage Generator Loss: 829.692288\tAverage Discriminator Loss: 0.000071\n",
      "\n",
      "Train time for epoch #4132 (step 4132): 1.344059\n",
      "Batch #10\tAverage Generator Loss: 824.879041\tAverage Discriminator Loss: 0.000029\n",
      "\n",
      "Train time for epoch #4133 (step 4133): 1.457259\n",
      "Batch #10\tAverage Generator Loss: 956.229773\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #4134 (step 4134): 1.449583\n",
      "Batch #10\tAverage Generator Loss: 732.076666\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #4135 (step 4135): 1.353312\n",
      "Batch #10\tAverage Generator Loss: 952.426236\tAverage Discriminator Loss: 0.000019\n",
      "\n",
      "Train time for epoch #4136 (step 4136): 1.450355\n",
      "Batch #10\tAverage Generator Loss: 869.095755\tAverage Discriminator Loss: 0.000024\n",
      "\n",
      "Train time for epoch #4137 (step 4137): 1.492330\n",
      "Batch #10\tAverage Generator Loss: 783.060672\tAverage Discriminator Loss: 0.000020\n",
      "\n",
      "Train time for epoch #4138 (step 4138): 1.453325\n",
      "Batch #10\tAverage Generator Loss: 888.096832\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #4139 (step 4139): 1.345201\n",
      "Batch #10\tAverage Generator Loss: 758.592072\tAverage Discriminator Loss: 0.000021\n",
      "\n",
      "Train time for epoch #4140 (step 4140): 1.590566\n",
      "Batch #10\tAverage Generator Loss: 823.397287\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #4141 (step 4141): 1.571528\n",
      "Batch #10\tAverage Generator Loss: 828.672665\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #4142 (step 4142): 1.461638\n",
      "Batch #10\tAverage Generator Loss: 831.129236\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #4143 (step 4143): 1.519472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 851.711963\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #4144 (step 4144): 1.589146\n",
      "Batch #10\tAverage Generator Loss: 672.905434\tAverage Discriminator Loss: 0.036761\n",
      "\n",
      "Train time for epoch #4145 (step 4145): 1.421161\n",
      "Batch #10\tAverage Generator Loss: 734.586409\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #4146 (step 4146): 1.464509\n",
      "Batch #10\tAverage Generator Loss: 799.956897\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #4147 (step 4147): 1.495610\n",
      "Batch #10\tAverage Generator Loss: 684.948373\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #4148 (step 4148): 1.298696\n",
      "Batch #10\tAverage Generator Loss: 730.124966\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #4149 (step 4149): 1.553296\n",
      "Batch #10\tAverage Generator Loss: 791.139990\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #4150 (step 4150): 1.626047\n",
      "Batch #10\tAverage Generator Loss: 826.993835\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #4151 (step 4151): 1.651110\n",
      "Batch #10\tAverage Generator Loss: 718.723669\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #4152 (step 4152): 1.352065\n",
      "Batch #10\tAverage Generator Loss: 763.686688\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #4153 (step 4153): 1.567836\n",
      "Batch #10\tAverage Generator Loss: 682.335928\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #4154 (step 4154): 1.462190\n",
      "Batch #10\tAverage Generator Loss: 707.284396\tAverage Discriminator Loss: 0.000442\n",
      "\n",
      "Train time for epoch #4155 (step 4155): 1.651350\n",
      "Batch #10\tAverage Generator Loss: 727.525208\tAverage Discriminator Loss: 0.003706\n",
      "\n",
      "Train time for epoch #4156 (step 4156): 1.438613\n",
      "Batch #10\tAverage Generator Loss: 724.485605\tAverage Discriminator Loss: 0.001092\n",
      "\n",
      "Train time for epoch #4157 (step 4157): 1.460499\n",
      "Batch #10\tAverage Generator Loss: 704.220377\tAverage Discriminator Loss: 0.000560\n",
      "\n",
      "Train time for epoch #4158 (step 4158): 1.592333\n",
      "Batch #10\tAverage Generator Loss: 675.708496\tAverage Discriminator Loss: 0.000060\n",
      "\n",
      "Train time for epoch #4159 (step 4159): 1.504378\n",
      "Batch #10\tAverage Generator Loss: 783.114764\tAverage Discriminator Loss: 0.000040\n",
      "\n",
      "Train time for epoch #4160 (step 4160): 1.298410\n",
      "Batch #10\tAverage Generator Loss: 706.068234\tAverage Discriminator Loss: 0.000029\n",
      "\n",
      "Train time for epoch #4161 (step 4161): 1.470113\n",
      "Batch #10\tAverage Generator Loss: 790.291840\tAverage Discriminator Loss: 0.000024\n",
      "\n",
      "Train time for epoch #4162 (step 4162): 1.448958\n",
      "Batch #10\tAverage Generator Loss: 651.099521\tAverage Discriminator Loss: 0.000020\n",
      "\n",
      "Train time for epoch #4163 (step 4163): 1.285447\n",
      "Batch #10\tAverage Generator Loss: 688.535342\tAverage Discriminator Loss: 0.000076\n",
      "\n",
      "Train time for epoch #4164 (step 4164): 1.472319\n",
      "Batch #10\tAverage Generator Loss: 701.822562\tAverage Discriminator Loss: 0.000021\n",
      "\n",
      "Train time for epoch #4165 (step 4165): 1.603364\n",
      "Batch #10\tAverage Generator Loss: 705.584201\tAverage Discriminator Loss: 0.000020\n",
      "\n",
      "Train time for epoch #4166 (step 4166): 1.471181\n",
      "Batch #10\tAverage Generator Loss: 766.421085\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #4167 (step 4167): 1.291676\n",
      "Batch #10\tAverage Generator Loss: 594.719409\tAverage Discriminator Loss: 0.000019\n",
      "\n",
      "Train time for epoch #4168 (step 4168): 1.557911\n",
      "Batch #10\tAverage Generator Loss: 715.530859\tAverage Discriminator Loss: 0.000020\n",
      "\n",
      "Train time for epoch #4169 (step 4169): 1.499755\n",
      "Batch #10\tAverage Generator Loss: 692.863589\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #4170 (step 4170): 1.359978\n",
      "Batch #10\tAverage Generator Loss: 738.724884\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #4171 (step 4171): 1.425917\n",
      "Batch #10\tAverage Generator Loss: 752.398499\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #4172 (step 4172): 1.507943\n",
      "Batch #10\tAverage Generator Loss: 701.052060\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #4173 (step 4173): 1.389917\n",
      "Batch #10\tAverage Generator Loss: 622.929771\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #4174 (step 4174): 1.539778\n",
      "Batch #10\tAverage Generator Loss: 718.260141\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #4175 (step 4175): 1.504597\n",
      "Batch #10\tAverage Generator Loss: 700.916922\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #4176 (step 4176): 1.463471\n",
      "Batch #10\tAverage Generator Loss: 709.165146\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #4177 (step 4177): 1.335804\n",
      "Batch #10\tAverage Generator Loss: 731.670251\tAverage Discriminator Loss: 0.000027\n",
      "\n",
      "Train time for epoch #4178 (step 4178): 1.526581\n",
      "Batch #10\tAverage Generator Loss: 730.378027\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #4179 (step 4179): 1.498079\n",
      "Batch #10\tAverage Generator Loss: 704.991541\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #4180 (step 4180): 1.282287\n",
      "Batch #10\tAverage Generator Loss: 640.184625\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #4181 (step 4181): 1.517466\n",
      "Batch #10\tAverage Generator Loss: 668.041440\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #4182 (step 4182): 1.556800\n",
      "Batch #10\tAverage Generator Loss: 757.570459\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #4183 (step 4183): 1.514511\n",
      "Batch #10\tAverage Generator Loss: 727.066876\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #4184 (step 4184): 1.458357\n",
      "Batch #10\tAverage Generator Loss: 722.793875\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #4185 (step 4185): 1.555911\n",
      "Batch #10\tAverage Generator Loss: 633.201601\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #4186 (step 4186): 1.573524\n",
      "Batch #10\tAverage Generator Loss: 772.822992\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #4187 (step 4187): 1.348922\n",
      "Batch #10\tAverage Generator Loss: 737.058710\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #4188 (step 4188): 1.486066\n",
      "Batch #10\tAverage Generator Loss: 748.733768\tAverage Discriminator Loss: 0.001118\n",
      "\n",
      "Train time for epoch #4189 (step 4189): 1.520378\n",
      "Batch #10\tAverage Generator Loss: 640.327573\tAverage Discriminator Loss: 0.004806\n",
      "\n",
      "Train time for epoch #4190 (step 4190): 1.393192\n",
      "Batch #10\tAverage Generator Loss: 691.926599\tAverage Discriminator Loss: 0.000071\n",
      "\n",
      "Train time for epoch #4191 (step 4191): 1.467035\n",
      "Batch #10\tAverage Generator Loss: 641.169870\tAverage Discriminator Loss: 0.001170\n",
      "\n",
      "Train time for epoch #4192 (step 4192): 1.546319\n",
      "Batch #10\tAverage Generator Loss: 768.159851\tAverage Discriminator Loss: 0.000220\n",
      "\n",
      "Train time for epoch #4193 (step 4193): 1.389415\n",
      "Batch #10\tAverage Generator Loss: 707.002344\tAverage Discriminator Loss: 0.000098\n",
      "\n",
      "Train time for epoch #4194 (step 4194): 1.518056\n",
      "Batch #10\tAverage Generator Loss: 761.445459\tAverage Discriminator Loss: 0.000037\n",
      "\n",
      "Train time for epoch #4195 (step 4195): 1.572298\n",
      "Batch #10\tAverage Generator Loss: 749.605382\tAverage Discriminator Loss: 0.000043\n",
      "\n",
      "Train time for epoch #4196 (step 4196): 1.340600\n",
      "Batch #10\tAverage Generator Loss: 753.345096\tAverage Discriminator Loss: 0.000037\n",
      "\n",
      "Train time for epoch #4197 (step 4197): 1.514897\n",
      "Batch #10\tAverage Generator Loss: 686.938007\tAverage Discriminator Loss: 0.033968\n",
      "\n",
      "Train time for epoch #4198 (step 4198): 1.521769\n",
      "Batch #10\tAverage Generator Loss: 805.582449\tAverage Discriminator Loss: 0.000022\n",
      "\n",
      "Train time for epoch #4199 (step 4199): 1.496099\n",
      "Batch #10\tAverage Generator Loss: 911.001636\tAverage Discriminator Loss: 0.001034\n",
      "\n",
      "Train time for epoch #4200 (step 4200): 1.558009\n",
      "Batch #10\tAverage Generator Loss: 767.773274\tAverage Discriminator Loss: 0.000264\n",
      "\n",
      "Train time for epoch #4201 (step 4201): 1.325660\n",
      "Batch #10\tAverage Generator Loss: 691.711365\tAverage Discriminator Loss: 0.000045\n",
      "\n",
      "Train time for epoch #4202 (step 4202): 1.431346\n",
      "Batch #10\tAverage Generator Loss: 867.163235\tAverage Discriminator Loss: 0.000033\n",
      "\n",
      "Train time for epoch #4203 (step 4203): 1.507798\n",
      "Batch #10\tAverage Generator Loss: 811.580951\tAverage Discriminator Loss: 0.000030\n",
      "\n",
      "Train time for epoch #4204 (step 4204): 1.281421\n",
      "Batch #10\tAverage Generator Loss: 846.013419\tAverage Discriminator Loss: 0.000029\n",
      "\n",
      "Train time for epoch #4205 (step 4205): 1.586118\n",
      "Batch #10\tAverage Generator Loss: 856.675351\tAverage Discriminator Loss: 0.000011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #4206 (step 4206): 1.545220\n",
      "Batch #10\tAverage Generator Loss: 856.190558\tAverage Discriminator Loss: 0.000023\n",
      "\n",
      "Train time for epoch #4207 (step 4207): 1.547982\n",
      "Batch #10\tAverage Generator Loss: 811.457413\tAverage Discriminator Loss: 0.000022\n",
      "\n",
      "Train time for epoch #4208 (step 4208): 1.515078\n",
      "Batch #10\tAverage Generator Loss: 807.686680\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #4209 (step 4209): 1.569325\n",
      "Batch #10\tAverage Generator Loss: 926.052411\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #4210 (step 4210): 1.528253\n",
      "Batch #10\tAverage Generator Loss: 864.607751\tAverage Discriminator Loss: 0.000019\n",
      "\n",
      "Train time for epoch #4211 (step 4211): 1.318907\n",
      "Batch #10\tAverage Generator Loss: 951.167218\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #4212 (step 4212): 1.523189\n",
      "Batch #10\tAverage Generator Loss: 756.222440\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #4213 (step 4213): 1.512387\n",
      "Batch #10\tAverage Generator Loss: 740.972375\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #4214 (step 4214): 1.520003\n",
      "Batch #10\tAverage Generator Loss: 941.406097\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #4215 (step 4215): 1.283669\n",
      "Batch #10\tAverage Generator Loss: 1073.804294\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #4216 (step 4216): 1.458409\n",
      "Batch #10\tAverage Generator Loss: 833.463181\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #4217 (step 4217): 1.643069\n",
      "Batch #10\tAverage Generator Loss: 987.083380\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #4218 (step 4218): 1.293707\n",
      "Batch #10\tAverage Generator Loss: 851.666458\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #4219 (step 4219): 1.541062\n",
      "Batch #10\tAverage Generator Loss: 966.105005\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #4220 (step 4220): 1.502544\n",
      "Batch #10\tAverage Generator Loss: 836.162848\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #4221 (step 4221): 1.406207\n",
      "Batch #10\tAverage Generator Loss: 882.106250\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #4222 (step 4222): 1.383241\n",
      "Batch #10\tAverage Generator Loss: 933.318079\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #4223 (step 4223): 1.479140\n",
      "Batch #10\tAverage Generator Loss: 800.673892\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #4224 (step 4224): 1.453044\n",
      "Batch #10\tAverage Generator Loss: 933.259143\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #4225 (step 4225): 1.329677\n",
      "Batch #10\tAverage Generator Loss: 954.170349\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #4226 (step 4226): 1.663564\n",
      "Batch #10\tAverage Generator Loss: 915.112296\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #4227 (step 4227): 1.634753\n",
      "Batch #10\tAverage Generator Loss: 809.038672\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #4228 (step 4228): 1.570944\n",
      "Batch #10\tAverage Generator Loss: 816.334729\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #4229 (step 4229): 1.391202\n",
      "Batch #10\tAverage Generator Loss: 828.429996\tAverage Discriminator Loss: 0.000035\n",
      "\n",
      "Train time for epoch #4230 (step 4230): 1.580972\n",
      "Batch #10\tAverage Generator Loss: 859.051208\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #4231 (step 4231): 1.475216\n",
      "Batch #10\tAverage Generator Loss: 872.176807\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #4232 (step 4232): 1.330124\n",
      "Batch #10\tAverage Generator Loss: 834.910959\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #4233 (step 4233): 1.566171\n",
      "Batch #10\tAverage Generator Loss: 911.279303\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #4234 (step 4234): 1.498083\n",
      "Batch #10\tAverage Generator Loss: 687.834407\tAverage Discriminator Loss: 0.001107\n",
      "\n",
      "Train time for epoch #4235 (step 4235): 1.332837\n",
      "Batch #10\tAverage Generator Loss: 662.754205\tAverage Discriminator Loss: 0.000081\n",
      "\n",
      "Train time for epoch #4236 (step 4236): 1.490153\n",
      "Batch #10\tAverage Generator Loss: 770.571082\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #4237 (step 4237): 1.453872\n",
      "Batch #10\tAverage Generator Loss: 621.132681\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #4238 (step 4238): 1.518714\n",
      "Batch #10\tAverage Generator Loss: 653.058984\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #4239 (step 4239): 1.445463\n",
      "Batch #10\tAverage Generator Loss: 755.228867\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #4240 (step 4240): 1.542320\n",
      "Batch #10\tAverage Generator Loss: 715.065485\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #4241 (step 4241): 1.277767\n",
      "Batch #10\tAverage Generator Loss: 630.528151\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #4242 (step 4242): 1.694501\n",
      "Batch #10\tAverage Generator Loss: 747.501077\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #4243 (step 4243): 1.475289\n",
      "Batch #10\tAverage Generator Loss: 733.870023\tAverage Discriminator Loss: 0.023235\n",
      "\n",
      "Train time for epoch #4244 (step 4244): 1.436809\n",
      "Batch #10\tAverage Generator Loss: 840.492905\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #4245 (step 4245): 1.397953\n",
      "Batch #10\tAverage Generator Loss: 850.247540\tAverage Discriminator Loss: 0.006571\n",
      "\n",
      "Train time for epoch #4246 (step 4246): 1.509713\n",
      "Batch #10\tAverage Generator Loss: 791.064563\tAverage Discriminator Loss: 0.003062\n",
      "\n",
      "Train time for epoch #4247 (step 4247): 1.448811\n",
      "Batch #10\tAverage Generator Loss: 744.288882\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #4248 (step 4248): 1.558967\n",
      "Batch #10\tAverage Generator Loss: 929.682159\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4249 (step 4249): 1.278770\n",
      "Batch #10\tAverage Generator Loss: 1149.673370\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4250 (step 4250): 1.548372\n",
      "Batch #10\tAverage Generator Loss: 1015.782257\tAverage Discriminator Loss: 0.028605\n",
      "\n",
      "Train time for epoch #4251 (step 4251): 1.509644\n",
      "Batch #10\tAverage Generator Loss: 914.044891\tAverage Discriminator Loss: 0.025816\n",
      "\n",
      "Train time for epoch #4252 (step 4252): 1.330409\n",
      "Batch #10\tAverage Generator Loss: 854.197913\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #4253 (step 4253): 1.503373\n",
      "Batch #10\tAverage Generator Loss: 1093.695801\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4254 (step 4254): 1.476611\n",
      "Batch #10\tAverage Generator Loss: 915.892993\tAverage Discriminator Loss: 0.004936\n",
      "\n",
      "Train time for epoch #4255 (step 4255): 1.610859\n",
      "Batch #10\tAverage Generator Loss: 812.898184\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #4256 (step 4256): 1.526731\n",
      "Batch #10\tAverage Generator Loss: 817.246603\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #4257 (step 4257): 1.460998\n",
      "Batch #10\tAverage Generator Loss: 1040.520868\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #4258 (step 4258): 1.671103\n",
      "Batch #10\tAverage Generator Loss: 930.251038\tAverage Discriminator Loss: 0.000103\n",
      "\n",
      "Train time for epoch #4259 (step 4259): 1.289159\n",
      "Batch #10\tAverage Generator Loss: 987.600470\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #4260 (step 4260): 1.461516\n",
      "Batch #10\tAverage Generator Loss: 974.160712\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #4261 (step 4261): 1.571193\n",
      "Batch #10\tAverage Generator Loss: 945.696548\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #4262 (step 4262): 1.471062\n",
      "Batch #10\tAverage Generator Loss: 963.385590\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #4263 (step 4263): 1.627856\n",
      "Batch #10\tAverage Generator Loss: 887.603008\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #4264 (step 4264): 1.440851\n",
      "Batch #10\tAverage Generator Loss: 899.806964\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #4265 (step 4265): 1.391045\n",
      "Batch #10\tAverage Generator Loss: 906.391205\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #4266 (step 4266): 1.514936\n",
      "Batch #10\tAverage Generator Loss: 769.914902\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #4267 (step 4267): 1.509603\n",
      "Batch #10\tAverage Generator Loss: 919.960516\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #4268 (step 4268): 1.444246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 783.408995\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #4269 (step 4269): 1.632958\n",
      "Batch #10\tAverage Generator Loss: 823.287842\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #4270 (step 4270): 1.512535\n",
      "Batch #10\tAverage Generator Loss: 900.947784\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #4271 (step 4271): 1.465597\n",
      "Batch #10\tAverage Generator Loss: 937.961401\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #4272 (step 4272): 1.322913\n",
      "Batch #10\tAverage Generator Loss: 784.453448\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #4273 (step 4273): 1.459069\n",
      "Batch #10\tAverage Generator Loss: 940.582007\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #4274 (step 4274): 1.517227\n",
      "Batch #10\tAverage Generator Loss: 881.439120\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #4275 (step 4275): 1.497872\n",
      "Batch #10\tAverage Generator Loss: 831.207260\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #4276 (step 4276): 1.348957\n",
      "Batch #10\tAverage Generator Loss: 837.071667\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #4277 (step 4277): 1.692748\n",
      "Batch #10\tAverage Generator Loss: 955.430249\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #4278 (step 4278): 1.553545\n",
      "Batch #10\tAverage Generator Loss: 952.800464\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #4279 (step 4279): 1.286416\n",
      "Batch #10\tAverage Generator Loss: 848.616949\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #4280 (step 4280): 1.501108\n",
      "Batch #10\tAverage Generator Loss: 976.834784\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #4281 (step 4281): 1.462285\n",
      "Batch #10\tAverage Generator Loss: 843.004083\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #4282 (step 4282): 1.337356\n",
      "Batch #10\tAverage Generator Loss: 817.748230\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #4283 (step 4283): 1.411825\n",
      "Batch #10\tAverage Generator Loss: 961.271210\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #4284 (step 4284): 1.517392\n",
      "Batch #10\tAverage Generator Loss: 945.820624\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #4285 (step 4285): 1.618847\n",
      "Batch #10\tAverage Generator Loss: 896.908942\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #4286 (step 4286): 1.358908\n",
      "Batch #10\tAverage Generator Loss: 868.294348\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #4287 (step 4287): 1.465887\n",
      "Batch #10\tAverage Generator Loss: 923.682471\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #4288 (step 4288): 1.454772\n",
      "Batch #10\tAverage Generator Loss: 936.444376\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #4289 (step 4289): 1.285494\n",
      "Batch #10\tAverage Generator Loss: 842.351944\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #4290 (step 4290): 1.482229\n",
      "Batch #10\tAverage Generator Loss: 764.902982\tAverage Discriminator Loss: 0.082335\n",
      "\n",
      "Train time for epoch #4291 (step 4291): 1.450093\n",
      "Batch #10\tAverage Generator Loss: 751.542477\tAverage Discriminator Loss: 0.000126\n",
      "\n",
      "Train time for epoch #4292 (step 4292): 1.452423\n",
      "Batch #10\tAverage Generator Loss: 653.573508\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #4293 (step 4293): 1.298868\n",
      "Batch #10\tAverage Generator Loss: 687.690591\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #4294 (step 4294): 1.414784\n",
      "Batch #10\tAverage Generator Loss: 668.822189\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #4295 (step 4295): 1.540472\n",
      "Batch #10\tAverage Generator Loss: 707.429630\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #4296 (step 4296): 1.558987\n",
      "Batch #10\tAverage Generator Loss: 601.361963\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #4297 (step 4297): 1.315255\n",
      "Batch #10\tAverage Generator Loss: 746.271460\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #4298 (step 4298): 1.468876\n",
      "Batch #10\tAverage Generator Loss: 602.696655\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #4299 (step 4299): 1.520107\n",
      "Batch #10\tAverage Generator Loss: 694.920285\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #4300 (step 4300): 1.324521\n",
      "Batch #10\tAverage Generator Loss: 590.330450\tAverage Discriminator Loss: 0.013234\n",
      "\n",
      "Train time for epoch #4301 (step 4301): 1.499239\n",
      "Batch #10\tAverage Generator Loss: 798.385345\tAverage Discriminator Loss: 0.000086\n",
      "\n",
      "Train time for epoch #4302 (step 4302): 1.509430\n",
      "Batch #10\tAverage Generator Loss: 861.703595\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #4303 (step 4303): 1.588519\n",
      "Batch #10\tAverage Generator Loss: 839.809680\tAverage Discriminator Loss: 0.044797\n",
      "\n",
      "Train time for epoch #4304 (step 4304): 1.346031\n",
      "Batch #10\tAverage Generator Loss: 762.046182\tAverage Discriminator Loss: 0.143162\n",
      "\n",
      "Train time for epoch #4305 (step 4305): 1.548524\n",
      "Batch #10\tAverage Generator Loss: 533.816997\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #4306 (step 4306): 1.498650\n",
      "Batch #10\tAverage Generator Loss: 526.429547\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4307 (step 4307): 1.287910\n",
      "Batch #10\tAverage Generator Loss: 604.276099\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4308 (step 4308): 1.455498\n",
      "Batch #10\tAverage Generator Loss: 503.898035\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4309 (step 4309): 1.464237\n",
      "Batch #10\tAverage Generator Loss: 513.909412\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4310 (step 4310): 1.520262\n",
      "Batch #10\tAverage Generator Loss: 435.006757\tAverage Discriminator Loss: 0.007725\n",
      "\n",
      "Train time for epoch #4311 (step 4311): 1.443622\n",
      "Batch #10\tAverage Generator Loss: 447.170685\tAverage Discriminator Loss: 0.000119\n",
      "\n",
      "Train time for epoch #4312 (step 4312): 1.531582\n",
      "Batch #10\tAverage Generator Loss: 487.130255\tAverage Discriminator Loss: 0.000047\n",
      "\n",
      "Train time for epoch #4313 (step 4313): 1.618042\n",
      "Batch #10\tAverage Generator Loss: 383.193713\tAverage Discriminator Loss: 0.000045\n",
      "\n",
      "Train time for epoch #4314 (step 4314): 1.288371\n",
      "Batch #10\tAverage Generator Loss: 479.580295\tAverage Discriminator Loss: 0.000032\n",
      "\n",
      "Train time for epoch #4315 (step 4315): 1.489283\n",
      "Batch #10\tAverage Generator Loss: 440.051712\tAverage Discriminator Loss: 0.000060\n",
      "\n",
      "Train time for epoch #4316 (step 4316): 1.461451\n",
      "Batch #10\tAverage Generator Loss: 413.812433\tAverage Discriminator Loss: 0.000045\n",
      "\n",
      "Train time for epoch #4317 (step 4317): 1.356528\n",
      "Batch #10\tAverage Generator Loss: 461.256439\tAverage Discriminator Loss: 0.000039\n",
      "\n",
      "Train time for epoch #4318 (step 4318): 1.475946\n",
      "Batch #10\tAverage Generator Loss: 472.240137\tAverage Discriminator Loss: 0.000023\n",
      "\n",
      "Train time for epoch #4319 (step 4319): 1.613608\n",
      "Batch #10\tAverage Generator Loss: 511.440549\tAverage Discriminator Loss: 0.000093\n",
      "\n",
      "Train time for epoch #4320 (step 4320): 1.515639\n",
      "Batch #10\tAverage Generator Loss: 504.554251\tAverage Discriminator Loss: 0.000029\n",
      "\n",
      "Train time for epoch #4321 (step 4321): 1.282140\n",
      "Batch #10\tAverage Generator Loss: 454.218466\tAverage Discriminator Loss: 0.000026\n",
      "\n",
      "Train time for epoch #4322 (step 4322): 1.516481\n",
      "Batch #10\tAverage Generator Loss: 454.927457\tAverage Discriminator Loss: 0.000424\n",
      "\n",
      "Train time for epoch #4323 (step 4323): 1.462310\n",
      "Batch #10\tAverage Generator Loss: 358.923119\tAverage Discriminator Loss: 0.061651\n",
      "\n",
      "Train time for epoch #4324 (step 4324): 1.258725\n",
      "Batch #10\tAverage Generator Loss: 426.536534\tAverage Discriminator Loss: 0.000129\n",
      "\n",
      "Train time for epoch #4325 (step 4325): 1.460354\n",
      "Batch #10\tAverage Generator Loss: 471.458737\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #4326 (step 4326): 1.549116\n",
      "Batch #10\tAverage Generator Loss: 524.338519\tAverage Discriminator Loss: 0.019125\n",
      "\n",
      "Train time for epoch #4327 (step 4327): 1.631323\n",
      "Batch #10\tAverage Generator Loss: 665.799750\tAverage Discriminator Loss: 0.004389\n",
      "\n",
      "Train time for epoch #4328 (step 4328): 1.334957\n",
      "Batch #10\tAverage Generator Loss: 719.053625\tAverage Discriminator Loss: 0.000112\n",
      "\n",
      "Train time for epoch #4329 (step 4329): 1.653980\n",
      "Batch #10\tAverage Generator Loss: 645.450586\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #4330 (step 4330): 1.458272\n",
      "Batch #10\tAverage Generator Loss: 664.590417\tAverage Discriminator Loss: 0.000005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #4331 (step 4331): 1.331346\n",
      "Batch #10\tAverage Generator Loss: 643.253845\tAverage Discriminator Loss: 0.003046\n",
      "\n",
      "Train time for epoch #4332 (step 4332): 1.479114\n",
      "Batch #10\tAverage Generator Loss: 678.542599\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #4333 (step 4333): 1.460827\n",
      "Batch #10\tAverage Generator Loss: 581.414880\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #4334 (step 4334): 1.367743\n",
      "Batch #10\tAverage Generator Loss: 736.401279\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #4335 (step 4335): 1.573553\n",
      "Batch #10\tAverage Generator Loss: 643.355322\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #4336 (step 4336): 1.520434\n",
      "Batch #10\tAverage Generator Loss: 744.440051\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #4337 (step 4337): 1.391982\n",
      "Batch #10\tAverage Generator Loss: 572.408740\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #4338 (step 4338): 1.501245\n",
      "Batch #10\tAverage Generator Loss: 685.247394\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #4339 (step 4339): 1.512113\n",
      "Batch #10\tAverage Generator Loss: 631.885159\tAverage Discriminator Loss: 0.002043\n",
      "\n",
      "Train time for epoch #4340 (step 4340): 1.295439\n",
      "Batch #10\tAverage Generator Loss: 665.781055\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #4341 (step 4341): 1.462548\n",
      "Batch #10\tAverage Generator Loss: 548.474525\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #4342 (step 4342): 1.510920\n",
      "Batch #10\tAverage Generator Loss: 631.617935\tAverage Discriminator Loss: 0.000020\n",
      "\n",
      "Train time for epoch #4343 (step 4343): 1.603026\n",
      "Batch #10\tAverage Generator Loss: 687.397681\tAverage Discriminator Loss: 0.000026\n",
      "\n",
      "Train time for epoch #4344 (step 4344): 1.285360\n",
      "Batch #10\tAverage Generator Loss: 734.298312\tAverage Discriminator Loss: 0.000022\n",
      "\n",
      "Train time for epoch #4345 (step 4345): 1.451147\n",
      "Batch #10\tAverage Generator Loss: 621.003897\tAverage Discriminator Loss: 0.000024\n",
      "\n",
      "Train time for epoch #4346 (step 4346): 1.540811\n",
      "Batch #10\tAverage Generator Loss: 665.915274\tAverage Discriminator Loss: 0.000028\n",
      "\n",
      "Train time for epoch #4347 (step 4347): 1.400567\n",
      "Batch #10\tAverage Generator Loss: 635.589011\tAverage Discriminator Loss: 0.000022\n",
      "\n",
      "Train time for epoch #4348 (step 4348): 1.499857\n",
      "Batch #10\tAverage Generator Loss: 725.785095\tAverage Discriminator Loss: 0.000027\n",
      "\n",
      "Train time for epoch #4349 (step 4349): 1.295292\n",
      "Batch #10\tAverage Generator Loss: 624.056433\tAverage Discriminator Loss: 0.000025\n",
      "\n",
      "Train time for epoch #4350 (step 4350): 1.617399\n",
      "Batch #10\tAverage Generator Loss: 669.538214\tAverage Discriminator Loss: 0.000022\n",
      "\n",
      "Train time for epoch #4351 (step 4351): 1.446211\n",
      "Batch #10\tAverage Generator Loss: 624.512253\tAverage Discriminator Loss: 0.000026\n",
      "\n",
      "Train time for epoch #4352 (step 4352): 1.515359\n",
      "Batch #10\tAverage Generator Loss: 630.377304\tAverage Discriminator Loss: 0.000024\n",
      "\n",
      "Train time for epoch #4353 (step 4353): 1.339628\n",
      "Batch #10\tAverage Generator Loss: 601.321683\tAverage Discriminator Loss: 0.000031\n",
      "\n",
      "Train time for epoch #4354 (step 4354): 1.451992\n",
      "Batch #10\tAverage Generator Loss: 669.269122\tAverage Discriminator Loss: 0.000022\n",
      "\n",
      "Train time for epoch #4355 (step 4355): 1.515230\n",
      "Batch #10\tAverage Generator Loss: 591.645682\tAverage Discriminator Loss: 0.000027\n",
      "\n",
      "Train time for epoch #4356 (step 4356): 1.266083\n",
      "Batch #10\tAverage Generator Loss: 638.936627\tAverage Discriminator Loss: 0.000019\n",
      "\n",
      "Train time for epoch #4357 (step 4357): 1.449550\n",
      "Batch #10\tAverage Generator Loss: 680.844562\tAverage Discriminator Loss: 0.000022\n",
      "\n",
      "Train time for epoch #4358 (step 4358): 1.511478\n",
      "Batch #10\tAverage Generator Loss: 669.302994\tAverage Discriminator Loss: 0.000019\n",
      "\n",
      "Train time for epoch #4359 (step 4359): 1.383437\n",
      "Batch #10\tAverage Generator Loss: 704.670099\tAverage Discriminator Loss: 0.000019\n",
      "\n",
      "Train time for epoch #4360 (step 4360): 1.526226\n",
      "Batch #10\tAverage Generator Loss: 675.019980\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #4361 (step 4361): 1.580041\n",
      "Batch #10\tAverage Generator Loss: 636.100043\tAverage Discriminator Loss: 0.000020\n",
      "\n",
      "Train time for epoch #4362 (step 4362): 1.280069\n",
      "Batch #10\tAverage Generator Loss: 590.293860\tAverage Discriminator Loss: 0.000021\n",
      "\n",
      "Train time for epoch #4363 (step 4363): 1.564553\n",
      "Batch #10\tAverage Generator Loss: 604.435497\tAverage Discriminator Loss: 0.001345\n",
      "\n",
      "Train time for epoch #4364 (step 4364): 1.478140\n",
      "Batch #10\tAverage Generator Loss: 623.801434\tAverage Discriminator Loss: 0.000082\n",
      "\n",
      "Train time for epoch #4365 (step 4365): 1.333388\n",
      "Batch #10\tAverage Generator Loss: 693.809164\tAverage Discriminator Loss: 0.000112\n",
      "\n",
      "Train time for epoch #4366 (step 4366): 1.534526\n",
      "Batch #10\tAverage Generator Loss: 646.027859\tAverage Discriminator Loss: 0.000094\n",
      "\n",
      "Train time for epoch #4367 (step 4367): 1.469186\n",
      "Batch #10\tAverage Generator Loss: 741.988821\tAverage Discriminator Loss: 0.000078\n",
      "\n",
      "Train time for epoch #4368 (step 4368): 1.575164\n",
      "Batch #10\tAverage Generator Loss: 572.104871\tAverage Discriminator Loss: 0.000063\n",
      "\n",
      "Train time for epoch #4369 (step 4369): 1.346838\n",
      "Batch #10\tAverage Generator Loss: 640.034253\tAverage Discriminator Loss: 0.000059\n",
      "\n",
      "Train time for epoch #4370 (step 4370): 1.516880\n",
      "Batch #10\tAverage Generator Loss: 651.998955\tAverage Discriminator Loss: 0.000048\n",
      "\n",
      "Train time for epoch #4371 (step 4371): 1.459879\n",
      "Batch #10\tAverage Generator Loss: 693.069986\tAverage Discriminator Loss: 0.000212\n",
      "\n",
      "Train time for epoch #4372 (step 4372): 1.287158\n",
      "Batch #10\tAverage Generator Loss: 710.962448\tAverage Discriminator Loss: 0.000050\n",
      "\n",
      "Train time for epoch #4373 (step 4373): 1.556869\n",
      "Batch #10\tAverage Generator Loss: 685.723190\tAverage Discriminator Loss: 0.000049\n",
      "\n",
      "Train time for epoch #4374 (step 4374): 1.455059\n",
      "Batch #10\tAverage Generator Loss: 646.693051\tAverage Discriminator Loss: 0.000046\n",
      "\n",
      "Train time for epoch #4375 (step 4375): 1.295559\n",
      "Batch #10\tAverage Generator Loss: 616.059572\tAverage Discriminator Loss: 0.000059\n",
      "\n",
      "Train time for epoch #4376 (step 4376): 1.587892\n",
      "Batch #10\tAverage Generator Loss: 675.467957\tAverage Discriminator Loss: 0.000076\n",
      "\n",
      "Train time for epoch #4377 (step 4377): 1.553697\n",
      "Batch #10\tAverage Generator Loss: 678.158414\tAverage Discriminator Loss: 0.000072\n",
      "\n",
      "Train time for epoch #4378 (step 4378): 1.452685\n",
      "Batch #10\tAverage Generator Loss: 680.257678\tAverage Discriminator Loss: 0.000065\n",
      "\n",
      "Train time for epoch #4379 (step 4379): 1.290155\n",
      "Batch #10\tAverage Generator Loss: 685.111374\tAverage Discriminator Loss: 0.002010\n",
      "\n",
      "Train time for epoch #4380 (step 4380): 1.460164\n",
      "Batch #10\tAverage Generator Loss: 619.765283\tAverage Discriminator Loss: 0.004579\n",
      "\n",
      "Train time for epoch #4381 (step 4381): 1.538889\n",
      "Batch #10\tAverage Generator Loss: 603.479779\tAverage Discriminator Loss: 0.004951\n",
      "\n",
      "Train time for epoch #4382 (step 4382): 1.386158\n",
      "Batch #10\tAverage Generator Loss: 715.934457\tAverage Discriminator Loss: 0.000020\n",
      "\n",
      "Train time for epoch #4383 (step 4383): 1.661663\n",
      "Batch #10\tAverage Generator Loss: 620.571832\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #4384 (step 4384): 1.510864\n",
      "Batch #10\tAverage Generator Loss: 656.305142\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #4385 (step 4385): 1.548446\n",
      "Batch #10\tAverage Generator Loss: 614.439334\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #4386 (step 4386): 1.403222\n",
      "Batch #10\tAverage Generator Loss: 680.577158\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #4387 (step 4387): 1.499601\n",
      "Batch #10\tAverage Generator Loss: 695.424988\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #4388 (step 4388): 1.560210\n",
      "Batch #10\tAverage Generator Loss: 647.901700\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #4389 (step 4389): 1.388244\n",
      "Batch #10\tAverage Generator Loss: 727.662585\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #4390 (step 4390): 1.588624\n",
      "Batch #10\tAverage Generator Loss: 647.852548\tAverage Discriminator Loss: 0.000054\n",
      "\n",
      "Train time for epoch #4391 (step 4391): 1.496953\n",
      "Batch #10\tAverage Generator Loss: 744.765482\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #4392 (step 4392): 1.454828\n",
      "Batch #10\tAverage Generator Loss: 747.726813\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #4393 (step 4393): 1.349019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 783.256879\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #4394 (step 4394): 1.511680\n",
      "Batch #10\tAverage Generator Loss: 658.224371\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #4395 (step 4395): 1.421814\n",
      "Batch #10\tAverage Generator Loss: 664.583830\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #4396 (step 4396): 1.287239\n",
      "Batch #10\tAverage Generator Loss: 713.056601\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #4397 (step 4397): 1.495043\n",
      "Batch #10\tAverage Generator Loss: 864.213507\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #4398 (step 4398): 1.526047\n",
      "Batch #10\tAverage Generator Loss: 620.848174\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #4399 (step 4399): 1.459816\n",
      "Batch #10\tAverage Generator Loss: 704.731943\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #4400 (step 4400): 1.461918\n",
      "Batch #10\tAverage Generator Loss: 689.458292\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #4401 (step 4401): 1.541787\n",
      "Batch #10\tAverage Generator Loss: 670.538202\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #4402 (step 4402): 1.334620\n",
      "Batch #10\tAverage Generator Loss: 731.264142\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #4403 (step 4403): 1.518250\n",
      "Batch #10\tAverage Generator Loss: 667.125829\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #4404 (step 4404): 1.456574\n",
      "Batch #10\tAverage Generator Loss: 698.920435\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #4405 (step 4405): 1.351111\n",
      "Batch #10\tAverage Generator Loss: 642.797906\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #4406 (step 4406): 1.420398\n",
      "Batch #10\tAverage Generator Loss: 704.443021\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #4407 (step 4407): 1.478453\n",
      "Batch #10\tAverage Generator Loss: 683.297189\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #4408 (step 4408): 1.600169\n",
      "Batch #10\tAverage Generator Loss: 708.636246\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #4409 (step 4409): 1.425022\n",
      "Batch #10\tAverage Generator Loss: 698.054269\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #4410 (step 4410): 1.546979\n",
      "Batch #10\tAverage Generator Loss: 707.816724\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #4411 (step 4411): 1.478565\n",
      "Batch #10\tAverage Generator Loss: 716.124966\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #4412 (step 4412): 1.565130\n",
      "Batch #10\tAverage Generator Loss: 728.235422\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #4413 (step 4413): 1.288244\n",
      "Batch #10\tAverage Generator Loss: 684.585083\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #4414 (step 4414): 1.527485\n",
      "Batch #10\tAverage Generator Loss: 757.506000\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #4415 (step 4415): 1.420145\n",
      "Batch #10\tAverage Generator Loss: 712.504156\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #4416 (step 4416): 1.280338\n",
      "Batch #10\tAverage Generator Loss: 749.586157\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #4417 (step 4417): 1.462362\n",
      "Batch #10\tAverage Generator Loss: 732.022516\tAverage Discriminator Loss: 0.005124\n",
      "\n",
      "Train time for epoch #4418 (step 4418): 1.456380\n",
      "Batch #10\tAverage Generator Loss: 708.951599\tAverage Discriminator Loss: 0.000037\n",
      "\n",
      "Train time for epoch #4419 (step 4419): 1.474155\n",
      "Batch #10\tAverage Generator Loss: 709.478140\tAverage Discriminator Loss: 0.000049\n",
      "\n",
      "Train time for epoch #4420 (step 4420): 1.358026\n",
      "Batch #10\tAverage Generator Loss: 644.248090\tAverage Discriminator Loss: 0.000075\n",
      "\n",
      "Train time for epoch #4421 (step 4421): 1.539368\n",
      "Batch #10\tAverage Generator Loss: 627.924509\tAverage Discriminator Loss: 0.000065\n",
      "\n",
      "Train time for epoch #4422 (step 4422): 1.469675\n",
      "Batch #10\tAverage Generator Loss: 706.580841\tAverage Discriminator Loss: 0.000063\n",
      "\n",
      "Train time for epoch #4423 (step 4423): 1.327656\n",
      "Batch #10\tAverage Generator Loss: 647.932437\tAverage Discriminator Loss: 0.000042\n",
      "\n",
      "Train time for epoch #4424 (step 4424): 1.631588\n",
      "Batch #10\tAverage Generator Loss: 728.973904\tAverage Discriminator Loss: 0.000025\n",
      "\n",
      "Train time for epoch #4425 (step 4425): 1.519538\n",
      "Batch #10\tAverage Generator Loss: 639.163374\tAverage Discriminator Loss: 0.000025\n",
      "\n",
      "Train time for epoch #4426 (step 4426): 1.438130\n",
      "Batch #10\tAverage Generator Loss: 691.666095\tAverage Discriminator Loss: 0.000032\n",
      "\n",
      "Train time for epoch #4427 (step 4427): 1.448883\n",
      "Batch #10\tAverage Generator Loss: 657.661533\tAverage Discriminator Loss: 0.000029\n",
      "\n",
      "Train time for epoch #4428 (step 4428): 1.590968\n",
      "Batch #10\tAverage Generator Loss: 745.948132\tAverage Discriminator Loss: 0.000030\n",
      "\n",
      "Train time for epoch #4429 (step 4429): 1.275637\n",
      "Batch #10\tAverage Generator Loss: 663.444711\tAverage Discriminator Loss: 0.000026\n",
      "\n",
      "Train time for epoch #4430 (step 4430): 1.480482\n",
      "Batch #10\tAverage Generator Loss: 646.983112\tAverage Discriminator Loss: 0.078322\n",
      "\n",
      "Train time for epoch #4431 (step 4431): 1.456409\n",
      "Batch #10\tAverage Generator Loss: 523.614795\tAverage Discriminator Loss: 0.010826\n",
      "\n",
      "Train time for epoch #4432 (step 4432): 1.470160\n",
      "Batch #10\tAverage Generator Loss: 568.593854\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #4433 (step 4433): 1.295886\n",
      "Batch #10\tAverage Generator Loss: 526.282774\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #4434 (step 4434): 1.556957\n",
      "Batch #10\tAverage Generator Loss: 596.102481\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #4435 (step 4435): 1.508708\n",
      "Batch #10\tAverage Generator Loss: 1021.151651\tAverage Discriminator Loss: 0.021998\n",
      "\n",
      "Train time for epoch #4436 (step 4436): 1.342236\n",
      "Batch #10\tAverage Generator Loss: 1376.094186\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #4437 (step 4437): 1.522195\n",
      "Batch #10\tAverage Generator Loss: 1175.508005\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4438 (step 4438): 1.502411\n",
      "Batch #10\tAverage Generator Loss: 1350.988403\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4439 (step 4439): 1.523718\n",
      "Batch #10\tAverage Generator Loss: 1410.333026\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4440 (step 4440): 1.368149\n",
      "Batch #10\tAverage Generator Loss: 1319.946667\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4441 (step 4441): 1.534769\n",
      "Batch #10\tAverage Generator Loss: 910.000882\tAverage Discriminator Loss: 0.182139\n",
      "\n",
      "Train time for epoch #4442 (step 4442): 1.290693\n",
      "Batch #10\tAverage Generator Loss: 1123.269849\tAverage Discriminator Loss: 0.012305\n",
      "\n",
      "Train time for epoch #4443 (step 4443): 1.523997\n",
      "Batch #10\tAverage Generator Loss: 1024.973883\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4444 (step 4444): 1.595897\n",
      "Batch #10\tAverage Generator Loss: 1118.389288\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4445 (step 4445): 1.468807\n",
      "Batch #10\tAverage Generator Loss: 1126.008392\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4446 (step 4446): 1.253700\n",
      "Batch #10\tAverage Generator Loss: 967.886887\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4447 (step 4447): 1.508918\n",
      "Batch #10\tAverage Generator Loss: 1148.663824\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4448 (step 4448): 1.545388\n",
      "Batch #10\tAverage Generator Loss: 1186.403867\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4449 (step 4449): 1.541334\n",
      "Batch #10\tAverage Generator Loss: 1359.243848\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4450 (step 4450): 1.241445\n",
      "Batch #10\tAverage Generator Loss: 1012.719739\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4451 (step 4451): 1.588526\n",
      "Batch #10\tAverage Generator Loss: 957.410541\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4452 (step 4452): 1.509910\n",
      "Batch #10\tAverage Generator Loss: 997.256921\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4453 (step 4453): 1.293759\n",
      "Batch #10\tAverage Generator Loss: 854.373846\tAverage Discriminator Loss: 0.466460\n",
      "\n",
      "Train time for epoch #4454 (step 4454): 1.488669\n",
      "Batch #10\tAverage Generator Loss: 1205.827594\tAverage Discriminator Loss: 0.020248\n",
      "\n",
      "Train time for epoch #4455 (step 4455): 1.548051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 1194.004419\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4456 (step 4456): 1.277976\n",
      "Batch #10\tAverage Generator Loss: 1050.792081\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4457 (step 4457): 1.468063\n",
      "Batch #10\tAverage Generator Loss: 974.499696\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4458 (step 4458): 1.581282\n",
      "Batch #10\tAverage Generator Loss: 1110.326160\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4459 (step 4459): 1.288951\n",
      "Batch #10\tAverage Generator Loss: 1116.326059\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4460 (step 4460): 1.467817\n",
      "Batch #10\tAverage Generator Loss: 1104.905963\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #4461 (step 4461): 1.560105\n",
      "Batch #10\tAverage Generator Loss: 1086.055246\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4462 (step 4462): 1.396119\n",
      "Batch #10\tAverage Generator Loss: 989.403882\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4463 (step 4463): 1.571251\n",
      "Batch #10\tAverage Generator Loss: 1029.397549\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4464 (step 4464): 1.581372\n",
      "Batch #10\tAverage Generator Loss: 1164.111688\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4465 (step 4465): 1.248590\n",
      "Batch #10\tAverage Generator Loss: 985.673053\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4466 (step 4466): 1.525737\n",
      "Batch #10\tAverage Generator Loss: 979.022244\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4467 (step 4467): 1.454135\n",
      "Batch #10\tAverage Generator Loss: 1142.277917\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4468 (step 4468): 1.312928\n",
      "Batch #10\tAverage Generator Loss: 997.915155\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4469 (step 4469): 1.477068\n",
      "Batch #10\tAverage Generator Loss: 1049.372955\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4470 (step 4470): 1.473475\n",
      "Batch #10\tAverage Generator Loss: 1355.323462\tAverage Discriminator Loss: 0.132201\n",
      "\n",
      "Train time for epoch #4471 (step 4471): 1.506691\n",
      "Batch #10\tAverage Generator Loss: 1167.799847\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #4472 (step 4472): 1.473638\n",
      "Batch #10\tAverage Generator Loss: 1025.376898\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #4473 (step 4473): 1.473356\n",
      "Batch #10\tAverage Generator Loss: 1160.800940\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #4474 (step 4474): 1.268483\n",
      "Batch #10\tAverage Generator Loss: 1148.311298\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #4475 (step 4475): 1.553063\n",
      "Batch #10\tAverage Generator Loss: 1308.962659\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #4476 (step 4476): 1.547440\n",
      "Batch #10\tAverage Generator Loss: 1129.585266\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #4477 (step 4477): 1.455436\n",
      "Batch #10\tAverage Generator Loss: 1106.518384\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #4478 (step 4478): 1.355943\n",
      "Batch #10\tAverage Generator Loss: 1214.837476\tAverage Discriminator Loss: 0.018740\n",
      "\n",
      "Train time for epoch #4479 (step 4479): 1.465549\n",
      "Batch #10\tAverage Generator Loss: 1178.605920\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #4480 (step 4480): 1.549336\n",
      "Batch #10\tAverage Generator Loss: 1091.421344\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #4481 (step 4481): 1.279668\n",
      "Batch #10\tAverage Generator Loss: 1233.871210\tAverage Discriminator Loss: 0.000020\n",
      "\n",
      "Train time for epoch #4482 (step 4482): 1.457835\n",
      "Batch #10\tAverage Generator Loss: 1031.927002\tAverage Discriminator Loss: 0.105494\n",
      "\n",
      "Train time for epoch #4483 (step 4483): 1.539986\n",
      "Batch #10\tAverage Generator Loss: 828.384041\tAverage Discriminator Loss: 0.000145\n",
      "\n",
      "Train time for epoch #4484 (step 4484): 1.425467\n",
      "Batch #10\tAverage Generator Loss: 942.973999\tAverage Discriminator Loss: 0.000023\n",
      "\n",
      "Train time for epoch #4485 (step 4485): 1.560588\n",
      "Batch #10\tAverage Generator Loss: 1091.224670\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #4486 (step 4486): 1.443012\n",
      "Batch #10\tAverage Generator Loss: 875.912958\tAverage Discriminator Loss: 0.000020\n",
      "\n",
      "Train time for epoch #4487 (step 4487): 1.459484\n",
      "Batch #10\tAverage Generator Loss: 993.829254\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #4488 (step 4488): 1.486473\n",
      "Batch #10\tAverage Generator Loss: 1002.458301\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #4489 (step 4489): 1.476295\n",
      "Batch #10\tAverage Generator Loss: 1013.589020\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #4490 (step 4490): 1.470567\n",
      "Batch #10\tAverage Generator Loss: 945.413351\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #4491 (step 4491): 1.287043\n",
      "Batch #10\tAverage Generator Loss: 987.334723\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #4492 (step 4492): 1.555445\n",
      "Batch #10\tAverage Generator Loss: 1037.527966\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #4493 (step 4493): 1.433084\n",
      "Batch #10\tAverage Generator Loss: 863.325262\tAverage Discriminator Loss: 0.048270\n",
      "\n",
      "Train time for epoch #4494 (step 4494): 1.301672\n",
      "Batch #10\tAverage Generator Loss: 1114.981488\tAverage Discriminator Loss: 0.019660\n",
      "\n",
      "Train time for epoch #4495 (step 4495): 1.410602\n",
      "Batch #10\tAverage Generator Loss: 1053.983752\tAverage Discriminator Loss: 0.000029\n",
      "\n",
      "Train time for epoch #4496 (step 4496): 1.519148\n",
      "Batch #10\tAverage Generator Loss: 937.489270\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #4497 (step 4497): 1.366581\n",
      "Batch #10\tAverage Generator Loss: 824.872543\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #4498 (step 4498): 1.458066\n",
      "Batch #10\tAverage Generator Loss: 1032.607239\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #4499 (step 4499): 1.444538\n",
      "Batch #10\tAverage Generator Loss: 1085.324774\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #4500 (step 4500): 1.380535\n",
      "Batch #10\tAverage Generator Loss: 1048.513965\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #4501 (step 4501): 1.470742\n",
      "Batch #10\tAverage Generator Loss: 916.022916\tAverage Discriminator Loss: 0.269445\n",
      "\n",
      "Train time for epoch #4502 (step 4502): 1.557453\n",
      "Batch #10\tAverage Generator Loss: 933.983167\tAverage Discriminator Loss: 0.000040\n",
      "\n",
      "Train time for epoch #4503 (step 4503): 1.273879\n",
      "Batch #10\tAverage Generator Loss: 923.008139\tAverage Discriminator Loss: 0.000041\n",
      "\n",
      "Train time for epoch #4504 (step 4504): 1.570106\n",
      "Batch #10\tAverage Generator Loss: 899.143030\tAverage Discriminator Loss: 0.005356\n",
      "\n",
      "Train time for epoch #4505 (step 4505): 1.598972\n",
      "Batch #10\tAverage Generator Loss: 1100.306879\tAverage Discriminator Loss: 0.000092\n",
      "\n",
      "Train time for epoch #4506 (step 4506): 1.289313\n",
      "Batch #10\tAverage Generator Loss: 953.754938\tAverage Discriminator Loss: 0.000061\n",
      "\n",
      "Train time for epoch #4507 (step 4507): 1.476771\n",
      "Batch #10\tAverage Generator Loss: 1085.202631\tAverage Discriminator Loss: 0.000042\n",
      "\n",
      "Train time for epoch #4508 (step 4508): 1.449867\n",
      "Batch #10\tAverage Generator Loss: 1029.137274\tAverage Discriminator Loss: 0.000048\n",
      "\n",
      "Train time for epoch #4509 (step 4509): 1.293097\n",
      "Batch #10\tAverage Generator Loss: 1087.466895\tAverage Discriminator Loss: 0.000029\n",
      "\n",
      "Train time for epoch #4510 (step 4510): 1.519196\n",
      "Batch #10\tAverage Generator Loss: 968.517468\tAverage Discriminator Loss: 0.000028\n",
      "\n",
      "Train time for epoch #4511 (step 4511): 1.512811\n",
      "Batch #10\tAverage Generator Loss: 905.244296\tAverage Discriminator Loss: 0.000026\n",
      "\n",
      "Train time for epoch #4512 (step 4512): 1.337515\n",
      "Batch #10\tAverage Generator Loss: 871.007695\tAverage Discriminator Loss: 0.001778\n",
      "\n",
      "Train time for epoch #4513 (step 4513): 1.619593\n",
      "Batch #10\tAverage Generator Loss: 1021.578375\tAverage Discriminator Loss: 0.000025\n",
      "\n",
      "Train time for epoch #4514 (step 4514): 1.478994\n",
      "Batch #10\tAverage Generator Loss: 928.907884\tAverage Discriminator Loss: 0.000025\n",
      "\n",
      "Train time for epoch #4515 (step 4515): 1.322341\n",
      "Batch #10\tAverage Generator Loss: 1007.917194\tAverage Discriminator Loss: 0.000020\n",
      "\n",
      "Train time for epoch #4516 (step 4516): 1.466851\n",
      "Batch #10\tAverage Generator Loss: 1116.908002\tAverage Discriminator Loss: 0.000020\n",
      "\n",
      "Train time for epoch #4517 (step 4517): 1.507724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 957.037234\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #4518 (step 4518): 1.346664\n",
      "Batch #10\tAverage Generator Loss: 973.020044\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #4519 (step 4519): 1.545400\n",
      "Batch #10\tAverage Generator Loss: 938.045035\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #4520 (step 4520): 1.512293\n",
      "Batch #10\tAverage Generator Loss: 1068.481027\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #4521 (step 4521): 1.285776\n",
      "Batch #10\tAverage Generator Loss: 1068.867426\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #4522 (step 4522): 1.457370\n",
      "Batch #10\tAverage Generator Loss: 950.516299\tAverage Discriminator Loss: 0.006314\n",
      "\n",
      "Train time for epoch #4523 (step 4523): 1.544799\n",
      "Batch #10\tAverage Generator Loss: 840.722328\tAverage Discriminator Loss: 0.000159\n",
      "\n",
      "Train time for epoch #4524 (step 4524): 1.282989\n",
      "Batch #10\tAverage Generator Loss: 969.364807\tAverage Discriminator Loss: 0.000221\n",
      "\n",
      "Train time for epoch #4525 (step 4525): 1.560255\n",
      "Batch #10\tAverage Generator Loss: 980.129199\tAverage Discriminator Loss: 0.000116\n",
      "\n",
      "Train time for epoch #4526 (step 4526): 1.469382\n",
      "Batch #10\tAverage Generator Loss: 950.741113\tAverage Discriminator Loss: 0.000072\n",
      "\n",
      "Train time for epoch #4527 (step 4527): 1.380269\n",
      "Batch #10\tAverage Generator Loss: 917.732443\tAverage Discriminator Loss: 0.000060\n",
      "\n",
      "Train time for epoch #4528 (step 4528): 1.488801\n",
      "Batch #10\tAverage Generator Loss: 1095.654443\tAverage Discriminator Loss: 0.000052\n",
      "\n",
      "Train time for epoch #4529 (step 4529): 1.528437\n",
      "Batch #10\tAverage Generator Loss: 937.102835\tAverage Discriminator Loss: 0.000037\n",
      "\n",
      "Train time for epoch #4530 (step 4530): 1.325982\n",
      "Batch #10\tAverage Generator Loss: 880.313354\tAverage Discriminator Loss: 0.000025\n",
      "\n",
      "Train time for epoch #4531 (step 4531): 1.475833\n",
      "Batch #10\tAverage Generator Loss: 960.853955\tAverage Discriminator Loss: 0.000030\n",
      "\n",
      "Train time for epoch #4532 (step 4532): 1.482202\n",
      "Batch #10\tAverage Generator Loss: 972.391360\tAverage Discriminator Loss: 0.000033\n",
      "\n",
      "Train time for epoch #4533 (step 4533): 1.281435\n",
      "Batch #10\tAverage Generator Loss: 953.337592\tAverage Discriminator Loss: 0.000027\n",
      "\n",
      "Train time for epoch #4534 (step 4534): 1.525162\n",
      "Batch #10\tAverage Generator Loss: 906.122882\tAverage Discriminator Loss: 0.000026\n",
      "\n",
      "Train time for epoch #4535 (step 4535): 1.627790\n",
      "Batch #10\tAverage Generator Loss: 936.077454\tAverage Discriminator Loss: 0.000023\n",
      "\n",
      "Train time for epoch #4536 (step 4536): 1.504585\n",
      "Batch #10\tAverage Generator Loss: 1085.592065\tAverage Discriminator Loss: 0.000028\n",
      "\n",
      "Train time for epoch #4537 (step 4537): 1.331861\n",
      "Batch #10\tAverage Generator Loss: 1054.063171\tAverage Discriminator Loss: 0.000020\n",
      "\n",
      "Train time for epoch #4538 (step 4538): 1.521775\n",
      "Batch #10\tAverage Generator Loss: 1018.144159\tAverage Discriminator Loss: 0.000024\n",
      "\n",
      "Train time for epoch #4539 (step 4539): 1.560036\n",
      "Batch #10\tAverage Generator Loss: 968.091589\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #4540 (step 4540): 1.414461\n",
      "Batch #10\tAverage Generator Loss: 935.407935\tAverage Discriminator Loss: 0.000020\n",
      "\n",
      "Train time for epoch #4541 (step 4541): 1.575223\n",
      "Batch #10\tAverage Generator Loss: 805.968417\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #4542 (step 4542): 1.472884\n",
      "Batch #10\tAverage Generator Loss: 1064.718872\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #4543 (step 4543): 1.338390\n",
      "Batch #10\tAverage Generator Loss: 1033.167114\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #4544 (step 4544): 1.525120\n",
      "Batch #10\tAverage Generator Loss: 908.062012\tAverage Discriminator Loss: 0.000020\n",
      "\n",
      "Train time for epoch #4545 (step 4545): 1.524365\n",
      "Batch #10\tAverage Generator Loss: 1021.745807\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #4546 (step 4546): 1.275167\n",
      "Batch #10\tAverage Generator Loss: 1036.713464\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #4547 (step 4547): 1.616369\n",
      "Batch #10\tAverage Generator Loss: 1082.394562\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #4548 (step 4548): 1.471969\n",
      "Batch #10\tAverage Generator Loss: 896.108618\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #4549 (step 4549): 1.389646\n",
      "Batch #10\tAverage Generator Loss: 1010.341498\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #4550 (step 4550): 1.486027\n",
      "Batch #10\tAverage Generator Loss: 1022.676477\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #4551 (step 4551): 1.609649\n",
      "Batch #10\tAverage Generator Loss: 868.061267\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #4552 (step 4552): 1.336468\n",
      "Batch #10\tAverage Generator Loss: 1079.129346\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #4553 (step 4553): 1.473412\n",
      "Batch #10\tAverage Generator Loss: 925.653159\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #4554 (step 4554): 1.550606\n",
      "Batch #10\tAverage Generator Loss: 974.754657\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #4555 (step 4555): 1.559669\n",
      "Batch #10\tAverage Generator Loss: 1068.739386\tAverage Discriminator Loss: 0.001190\n",
      "\n",
      "Train time for epoch #4556 (step 4556): 1.301169\n",
      "Batch #10\tAverage Generator Loss: 911.567722\tAverage Discriminator Loss: 0.000060\n",
      "\n",
      "Train time for epoch #4557 (step 4557): 1.474088\n",
      "Batch #10\tAverage Generator Loss: 1065.387244\tAverage Discriminator Loss: 0.000044\n",
      "\n",
      "Train time for epoch #4558 (step 4558): 1.558902\n",
      "Batch #10\tAverage Generator Loss: 986.069482\tAverage Discriminator Loss: 0.000039\n",
      "\n",
      "Train time for epoch #4559 (step 4559): 1.361269\n",
      "Batch #10\tAverage Generator Loss: 1011.629468\tAverage Discriminator Loss: 0.000030\n",
      "\n",
      "Train time for epoch #4560 (step 4560): 1.469286\n",
      "Batch #10\tAverage Generator Loss: 1021.841528\tAverage Discriminator Loss: 0.000037\n",
      "\n",
      "Train time for epoch #4561 (step 4561): 1.418099\n",
      "Batch #10\tAverage Generator Loss: 1045.335645\tAverage Discriminator Loss: 0.000021\n",
      "\n",
      "Train time for epoch #4562 (step 4562): 1.279895\n",
      "Batch #10\tAverage Generator Loss: 983.207892\tAverage Discriminator Loss: 0.000027\n",
      "\n",
      "Train time for epoch #4563 (step 4563): 1.500845\n",
      "Batch #10\tAverage Generator Loss: 1102.315228\tAverage Discriminator Loss: 0.000024\n",
      "\n",
      "Train time for epoch #4564 (step 4564): 1.524471\n",
      "Batch #10\tAverage Generator Loss: 866.324664\tAverage Discriminator Loss: 0.000026\n",
      "\n",
      "Train time for epoch #4565 (step 4565): 1.282267\n",
      "Batch #10\tAverage Generator Loss: 964.708160\tAverage Discriminator Loss: 0.000024\n",
      "\n",
      "Train time for epoch #4566 (step 4566): 1.474838\n",
      "Batch #10\tAverage Generator Loss: 981.351361\tAverage Discriminator Loss: 0.000023\n",
      "\n",
      "Train time for epoch #4567 (step 4567): 1.475789\n",
      "Batch #10\tAverage Generator Loss: 1009.711252\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #4568 (step 4568): 1.273718\n",
      "Batch #10\tAverage Generator Loss: 1032.276361\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #4569 (step 4569): 1.464863\n",
      "Batch #10\tAverage Generator Loss: 765.179292\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #4570 (step 4570): 1.473654\n",
      "Batch #10\tAverage Generator Loss: 971.372318\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #4571 (step 4571): 1.291995\n",
      "Batch #10\tAverage Generator Loss: 976.997723\tAverage Discriminator Loss: 0.008336\n",
      "\n",
      "Train time for epoch #4572 (step 4572): 1.523158\n",
      "Batch #10\tAverage Generator Loss: 941.892093\tAverage Discriminator Loss: 0.002481\n",
      "\n",
      "Train time for epoch #4573 (step 4573): 1.485013\n",
      "Batch #10\tAverage Generator Loss: 982.305463\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #4574 (step 4574): 1.348605\n",
      "Batch #10\tAverage Generator Loss: 867.487891\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #4575 (step 4575): 1.470854\n",
      "Batch #10\tAverage Generator Loss: 955.755835\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #4576 (step 4576): 1.519641\n",
      "Batch #10\tAverage Generator Loss: 933.644287\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #4577 (step 4577): 1.489264\n",
      "Batch #10\tAverage Generator Loss: 1003.614197\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #4578 (step 4578): 1.430748\n",
      "Batch #10\tAverage Generator Loss: 946.457385\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #4579 (step 4579): 1.463386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 939.294031\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #4580 (step 4580): 1.586606\n",
      "Batch #10\tAverage Generator Loss: 816.247324\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #4581 (step 4581): 1.436357\n",
      "Batch #10\tAverage Generator Loss: 992.526300\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #4582 (step 4582): 1.553698\n",
      "Batch #10\tAverage Generator Loss: 919.160257\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #4583 (step 4583): 1.458834\n",
      "Batch #10\tAverage Generator Loss: 908.997318\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #4584 (step 4584): 1.300853\n",
      "Batch #10\tAverage Generator Loss: 1020.561346\tAverage Discriminator Loss: 0.078388\n",
      "\n",
      "Train time for epoch #4585 (step 4585): 1.585032\n",
      "Batch #10\tAverage Generator Loss: 852.893271\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #4586 (step 4586): 1.498367\n",
      "Batch #10\tAverage Generator Loss: 927.173938\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4587 (step 4587): 1.329956\n",
      "Batch #10\tAverage Generator Loss: 820.449927\tAverage Discriminator Loss: 0.007399\n",
      "\n",
      "Train time for epoch #4588 (step 4588): 1.466750\n",
      "Batch #10\tAverage Generator Loss: 908.021628\tAverage Discriminator Loss: 0.000287\n",
      "\n",
      "Train time for epoch #4589 (step 4589): 1.602532\n",
      "Batch #10\tAverage Generator Loss: 880.450014\tAverage Discriminator Loss: 0.000224\n",
      "\n",
      "Train time for epoch #4590 (step 4590): 1.290308\n",
      "Batch #10\tAverage Generator Loss: 948.149963\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #4591 (step 4591): 1.639163\n",
      "Batch #10\tAverage Generator Loss: 989.770087\tAverage Discriminator Loss: 0.000047\n",
      "\n",
      "Train time for epoch #4592 (step 4592): 1.586631\n",
      "Batch #10\tAverage Generator Loss: 919.781531\tAverage Discriminator Loss: 0.000041\n",
      "\n",
      "Train time for epoch #4593 (step 4593): 1.340900\n",
      "Batch #10\tAverage Generator Loss: 981.280441\tAverage Discriminator Loss: 0.000036\n",
      "\n",
      "Train time for epoch #4594 (step 4594): 1.409011\n",
      "Batch #10\tAverage Generator Loss: 1087.710760\tAverage Discriminator Loss: 0.000047\n",
      "\n",
      "Train time for epoch #4595 (step 4595): 1.468354\n",
      "Batch #10\tAverage Generator Loss: 970.764575\tAverage Discriminator Loss: 0.000040\n",
      "\n",
      "Train time for epoch #4596 (step 4596): 1.386987\n",
      "Batch #10\tAverage Generator Loss: 863.239667\tAverage Discriminator Loss: 0.000035\n",
      "\n",
      "Train time for epoch #4597 (step 4597): 1.468747\n",
      "Batch #10\tAverage Generator Loss: 985.478448\tAverage Discriminator Loss: 0.000033\n",
      "\n",
      "Train time for epoch #4598 (step 4598): 1.540398\n",
      "Batch #10\tAverage Generator Loss: 849.216736\tAverage Discriminator Loss: 0.000031\n",
      "\n",
      "Train time for epoch #4599 (step 4599): 1.306634\n",
      "Batch #10\tAverage Generator Loss: 965.052740\tAverage Discriminator Loss: 0.000028\n",
      "\n",
      "Train time for epoch #4600 (step 4600): 1.472418\n",
      "Batch #10\tAverage Generator Loss: 907.477588\tAverage Discriminator Loss: 0.000023\n",
      "\n",
      "Train time for epoch #4601 (step 4601): 1.520186\n",
      "Batch #10\tAverage Generator Loss: 948.528610\tAverage Discriminator Loss: 0.000025\n",
      "\n",
      "Train time for epoch #4602 (step 4602): 1.567967\n",
      "Batch #10\tAverage Generator Loss: 861.892792\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #4603 (step 4603): 1.273159\n",
      "Batch #10\tAverage Generator Loss: 962.575909\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #4604 (step 4604): 1.477092\n",
      "Batch #10\tAverage Generator Loss: 989.018799\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #4605 (step 4605): 1.474445\n",
      "Batch #10\tAverage Generator Loss: 963.046759\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #4606 (step 4606): 1.282369\n",
      "Batch #10\tAverage Generator Loss: 943.982751\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #4607 (step 4607): 1.605799\n",
      "Batch #10\tAverage Generator Loss: 1065.700909\tAverage Discriminator Loss: 0.000020\n",
      "\n",
      "Train time for epoch #4608 (step 4608): 1.539222\n",
      "Batch #10\tAverage Generator Loss: 898.799277\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #4609 (step 4609): 1.282228\n",
      "Batch #10\tAverage Generator Loss: 910.606171\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #4610 (step 4610): 1.537029\n",
      "Batch #10\tAverage Generator Loss: 916.562579\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #4611 (step 4611): 1.714809\n",
      "Batch #10\tAverage Generator Loss: 1011.475031\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #4612 (step 4612): 1.278491\n",
      "Batch #10\tAverage Generator Loss: 900.112708\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #4613 (step 4613): 1.508821\n",
      "Batch #10\tAverage Generator Loss: 952.734546\tAverage Discriminator Loss: 0.003060\n",
      "\n",
      "Train time for epoch #4614 (step 4614): 1.312749\n",
      "Batch #10\tAverage Generator Loss: 999.004001\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #4615 (step 4615): 1.468199\n",
      "Batch #10\tAverage Generator Loss: 1033.476582\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #4616 (step 4616): 1.583326\n",
      "Batch #10\tAverage Generator Loss: 906.426474\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #4617 (step 4617): 1.468686\n",
      "Batch #10\tAverage Generator Loss: 1112.131702\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4618 (step 4618): 1.340518\n",
      "Batch #10\tAverage Generator Loss: 1031.501129\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4619 (step 4619): 1.632803\n",
      "Batch #10\tAverage Generator Loss: 964.363441\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4620 (step 4620): 1.621034\n",
      "Batch #10\tAverage Generator Loss: 952.945282\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4621 (step 4621): 1.330503\n",
      "Batch #10\tAverage Generator Loss: 1000.558124\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4622 (step 4622): 1.506363\n",
      "Batch #10\tAverage Generator Loss: 1017.562512\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4623 (step 4623): 1.519986\n",
      "Batch #10\tAverage Generator Loss: 964.195483\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4624 (step 4624): 1.284671\n",
      "Batch #10\tAverage Generator Loss: 1072.813110\tAverage Discriminator Loss: 0.017879\n",
      "\n",
      "Train time for epoch #4625 (step 4625): 1.469067\n",
      "Batch #10\tAverage Generator Loss: 941.557877\tAverage Discriminator Loss: 0.000697\n",
      "\n",
      "Train time for epoch #4626 (step 4626): 1.474531\n",
      "Batch #10\tAverage Generator Loss: 958.868384\tAverage Discriminator Loss: 0.000022\n",
      "\n",
      "Train time for epoch #4627 (step 4627): 1.284055\n",
      "Batch #10\tAverage Generator Loss: 1058.149298\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #4628 (step 4628): 1.565876\n",
      "Batch #10\tAverage Generator Loss: 933.812262\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #4629 (step 4629): 1.576555\n",
      "Batch #10\tAverage Generator Loss: 829.554323\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #4630 (step 4630): 1.322508\n",
      "Batch #10\tAverage Generator Loss: 971.006573\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #4631 (step 4631): 1.467753\n",
      "Batch #10\tAverage Generator Loss: 1001.354510\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #4632 (step 4632): 1.475004\n",
      "Batch #10\tAverage Generator Loss: 965.825421\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #4633 (step 4633): 1.346234\n",
      "Batch #10\tAverage Generator Loss: 808.225320\tAverage Discriminator Loss: 0.003593\n",
      "\n",
      "Train time for epoch #4634 (step 4634): 1.438726\n",
      "Batch #10\tAverage Generator Loss: 901.070480\tAverage Discriminator Loss: 0.003368\n",
      "\n",
      "Train time for epoch #4635 (step 4635): 1.518160\n",
      "Batch #10\tAverage Generator Loss: 937.668524\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #4636 (step 4636): 1.329449\n",
      "Batch #10\tAverage Generator Loss: 941.885455\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #4637 (step 4637): 1.512944\n",
      "Batch #10\tAverage Generator Loss: 993.543915\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #4638 (step 4638): 1.532689\n",
      "Batch #10\tAverage Generator Loss: 965.676215\tAverage Discriminator Loss: 0.036545\n",
      "\n",
      "Train time for epoch #4639 (step 4639): 1.338007\n",
      "Batch #10\tAverage Generator Loss: 997.534656\tAverage Discriminator Loss: 0.044452\n",
      "\n",
      "Train time for epoch #4640 (step 4640): 1.618825\n",
      "Batch #10\tAverage Generator Loss: 993.179419\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #4641 (step 4641): 1.467035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 889.613803\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #4642 (step 4642): 1.481621\n",
      "Batch #10\tAverage Generator Loss: 948.275073\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #4643 (step 4643): 1.421102\n",
      "Batch #10\tAverage Generator Loss: 930.238617\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #4644 (step 4644): 1.503168\n",
      "Batch #10\tAverage Generator Loss: 822.767578\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #4645 (step 4645): 1.285321\n",
      "Batch #10\tAverage Generator Loss: 956.483612\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #4646 (step 4646): 1.573730\n",
      "Batch #10\tAverage Generator Loss: 815.829639\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #4647 (step 4647): 1.554125\n",
      "Batch #10\tAverage Generator Loss: 931.531470\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #4648 (step 4648): 1.279612\n",
      "Batch #10\tAverage Generator Loss: 683.866530\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #4649 (step 4649): 1.428661\n",
      "Batch #10\tAverage Generator Loss: 886.807764\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #4650 (step 4650): 1.467685\n",
      "Batch #10\tAverage Generator Loss: 831.624094\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #4651 (step 4651): 1.340028\n",
      "Batch #10\tAverage Generator Loss: 882.700031\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #4652 (step 4652): 1.513906\n",
      "Batch #10\tAverage Generator Loss: 921.340131\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #4653 (step 4653): 1.485767\n",
      "Batch #10\tAverage Generator Loss: 912.064020\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #4654 (step 4654): 1.531429\n",
      "Batch #10\tAverage Generator Loss: 882.066077\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #4655 (step 4655): 1.287304\n",
      "Batch #10\tAverage Generator Loss: 1007.159491\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #4656 (step 4656): 1.604336\n",
      "Batch #10\tAverage Generator Loss: 898.720914\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #4657 (step 4657): 1.471444\n",
      "Batch #10\tAverage Generator Loss: 839.016208\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #4658 (step 4658): 1.318560\n",
      "Batch #10\tAverage Generator Loss: 915.379401\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #4659 (step 4659): 1.503410\n",
      "Batch #10\tAverage Generator Loss: 930.859158\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #4660 (step 4660): 1.467233\n",
      "Batch #10\tAverage Generator Loss: 926.421912\tAverage Discriminator Loss: 0.000029\n",
      "\n",
      "Train time for epoch #4661 (step 4661): 1.391044\n",
      "Batch #10\tAverage Generator Loss: 839.875842\tAverage Discriminator Loss: 0.000377\n",
      "\n",
      "Train time for epoch #4662 (step 4662): 1.506380\n",
      "Batch #10\tAverage Generator Loss: 812.282562\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #4663 (step 4663): 1.296595\n",
      "Batch #10\tAverage Generator Loss: 804.584282\tAverage Discriminator Loss: 0.000037\n",
      "\n",
      "Train time for epoch #4664 (step 4664): 1.606557\n",
      "Batch #10\tAverage Generator Loss: 902.360339\tAverage Discriminator Loss: 0.000027\n",
      "\n",
      "Train time for epoch #4665 (step 4665): 1.622252\n",
      "Batch #10\tAverage Generator Loss: 875.707269\tAverage Discriminator Loss: 0.000019\n",
      "\n",
      "Train time for epoch #4666 (step 4666): 1.513273\n",
      "Batch #10\tAverage Generator Loss: 855.893103\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #4667 (step 4667): 1.500653\n",
      "Batch #10\tAverage Generator Loss: 812.341801\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #4668 (step 4668): 1.473726\n",
      "Batch #10\tAverage Generator Loss: 761.001651\tAverage Discriminator Loss: 0.122987\n",
      "\n",
      "Train time for epoch #4669 (step 4669): 1.564972\n",
      "Batch #10\tAverage Generator Loss: 795.500677\tAverage Discriminator Loss: 0.000107\n",
      "\n",
      "Train time for epoch #4670 (step 4670): 1.381697\n",
      "Batch #10\tAverage Generator Loss: 686.192535\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #4671 (step 4671): 1.471065\n",
      "Batch #10\tAverage Generator Loss: 788.281787\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #4672 (step 4672): 1.520684\n",
      "Batch #10\tAverage Generator Loss: 819.037781\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #4673 (step 4673): 1.333794\n",
      "Batch #10\tAverage Generator Loss: 735.653354\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #4674 (step 4674): 1.574404\n",
      "Batch #10\tAverage Generator Loss: 729.044983\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #4675 (step 4675): 1.605587\n",
      "Batch #10\tAverage Generator Loss: 792.848331\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #4676 (step 4676): 1.243103\n",
      "Batch #10\tAverage Generator Loss: 888.886414\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #4677 (step 4677): 1.489027\n",
      "Batch #10\tAverage Generator Loss: 849.477365\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #4678 (step 4678): 1.484712\n",
      "Batch #10\tAverage Generator Loss: 768.782730\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #4679 (step 4679): 1.392902\n",
      "Batch #10\tAverage Generator Loss: 849.629932\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #4680 (step 4680): 1.474292\n",
      "Batch #10\tAverage Generator Loss: 747.309381\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #4681 (step 4681): 1.488286\n",
      "Batch #10\tAverage Generator Loss: 767.653842\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #4682 (step 4682): 1.425009\n",
      "Batch #10\tAverage Generator Loss: 772.930963\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #4683 (step 4683): 1.689154\n",
      "Batch #10\tAverage Generator Loss: 817.308194\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #4684 (step 4684): 1.594589\n",
      "Batch #10\tAverage Generator Loss: 825.781775\tAverage Discriminator Loss: 0.012398\n",
      "\n",
      "Train time for epoch #4685 (step 4685): 1.369259\n",
      "Batch #10\tAverage Generator Loss: 866.372021\tAverage Discriminator Loss: 0.001845\n",
      "\n",
      "Train time for epoch #4686 (step 4686): 1.428437\n",
      "Batch #10\tAverage Generator Loss: 823.302960\tAverage Discriminator Loss: 0.000038\n",
      "\n",
      "Train time for epoch #4687 (step 4687): 1.478806\n",
      "Batch #10\tAverage Generator Loss: 809.520978\tAverage Discriminator Loss: 0.013245\n",
      "\n",
      "Train time for epoch #4688 (step 4688): 1.299811\n",
      "Batch #10\tAverage Generator Loss: 753.218608\tAverage Discriminator Loss: 0.040011\n",
      "\n",
      "Train time for epoch #4689 (step 4689): 1.649563\n",
      "Batch #10\tAverage Generator Loss: 846.757422\tAverage Discriminator Loss: 0.000659\n",
      "\n",
      "Train time for epoch #4690 (step 4690): 1.580637\n",
      "Batch #10\tAverage Generator Loss: 840.748773\tAverage Discriminator Loss: 0.000059\n",
      "\n",
      "Train time for epoch #4691 (step 4691): 1.408667\n",
      "Batch #10\tAverage Generator Loss: 805.545111\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #4692 (step 4692): 1.523100\n",
      "Batch #10\tAverage Generator Loss: 747.394339\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #4693 (step 4693): 1.290581\n",
      "Batch #10\tAverage Generator Loss: 762.074472\tAverage Discriminator Loss: 0.002383\n",
      "\n",
      "Train time for epoch #4694 (step 4694): 1.539779\n",
      "Batch #10\tAverage Generator Loss: 770.626535\tAverage Discriminator Loss: 0.000593\n",
      "\n",
      "Train time for epoch #4695 (step 4695): 1.540079\n",
      "Batch #10\tAverage Generator Loss: 821.888284\tAverage Discriminator Loss: 0.000098\n",
      "\n",
      "Train time for epoch #4696 (step 4696): 1.583895\n",
      "Batch #10\tAverage Generator Loss: 816.694748\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #4697 (step 4697): 1.343029\n",
      "Batch #10\tAverage Generator Loss: 848.336792\tAverage Discriminator Loss: 0.000477\n",
      "\n",
      "Train time for epoch #4698 (step 4698): 1.527017\n",
      "Batch #10\tAverage Generator Loss: 862.486594\tAverage Discriminator Loss: 0.000022\n",
      "\n",
      "Train time for epoch #4699 (step 4699): 1.454123\n",
      "Batch #10\tAverage Generator Loss: 795.044125\tAverage Discriminator Loss: 0.000023\n",
      "\n",
      "Train time for epoch #4700 (step 4700): 1.336528\n",
      "Batch #10\tAverage Generator Loss: 765.214444\tAverage Discriminator Loss: 0.000037\n",
      "\n",
      "Train time for epoch #4701 (step 4701): 1.540552\n",
      "Batch #10\tAverage Generator Loss: 906.834167\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #4702 (step 4702): 1.520178\n",
      "Batch #10\tAverage Generator Loss: 893.561310\tAverage Discriminator Loss: 0.000019\n",
      "\n",
      "Train time for epoch #4703 (step 4703): 1.443753\n",
      "Batch #10\tAverage Generator Loss: 934.841589\tAverage Discriminator Loss: 0.000016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #4704 (step 4704): 1.453562\n",
      "Batch #10\tAverage Generator Loss: 852.318362\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #4705 (step 4705): 1.518031\n",
      "Batch #10\tAverage Generator Loss: 869.932056\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #4706 (step 4706): 1.416170\n",
      "Batch #10\tAverage Generator Loss: 860.343085\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #4707 (step 4707): 1.661760\n",
      "Batch #10\tAverage Generator Loss: 822.850528\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #4708 (step 4708): 1.485099\n",
      "Batch #10\tAverage Generator Loss: 853.109851\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #4709 (step 4709): 1.340000\n",
      "Batch #10\tAverage Generator Loss: 890.492261\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #4710 (step 4710): 1.533021\n",
      "Batch #10\tAverage Generator Loss: 734.335056\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #4711 (step 4711): 1.517265\n",
      "Batch #10\tAverage Generator Loss: 842.599023\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #4712 (step 4712): 1.347605\n",
      "Batch #10\tAverage Generator Loss: 902.409315\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #4713 (step 4713): 1.463884\n",
      "Batch #10\tAverage Generator Loss: 766.758527\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #4714 (step 4714): 1.632394\n",
      "Batch #10\tAverage Generator Loss: 864.038074\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #4715 (step 4715): 1.303963\n",
      "Batch #10\tAverage Generator Loss: 909.164795\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #4716 (step 4716): 1.642716\n",
      "Batch #10\tAverage Generator Loss: 894.416394\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #4717 (step 4717): 1.564565\n",
      "Batch #10\tAverage Generator Loss: 807.519901\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #4718 (step 4718): 1.528136\n",
      "Batch #10\tAverage Generator Loss: 865.917584\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #4719 (step 4719): 1.369363\n",
      "Batch #10\tAverage Generator Loss: 822.412970\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #4720 (step 4720): 1.477506\n",
      "Batch #10\tAverage Generator Loss: 884.392255\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #4721 (step 4721): 1.342973\n",
      "Batch #10\tAverage Generator Loss: 860.224054\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #4722 (step 4722): 1.431012\n",
      "Batch #10\tAverage Generator Loss: 808.222173\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #4723 (step 4723): 1.484613\n",
      "Batch #10\tAverage Generator Loss: 823.158472\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #4724 (step 4724): 1.318241\n",
      "Batch #10\tAverage Generator Loss: 795.335480\tAverage Discriminator Loss: 0.016262\n",
      "\n",
      "Train time for epoch #4725 (step 4725): 1.605119\n",
      "Batch #10\tAverage Generator Loss: 793.092551\tAverage Discriminator Loss: 0.000118\n",
      "\n",
      "Train time for epoch #4726 (step 4726): 1.488129\n",
      "Batch #10\tAverage Generator Loss: 782.827194\tAverage Discriminator Loss: 0.000072\n",
      "\n",
      "Train time for epoch #4727 (step 4727): 1.580321\n",
      "Batch #10\tAverage Generator Loss: 729.803476\tAverage Discriminator Loss: 0.000025\n",
      "\n",
      "Train time for epoch #4728 (step 4728): 1.318285\n",
      "Batch #10\tAverage Generator Loss: 731.237384\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #4729 (step 4729): 1.553677\n",
      "Batch #10\tAverage Generator Loss: 826.262811\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #4730 (step 4730): 1.463040\n",
      "Batch #10\tAverage Generator Loss: 869.239233\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #4731 (step 4731): 1.325010\n",
      "Batch #10\tAverage Generator Loss: 780.207281\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #4732 (step 4732): 1.460221\n",
      "Batch #10\tAverage Generator Loss: 804.883865\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #4733 (step 4733): 1.500063\n",
      "Batch #10\tAverage Generator Loss: 834.637372\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #4734 (step 4734): 1.370307\n",
      "Batch #10\tAverage Generator Loss: 813.865973\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #4735 (step 4735): 1.504900\n",
      "Batch #10\tAverage Generator Loss: 802.126700\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #4736 (step 4736): 1.538292\n",
      "Batch #10\tAverage Generator Loss: 791.977820\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #4737 (step 4737): 1.341326\n",
      "Batch #10\tAverage Generator Loss: 876.284448\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #4738 (step 4738): 1.522397\n",
      "Batch #10\tAverage Generator Loss: 709.122836\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #4739 (step 4739): 1.631622\n",
      "Batch #10\tAverage Generator Loss: 738.244983\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #4740 (step 4740): 1.289002\n",
      "Batch #10\tAverage Generator Loss: 771.469489\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #4741 (step 4741): 1.471903\n",
      "Batch #10\tAverage Generator Loss: 741.878275\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #4742 (step 4742): 1.434128\n",
      "Batch #10\tAverage Generator Loss: 837.802295\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #4743 (step 4743): 1.393105\n",
      "Batch #10\tAverage Generator Loss: 780.009631\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #4744 (step 4744): 1.538024\n",
      "Batch #10\tAverage Generator Loss: 898.259406\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #4745 (step 4745): 1.509439\n",
      "Batch #10\tAverage Generator Loss: 800.859097\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #4746 (step 4746): 1.293796\n",
      "Batch #10\tAverage Generator Loss: 787.597943\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #4747 (step 4747): 1.625541\n",
      "Batch #10\tAverage Generator Loss: 809.513864\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #4748 (step 4748): 1.444850\n",
      "Batch #10\tAverage Generator Loss: 902.616711\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #4749 (step 4749): 1.437840\n",
      "Batch #10\tAverage Generator Loss: 764.667242\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #4750 (step 4750): 1.434611\n",
      "Batch #10\tAverage Generator Loss: 778.041312\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #4751 (step 4751): 1.559720\n",
      "Batch #10\tAverage Generator Loss: 763.804175\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #4752 (step 4752): 1.364647\n",
      "Batch #10\tAverage Generator Loss: 762.947144\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #4753 (step 4753): 1.423470\n",
      "Batch #10\tAverage Generator Loss: 642.686260\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #4754 (step 4754): 1.516328\n",
      "Batch #10\tAverage Generator Loss: 786.144037\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #4755 (step 4755): 1.379255\n",
      "Batch #10\tAverage Generator Loss: 786.320044\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #4756 (step 4756): 1.537785\n",
      "Batch #10\tAverage Generator Loss: 750.842990\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #4757 (step 4757): 1.533573\n",
      "Batch #10\tAverage Generator Loss: 743.975311\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #4758 (step 4758): 1.328204\n",
      "Batch #10\tAverage Generator Loss: 888.379352\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #4759 (step 4759): 1.531085\n",
      "Batch #10\tAverage Generator Loss: 718.248224\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #4760 (step 4760): 1.466459\n",
      "Batch #10\tAverage Generator Loss: 733.693689\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #4761 (step 4761): 1.438791\n",
      "Batch #10\tAverage Generator Loss: 837.345743\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #4762 (step 4762): 1.585805\n",
      "Batch #10\tAverage Generator Loss: 832.661151\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #4763 (step 4763): 1.545306\n",
      "Batch #10\tAverage Generator Loss: 779.419159\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #4764 (step 4764): 1.305555\n",
      "Batch #10\tAverage Generator Loss: 811.721664\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #4765 (step 4765): 1.465411\n",
      "Batch #10\tAverage Generator Loss: 890.320538\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #4766 (step 4766): 1.529285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 838.834442\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #4767 (step 4767): 1.401932\n",
      "Batch #10\tAverage Generator Loss: 904.745197\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #4768 (step 4768): 1.633666\n",
      "Batch #10\tAverage Generator Loss: 778.775629\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #4769 (step 4769): 1.426651\n",
      "Batch #10\tAverage Generator Loss: 800.852295\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #4770 (step 4770): 1.335887\n",
      "Batch #10\tAverage Generator Loss: 782.355545\tAverage Discriminator Loss: 0.010444\n",
      "\n",
      "Train time for epoch #4771 (step 4771): 1.545907\n",
      "Batch #10\tAverage Generator Loss: 776.243088\tAverage Discriminator Loss: 0.001378\n",
      "\n",
      "Train time for epoch #4772 (step 4772): 1.546706\n",
      "Batch #10\tAverage Generator Loss: 749.373950\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #4773 (step 4773): 1.293947\n",
      "Batch #10\tAverage Generator Loss: 787.394526\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #4774 (step 4774): 1.508330\n",
      "Batch #10\tAverage Generator Loss: 733.221695\tAverage Discriminator Loss: 0.000276\n",
      "\n",
      "Train time for epoch #4775 (step 4775): 1.569205\n",
      "Batch #10\tAverage Generator Loss: 754.439798\tAverage Discriminator Loss: 0.001228\n",
      "\n",
      "Train time for epoch #4776 (step 4776): 1.272342\n",
      "Batch #10\tAverage Generator Loss: 784.073309\tAverage Discriminator Loss: 0.000082\n",
      "\n",
      "Train time for epoch #4777 (step 4777): 1.475918\n",
      "Batch #10\tAverage Generator Loss: 835.471954\tAverage Discriminator Loss: 0.000084\n",
      "\n",
      "Train time for epoch #4778 (step 4778): 1.331944\n",
      "Batch #10\tAverage Generator Loss: 751.147122\tAverage Discriminator Loss: 0.000055\n",
      "\n",
      "Train time for epoch #4779 (step 4779): 1.524279\n",
      "Batch #10\tAverage Generator Loss: 719.615079\tAverage Discriminator Loss: 0.000029\n",
      "\n",
      "Train time for epoch #4780 (step 4780): 1.621881\n",
      "Batch #10\tAverage Generator Loss: 871.044824\tAverage Discriminator Loss: 0.000024\n",
      "\n",
      "Train time for epoch #4781 (step 4781): 1.279117\n",
      "Batch #10\tAverage Generator Loss: 866.413910\tAverage Discriminator Loss: 0.000019\n",
      "\n",
      "Train time for epoch #4782 (step 4782): 1.471858\n",
      "Batch #10\tAverage Generator Loss: 783.187607\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #4783 (step 4783): 1.621407\n",
      "Batch #10\tAverage Generator Loss: 775.114053\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #4784 (step 4784): 1.389827\n",
      "Batch #10\tAverage Generator Loss: 808.298190\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #4785 (step 4785): 1.595772\n",
      "Batch #10\tAverage Generator Loss: 769.954623\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #4786 (step 4786): 1.572028\n",
      "Batch #10\tAverage Generator Loss: 787.802600\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #4787 (step 4787): 1.307451\n",
      "Batch #10\tAverage Generator Loss: 692.927127\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #4788 (step 4788): 1.512025\n",
      "Batch #10\tAverage Generator Loss: 779.060599\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #4789 (step 4789): 1.572833\n",
      "Batch #10\tAverage Generator Loss: 786.135641\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #4790 (step 4790): 1.286208\n",
      "Batch #10\tAverage Generator Loss: 797.554880\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #4791 (step 4791): 1.518675\n",
      "Batch #10\tAverage Generator Loss: 773.181238\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #4792 (step 4792): 1.433312\n",
      "Batch #10\tAverage Generator Loss: 740.274472\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #4793 (step 4793): 1.290781\n",
      "Batch #10\tAverage Generator Loss: 767.472678\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #4794 (step 4794): 1.420157\n",
      "Batch #10\tAverage Generator Loss: 787.109476\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #4795 (step 4795): 1.604521\n",
      "Batch #10\tAverage Generator Loss: 785.039777\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #4796 (step 4796): 1.411191\n",
      "Batch #10\tAverage Generator Loss: 766.006929\tAverage Discriminator Loss: 0.000411\n",
      "\n",
      "Train time for epoch #4797 (step 4797): 1.697033\n",
      "Batch #10\tAverage Generator Loss: 760.476712\tAverage Discriminator Loss: 0.024629\n",
      "\n",
      "Train time for epoch #4798 (step 4798): 1.648631\n",
      "Batch #10\tAverage Generator Loss: 768.688174\tAverage Discriminator Loss: 0.000112\n",
      "\n",
      "Train time for epoch #4799 (step 4799): 1.281266\n",
      "Batch #10\tAverage Generator Loss: 770.084457\tAverage Discriminator Loss: 0.000081\n",
      "\n",
      "Train time for epoch #4800 (step 4800): 1.536212\n",
      "Batch #10\tAverage Generator Loss: 732.985272\tAverage Discriminator Loss: 0.000036\n",
      "\n",
      "Train time for epoch #4801 (step 4801): 1.483426\n",
      "Batch #10\tAverage Generator Loss: 839.984985\tAverage Discriminator Loss: 0.001536\n",
      "\n",
      "Train time for epoch #4802 (step 4802): 1.286342\n",
      "Batch #10\tAverage Generator Loss: 865.589490\tAverage Discriminator Loss: 0.000702\n",
      "\n",
      "Train time for epoch #4803 (step 4803): 1.476565\n",
      "Batch #10\tAverage Generator Loss: 827.263568\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #4804 (step 4804): 1.430360\n",
      "Batch #10\tAverage Generator Loss: 875.144168\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #4805 (step 4805): 1.299371\n",
      "Batch #10\tAverage Generator Loss: 922.599530\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #4806 (step 4806): 1.546872\n",
      "Batch #10\tAverage Generator Loss: 869.819623\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #4807 (step 4807): 1.234857\n",
      "Batch #10\tAverage Generator Loss: 818.437390\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #4808 (step 4808): 1.736154\n",
      "Batch #10\tAverage Generator Loss: 844.772314\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #4809 (step 4809): 1.473454\n",
      "Batch #10\tAverage Generator Loss: 747.255116\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #4810 (step 4810): 1.317519\n",
      "Batch #10\tAverage Generator Loss: 817.209753\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #4811 (step 4811): 1.562699\n",
      "Batch #10\tAverage Generator Loss: 811.431833\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #4812 (step 4812): 1.532391\n",
      "Batch #10\tAverage Generator Loss: 776.997980\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #4813 (step 4813): 1.524187\n",
      "Batch #10\tAverage Generator Loss: 831.540466\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #4814 (step 4814): 1.279966\n",
      "Batch #10\tAverage Generator Loss: 845.059998\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #4815 (step 4815): 1.434667\n",
      "Batch #10\tAverage Generator Loss: 798.960806\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #4816 (step 4816): 1.476079\n",
      "Batch #10\tAverage Generator Loss: 772.958534\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #4817 (step 4817): 1.298838\n",
      "Batch #10\tAverage Generator Loss: 921.875970\tAverage Discriminator Loss: 0.000416\n",
      "\n",
      "Train time for epoch #4818 (step 4818): 1.547724\n",
      "Batch #10\tAverage Generator Loss: 837.659399\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #4819 (step 4819): 1.281005\n",
      "Batch #10\tAverage Generator Loss: 823.544843\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #4820 (step 4820): 1.550112\n",
      "Batch #10\tAverage Generator Loss: 877.661084\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #4821 (step 4821): 1.605715\n",
      "Batch #10\tAverage Generator Loss: 838.120657\tAverage Discriminator Loss: 0.028050\n",
      "\n",
      "Train time for epoch #4822 (step 4822): 1.372772\n",
      "Batch #10\tAverage Generator Loss: 861.311905\tAverage Discriminator Loss: 0.000200\n",
      "\n",
      "Train time for epoch #4823 (step 4823): 1.522378\n",
      "Batch #10\tAverage Generator Loss: 830.611685\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #4824 (step 4824): 1.531768\n",
      "Batch #10\tAverage Generator Loss: 966.023352\tAverage Discriminator Loss: 0.003251\n",
      "\n",
      "Train time for epoch #4825 (step 4825): 1.280135\n",
      "Batch #10\tAverage Generator Loss: 1044.881793\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #4826 (step 4826): 1.507238\n",
      "Batch #10\tAverage Generator Loss: 884.582254\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #4827 (step 4827): 1.485913\n",
      "Batch #10\tAverage Generator Loss: 1059.882397\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #4828 (step 4828): 1.388674\n",
      "Batch #10\tAverage Generator Loss: 965.729050\tAverage Discriminator Loss: 0.000014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #4829 (step 4829): 1.473606\n",
      "Batch #10\tAverage Generator Loss: 892.400446\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #4830 (step 4830): 1.471852\n",
      "Batch #10\tAverage Generator Loss: 966.525830\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #4831 (step 4831): 1.376449\n",
      "Batch #10\tAverage Generator Loss: 1033.002985\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #4832 (step 4832): 1.610909\n",
      "Batch #10\tAverage Generator Loss: 877.776868\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #4833 (step 4833): 1.489454\n",
      "Batch #10\tAverage Generator Loss: 1004.952338\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #4834 (step 4834): 1.292932\n",
      "Batch #10\tAverage Generator Loss: 919.429889\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #4835 (step 4835): 1.481023\n",
      "Batch #10\tAverage Generator Loss: 786.920859\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #4836 (step 4836): 1.529234\n",
      "Batch #10\tAverage Generator Loss: 966.741678\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #4837 (step 4837): 1.286481\n",
      "Batch #10\tAverage Generator Loss: 1075.381366\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #4838 (step 4838): 1.585490\n",
      "Batch #10\tAverage Generator Loss: 921.182227\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #4839 (step 4839): 1.593025\n",
      "Batch #10\tAverage Generator Loss: 905.101047\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #4840 (step 4840): 1.323366\n",
      "Batch #10\tAverage Generator Loss: 924.858978\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #4841 (step 4841): 1.429910\n",
      "Batch #10\tAverage Generator Loss: 986.468085\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #4842 (step 4842): 1.618995\n",
      "Batch #10\tAverage Generator Loss: 895.219138\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #4843 (step 4843): 1.423226\n",
      "Batch #10\tAverage Generator Loss: 1037.848120\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #4844 (step 4844): 1.588325\n",
      "Batch #10\tAverage Generator Loss: 1024.888849\tAverage Discriminator Loss: 0.005214\n",
      "\n",
      "Train time for epoch #4845 (step 4845): 1.477792\n",
      "Batch #10\tAverage Generator Loss: 925.696887\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4846 (step 4846): 1.287437\n",
      "Batch #10\tAverage Generator Loss: 967.165610\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4847 (step 4847): 1.528469\n",
      "Batch #10\tAverage Generator Loss: 1068.391913\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4848 (step 4848): 1.575200\n",
      "Batch #10\tAverage Generator Loss: 895.291925\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4849 (step 4849): 1.296497\n",
      "Batch #10\tAverage Generator Loss: 1104.528754\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4850 (step 4850): 1.482084\n",
      "Batch #10\tAverage Generator Loss: 1156.824274\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4851 (step 4851): 1.544766\n",
      "Batch #10\tAverage Generator Loss: 1009.906726\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4852 (step 4852): 1.342335\n",
      "Batch #10\tAverage Generator Loss: 902.551328\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4853 (step 4853): 1.624159\n",
      "Batch #10\tAverage Generator Loss: 906.719147\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4854 (step 4854): 1.578315\n",
      "Batch #10\tAverage Generator Loss: 946.104510\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4855 (step 4855): 1.273682\n",
      "Batch #10\tAverage Generator Loss: 1014.488416\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4856 (step 4856): 1.511186\n",
      "Batch #10\tAverage Generator Loss: 975.761438\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4857 (step 4857): 1.295795\n",
      "Batch #10\tAverage Generator Loss: 972.272144\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4858 (step 4858): 1.524978\n",
      "Batch #10\tAverage Generator Loss: 774.597797\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4859 (step 4859): 1.473770\n",
      "Batch #10\tAverage Generator Loss: 901.087056\tAverage Discriminator Loss: 1.676402\n",
      "\n",
      "Train time for epoch #4860 (step 4860): 1.512163\n",
      "Batch #10\tAverage Generator Loss: 707.988062\tAverage Discriminator Loss: 0.731827\n",
      "\n",
      "Train time for epoch #4861 (step 4861): 1.386769\n",
      "Batch #10\tAverage Generator Loss: 704.653848\tAverage Discriminator Loss: 0.017254\n",
      "\n",
      "Train time for epoch #4862 (step 4862): 1.472688\n",
      "Batch #10\tAverage Generator Loss: 870.984058\tAverage Discriminator Loss: 0.000060\n",
      "\n",
      "Train time for epoch #4863 (step 4863): 1.625562\n",
      "Batch #10\tAverage Generator Loss: 718.483354\tAverage Discriminator Loss: 0.038107\n",
      "\n",
      "Train time for epoch #4864 (step 4864): 1.338608\n",
      "Batch #10\tAverage Generator Loss: 811.373294\tAverage Discriminator Loss: 0.042637\n",
      "\n",
      "Train time for epoch #4865 (step 4865): 1.552764\n",
      "Batch #10\tAverage Generator Loss: 984.517761\tAverage Discriminator Loss: 0.028971\n",
      "\n",
      "Train time for epoch #4866 (step 4866): 1.533945\n",
      "Batch #10\tAverage Generator Loss: 962.506802\tAverage Discriminator Loss: 0.000053\n",
      "\n",
      "Train time for epoch #4867 (step 4867): 1.369743\n",
      "Batch #10\tAverage Generator Loss: 964.533963\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #4868 (step 4868): 1.507784\n",
      "Batch #10\tAverage Generator Loss: 853.051491\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #4869 (step 4869): 1.460434\n",
      "Batch #10\tAverage Generator Loss: 855.677032\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #4870 (step 4870): 1.336597\n",
      "Batch #10\tAverage Generator Loss: 1104.478235\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #4871 (step 4871): 1.473495\n",
      "Batch #10\tAverage Generator Loss: 895.834557\tAverage Discriminator Loss: 0.000027\n",
      "\n",
      "Train time for epoch #4872 (step 4872): 1.512339\n",
      "Batch #10\tAverage Generator Loss: 815.873770\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #4873 (step 4873): 1.415453\n",
      "Batch #10\tAverage Generator Loss: 1011.803217\tAverage Discriminator Loss: 0.006584\n",
      "\n",
      "Train time for epoch #4874 (step 4874): 1.487090\n",
      "Batch #10\tAverage Generator Loss: 834.355574\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #4875 (step 4875): 1.533963\n",
      "Batch #10\tAverage Generator Loss: 838.112167\tAverage Discriminator Loss: 0.000076\n",
      "\n",
      "Train time for epoch #4876 (step 4876): 1.291415\n",
      "Batch #10\tAverage Generator Loss: 1104.861182\tAverage Discriminator Loss: 0.002221\n",
      "\n",
      "Train time for epoch #4877 (step 4877): 1.479137\n",
      "Batch #10\tAverage Generator Loss: 800.842514\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #4878 (step 4878): 1.520634\n",
      "Batch #10\tAverage Generator Loss: 800.412938\tAverage Discriminator Loss: 0.106507\n",
      "\n",
      "Train time for epoch #4879 (step 4879): 1.278965\n",
      "Batch #10\tAverage Generator Loss: 1005.998836\tAverage Discriminator Loss: 0.014487\n",
      "\n",
      "Train time for epoch #4880 (step 4880): 1.628807\n",
      "Batch #10\tAverage Generator Loss: 940.316269\tAverage Discriminator Loss: 0.185654\n",
      "\n",
      "Train time for epoch #4881 (step 4881): 1.496092\n",
      "Batch #10\tAverage Generator Loss: 910.840530\tAverage Discriminator Loss: 0.000165\n",
      "\n",
      "Train time for epoch #4882 (step 4882): 1.294864\n",
      "Batch #10\tAverage Generator Loss: 942.586887\tAverage Discriminator Loss: 0.000037\n",
      "\n",
      "Train time for epoch #4883 (step 4883): 1.514565\n",
      "Batch #10\tAverage Generator Loss: 898.762550\tAverage Discriminator Loss: 0.000031\n",
      "\n",
      "Train time for epoch #4884 (step 4884): 1.557117\n",
      "Batch #10\tAverage Generator Loss: 1013.893866\tAverage Discriminator Loss: 0.000027\n",
      "\n",
      "Train time for epoch #4885 (step 4885): 1.282237\n",
      "Batch #10\tAverage Generator Loss: 1003.493976\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #4886 (step 4886): 1.543303\n",
      "Batch #10\tAverage Generator Loss: 804.429547\tAverage Discriminator Loss: 0.049102\n",
      "\n",
      "Train time for epoch #4887 (step 4887): 1.529281\n",
      "Batch #10\tAverage Generator Loss: 849.824066\tAverage Discriminator Loss: 0.000029\n",
      "\n",
      "Train time for epoch #4888 (step 4888): 1.296564\n",
      "Batch #10\tAverage Generator Loss: 911.014618\tAverage Discriminator Loss: 0.000021\n",
      "\n",
      "Train time for epoch #4889 (step 4889): 1.476138\n",
      "Batch #10\tAverage Generator Loss: 1079.217105\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #4890 (step 4890): 1.289270\n",
      "Batch #10\tAverage Generator Loss: 984.941098\tAverage Discriminator Loss: 0.000004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #4891 (step 4891): 1.530659\n",
      "Batch #10\tAverage Generator Loss: 944.345319\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #4892 (step 4892): 1.571938\n",
      "Batch #10\tAverage Generator Loss: 865.066064\tAverage Discriminator Loss: 0.006695\n",
      "\n",
      "Train time for epoch #4893 (step 4893): 1.473470\n",
      "Batch #10\tAverage Generator Loss: 991.675226\tAverage Discriminator Loss: 0.000046\n",
      "\n",
      "Train time for epoch #4894 (step 4894): 1.439434\n",
      "Batch #10\tAverage Generator Loss: 999.010059\tAverage Discriminator Loss: 0.000072\n",
      "\n",
      "Train time for epoch #4895 (step 4895): 1.515697\n",
      "Batch #10\tAverage Generator Loss: 777.225232\tAverage Discriminator Loss: 0.016911\n",
      "\n",
      "Train time for epoch #4896 (step 4896): 1.524016\n",
      "Batch #10\tAverage Generator Loss: 949.726801\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #4897 (step 4897): 1.292560\n",
      "Batch #10\tAverage Generator Loss: 964.553104\tAverage Discriminator Loss: 0.000588\n",
      "\n",
      "Train time for epoch #4898 (step 4898): 1.521270\n",
      "Batch #10\tAverage Generator Loss: 880.342816\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4899 (step 4899): 1.527516\n",
      "Batch #10\tAverage Generator Loss: 865.460397\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4900 (step 4900): 1.311912\n",
      "Batch #10\tAverage Generator Loss: 930.812854\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4901 (step 4901): 1.577050\n",
      "Batch #10\tAverage Generator Loss: 830.698907\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4902 (step 4902): 1.531574\n",
      "Batch #10\tAverage Generator Loss: 964.472357\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4903 (step 4903): 1.384485\n",
      "Batch #10\tAverage Generator Loss: 868.097202\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4904 (step 4904): 1.517940\n",
      "Batch #10\tAverage Generator Loss: 1010.974396\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4905 (step 4905): 1.592252\n",
      "Batch #10\tAverage Generator Loss: 912.961943\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4906 (step 4906): 1.347316\n",
      "Batch #10\tAverage Generator Loss: 963.860468\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #4907 (step 4907): 1.575611\n",
      "Batch #10\tAverage Generator Loss: 912.827850\tAverage Discriminator Loss: 0.000025\n",
      "\n",
      "Train time for epoch #4908 (step 4908): 1.459022\n",
      "Batch #10\tAverage Generator Loss: 965.092676\tAverage Discriminator Loss: 0.019463\n",
      "\n",
      "Train time for epoch #4909 (step 4909): 1.520005\n",
      "Batch #10\tAverage Generator Loss: 884.692548\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #4910 (step 4910): 1.533208\n",
      "Batch #10\tAverage Generator Loss: 837.370056\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #4911 (step 4911): 1.539249\n",
      "Batch #10\tAverage Generator Loss: 1039.971503\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #4912 (step 4912): 1.403004\n",
      "Batch #10\tAverage Generator Loss: 935.673029\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #4913 (step 4913): 1.483646\n",
      "Batch #10\tAverage Generator Loss: 772.691470\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #4914 (step 4914): 1.361687\n",
      "Batch #10\tAverage Generator Loss: 995.375018\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #4915 (step 4915): 1.479212\n",
      "Batch #10\tAverage Generator Loss: 747.526312\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #4916 (step 4916): 1.641850\n",
      "Batch #10\tAverage Generator Loss: 919.491217\tAverage Discriminator Loss: 0.000021\n",
      "\n",
      "Train time for epoch #4917 (step 4917): 1.444879\n",
      "Batch #10\tAverage Generator Loss: 1038.249969\tAverage Discriminator Loss: 0.000248\n",
      "\n",
      "Train time for epoch #4918 (step 4918): 1.488317\n",
      "Batch #10\tAverage Generator Loss: 933.580298\tAverage Discriminator Loss: 0.000042\n",
      "\n",
      "Train time for epoch #4919 (step 4919): 1.517636\n",
      "Batch #10\tAverage Generator Loss: 995.586224\tAverage Discriminator Loss: 0.000048\n",
      "\n",
      "Train time for epoch #4920 (step 4920): 1.525227\n",
      "Batch #10\tAverage Generator Loss: 950.907172\tAverage Discriminator Loss: 0.000044\n",
      "\n",
      "Train time for epoch #4921 (step 4921): 1.351774\n",
      "Batch #10\tAverage Generator Loss: 897.374133\tAverage Discriminator Loss: 0.000070\n",
      "\n",
      "Train time for epoch #4922 (step 4922): 1.514698\n",
      "Batch #10\tAverage Generator Loss: 958.876038\tAverage Discriminator Loss: 0.000029\n",
      "\n",
      "Train time for epoch #4923 (step 4923): 1.425683\n",
      "Batch #10\tAverage Generator Loss: 864.438162\tAverage Discriminator Loss: 0.000031\n",
      "\n",
      "Train time for epoch #4924 (step 4924): 1.395064\n",
      "Batch #10\tAverage Generator Loss: 948.456677\tAverage Discriminator Loss: 0.000067\n",
      "\n",
      "Train time for epoch #4925 (step 4925): 1.587479\n",
      "Batch #10\tAverage Generator Loss: 948.755426\tAverage Discriminator Loss: 0.000043\n",
      "\n",
      "Train time for epoch #4926 (step 4926): 1.423614\n",
      "Batch #10\tAverage Generator Loss: 934.518933\tAverage Discriminator Loss: 0.000025\n",
      "\n",
      "Train time for epoch #4927 (step 4927): 1.572000\n",
      "Batch #10\tAverage Generator Loss: 926.290259\tAverage Discriminator Loss: 0.000025\n",
      "\n",
      "Train time for epoch #4928 (step 4928): 1.533394\n",
      "Batch #10\tAverage Generator Loss: 870.657648\tAverage Discriminator Loss: 0.000027\n",
      "\n",
      "Train time for epoch #4929 (step 4929): 1.389421\n",
      "Batch #10\tAverage Generator Loss: 903.406018\tAverage Discriminator Loss: 0.000024\n",
      "\n",
      "Train time for epoch #4930 (step 4930): 1.486923\n",
      "Batch #10\tAverage Generator Loss: 900.185352\tAverage Discriminator Loss: 0.000033\n",
      "\n",
      "Train time for epoch #4931 (step 4931): 1.496060\n",
      "Batch #10\tAverage Generator Loss: 910.332617\tAverage Discriminator Loss: 0.000024\n",
      "\n",
      "Train time for epoch #4932 (step 4932): 1.331882\n",
      "Batch #10\tAverage Generator Loss: 850.295422\tAverage Discriminator Loss: 0.000030\n",
      "\n",
      "Train time for epoch #4933 (step 4933): 1.636765\n",
      "Batch #10\tAverage Generator Loss: 969.679932\tAverage Discriminator Loss: 0.000020\n",
      "\n",
      "Train time for epoch #4934 (step 4934): 1.529788\n",
      "Batch #10\tAverage Generator Loss: 904.878156\tAverage Discriminator Loss: 0.000025\n",
      "\n",
      "Train time for epoch #4935 (step 4935): 1.372988\n",
      "Batch #10\tAverage Generator Loss: 949.511658\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #4936 (step 4936): 1.487724\n",
      "Batch #10\tAverage Generator Loss: 918.044653\tAverage Discriminator Loss: 0.000024\n",
      "\n",
      "Train time for epoch #4937 (step 4937): 1.557783\n",
      "Batch #10\tAverage Generator Loss: 789.874448\tAverage Discriminator Loss: 0.000023\n",
      "\n",
      "Train time for epoch #4938 (step 4938): 1.343421\n",
      "Batch #10\tAverage Generator Loss: 870.340863\tAverage Discriminator Loss: 0.000023\n",
      "\n",
      "Train time for epoch #4939 (step 4939): 1.574506\n",
      "Batch #10\tAverage Generator Loss: 932.811324\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #4940 (step 4940): 1.557190\n",
      "Batch #10\tAverage Generator Loss: 936.942413\tAverage Discriminator Loss: 0.000020\n",
      "\n",
      "Train time for epoch #4941 (step 4941): 1.287203\n",
      "Batch #10\tAverage Generator Loss: 947.417493\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #4942 (step 4942): 1.563405\n",
      "Batch #10\tAverage Generator Loss: 853.864276\tAverage Discriminator Loss: 0.000019\n",
      "\n",
      "Train time for epoch #4943 (step 4943): 1.509005\n",
      "Batch #10\tAverage Generator Loss: 821.765936\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #4944 (step 4944): 1.450918\n",
      "Batch #10\tAverage Generator Loss: 1016.218256\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #4945 (step 4945): 1.634526\n",
      "Batch #10\tAverage Generator Loss: 933.166815\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #4946 (step 4946): 1.475938\n",
      "Batch #10\tAverage Generator Loss: 992.149377\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #4947 (step 4947): 1.338965\n",
      "Batch #10\tAverage Generator Loss: 913.391937\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #4948 (step 4948): 1.651503\n",
      "Batch #10\tAverage Generator Loss: 981.512372\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #4949 (step 4949): 1.587101\n",
      "Batch #10\tAverage Generator Loss: 990.690967\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #4950 (step 4950): 1.368997\n",
      "Batch #10\tAverage Generator Loss: 961.453998\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #4951 (step 4951): 1.509801\n",
      "Batch #10\tAverage Generator Loss: 943.339966\tAverage Discriminator Loss: 0.000069\n",
      "\n",
      "Train time for epoch #4952 (step 4952): 1.583458\n",
      "Batch #10\tAverage Generator Loss: 873.375552\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #4953 (step 4953): 1.346090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 817.522968\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #4954 (step 4954): 1.477012\n",
      "Batch #10\tAverage Generator Loss: 805.462695\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #4955 (step 4955): 1.637223\n",
      "Batch #10\tAverage Generator Loss: 916.800867\tAverage Discriminator Loss: 0.000168\n",
      "\n",
      "Train time for epoch #4956 (step 4956): 1.374780\n",
      "Batch #10\tAverage Generator Loss: 811.114359\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #4957 (step 4957): 1.513793\n",
      "Batch #10\tAverage Generator Loss: 1032.016937\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #4958 (step 4958): 1.493982\n",
      "Batch #10\tAverage Generator Loss: 943.971857\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #4959 (step 4959): 1.294995\n",
      "Batch #10\tAverage Generator Loss: 882.748227\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #4960 (step 4960): 1.487777\n",
      "Batch #10\tAverage Generator Loss: 980.206989\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #4961 (step 4961): 1.623156\n",
      "Batch #10\tAverage Generator Loss: 958.815552\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #4962 (step 4962): 1.284352\n",
      "Batch #10\tAverage Generator Loss: 882.018134\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #4963 (step 4963): 1.448762\n",
      "Batch #10\tAverage Generator Loss: 981.480261\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #4964 (step 4964): 1.241466\n",
      "Batch #10\tAverage Generator Loss: 916.306952\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #4965 (step 4965): 1.481792\n",
      "Batch #10\tAverage Generator Loss: 1007.037433\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #4966 (step 4966): 1.489106\n",
      "Batch #10\tAverage Generator Loss: 905.461761\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #4967 (step 4967): 1.270721\n",
      "Batch #10\tAverage Generator Loss: 883.243762\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #4968 (step 4968): 1.476722\n",
      "Batch #10\tAverage Generator Loss: 858.500586\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #4969 (step 4969): 1.522796\n",
      "Batch #10\tAverage Generator Loss: 1004.208459\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #4970 (step 4970): 1.298309\n",
      "Batch #10\tAverage Generator Loss: 930.537457\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #4971 (step 4971): 1.478375\n",
      "Batch #10\tAverage Generator Loss: 850.854041\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #4972 (step 4972): 1.552173\n",
      "Batch #10\tAverage Generator Loss: 935.880286\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #4973 (step 4973): 1.383030\n",
      "Batch #10\tAverage Generator Loss: 857.488089\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #4974 (step 4974): 1.481351\n",
      "Batch #10\tAverage Generator Loss: 883.726788\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #4975 (step 4975): 1.435403\n",
      "Batch #10\tAverage Generator Loss: 890.464178\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #4976 (step 4976): 1.283825\n",
      "Batch #10\tAverage Generator Loss: 960.144958\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #4977 (step 4977): 1.527061\n",
      "Batch #10\tAverage Generator Loss: 833.029227\tAverage Discriminator Loss: 0.000194\n",
      "\n",
      "Train time for epoch #4978 (step 4978): 1.551785\n",
      "Batch #10\tAverage Generator Loss: 896.213013\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #4979 (step 4979): 1.334076\n",
      "Batch #10\tAverage Generator Loss: 845.529709\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #4980 (step 4980): 1.466284\n",
      "Batch #10\tAverage Generator Loss: 1164.642041\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #4981 (step 4981): 1.567194\n",
      "Batch #10\tAverage Generator Loss: 987.643152\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #4982 (step 4982): 1.343791\n",
      "Batch #10\tAverage Generator Loss: 899.674731\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #4983 (step 4983): 1.525858\n",
      "Batch #10\tAverage Generator Loss: 1035.962421\tAverage Discriminator Loss: 0.003318\n",
      "\n",
      "Train time for epoch #4984 (step 4984): 1.465060\n",
      "Batch #10\tAverage Generator Loss: 964.110193\tAverage Discriminator Loss: 0.000103\n",
      "\n",
      "Train time for epoch #4985 (step 4985): 1.286229\n",
      "Batch #10\tAverage Generator Loss: 920.097607\tAverage Discriminator Loss: 0.000115\n",
      "\n",
      "Train time for epoch #4986 (step 4986): 1.571161\n",
      "Batch #10\tAverage Generator Loss: 915.843030\tAverage Discriminator Loss: 0.000092\n",
      "\n",
      "Train time for epoch #4987 (step 4987): 1.347537\n",
      "Batch #10\tAverage Generator Loss: 914.123712\tAverage Discriminator Loss: 0.000036\n",
      "\n",
      "Train time for epoch #4988 (step 4988): 1.615807\n",
      "Batch #10\tAverage Generator Loss: 902.254636\tAverage Discriminator Loss: 0.000061\n",
      "\n",
      "Train time for epoch #4989 (step 4989): 1.495467\n",
      "Batch #10\tAverage Generator Loss: 879.965497\tAverage Discriminator Loss: 0.000053\n",
      "\n",
      "Train time for epoch #4990 (step 4990): 1.287879\n",
      "Batch #10\tAverage Generator Loss: 954.457813\tAverage Discriminator Loss: 0.000042\n",
      "\n",
      "Train time for epoch #4991 (step 4991): 1.529417\n",
      "Batch #10\tAverage Generator Loss: 1026.134387\tAverage Discriminator Loss: 0.000039\n",
      "\n",
      "Train time for epoch #4992 (step 4992): 1.475645\n",
      "Batch #10\tAverage Generator Loss: 835.571661\tAverage Discriminator Loss: 0.000036\n",
      "\n",
      "Train time for epoch #4993 (step 4993): 1.285546\n",
      "Batch #10\tAverage Generator Loss: 874.083707\tAverage Discriminator Loss: 0.000028\n",
      "\n",
      "Train time for epoch #4994 (step 4994): 1.494733\n",
      "Batch #10\tAverage Generator Loss: 803.223346\tAverage Discriminator Loss: 0.000028\n",
      "\n",
      "Train time for epoch #4995 (step 4995): 1.537694\n",
      "Batch #10\tAverage Generator Loss: 807.528540\tAverage Discriminator Loss: 0.000022\n",
      "\n",
      "Train time for epoch #4996 (step 4996): 1.345640\n",
      "Batch #10\tAverage Generator Loss: 913.233563\tAverage Discriminator Loss: 0.000019\n",
      "\n",
      "Train time for epoch #4997 (step 4997): 1.627554\n",
      "Batch #10\tAverage Generator Loss: 981.062842\tAverage Discriminator Loss: 0.000020\n",
      "\n",
      "Train time for epoch #4998 (step 4998): 1.475000\n",
      "Batch #10\tAverage Generator Loss: 983.905798\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #4999 (step 4999): 1.286785\n",
      "Batch #10\tAverage Generator Loss: 972.197284\tAverage Discriminator Loss: 0.000020\n",
      "\n",
      "Train time for epoch #5000 (step 5000): 1.517120\n",
      "Batch #10\tAverage Generator Loss: 962.572308\tAverage Discriminator Loss: 0.000022\n",
      "\n",
      "Train time for epoch #5001 (step 5001): 1.621060\n",
      "Batch #10\tAverage Generator Loss: 939.641119\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #5002 (step 5002): 1.337617\n",
      "Batch #10\tAverage Generator Loss: 889.038269\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #5003 (step 5003): 1.486632\n",
      "Batch #10\tAverage Generator Loss: 922.803992\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #5004 (step 5004): 1.526151\n",
      "Batch #10\tAverage Generator Loss: 861.477769\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #5005 (step 5005): 1.444013\n",
      "Batch #10\tAverage Generator Loss: 937.480609\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #5006 (step 5006): 1.474972\n",
      "Batch #10\tAverage Generator Loss: 928.213504\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #5007 (step 5007): 1.527844\n",
      "Batch #10\tAverage Generator Loss: 918.770648\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #5008 (step 5008): 1.430429\n",
      "Batch #10\tAverage Generator Loss: 993.360248\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #5009 (step 5009): 1.580184\n",
      "Batch #10\tAverage Generator Loss: 863.196744\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #5010 (step 5010): 1.704243\n",
      "Batch #10\tAverage Generator Loss: 1027.290814\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #5011 (step 5011): 1.350470\n",
      "Batch #10\tAverage Generator Loss: 939.535126\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #5012 (step 5012): 1.569159\n",
      "Batch #10\tAverage Generator Loss: 822.280725\tAverage Discriminator Loss: 0.000022\n",
      "\n",
      "Train time for epoch #5013 (step 5013): 1.601042\n",
      "Batch #10\tAverage Generator Loss: 884.414291\tAverage Discriminator Loss: 0.000019\n",
      "\n",
      "Train time for epoch #5014 (step 5014): 1.284696\n",
      "Batch #10\tAverage Generator Loss: 894.971774\tAverage Discriminator Loss: 0.000019\n",
      "\n",
      "Train time for epoch #5015 (step 5015): 1.586169\n",
      "Batch #10\tAverage Generator Loss: 932.562415\tAverage Discriminator Loss: 0.000017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #5016 (step 5016): 1.538347\n",
      "Batch #10\tAverage Generator Loss: 827.620004\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #5017 (step 5017): 1.302039\n",
      "Batch #10\tAverage Generator Loss: 861.596283\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #5018 (step 5018): 1.525528\n",
      "Batch #10\tAverage Generator Loss: 984.888068\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #5019 (step 5019): 1.283598\n",
      "Batch #10\tAverage Generator Loss: 861.975507\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #5020 (step 5020): 1.532153\n",
      "Batch #10\tAverage Generator Loss: 928.808264\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #5021 (step 5021): 1.597234\n",
      "Batch #10\tAverage Generator Loss: 901.902481\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #5022 (step 5022): 1.290735\n",
      "Batch #10\tAverage Generator Loss: 904.713815\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #5023 (step 5023): 1.526591\n",
      "Batch #10\tAverage Generator Loss: 992.990527\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #5024 (step 5024): 1.570957\n",
      "Batch #10\tAverage Generator Loss: 938.017529\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #5025 (step 5025): 1.290974\n",
      "Batch #10\tAverage Generator Loss: 920.700104\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #5026 (step 5026): 1.464984\n",
      "Batch #10\tAverage Generator Loss: 871.743066\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #5027 (step 5027): 1.578694\n",
      "Batch #10\tAverage Generator Loss: 873.723029\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #5028 (step 5028): 1.296088\n",
      "Batch #10\tAverage Generator Loss: 971.699646\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #5029 (step 5029): 1.534672\n",
      "Batch #10\tAverage Generator Loss: 911.966913\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #5030 (step 5030): 1.492527\n",
      "Batch #10\tAverage Generator Loss: 850.084573\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #5031 (step 5031): 1.383391\n",
      "Batch #10\tAverage Generator Loss: 938.839761\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #5032 (step 5032): 1.574410\n",
      "Batch #10\tAverage Generator Loss: 860.582574\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #5033 (step 5033): 1.562034\n",
      "Batch #10\tAverage Generator Loss: 918.018262\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #5034 (step 5034): 1.375129\n",
      "Batch #10\tAverage Generator Loss: 865.001837\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #5035 (step 5035): 1.498319\n",
      "Batch #10\tAverage Generator Loss: 884.464056\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #5036 (step 5036): 1.482781\n",
      "Batch #10\tAverage Generator Loss: 809.663272\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #5037 (step 5037): 1.300716\n",
      "Batch #10\tAverage Generator Loss: 884.824530\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #5038 (step 5038): 1.686770\n",
      "Batch #10\tAverage Generator Loss: 942.665002\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #5039 (step 5039): 1.313876\n",
      "Batch #10\tAverage Generator Loss: 879.644492\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #5040 (step 5040): 1.515933\n",
      "Batch #10\tAverage Generator Loss: 997.071735\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #5041 (step 5041): 1.499804\n",
      "Batch #10\tAverage Generator Loss: 928.949365\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #5042 (step 5042): 1.606139\n",
      "Batch #10\tAverage Generator Loss: 874.756873\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #5043 (step 5043): 1.349257\n",
      "Batch #10\tAverage Generator Loss: 835.854729\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #5044 (step 5044): 1.550418\n",
      "Batch #10\tAverage Generator Loss: 845.093701\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #5045 (step 5045): 1.490444\n",
      "Batch #10\tAverage Generator Loss: 996.878015\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #5046 (step 5046): 1.284050\n",
      "Batch #10\tAverage Generator Loss: 965.260699\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #5047 (step 5047): 1.489402\n",
      "Batch #10\tAverage Generator Loss: 955.302478\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #5048 (step 5048): 1.528587\n",
      "Batch #10\tAverage Generator Loss: 878.554736\tAverage Discriminator Loss: 0.037769\n",
      "\n",
      "Train time for epoch #5049 (step 5049): 1.287287\n",
      "Batch #10\tAverage Generator Loss: 876.246552\tAverage Discriminator Loss: 0.000099\n",
      "\n",
      "Train time for epoch #5050 (step 5050): 1.591258\n",
      "Batch #10\tAverage Generator Loss: 797.566818\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #5051 (step 5051): 1.294395\n",
      "Batch #10\tAverage Generator Loss: 845.945441\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #5052 (step 5052): 1.656836\n",
      "Batch #10\tAverage Generator Loss: 784.520892\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #5053 (step 5053): 1.530931\n",
      "Batch #10\tAverage Generator Loss: 724.522952\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #5054 (step 5054): 1.389111\n",
      "Batch #10\tAverage Generator Loss: 692.260493\tAverage Discriminator Loss: 0.004835\n",
      "\n",
      "Train time for epoch #5055 (step 5055): 1.475488\n",
      "Batch #10\tAverage Generator Loss: 850.009448\tAverage Discriminator Loss: 0.000297\n",
      "\n",
      "Train time for epoch #5056 (step 5056): 1.491935\n",
      "Batch #10\tAverage Generator Loss: 633.582376\tAverage Discriminator Loss: 0.000134\n",
      "\n",
      "Train time for epoch #5057 (step 5057): 1.258522\n",
      "Batch #10\tAverage Generator Loss: 733.702553\tAverage Discriminator Loss: 0.000052\n",
      "\n",
      "Train time for epoch #5058 (step 5058): 1.482371\n",
      "Batch #10\tAverage Generator Loss: 690.751999\tAverage Discriminator Loss: 0.000057\n",
      "\n",
      "Train time for epoch #5059 (step 5059): 1.518613\n",
      "Batch #10\tAverage Generator Loss: 811.285257\tAverage Discriminator Loss: 0.000024\n",
      "\n",
      "Train time for epoch #5060 (step 5060): 1.387694\n",
      "Batch #10\tAverage Generator Loss: 620.961273\tAverage Discriminator Loss: 0.000036\n",
      "\n",
      "Train time for epoch #5061 (step 5061): 1.503008\n",
      "Batch #10\tAverage Generator Loss: 676.971408\tAverage Discriminator Loss: 0.000029\n",
      "\n",
      "Train time for epoch #5062 (step 5062): 1.557639\n",
      "Batch #10\tAverage Generator Loss: 795.067169\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #5063 (step 5063): 1.295978\n",
      "Batch #10\tAverage Generator Loss: 809.085605\tAverage Discriminator Loss: 0.000025\n",
      "\n",
      "Train time for epoch #5064 (step 5064): 1.657140\n",
      "Batch #10\tAverage Generator Loss: 809.298373\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #5065 (step 5065): 1.540818\n",
      "Batch #10\tAverage Generator Loss: 708.438132\tAverage Discriminator Loss: 0.000020\n",
      "\n",
      "Train time for epoch #5066 (step 5066): 1.325054\n",
      "Batch #10\tAverage Generator Loss: 569.597247\tAverage Discriminator Loss: 0.288540\n",
      "\n",
      "Train time for epoch #5067 (step 5067): 1.595541\n",
      "Batch #10\tAverage Generator Loss: 1168.404169\tAverage Discriminator Loss: 0.375030\n",
      "\n",
      "Train time for epoch #5068 (step 5068): 1.494886\n",
      "Batch #10\tAverage Generator Loss: 1284.888416\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5069 (step 5069): 1.565298\n",
      "Batch #10\tAverage Generator Loss: 1254.553757\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5070 (step 5070): 1.544331\n",
      "Batch #10\tAverage Generator Loss: 1279.387042\tAverage Discriminator Loss: 0.035122\n",
      "\n",
      "Train time for epoch #5071 (step 5071): 1.555962\n",
      "Batch #10\tAverage Generator Loss: 1283.061493\tAverage Discriminator Loss: 0.005265\n",
      "\n",
      "Train time for epoch #5072 (step 5072): 1.366888\n",
      "Batch #10\tAverage Generator Loss: 1175.865567\tAverage Discriminator Loss: 0.109145\n",
      "\n",
      "Train time for epoch #5073 (step 5073): 1.479109\n",
      "Batch #10\tAverage Generator Loss: 1375.206274\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5074 (step 5074): 1.323977\n",
      "Batch #10\tAverage Generator Loss: 1387.206580\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5075 (step 5075): 1.510846\n",
      "Batch #10\tAverage Generator Loss: 1171.468524\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5076 (step 5076): 1.556109\n",
      "Batch #10\tAverage Generator Loss: 1636.318585\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5077 (step 5077): 1.298733\n",
      "Batch #10\tAverage Generator Loss: 1411.788339\tAverage Discriminator Loss: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #5078 (step 5078): 1.487511\n",
      "Batch #10\tAverage Generator Loss: 1636.893506\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5079 (step 5079): 1.490927\n",
      "Batch #10\tAverage Generator Loss: 1290.025751\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5080 (step 5080): 1.447562\n",
      "Batch #10\tAverage Generator Loss: 1466.616815\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5081 (step 5081): 1.425649\n",
      "Batch #10\tAverage Generator Loss: 1332.187555\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5082 (step 5082): 1.492944\n",
      "Batch #10\tAverage Generator Loss: 1281.195673\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #5083 (step 5083): 1.289838\n",
      "Batch #10\tAverage Generator Loss: 1241.994751\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5084 (step 5084): 1.615654\n",
      "Batch #10\tAverage Generator Loss: 1398.324902\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5085 (step 5085): 1.557083\n",
      "Batch #10\tAverage Generator Loss: 1273.694141\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5086 (step 5086): 1.390068\n",
      "Batch #10\tAverage Generator Loss: 1205.668768\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5087 (step 5087): 1.530161\n",
      "Batch #10\tAverage Generator Loss: 1507.487860\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5088 (step 5088): 1.514915\n",
      "Batch #10\tAverage Generator Loss: 1274.324438\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5089 (step 5089): 1.234582\n",
      "Batch #10\tAverage Generator Loss: 1367.136328\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5090 (step 5090): 1.498668\n",
      "Batch #10\tAverage Generator Loss: 1283.115759\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5091 (step 5091): 1.361266\n",
      "Batch #10\tAverage Generator Loss: 1256.212964\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5092 (step 5092): 1.535909\n",
      "Batch #10\tAverage Generator Loss: 1244.312103\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5093 (step 5093): 1.530815\n",
      "Batch #10\tAverage Generator Loss: 1314.996027\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5094 (step 5094): 1.405839\n",
      "Batch #10\tAverage Generator Loss: 1363.728442\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5095 (step 5095): 1.500237\n",
      "Batch #10\tAverage Generator Loss: 1306.042004\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5096 (step 5096): 1.538678\n",
      "Batch #10\tAverage Generator Loss: 1293.184937\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5097 (step 5097): 1.235976\n",
      "Batch #10\tAverage Generator Loss: 1174.055627\tAverage Discriminator Loss: 0.013446\n",
      "\n",
      "Train time for epoch #5098 (step 5098): 1.613449\n",
      "Batch #10\tAverage Generator Loss: 1433.363428\tAverage Discriminator Loss: 0.000028\n",
      "\n",
      "Train time for epoch #5099 (step 5099): 1.599309\n",
      "Batch #10\tAverage Generator Loss: 1331.267249\tAverage Discriminator Loss: 0.000134\n",
      "\n",
      "Train time for epoch #5100 (step 5100): 1.242876\n",
      "Batch #10\tAverage Generator Loss: 1381.102777\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5101 (step 5101): 1.560170\n",
      "Batch #10\tAverage Generator Loss: 1316.751459\tAverage Discriminator Loss: 0.017753\n",
      "\n",
      "Train time for epoch #5102 (step 5102): 1.358290\n",
      "Batch #10\tAverage Generator Loss: 1456.906805\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5103 (step 5103): 1.536395\n",
      "Batch #10\tAverage Generator Loss: 1229.413864\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5104 (step 5104): 1.523075\n",
      "Batch #10\tAverage Generator Loss: 1199.250021\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #5105 (step 5105): 1.319282\n",
      "Batch #10\tAverage Generator Loss: 1253.860736\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #5106 (step 5106): 1.450115\n",
      "Batch #10\tAverage Generator Loss: 1314.276831\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5107 (step 5107): 1.484968\n",
      "Batch #10\tAverage Generator Loss: 1289.182324\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5108 (step 5108): 1.402612\n",
      "Batch #10\tAverage Generator Loss: 1254.343427\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5109 (step 5109): 1.540527\n",
      "Batch #10\tAverage Generator Loss: 1417.575293\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5110 (step 5110): 1.346104\n",
      "Batch #10\tAverage Generator Loss: 1223.497028\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5111 (step 5111): 1.542691\n",
      "Batch #10\tAverage Generator Loss: 1272.893915\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5112 (step 5112): 1.522362\n",
      "Batch #10\tAverage Generator Loss: 1256.608337\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5113 (step 5113): 1.433826\n",
      "Batch #10\tAverage Generator Loss: 1291.860437\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5114 (step 5114): 1.562562\n",
      "Batch #10\tAverage Generator Loss: 1361.615033\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5115 (step 5115): 1.438475\n",
      "Batch #10\tAverage Generator Loss: 1271.911462\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5116 (step 5116): 1.348251\n",
      "Batch #10\tAverage Generator Loss: 1257.144806\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5117 (step 5117): 1.748860\n",
      "Batch #10\tAverage Generator Loss: 1202.985437\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5118 (step 5118): 1.574390\n",
      "Batch #10\tAverage Generator Loss: 1278.109070\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5119 (step 5119): 1.384902\n",
      "Batch #10\tAverage Generator Loss: 1390.066394\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5120 (step 5120): 1.619464\n",
      "Batch #10\tAverage Generator Loss: 1433.681775\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5121 (step 5121): 1.482694\n",
      "Batch #10\tAverage Generator Loss: 1373.715308\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5122 (step 5122): 1.346926\n",
      "Batch #10\tAverage Generator Loss: 1217.940060\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5123 (step 5123): 1.646125\n",
      "Batch #10\tAverage Generator Loss: 1247.439008\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5124 (step 5124): 1.592785\n",
      "Batch #10\tAverage Generator Loss: 1365.915088\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5125 (step 5125): 1.370525\n",
      "Batch #10\tAverage Generator Loss: 1265.621754\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5126 (step 5126): 1.549215\n",
      "Batch #10\tAverage Generator Loss: 1379.474213\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5127 (step 5127): 1.636873\n",
      "Batch #10\tAverage Generator Loss: 1333.086365\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5128 (step 5128): 1.397208\n",
      "Batch #10\tAverage Generator Loss: 1232.685181\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5129 (step 5129): 1.444808\n",
      "Batch #10\tAverage Generator Loss: 1500.295966\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5130 (step 5130): 1.464050\n",
      "Batch #10\tAverage Generator Loss: 1401.335913\tAverage Discriminator Loss: 0.000172\n",
      "\n",
      "Train time for epoch #5131 (step 5131): 1.322325\n",
      "Batch #10\tAverage Generator Loss: 1352.522937\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5132 (step 5132): 1.599426\n",
      "Batch #10\tAverage Generator Loss: 1262.217609\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #5133 (step 5133): 1.624100\n",
      "Batch #10\tAverage Generator Loss: 1231.207037\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5134 (step 5134): 1.430469\n",
      "Batch #10\tAverage Generator Loss: 1401.965643\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5135 (step 5135): 1.497950\n",
      "Batch #10\tAverage Generator Loss: 1250.340271\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #5136 (step 5136): 1.591532\n",
      "Batch #10\tAverage Generator Loss: 1365.205981\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5137 (step 5137): 1.369042\n",
      "Batch #10\tAverage Generator Loss: 1355.492932\tAverage Discriminator Loss: 0.000167\n",
      "\n",
      "Train time for epoch #5138 (step 5138): 1.479534\n",
      "Batch #10\tAverage Generator Loss: 1218.714575\tAverage Discriminator Loss: 0.000071\n",
      "\n",
      "Train time for epoch #5139 (step 5139): 1.601779\n",
      "Batch #10\tAverage Generator Loss: 1413.468121\tAverage Discriminator Loss: 0.000009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #5140 (step 5140): 1.388494\n",
      "Batch #10\tAverage Generator Loss: 1138.619211\tAverage Discriminator Loss: 0.064164\n",
      "\n",
      "Train time for epoch #5141 (step 5141): 1.488780\n",
      "Batch #10\tAverage Generator Loss: 1295.587042\tAverage Discriminator Loss: 0.005189\n",
      "\n",
      "Train time for epoch #5142 (step 5142): 1.654964\n",
      "Batch #10\tAverage Generator Loss: 1293.206140\tAverage Discriminator Loss: 0.042573\n",
      "\n",
      "Train time for epoch #5143 (step 5143): 1.504317\n",
      "Batch #10\tAverage Generator Loss: 1329.799435\tAverage Discriminator Loss: 0.003752\n",
      "\n",
      "Train time for epoch #5144 (step 5144): 1.681307\n",
      "Batch #10\tAverage Generator Loss: 1422.928973\tAverage Discriminator Loss: 0.002217\n",
      "\n",
      "Train time for epoch #5145 (step 5145): 1.388094\n",
      "Batch #10\tAverage Generator Loss: 1401.095264\tAverage Discriminator Loss: 0.004670\n",
      "\n",
      "Train time for epoch #5146 (step 5146): 1.524303\n",
      "Batch #10\tAverage Generator Loss: 1385.853442\tAverage Discriminator Loss: 0.000087\n",
      "\n",
      "Train time for epoch #5147 (step 5147): 1.453740\n",
      "Batch #10\tAverage Generator Loss: 1146.126544\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5148 (step 5148): 1.410431\n",
      "Batch #10\tAverage Generator Loss: 1404.625562\tAverage Discriminator Loss: 0.000087\n",
      "\n",
      "Train time for epoch #5149 (step 5149): 1.692784\n",
      "Batch #10\tAverage Generator Loss: 1408.670380\tAverage Discriminator Loss: 0.006525\n",
      "\n",
      "Train time for epoch #5150 (step 5150): 1.326585\n",
      "Batch #10\tAverage Generator Loss: 1475.474939\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #5151 (step 5151): 1.535037\n",
      "Batch #10\tAverage Generator Loss: 1415.927197\tAverage Discriminator Loss: 0.000296\n",
      "\n",
      "Train time for epoch #5152 (step 5152): 1.557754\n",
      "Batch #10\tAverage Generator Loss: 1493.238727\tAverage Discriminator Loss: 0.000183\n",
      "\n",
      "Train time for epoch #5153 (step 5153): 1.385800\n",
      "Batch #10\tAverage Generator Loss: 1394.901953\tAverage Discriminator Loss: 0.000088\n",
      "\n",
      "Train time for epoch #5154 (step 5154): 1.626990\n",
      "Batch #10\tAverage Generator Loss: 1318.553918\tAverage Discriminator Loss: 0.000067\n",
      "\n",
      "Train time for epoch #5155 (step 5155): 1.586470\n",
      "Batch #10\tAverage Generator Loss: 1336.074640\tAverage Discriminator Loss: 0.150624\n",
      "\n",
      "Train time for epoch #5156 (step 5156): 1.340957\n",
      "Batch #10\tAverage Generator Loss: 1405.400098\tAverage Discriminator Loss: 0.063641\n",
      "\n",
      "Train time for epoch #5157 (step 5157): 1.483008\n",
      "Batch #10\tAverage Generator Loss: 1338.986322\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #5158 (step 5158): 1.558707\n",
      "Batch #10\tAverage Generator Loss: 1376.502472\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #5159 (step 5159): 1.280100\n",
      "Batch #10\tAverage Generator Loss: 1299.890784\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5160 (step 5160): 1.524259\n",
      "Batch #10\tAverage Generator Loss: 1155.471756\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5161 (step 5161): 1.495395\n",
      "Batch #10\tAverage Generator Loss: 1272.276367\tAverage Discriminator Loss: 0.001600\n",
      "\n",
      "Train time for epoch #5162 (step 5162): 1.374262\n",
      "Batch #10\tAverage Generator Loss: 1057.978540\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #5163 (step 5163): 1.492975\n",
      "Batch #10\tAverage Generator Loss: 1267.200928\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #5164 (step 5164): 1.498749\n",
      "Batch #10\tAverage Generator Loss: 1247.651013\tAverage Discriminator Loss: 0.003327\n",
      "\n",
      "Train time for epoch #5165 (step 5165): 1.378395\n",
      "Batch #10\tAverage Generator Loss: 1115.522296\tAverage Discriminator Loss: 0.000074\n",
      "\n",
      "Train time for epoch #5166 (step 5166): 1.480594\n",
      "Batch #10\tAverage Generator Loss: 1301.946478\tAverage Discriminator Loss: 0.000067\n",
      "\n",
      "Train time for epoch #5167 (step 5167): 1.399375\n",
      "Batch #10\tAverage Generator Loss: 1213.491867\tAverage Discriminator Loss: 0.000029\n",
      "\n",
      "Train time for epoch #5168 (step 5168): 1.481754\n",
      "Batch #10\tAverage Generator Loss: 1112.674103\tAverage Discriminator Loss: 0.000054\n",
      "\n",
      "Train time for epoch #5169 (step 5169): 1.492899\n",
      "Batch #10\tAverage Generator Loss: 1163.022913\tAverage Discriminator Loss: 0.000029\n",
      "\n",
      "Train time for epoch #5170 (step 5170): 1.398695\n",
      "Batch #10\tAverage Generator Loss: 1203.775238\tAverage Discriminator Loss: 0.000026\n",
      "\n",
      "Train time for epoch #5171 (step 5171): 1.532666\n",
      "Batch #10\tAverage Generator Loss: 1149.190564\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #5172 (step 5172): 1.492677\n",
      "Batch #10\tAverage Generator Loss: 1277.997198\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #5173 (step 5173): 1.290434\n",
      "Batch #10\tAverage Generator Loss: 1276.695721\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #5174 (step 5174): 1.583955\n",
      "Batch #10\tAverage Generator Loss: 1435.315417\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #5175 (step 5175): 1.530527\n",
      "Batch #10\tAverage Generator Loss: 1288.448468\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #5176 (step 5176): 1.394945\n",
      "Batch #10\tAverage Generator Loss: 1152.156830\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #5177 (step 5177): 1.588975\n",
      "Batch #10\tAverage Generator Loss: 1276.589258\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #5178 (step 5178): 1.389513\n",
      "Batch #10\tAverage Generator Loss: 1351.535052\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #5179 (step 5179): 1.516072\n",
      "Batch #10\tAverage Generator Loss: 1255.496564\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #5180 (step 5180): 1.573595\n",
      "Batch #10\tAverage Generator Loss: 1154.394177\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #5181 (step 5181): 1.285190\n",
      "Batch #10\tAverage Generator Loss: 1336.841864\tAverage Discriminator Loss: 0.000035\n",
      "\n",
      "Train time for epoch #5182 (step 5182): 1.587541\n",
      "Batch #10\tAverage Generator Loss: 1283.396527\tAverage Discriminator Loss: 0.000035\n",
      "\n",
      "Train time for epoch #5183 (step 5183): 1.491719\n",
      "Batch #10\tAverage Generator Loss: 1308.918451\tAverage Discriminator Loss: 0.000216\n",
      "\n",
      "Train time for epoch #5184 (step 5184): 1.517323\n",
      "Batch #10\tAverage Generator Loss: 1207.241791\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #5185 (step 5185): 1.515224\n",
      "Batch #10\tAverage Generator Loss: 1049.219272\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #5186 (step 5186): 1.574702\n",
      "Batch #10\tAverage Generator Loss: 1220.830481\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #5187 (step 5187): 1.362394\n",
      "Batch #10\tAverage Generator Loss: 1256.590747\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #5188 (step 5188): 1.749132\n",
      "Batch #10\tAverage Generator Loss: 1274.924683\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #5189 (step 5189): 1.305247\n",
      "Batch #10\tAverage Generator Loss: 1170.832654\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #5190 (step 5190): 1.481265\n",
      "Batch #10\tAverage Generator Loss: 1172.869467\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #5191 (step 5191): 1.568242\n",
      "Batch #10\tAverage Generator Loss: 942.295480\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #5192 (step 5192): 1.446893\n",
      "Batch #10\tAverage Generator Loss: 1131.882928\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #5193 (step 5193): 1.236992\n",
      "Batch #10\tAverage Generator Loss: 1266.193732\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #5194 (step 5194): 1.527477\n",
      "Batch #10\tAverage Generator Loss: 1202.144165\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #5195 (step 5195): 1.379673\n",
      "Batch #10\tAverage Generator Loss: 1188.078979\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #5196 (step 5196): 1.586239\n",
      "Batch #10\tAverage Generator Loss: 1333.869495\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #5197 (step 5197): 1.482641\n",
      "Batch #10\tAverage Generator Loss: 1100.184607\tAverage Discriminator Loss: 0.010743\n",
      "\n",
      "Train time for epoch #5198 (step 5198): 1.379596\n",
      "Batch #10\tAverage Generator Loss: 1124.975952\tAverage Discriminator Loss: 0.000338\n",
      "\n",
      "Train time for epoch #5199 (step 5199): 1.586615\n",
      "Batch #10\tAverage Generator Loss: 1238.464337\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #5200 (step 5200): 1.571235\n",
      "Batch #10\tAverage Generator Loss: 1000.844025\tAverage Discriminator Loss: 0.000025\n",
      "\n",
      "Train time for epoch #5201 (step 5201): 1.339030\n",
      "Batch #10\tAverage Generator Loss: 1283.861011\tAverage Discriminator Loss: 0.000007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #5202 (step 5202): 1.621111\n",
      "Batch #10\tAverage Generator Loss: 1215.217035\tAverage Discriminator Loss: 0.000019\n",
      "\n",
      "Train time for epoch #5203 (step 5203): 1.533786\n",
      "Batch #10\tAverage Generator Loss: 1272.110156\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #5204 (step 5204): 1.337210\n",
      "Batch #10\tAverage Generator Loss: 1179.270609\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #5205 (step 5205): 1.481563\n",
      "Batch #10\tAverage Generator Loss: 1234.371378\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #5206 (step 5206): 1.542389\n",
      "Batch #10\tAverage Generator Loss: 1135.444354\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #5207 (step 5207): 1.436748\n",
      "Batch #10\tAverage Generator Loss: 1157.909344\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #5208 (step 5208): 1.485352\n",
      "Batch #10\tAverage Generator Loss: 1219.010669\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #5209 (step 5209): 1.492056\n",
      "Batch #10\tAverage Generator Loss: 997.606696\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #5210 (step 5210): 1.351892\n",
      "Batch #10\tAverage Generator Loss: 1290.971942\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #5211 (step 5211): 1.510517\n",
      "Batch #10\tAverage Generator Loss: 1205.908105\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #5212 (step 5212): 1.378954\n",
      "Batch #10\tAverage Generator Loss: 1121.025739\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #5213 (step 5213): 1.563439\n",
      "Batch #10\tAverage Generator Loss: 1151.314667\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #5214 (step 5214): 1.564915\n",
      "Batch #10\tAverage Generator Loss: 1061.010791\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #5215 (step 5215): 1.299881\n",
      "Batch #10\tAverage Generator Loss: 1239.329346\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #5216 (step 5216): 1.496151\n",
      "Batch #10\tAverage Generator Loss: 1099.741656\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #5217 (step 5217): 1.486694\n",
      "Batch #10\tAverage Generator Loss: 1306.527167\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #5218 (step 5218): 1.324364\n",
      "Batch #10\tAverage Generator Loss: 1049.148859\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #5219 (step 5219): 1.478427\n",
      "Batch #10\tAverage Generator Loss: 1003.553210\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #5220 (step 5220): 1.492868\n",
      "Batch #10\tAverage Generator Loss: 1042.742572\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #5221 (step 5221): 1.443206\n",
      "Batch #10\tAverage Generator Loss: 1256.719705\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #5222 (step 5222): 1.431688\n",
      "Batch #10\tAverage Generator Loss: 1100.208899\tAverage Discriminator Loss: 0.014650\n",
      "\n",
      "Train time for epoch #5223 (step 5223): 1.543739\n",
      "Batch #10\tAverage Generator Loss: 1216.096277\tAverage Discriminator Loss: 0.000022\n",
      "\n",
      "Train time for epoch #5224 (step 5224): 1.284223\n",
      "Batch #10\tAverage Generator Loss: 1250.678668\tAverage Discriminator Loss: 0.000107\n",
      "\n",
      "Train time for epoch #5225 (step 5225): 1.472087\n",
      "Batch #10\tAverage Generator Loss: 1095.381183\tAverage Discriminator Loss: 0.000058\n",
      "\n",
      "Train time for epoch #5226 (step 5226): 1.542039\n",
      "Batch #10\tAverage Generator Loss: 1042.139456\tAverage Discriminator Loss: 0.000045\n",
      "\n",
      "Train time for epoch #5227 (step 5227): 1.400647\n",
      "Batch #10\tAverage Generator Loss: 1310.318115\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #5228 (step 5228): 1.485075\n",
      "Batch #10\tAverage Generator Loss: 1056.238237\tAverage Discriminator Loss: 0.000025\n",
      "\n",
      "Train time for epoch #5229 (step 5229): 1.477541\n",
      "Batch #10\tAverage Generator Loss: 1102.906732\tAverage Discriminator Loss: 0.000020\n",
      "\n",
      "Train time for epoch #5230 (step 5230): 1.280751\n",
      "Batch #10\tAverage Generator Loss: 1165.634671\tAverage Discriminator Loss: 0.011635\n",
      "\n",
      "Train time for epoch #5231 (step 5231): 1.491652\n",
      "Batch #10\tAverage Generator Loss: 1094.810138\tAverage Discriminator Loss: 0.000133\n",
      "\n",
      "Train time for epoch #5232 (step 5232): 1.437035\n",
      "Batch #10\tAverage Generator Loss: 1282.571094\tAverage Discriminator Loss: 0.000045\n",
      "\n",
      "Train time for epoch #5233 (step 5233): 1.627038\n",
      "Batch #10\tAverage Generator Loss: 1183.396429\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #5234 (step 5234): 1.541430\n",
      "Batch #10\tAverage Generator Loss: 1062.829626\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #5235 (step 5235): 1.366585\n",
      "Batch #10\tAverage Generator Loss: 1202.810321\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #5236 (step 5236): 1.517945\n",
      "Batch #10\tAverage Generator Loss: 1224.284460\tAverage Discriminator Loss: 0.000029\n",
      "\n",
      "Train time for epoch #5237 (step 5237): 1.344761\n",
      "Batch #10\tAverage Generator Loss: 1220.999780\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #5238 (step 5238): 1.621173\n",
      "Batch #10\tAverage Generator Loss: 1292.254523\tAverage Discriminator Loss: 0.000021\n",
      "\n",
      "Train time for epoch #5239 (step 5239): 1.625151\n",
      "Batch #10\tAverage Generator Loss: 1184.357721\tAverage Discriminator Loss: 0.344470\n",
      "\n",
      "Train time for epoch #5240 (step 5240): 1.238477\n",
      "Batch #10\tAverage Generator Loss: 1277.315485\tAverage Discriminator Loss: 0.007038\n",
      "\n",
      "Train time for epoch #5241 (step 5241): 1.547154\n",
      "Batch #10\tAverage Generator Loss: 1139.624219\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5242 (step 5242): 1.561529\n",
      "Batch #10\tAverage Generator Loss: 1074.507355\tAverage Discriminator Loss: 0.015100\n",
      "\n",
      "Train time for epoch #5243 (step 5243): 1.333322\n",
      "Batch #10\tAverage Generator Loss: 1204.021094\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #5244 (step 5244): 1.526808\n",
      "Batch #10\tAverage Generator Loss: 1163.439746\tAverage Discriminator Loss: 0.006171\n",
      "\n",
      "Train time for epoch #5245 (step 5245): 1.488184\n",
      "Batch #10\tAverage Generator Loss: 1207.755896\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #5246 (step 5246): 1.349989\n",
      "Batch #10\tAverage Generator Loss: 1082.649750\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5247 (step 5247): 1.503079\n",
      "Batch #10\tAverage Generator Loss: 1134.620959\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #5248 (step 5248): 1.597652\n",
      "Batch #10\tAverage Generator Loss: 1116.868585\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5249 (step 5249): 1.460042\n",
      "Batch #10\tAverage Generator Loss: 1008.104615\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #5250 (step 5250): 1.558590\n",
      "Batch #10\tAverage Generator Loss: 1131.751776\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #5251 (step 5251): 1.546952\n",
      "Batch #10\tAverage Generator Loss: 977.405164\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #5252 (step 5252): 1.346012\n",
      "Batch #10\tAverage Generator Loss: 1120.447235\tAverage Discriminator Loss: 0.000153\n",
      "\n",
      "Train time for epoch #5253 (step 5253): 1.571184\n",
      "Batch #10\tAverage Generator Loss: 1028.601160\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #5254 (step 5254): 1.403963\n",
      "Batch #10\tAverage Generator Loss: 1097.725433\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5255 (step 5255): 1.494820\n",
      "Batch #10\tAverage Generator Loss: 1269.405896\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #5256 (step 5256): 1.528047\n",
      "Batch #10\tAverage Generator Loss: 1144.188239\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #5257 (step 5257): 1.485575\n",
      "Batch #10\tAverage Generator Loss: 1175.151108\tAverage Discriminator Loss: 0.008617\n",
      "\n",
      "Train time for epoch #5258 (step 5258): 1.546972\n",
      "Batch #10\tAverage Generator Loss: 1151.427625\tAverage Discriminator Loss: 0.000027\n",
      "\n",
      "Train time for epoch #5259 (step 5259): 1.547484\n",
      "Batch #10\tAverage Generator Loss: 1217.719598\tAverage Discriminator Loss: 0.000034\n",
      "\n",
      "Train time for epoch #5260 (step 5260): 1.286453\n",
      "Batch #10\tAverage Generator Loss: 1255.654395\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #5261 (step 5261): 1.575065\n",
      "Batch #10\tAverage Generator Loss: 1074.239362\tAverage Discriminator Loss: 0.000031\n",
      "\n",
      "Train time for epoch #5262 (step 5262): 1.389575\n",
      "Batch #10\tAverage Generator Loss: 1223.255273\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #5263 (step 5263): 1.658145\n",
      "Batch #10\tAverage Generator Loss: 1235.023340\tAverage Discriminator Loss: 0.000198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #5264 (step 5264): 1.477517\n",
      "Batch #10\tAverage Generator Loss: 1089.532648\tAverage Discriminator Loss: 0.000071\n",
      "\n",
      "Train time for epoch #5265 (step 5265): 1.335450\n",
      "Batch #10\tAverage Generator Loss: 1089.725635\tAverage Discriminator Loss: 0.000047\n",
      "\n",
      "Train time for epoch #5266 (step 5266): 1.530165\n",
      "Batch #10\tAverage Generator Loss: 1043.163257\tAverage Discriminator Loss: 0.000032\n",
      "\n",
      "Train time for epoch #5267 (step 5267): 1.489819\n",
      "Batch #10\tAverage Generator Loss: 1127.127826\tAverage Discriminator Loss: 0.000030\n",
      "\n",
      "Train time for epoch #5268 (step 5268): 1.359219\n",
      "Batch #10\tAverage Generator Loss: 1167.812610\tAverage Discriminator Loss: 0.000045\n",
      "\n",
      "Train time for epoch #5269 (step 5269): 1.525830\n",
      "Batch #10\tAverage Generator Loss: 1031.435315\tAverage Discriminator Loss: 0.000025\n",
      "\n",
      "Train time for epoch #5270 (step 5270): 1.478914\n",
      "Batch #10\tAverage Generator Loss: 1083.569617\tAverage Discriminator Loss: 0.000021\n",
      "\n",
      "Train time for epoch #5271 (step 5271): 1.467186\n",
      "Batch #10\tAverage Generator Loss: 1158.725592\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #5272 (step 5272): 1.479651\n",
      "Batch #10\tAverage Generator Loss: 1183.564063\tAverage Discriminator Loss: 0.004261\n",
      "\n",
      "Train time for epoch #5273 (step 5273): 1.531115\n",
      "Batch #10\tAverage Generator Loss: 1157.873773\tAverage Discriminator Loss: 0.009140\n",
      "\n",
      "Train time for epoch #5274 (step 5274): 1.442674\n",
      "Batch #10\tAverage Generator Loss: 872.776895\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #5275 (step 5275): 1.457949\n",
      "Batch #10\tAverage Generator Loss: 1156.930048\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #5276 (step 5276): 1.532789\n",
      "Batch #10\tAverage Generator Loss: 1174.835175\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5277 (step 5277): 1.369892\n",
      "Batch #10\tAverage Generator Loss: 1232.020084\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5278 (step 5278): 1.530381\n",
      "Batch #10\tAverage Generator Loss: 1084.813373\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #5279 (step 5279): 1.445833\n",
      "Batch #10\tAverage Generator Loss: 1155.170880\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #5280 (step 5280): 1.480931\n",
      "Batch #10\tAverage Generator Loss: 1061.620731\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5281 (step 5281): 1.496493\n",
      "Batch #10\tAverage Generator Loss: 1165.985272\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #5282 (step 5282): 1.324985\n",
      "Batch #10\tAverage Generator Loss: 1193.547131\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #5283 (step 5283): 1.596821\n",
      "Batch #10\tAverage Generator Loss: 1186.100061\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #5284 (step 5284): 1.330519\n",
      "Batch #10\tAverage Generator Loss: 993.766905\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #5285 (step 5285): 1.654074\n",
      "Batch #10\tAverage Generator Loss: 1205.363220\tAverage Discriminator Loss: 0.000043\n",
      "\n",
      "Train time for epoch #5286 (step 5286): 1.542971\n",
      "Batch #10\tAverage Generator Loss: 1185.125677\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #5287 (step 5287): 1.324483\n",
      "Batch #10\tAverage Generator Loss: 1222.858868\tAverage Discriminator Loss: 0.023517\n",
      "\n",
      "Train time for epoch #5288 (step 5288): 1.536403\n",
      "Batch #10\tAverage Generator Loss: 1108.264786\tAverage Discriminator Loss: 0.009075\n",
      "\n",
      "Train time for epoch #5289 (step 5289): 1.502910\n",
      "Batch #10\tAverage Generator Loss: 1155.430890\tAverage Discriminator Loss: 0.000034\n",
      "\n",
      "Train time for epoch #5290 (step 5290): 1.269356\n",
      "Batch #10\tAverage Generator Loss: 1106.871472\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #5291 (step 5291): 1.549707\n",
      "Batch #10\tAverage Generator Loss: 1289.963116\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #5292 (step 5292): 1.491492\n",
      "Batch #10\tAverage Generator Loss: 1205.919299\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #5293 (step 5293): 1.427918\n",
      "Batch #10\tAverage Generator Loss: 1065.246851\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #5294 (step 5294): 1.490119\n",
      "Batch #10\tAverage Generator Loss: 1087.730664\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #5295 (step 5295): 1.495058\n",
      "Batch #10\tAverage Generator Loss: 1033.615298\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #5296 (step 5296): 1.298767\n",
      "Batch #10\tAverage Generator Loss: 1201.186359\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #5297 (step 5297): 1.521356\n",
      "Batch #10\tAverage Generator Loss: 1044.029422\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #5298 (step 5298): 1.283536\n",
      "Batch #10\tAverage Generator Loss: 1260.080157\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #5299 (step 5299): 1.615189\n",
      "Batch #10\tAverage Generator Loss: 1261.585406\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #5300 (step 5300): 1.766776\n",
      "Batch #10\tAverage Generator Loss: 1165.140814\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #5301 (step 5301): 1.509889\n",
      "Batch #10\tAverage Generator Loss: 1209.641150\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #5302 (step 5302): 1.833176\n",
      "Batch #10\tAverage Generator Loss: 1208.050372\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #5303 (step 5303): 1.876119\n",
      "Batch #10\tAverage Generator Loss: 1054.192365\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #5304 (step 5304): 1.846704\n",
      "Batch #10\tAverage Generator Loss: 1082.037195\tAverage Discriminator Loss: 0.026344\n",
      "\n",
      "Train time for epoch #5305 (step 5305): 2.068098\n",
      "Batch #10\tAverage Generator Loss: 1067.071204\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #5306 (step 5306): 1.289390\n",
      "Batch #10\tAverage Generator Loss: 1250.252649\tAverage Discriminator Loss: 0.000026\n",
      "\n",
      "Train time for epoch #5307 (step 5307): 2.219105\n",
      "Batch #10\tAverage Generator Loss: 989.464056\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #5308 (step 5308): 1.488440\n",
      "Batch #10\tAverage Generator Loss: 1144.613306\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #5309 (step 5309): 1.304325\n",
      "Batch #10\tAverage Generator Loss: 1031.621683\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #5310 (step 5310): 1.473056\n",
      "Batch #10\tAverage Generator Loss: 916.389789\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #5311 (step 5311): 1.480233\n",
      "Batch #10\tAverage Generator Loss: 1026.533771\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #5312 (step 5312): 1.353616\n",
      "Batch #10\tAverage Generator Loss: 1094.110864\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #5313 (step 5313): 1.483303\n",
      "Batch #10\tAverage Generator Loss: 1025.903174\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #5314 (step 5314): 1.733422\n",
      "Batch #10\tAverage Generator Loss: 1065.612500\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #5315 (step 5315): 1.397933\n",
      "Batch #10\tAverage Generator Loss: 1163.277594\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #5316 (step 5316): 1.537914\n",
      "Batch #10\tAverage Generator Loss: 1207.054077\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #5317 (step 5317): 1.500907\n",
      "Batch #10\tAverage Generator Loss: 1364.920563\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #5318 (step 5318): 1.365960\n",
      "Batch #10\tAverage Generator Loss: 1183.935937\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #5319 (step 5319): 1.486967\n",
      "Batch #10\tAverage Generator Loss: 1115.094482\tAverage Discriminator Loss: 0.003099\n",
      "\n",
      "Train time for epoch #5320 (step 5320): 1.294370\n",
      "Batch #10\tAverage Generator Loss: 1110.108588\tAverage Discriminator Loss: 0.000079\n",
      "\n",
      "Train time for epoch #5321 (step 5321): 1.482763\n",
      "Batch #10\tAverage Generator Loss: 1112.120319\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #5322 (step 5322): 1.571136\n",
      "Batch #10\tAverage Generator Loss: 1067.745349\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #5323 (step 5323): 1.323460\n",
      "Batch #10\tAverage Generator Loss: 1092.170795\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #5324 (step 5324): 1.492519\n",
      "Batch #10\tAverage Generator Loss: 1062.197394\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #5325 (step 5325): 1.496576\n",
      "Batch #10\tAverage Generator Loss: 1098.536218\tAverage Discriminator Loss: 0.000007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #5326 (step 5326): 1.348954\n",
      "Batch #10\tAverage Generator Loss: 973.563254\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #5327 (step 5327): 1.645278\n",
      "Batch #10\tAverage Generator Loss: 1105.778357\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #5328 (step 5328): 1.286702\n",
      "Batch #10\tAverage Generator Loss: 1029.429785\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #5329 (step 5329): 1.482426\n",
      "Batch #10\tAverage Generator Loss: 1029.129553\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #5330 (step 5330): 1.491703\n",
      "Batch #10\tAverage Generator Loss: 988.509061\tAverage Discriminator Loss: 0.006022\n",
      "\n",
      "Train time for epoch #5331 (step 5331): 1.274775\n",
      "Batch #10\tAverage Generator Loss: 1063.538849\tAverage Discriminator Loss: 0.000707\n",
      "\n",
      "Train time for epoch #5332 (step 5332): 1.536205\n",
      "Batch #10\tAverage Generator Loss: 945.026947\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #5333 (step 5333): 1.572405\n",
      "Batch #10\tAverage Generator Loss: 1138.337805\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #5334 (step 5334): 1.286316\n",
      "Batch #10\tAverage Generator Loss: 1113.620544\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #5335 (step 5335): 1.587341\n",
      "Batch #10\tAverage Generator Loss: 1146.011938\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5336 (step 5336): 1.337886\n",
      "Batch #10\tAverage Generator Loss: 1209.727106\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #5337 (step 5337): 1.557078\n",
      "Batch #10\tAverage Generator Loss: 972.815540\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #5338 (step 5338): 1.655681\n",
      "Batch #10\tAverage Generator Loss: 933.954211\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #5339 (step 5339): 1.288757\n",
      "Batch #10\tAverage Generator Loss: 1114.208734\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #5340 (step 5340): 1.579198\n",
      "Batch #10\tAverage Generator Loss: 872.159750\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #5341 (step 5341): 1.557222\n",
      "Batch #10\tAverage Generator Loss: 932.005942\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #5342 (step 5342): 1.429962\n",
      "Batch #10\tAverage Generator Loss: 1122.466577\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5343 (step 5343): 1.532949\n",
      "Batch #10\tAverage Generator Loss: 1062.971783\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #5344 (step 5344): 1.486156\n",
      "Batch #10\tAverage Generator Loss: 1064.126758\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #5345 (step 5345): 1.405805\n",
      "Batch #10\tAverage Generator Loss: 1016.841159\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #5346 (step 5346): 1.652827\n",
      "Batch #10\tAverage Generator Loss: 1079.718353\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5347 (step 5347): 1.431800\n",
      "Batch #10\tAverage Generator Loss: 1152.869305\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #5348 (step 5348): 1.620424\n",
      "Batch #10\tAverage Generator Loss: 1086.060895\tAverage Discriminator Loss: 0.001424\n",
      "\n",
      "Train time for epoch #5349 (step 5349): 1.530772\n",
      "Batch #10\tAverage Generator Loss: 1000.819821\tAverage Discriminator Loss: 0.022438\n",
      "\n",
      "Train time for epoch #5350 (step 5350): 1.275897\n",
      "Batch #10\tAverage Generator Loss: 1127.272455\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #5351 (step 5351): 1.628788\n",
      "Batch #10\tAverage Generator Loss: 957.567499\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5352 (step 5352): 1.543426\n",
      "Batch #10\tAverage Generator Loss: 1364.067944\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5353 (step 5353): 1.277150\n",
      "Batch #10\tAverage Generator Loss: 988.660233\tAverage Discriminator Loss: 0.064916\n",
      "\n",
      "Train time for epoch #5354 (step 5354): 1.472687\n",
      "Batch #10\tAverage Generator Loss: 1164.424591\tAverage Discriminator Loss: 0.000373\n",
      "\n",
      "Train time for epoch #5355 (step 5355): 1.289144\n",
      "Batch #10\tAverage Generator Loss: 1093.594806\tAverage Discriminator Loss: 0.137780\n",
      "\n",
      "Train time for epoch #5356 (step 5356): 1.582850\n",
      "Batch #10\tAverage Generator Loss: 964.560217\tAverage Discriminator Loss: 0.014221\n",
      "\n",
      "Train time for epoch #5357 (step 5357): 1.540058\n",
      "Batch #10\tAverage Generator Loss: 1022.479327\tAverage Discriminator Loss: 0.000038\n",
      "\n",
      "Train time for epoch #5358 (step 5358): 1.345771\n",
      "Batch #10\tAverage Generator Loss: 1054.984079\tAverage Discriminator Loss: 0.000042\n",
      "\n",
      "Train time for epoch #5359 (step 5359): 1.464971\n",
      "Batch #10\tAverage Generator Loss: 1065.168048\tAverage Discriminator Loss: 0.000040\n",
      "\n",
      "Train time for epoch #5360 (step 5360): 1.495457\n",
      "Batch #10\tAverage Generator Loss: 1124.130518\tAverage Discriminator Loss: 0.011202\n",
      "\n",
      "Train time for epoch #5361 (step 5361): 1.390079\n",
      "Batch #10\tAverage Generator Loss: 1034.355121\tAverage Discriminator Loss: 0.000857\n",
      "\n",
      "Train time for epoch #5362 (step 5362): 1.573966\n",
      "Batch #10\tAverage Generator Loss: 1049.116437\tAverage Discriminator Loss: 0.000048\n",
      "\n",
      "Train time for epoch #5363 (step 5363): 1.482615\n",
      "Batch #10\tAverage Generator Loss: 1126.296448\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #5364 (step 5364): 1.357702\n",
      "Batch #10\tAverage Generator Loss: 1066.459265\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #5365 (step 5365): 1.608032\n",
      "Batch #10\tAverage Generator Loss: 1231.678107\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #5366 (step 5366): 1.602339\n",
      "Batch #10\tAverage Generator Loss: 1032.815051\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #5367 (step 5367): 1.371600\n",
      "Batch #10\tAverage Generator Loss: 1025.444748\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #5368 (step 5368): 1.527947\n",
      "Batch #10\tAverage Generator Loss: 1139.832404\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #5369 (step 5369): 1.514530\n",
      "Batch #10\tAverage Generator Loss: 1008.999536\tAverage Discriminator Loss: 0.010836\n",
      "\n",
      "Train time for epoch #5370 (step 5370): 1.351994\n",
      "Batch #10\tAverage Generator Loss: 877.316254\tAverage Discriminator Loss: 0.000474\n",
      "\n",
      "Train time for epoch #5371 (step 5371): 1.555377\n",
      "Batch #10\tAverage Generator Loss: 1109.082733\tAverage Discriminator Loss: 0.000020\n",
      "\n",
      "Train time for epoch #5372 (step 5372): 1.523222\n",
      "Batch #10\tAverage Generator Loss: 993.824713\tAverage Discriminator Loss: 0.006541\n",
      "\n",
      "Train time for epoch #5373 (step 5373): 1.379739\n",
      "Batch #10\tAverage Generator Loss: 1003.282849\tAverage Discriminator Loss: 0.004910\n",
      "\n",
      "Train time for epoch #5374 (step 5374): 1.577603\n",
      "Batch #10\tAverage Generator Loss: 940.154565\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5375 (step 5375): 1.296722\n",
      "Batch #10\tAverage Generator Loss: 961.694678\tAverage Discriminator Loss: 0.002993\n",
      "\n",
      "Train time for epoch #5376 (step 5376): 1.495745\n",
      "Batch #10\tAverage Generator Loss: 771.709207\tAverage Discriminator Loss: 0.000345\n",
      "\n",
      "Train time for epoch #5377 (step 5377): 1.632356\n",
      "Batch #10\tAverage Generator Loss: 1006.606641\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #5378 (step 5378): 1.325175\n",
      "Batch #10\tAverage Generator Loss: 894.533173\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #5379 (step 5379): 1.559577\n",
      "Batch #10\tAverage Generator Loss: 789.955338\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #5380 (step 5380): 1.345609\n",
      "Batch #10\tAverage Generator Loss: 896.102249\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #5381 (step 5381): 1.479407\n",
      "Batch #10\tAverage Generator Loss: 936.298389\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #5382 (step 5382): 1.544784\n",
      "Batch #10\tAverage Generator Loss: 908.686630\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #5383 (step 5383): 1.304909\n",
      "Batch #10\tAverage Generator Loss: 889.221222\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #5384 (step 5384): 1.491659\n",
      "Batch #10\tAverage Generator Loss: 952.815158\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #5385 (step 5385): 1.695727\n",
      "Batch #10\tAverage Generator Loss: 909.746881\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #5386 (step 5386): 1.327490\n",
      "Batch #10\tAverage Generator Loss: 961.619409\tAverage Discriminator Loss: 0.003805\n",
      "\n",
      "Train time for epoch #5387 (step 5387): 1.535209\n",
      "Batch #10\tAverage Generator Loss: 888.990387\tAverage Discriminator Loss: 0.000012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #5388 (step 5388): 1.366329\n",
      "Batch #10\tAverage Generator Loss: 969.318127\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #5389 (step 5389): 1.567001\n",
      "Batch #10\tAverage Generator Loss: 873.781647\tAverage Discriminator Loss: 0.000019\n",
      "\n",
      "Train time for epoch #5390 (step 5390): 1.567810\n",
      "Batch #10\tAverage Generator Loss: 914.218347\tAverage Discriminator Loss: 0.000023\n",
      "\n",
      "Train time for epoch #5391 (step 5391): 1.395826\n",
      "Batch #10\tAverage Generator Loss: 840.699112\tAverage Discriminator Loss: 0.000024\n",
      "\n",
      "Train time for epoch #5392 (step 5392): 1.538434\n",
      "Batch #10\tAverage Generator Loss: 956.080801\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #5393 (step 5393): 1.552269\n",
      "Batch #10\tAverage Generator Loss: 924.990094\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #5394 (step 5394): 1.436305\n",
      "Batch #10\tAverage Generator Loss: 788.099670\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #5395 (step 5395): 1.639773\n",
      "Batch #10\tAverage Generator Loss: 885.015454\tAverage Discriminator Loss: 0.005257\n",
      "\n",
      "Train time for epoch #5396 (step 5396): 1.667798\n",
      "Batch #10\tAverage Generator Loss: 816.655447\tAverage Discriminator Loss: 0.000084\n",
      "\n",
      "Train time for epoch #5397 (step 5397): 1.236255\n",
      "Batch #10\tAverage Generator Loss: 960.595557\tAverage Discriminator Loss: 0.000048\n",
      "\n",
      "Train time for epoch #5398 (step 5398): 1.541921\n",
      "Batch #10\tAverage Generator Loss: 953.335156\tAverage Discriminator Loss: 0.000039\n",
      "\n",
      "Train time for epoch #5399 (step 5399): 1.341309\n",
      "Batch #10\tAverage Generator Loss: 839.498474\tAverage Discriminator Loss: 0.000038\n",
      "\n",
      "Train time for epoch #5400 (step 5400): 1.586370\n",
      "Batch #10\tAverage Generator Loss: 893.441449\tAverage Discriminator Loss: 0.000041\n",
      "\n",
      "Train time for epoch #5401 (step 5401): 1.305172\n",
      "Batch #10\tAverage Generator Loss: 957.589984\tAverage Discriminator Loss: 0.000021\n",
      "\n",
      "Train time for epoch #5402 (step 5402): 1.498706\n",
      "Batch #10\tAverage Generator Loss: 870.008423\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #5403 (step 5403): 1.570118\n",
      "Batch #10\tAverage Generator Loss: 983.891559\tAverage Discriminator Loss: 0.000023\n",
      "\n",
      "Train time for epoch #5404 (step 5404): 1.395621\n",
      "Batch #10\tAverage Generator Loss: 886.842053\tAverage Discriminator Loss: 0.000026\n",
      "\n",
      "Train time for epoch #5405 (step 5405): 1.543946\n",
      "Batch #10\tAverage Generator Loss: 829.154944\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #5406 (step 5406): 1.508653\n",
      "Batch #10\tAverage Generator Loss: 887.710776\tAverage Discriminator Loss: 0.000019\n",
      "\n",
      "Train time for epoch #5407 (step 5407): 1.395610\n",
      "Batch #10\tAverage Generator Loss: 884.311194\tAverage Discriminator Loss: 0.000020\n",
      "\n",
      "Train time for epoch #5408 (step 5408): 1.733402\n",
      "Batch #10\tAverage Generator Loss: 826.791025\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #5409 (step 5409): 1.325851\n",
      "Batch #10\tAverage Generator Loss: 930.643985\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #5410 (step 5410): 1.488183\n",
      "Batch #10\tAverage Generator Loss: 923.172461\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #5411 (step 5411): 1.472484\n",
      "Batch #10\tAverage Generator Loss: 878.050708\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #5412 (step 5412): 1.394690\n",
      "Batch #10\tAverage Generator Loss: 921.697217\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #5413 (step 5413): 1.501748\n",
      "Batch #10\tAverage Generator Loss: 748.414264\tAverage Discriminator Loss: 0.000165\n",
      "\n",
      "Train time for epoch #5414 (step 5414): 1.283713\n",
      "Batch #10\tAverage Generator Loss: 814.493182\tAverage Discriminator Loss: 0.019028\n",
      "\n",
      "Train time for epoch #5415 (step 5415): 1.609796\n",
      "Batch #10\tAverage Generator Loss: 919.304749\tAverage Discriminator Loss: 0.000100\n",
      "\n",
      "Train time for epoch #5416 (step 5416): 1.542446\n",
      "Batch #10\tAverage Generator Loss: 855.735913\tAverage Discriminator Loss: 0.000072\n",
      "\n",
      "Train time for epoch #5417 (step 5417): 1.294617\n",
      "Batch #10\tAverage Generator Loss: 795.566437\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #5418 (step 5418): 1.541738\n",
      "Batch #10\tAverage Generator Loss: 948.314526\tAverage Discriminator Loss: 0.000040\n",
      "\n",
      "Train time for epoch #5419 (step 5419): 1.577646\n",
      "Batch #10\tAverage Generator Loss: 842.916199\tAverage Discriminator Loss: 0.000032\n",
      "\n",
      "Train time for epoch #5420 (step 5420): 1.340937\n",
      "Batch #10\tAverage Generator Loss: 940.555896\tAverage Discriminator Loss: 0.000027\n",
      "\n",
      "Train time for epoch #5421 (step 5421): 1.539238\n",
      "Batch #10\tAverage Generator Loss: 765.888931\tAverage Discriminator Loss: 0.000023\n",
      "\n",
      "Train time for epoch #5422 (step 5422): 1.326321\n",
      "Batch #10\tAverage Generator Loss: 910.868176\tAverage Discriminator Loss: 0.000021\n",
      "\n",
      "Train time for epoch #5423 (step 5423): 1.591682\n",
      "Batch #10\tAverage Generator Loss: 895.434875\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #5424 (step 5424): 1.538980\n",
      "Batch #10\tAverage Generator Loss: 1024.552625\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #5425 (step 5425): 1.280007\n",
      "Batch #10\tAverage Generator Loss: 888.898260\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #5426 (step 5426): 1.502474\n",
      "Batch #10\tAverage Generator Loss: 939.413892\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #5427 (step 5427): 1.493298\n",
      "Batch #10\tAverage Generator Loss: 899.346301\tAverage Discriminator Loss: 0.000033\n",
      "\n",
      "Train time for epoch #5428 (step 5428): 1.335394\n",
      "Batch #10\tAverage Generator Loss: 973.058978\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #5429 (step 5429): 1.478993\n",
      "Batch #10\tAverage Generator Loss: 982.220734\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #5430 (step 5430): 1.567133\n",
      "Batch #10\tAverage Generator Loss: 955.161475\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #5431 (step 5431): 1.420562\n",
      "Batch #10\tAverage Generator Loss: 967.145349\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #5432 (step 5432): 1.433717\n",
      "Batch #10\tAverage Generator Loss: 801.005502\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #5433 (step 5433): 1.378123\n",
      "Batch #10\tAverage Generator Loss: 858.686023\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #5434 (step 5434): 1.571882\n",
      "Batch #10\tAverage Generator Loss: 933.341571\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #5435 (step 5435): 1.655398\n",
      "Batch #10\tAverage Generator Loss: 971.905328\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #5436 (step 5436): 1.301602\n",
      "Batch #10\tAverage Generator Loss: 902.544528\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #5437 (step 5437): 1.634872\n",
      "Batch #10\tAverage Generator Loss: 922.876212\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #5438 (step 5438): 1.492990\n",
      "Batch #10\tAverage Generator Loss: 864.473735\tAverage Discriminator Loss: 0.000173\n",
      "\n",
      "Train time for epoch #5439 (step 5439): 1.344012\n",
      "Batch #10\tAverage Generator Loss: 931.565454\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #5440 (step 5440): 1.609580\n",
      "Batch #10\tAverage Generator Loss: 975.186951\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #5441 (step 5441): 1.503596\n",
      "Batch #10\tAverage Generator Loss: 887.057263\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #5442 (step 5442): 1.529989\n",
      "Batch #10\tAverage Generator Loss: 876.686371\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #5443 (step 5443): 1.555740\n",
      "Batch #10\tAverage Generator Loss: 936.473212\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #5444 (step 5444): 1.360249\n",
      "Batch #10\tAverage Generator Loss: 905.048053\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #5445 (step 5445): 1.531772\n",
      "Batch #10\tAverage Generator Loss: 834.981464\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #5446 (step 5446): 1.274342\n",
      "Batch #10\tAverage Generator Loss: 1013.161328\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #5447 (step 5447): 1.609619\n",
      "Batch #10\tAverage Generator Loss: 907.004102\tAverage Discriminator Loss: 0.004119\n",
      "\n",
      "Train time for epoch #5448 (step 5448): 1.587901\n",
      "Batch #10\tAverage Generator Loss: 920.364978\tAverage Discriminator Loss: 0.000296\n",
      "\n",
      "Train time for epoch #5449 (step 5449): 1.279575\n",
      "Batch #10\tAverage Generator Loss: 1043.929437\tAverage Discriminator Loss: 0.000019\n",
      "\n",
      "Train time for epoch #5450 (step 5450): 1.542428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 898.482443\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #5451 (step 5451): 1.283735\n",
      "Batch #10\tAverage Generator Loss: 945.746161\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #5452 (step 5452): 1.486298\n",
      "Batch #10\tAverage Generator Loss: 1104.503729\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #5453 (step 5453): 1.464912\n",
      "Batch #10\tAverage Generator Loss: 986.763400\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #5454 (step 5454): 1.335700\n",
      "Batch #10\tAverage Generator Loss: 896.063324\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #5455 (step 5455): 1.549087\n",
      "Batch #10\tAverage Generator Loss: 915.716211\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #5456 (step 5456): 1.582544\n",
      "Batch #10\tAverage Generator Loss: 892.885199\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #5457 (step 5457): 1.292786\n",
      "Batch #10\tAverage Generator Loss: 960.592780\tAverage Discriminator Loss: 0.012875\n",
      "\n",
      "Train time for epoch #5458 (step 5458): 1.519853\n",
      "Batch #10\tAverage Generator Loss: 1030.566492\tAverage Discriminator Loss: 0.000155\n",
      "\n",
      "Train time for epoch #5459 (step 5459): 1.331521\n",
      "Batch #10\tAverage Generator Loss: 893.046933\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #5460 (step 5460): 1.540751\n",
      "Batch #10\tAverage Generator Loss: 1002.706244\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #5461 (step 5461): 1.532245\n",
      "Batch #10\tAverage Generator Loss: 863.895346\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5462 (step 5462): 1.388491\n",
      "Batch #10\tAverage Generator Loss: 985.618051\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #5463 (step 5463): 1.492788\n",
      "Batch #10\tAverage Generator Loss: 1099.696143\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #5464 (step 5464): 1.383936\n",
      "Batch #10\tAverage Generator Loss: 770.465866\tAverage Discriminator Loss: 0.003912\n",
      "\n",
      "Train time for epoch #5465 (step 5465): 1.495149\n",
      "Batch #10\tAverage Generator Loss: 801.717824\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #5466 (step 5466): 1.636901\n",
      "Batch #10\tAverage Generator Loss: 842.910651\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #5467 (step 5467): 1.410114\n",
      "Batch #10\tAverage Generator Loss: 963.809058\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5468 (step 5468): 1.524202\n",
      "Batch #10\tAverage Generator Loss: 994.596069\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #5469 (step 5469): 1.338937\n",
      "Batch #10\tAverage Generator Loss: 878.387451\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #5470 (step 5470): 1.508571\n",
      "Batch #10\tAverage Generator Loss: 930.385175\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5471 (step 5471): 1.620990\n",
      "Batch #10\tAverage Generator Loss: 1036.367340\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #5472 (step 5472): 1.320004\n",
      "Batch #10\tAverage Generator Loss: 837.155875\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #5473 (step 5473): 1.518733\n",
      "Batch #10\tAverage Generator Loss: 911.312158\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #5474 (step 5474): 1.626359\n",
      "Batch #10\tAverage Generator Loss: 945.483319\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #5475 (step 5475): 1.427862\n",
      "Batch #10\tAverage Generator Loss: 941.853052\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #5476 (step 5476): 1.494979\n",
      "Batch #10\tAverage Generator Loss: 912.965167\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #5477 (step 5477): 1.396147\n",
      "Batch #10\tAverage Generator Loss: 924.917633\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #5478 (step 5478): 1.544572\n",
      "Batch #10\tAverage Generator Loss: 885.662967\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #5479 (step 5479): 1.678030\n",
      "Batch #10\tAverage Generator Loss: 982.912885\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #5480 (step 5480): 1.325838\n",
      "Batch #10\tAverage Generator Loss: 962.281018\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #5481 (step 5481): 1.508479\n",
      "Batch #10\tAverage Generator Loss: 924.833484\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #5482 (step 5482): 1.376137\n",
      "Batch #10\tAverage Generator Loss: 903.644290\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #5483 (step 5483): 1.466960\n",
      "Batch #10\tAverage Generator Loss: 897.481863\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #5484 (step 5484): 1.506364\n",
      "Batch #10\tAverage Generator Loss: 924.702072\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #5485 (step 5485): 1.297890\n",
      "Batch #10\tAverage Generator Loss: 791.249121\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #5486 (step 5486): 1.536657\n",
      "Batch #10\tAverage Generator Loss: 962.913092\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #5487 (step 5487): 1.519193\n",
      "Batch #10\tAverage Generator Loss: 812.182184\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #5488 (step 5488): 1.340319\n",
      "Batch #10\tAverage Generator Loss: 890.194043\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #5489 (step 5489): 1.508956\n",
      "Batch #10\tAverage Generator Loss: 871.537241\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #5490 (step 5490): 1.484607\n",
      "Batch #10\tAverage Generator Loss: 988.778485\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #5491 (step 5491): 1.382040\n",
      "Batch #10\tAverage Generator Loss: 902.174298\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #5492 (step 5492): 1.537560\n",
      "Batch #10\tAverage Generator Loss: 839.897794\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #5493 (step 5493): 1.339168\n",
      "Batch #10\tAverage Generator Loss: 962.549731\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #5494 (step 5494): 1.499175\n",
      "Batch #10\tAverage Generator Loss: 910.563416\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #5495 (step 5495): 1.522189\n",
      "Batch #10\tAverage Generator Loss: 924.521417\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #5496 (step 5496): 1.340657\n",
      "Batch #10\tAverage Generator Loss: 987.985941\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #5497 (step 5497): 1.487556\n",
      "Batch #10\tAverage Generator Loss: 905.128693\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #5498 (step 5498): 1.611797\n",
      "Batch #10\tAverage Generator Loss: 957.977991\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #5499 (step 5499): 1.331005\n",
      "Batch #10\tAverage Generator Loss: 822.356281\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #5500 (step 5500): 1.490789\n",
      "Batch #10\tAverage Generator Loss: 917.736560\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #5501 (step 5501): 1.342282\n",
      "Batch #10\tAverage Generator Loss: 765.417712\tAverage Discriminator Loss: 0.022982\n",
      "\n",
      "Train time for epoch #5502 (step 5502): 1.489980\n",
      "Batch #10\tAverage Generator Loss: 785.670398\tAverage Discriminator Loss: 0.000020\n",
      "\n",
      "Train time for epoch #5503 (step 5503): 1.510752\n",
      "Batch #10\tAverage Generator Loss: 751.631158\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #5504 (step 5504): 1.337624\n",
      "Batch #10\tAverage Generator Loss: 719.239874\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #5505 (step 5505): 1.551254\n",
      "Batch #10\tAverage Generator Loss: 863.219565\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #5506 (step 5506): 1.564397\n",
      "Batch #10\tAverage Generator Loss: 853.449368\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #5507 (step 5507): 1.303594\n",
      "Batch #10\tAverage Generator Loss: 851.145398\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #5508 (step 5508): 1.570866\n",
      "Batch #10\tAverage Generator Loss: 1000.490875\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #5509 (step 5509): 1.419945\n",
      "Batch #10\tAverage Generator Loss: 991.425732\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #5510 (step 5510): 1.500429\n",
      "Batch #10\tAverage Generator Loss: 880.274420\tAverage Discriminator Loss: 0.007444\n",
      "\n",
      "Train time for epoch #5511 (step 5511): 1.301038\n",
      "Batch #10\tAverage Generator Loss: 885.798972\tAverage Discriminator Loss: 0.000867\n",
      "\n",
      "Train time for epoch #5512 (step 5512): 1.506830\n",
      "Batch #10\tAverage Generator Loss: 870.268234\tAverage Discriminator Loss: 0.000014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #5513 (step 5513): 1.592710\n",
      "Batch #10\tAverage Generator Loss: 890.280707\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #5514 (step 5514): 1.401178\n",
      "Batch #10\tAverage Generator Loss: 884.933173\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #5515 (step 5515): 1.474333\n",
      "Batch #10\tAverage Generator Loss: 976.662787\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #5516 (step 5516): 1.553173\n",
      "Batch #10\tAverage Generator Loss: 917.871069\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #5517 (step 5517): 1.287370\n",
      "Batch #10\tAverage Generator Loss: 997.306079\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #5518 (step 5518): 1.589126\n",
      "Batch #10\tAverage Generator Loss: 1027.384241\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #5519 (step 5519): 1.338825\n",
      "Batch #10\tAverage Generator Loss: 802.853366\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #5520 (step 5520): 1.543964\n",
      "Batch #10\tAverage Generator Loss: 1004.681201\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #5521 (step 5521): 1.549857\n",
      "Batch #10\tAverage Generator Loss: 956.953156\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #5522 (step 5522): 1.292939\n",
      "Batch #10\tAverage Generator Loss: 986.159668\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #5523 (step 5523): 1.606768\n",
      "Batch #10\tAverage Generator Loss: 903.884863\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #5524 (step 5524): 1.559372\n",
      "Batch #10\tAverage Generator Loss: 924.563263\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #5525 (step 5525): 1.307474\n",
      "Batch #10\tAverage Generator Loss: 856.497968\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #5526 (step 5526): 1.554040\n",
      "Batch #10\tAverage Generator Loss: 939.504910\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #5527 (step 5527): 1.338176\n",
      "Batch #10\tAverage Generator Loss: 924.397845\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #5528 (step 5528): 1.561520\n",
      "Batch #10\tAverage Generator Loss: 891.929950\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #5529 (step 5529): 1.583557\n",
      "Batch #10\tAverage Generator Loss: 1012.374713\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #5530 (step 5530): 1.235567\n",
      "Batch #10\tAverage Generator Loss: 961.766174\tAverage Discriminator Loss: 0.000029\n",
      "\n",
      "Train time for epoch #5531 (step 5531): 1.505540\n",
      "Batch #10\tAverage Generator Loss: 921.573450\tAverage Discriminator Loss: 0.000130\n",
      "\n",
      "Train time for epoch #5532 (step 5532): 1.497384\n",
      "Batch #10\tAverage Generator Loss: 925.540955\tAverage Discriminator Loss: 0.000051\n",
      "\n",
      "Train time for epoch #5533 (step 5533): 1.339014\n",
      "Batch #10\tAverage Generator Loss: 946.756055\tAverage Discriminator Loss: 0.000033\n",
      "\n",
      "Train time for epoch #5534 (step 5534): 1.652401\n",
      "Batch #10\tAverage Generator Loss: 1006.915326\tAverage Discriminator Loss: 0.000022\n",
      "\n",
      "Train time for epoch #5535 (step 5535): 1.351836\n",
      "Batch #10\tAverage Generator Loss: 947.367218\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #5536 (step 5536): 1.594266\n",
      "Batch #10\tAverage Generator Loss: 863.077649\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #5537 (step 5537): 1.486095\n",
      "Batch #10\tAverage Generator Loss: 950.021088\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #5538 (step 5538): 1.370293\n",
      "Batch #10\tAverage Generator Loss: 883.151450\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #5539 (step 5539): 1.505963\n",
      "Batch #10\tAverage Generator Loss: 885.776373\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #5540 (step 5540): 1.339132\n",
      "Batch #10\tAverage Generator Loss: 838.869055\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #5541 (step 5541): 1.541735\n",
      "Batch #10\tAverage Generator Loss: 866.417242\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #5542 (step 5542): 1.483394\n",
      "Batch #10\tAverage Generator Loss: 857.580942\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #5543 (step 5543): 1.289773\n",
      "Batch #10\tAverage Generator Loss: 884.388321\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #5544 (step 5544): 1.589776\n",
      "Batch #10\tAverage Generator Loss: 947.752319\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #5545 (step 5545): 1.470196\n",
      "Batch #10\tAverage Generator Loss: 892.675342\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #5546 (step 5546): 1.434798\n",
      "Batch #10\tAverage Generator Loss: 1022.866800\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #5547 (step 5547): 1.558173\n",
      "Batch #10\tAverage Generator Loss: 908.864444\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #5548 (step 5548): 1.392455\n",
      "Batch #10\tAverage Generator Loss: 873.529581\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #5549 (step 5549): 1.583497\n",
      "Batch #10\tAverage Generator Loss: 884.793651\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #5550 (step 5550): 1.495682\n",
      "Batch #10\tAverage Generator Loss: 923.789038\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #5551 (step 5551): 1.339759\n",
      "Batch #10\tAverage Generator Loss: 920.612640\tAverage Discriminator Loss: 0.000059\n",
      "\n",
      "Train time for epoch #5552 (step 5552): 1.475279\n",
      "Batch #10\tAverage Generator Loss: 776.183240\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #5553 (step 5553): 1.442191\n",
      "Batch #10\tAverage Generator Loss: 950.481909\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #5554 (step 5554): 1.635475\n",
      "Batch #10\tAverage Generator Loss: 863.583255\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #5555 (step 5555): 1.501577\n",
      "Batch #10\tAverage Generator Loss: 965.907947\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #5556 (step 5556): 1.341562\n",
      "Batch #10\tAverage Generator Loss: 901.523508\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #5557 (step 5557): 1.573189\n",
      "Batch #10\tAverage Generator Loss: 916.261435\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #5558 (step 5558): 1.492965\n",
      "Batch #10\tAverage Generator Loss: 978.674377\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #5559 (step 5559): 1.327872\n",
      "Batch #10\tAverage Generator Loss: 994.296503\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #5560 (step 5560): 1.540343\n",
      "Batch #10\tAverage Generator Loss: 894.933936\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #5561 (step 5561): 1.469177\n",
      "Batch #10\tAverage Generator Loss: 893.540918\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #5562 (step 5562): 1.505746\n",
      "Batch #10\tAverage Generator Loss: 1037.445209\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #5563 (step 5563): 1.531217\n",
      "Batch #10\tAverage Generator Loss: 908.559427\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #5564 (step 5564): 1.335758\n",
      "Batch #10\tAverage Generator Loss: 959.750653\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #5565 (step 5565): 1.511456\n",
      "Batch #10\tAverage Generator Loss: 806.992810\tAverage Discriminator Loss: 0.006277\n",
      "\n",
      "Train time for epoch #5566 (step 5566): 1.584840\n",
      "Batch #10\tAverage Generator Loss: 1036.487512\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5567 (step 5567): 1.451513\n",
      "Batch #10\tAverage Generator Loss: 958.873108\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5568 (step 5568): 1.502159\n",
      "Batch #10\tAverage Generator Loss: 1037.041129\tAverage Discriminator Loss: 0.000025\n",
      "\n",
      "Train time for epoch #5569 (step 5569): 1.295322\n",
      "Batch #10\tAverage Generator Loss: 1019.153735\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5570 (step 5570): 1.540597\n",
      "Batch #10\tAverage Generator Loss: 1056.430072\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5571 (step 5571): 1.606282\n",
      "Batch #10\tAverage Generator Loss: 995.755121\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5572 (step 5572): 1.366265\n",
      "Batch #10\tAverage Generator Loss: 992.249054\tAverage Discriminator Loss: 0.001339\n",
      "\n",
      "Train time for epoch #5573 (step 5573): 1.434597\n",
      "Batch #10\tAverage Generator Loss: 1006.461743\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5574 (step 5574): 1.286258\n",
      "Batch #10\tAverage Generator Loss: 1080.051923\tAverage Discriminator Loss: 0.000001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #5575 (step 5575): 1.460241\n",
      "Batch #10\tAverage Generator Loss: 919.148187\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5576 (step 5576): 1.547147\n",
      "Batch #10\tAverage Generator Loss: 1044.117682\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5577 (step 5577): 1.297610\n",
      "Batch #10\tAverage Generator Loss: 1002.961102\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5578 (step 5578): 1.441803\n",
      "Batch #10\tAverage Generator Loss: 1000.317151\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5579 (step 5579): 1.289383\n",
      "Batch #10\tAverage Generator Loss: 1067.794788\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5580 (step 5580): 1.559578\n",
      "Batch #10\tAverage Generator Loss: 944.494937\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #5581 (step 5581): 1.537231\n",
      "Batch #10\tAverage Generator Loss: 981.442909\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5582 (step 5582): 1.286884\n",
      "Batch #10\tAverage Generator Loss: 1016.375616\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5583 (step 5583): 1.484729\n",
      "Batch #10\tAverage Generator Loss: 936.637280\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5584 (step 5584): 1.667899\n",
      "Batch #10\tAverage Generator Loss: 969.347458\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5585 (step 5585): 1.287563\n",
      "Batch #10\tAverage Generator Loss: 965.433932\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5586 (step 5586): 1.502200\n",
      "Batch #10\tAverage Generator Loss: 1060.810974\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5587 (step 5587): 1.566251\n",
      "Batch #10\tAverage Generator Loss: 916.266318\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5588 (step 5588): 1.372613\n",
      "Batch #10\tAverage Generator Loss: 938.271014\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5589 (step 5589): 1.491093\n",
      "Batch #10\tAverage Generator Loss: 973.948126\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5590 (step 5590): 1.585823\n",
      "Batch #10\tAverage Generator Loss: 994.298437\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5591 (step 5591): 1.440488\n",
      "Batch #10\tAverage Generator Loss: 1046.121411\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5592 (step 5592): 1.607039\n",
      "Batch #10\tAverage Generator Loss: 970.502209\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5593 (step 5593): 1.291620\n",
      "Batch #10\tAverage Generator Loss: 1055.631573\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5594 (step 5594): 1.528871\n",
      "Batch #10\tAverage Generator Loss: 1015.657452\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5595 (step 5595): 1.569263\n",
      "Batch #10\tAverage Generator Loss: 995.931671\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5596 (step 5596): 1.561865\n",
      "Batch #10\tAverage Generator Loss: 953.456012\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5597 (step 5597): 1.590168\n",
      "Batch #10\tAverage Generator Loss: 862.006006\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5598 (step 5598): 1.285665\n",
      "Batch #10\tAverage Generator Loss: 1070.141705\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5599 (step 5599): 1.605058\n",
      "Batch #10\tAverage Generator Loss: 914.096344\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5600 (step 5600): 1.555238\n",
      "Batch #10\tAverage Generator Loss: 980.816632\tAverage Discriminator Loss: 0.043419\n",
      "\n",
      "Train time for epoch #5601 (step 5601): 1.329895\n",
      "Batch #10\tAverage Generator Loss: 856.532184\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #5602 (step 5602): 1.496150\n",
      "Batch #10\tAverage Generator Loss: 828.452420\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5603 (step 5603): 1.626113\n",
      "Batch #10\tAverage Generator Loss: 745.406268\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5604 (step 5604): 1.281460\n",
      "Batch #10\tAverage Generator Loss: 794.685434\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5605 (step 5605): 1.588468\n",
      "Batch #10\tAverage Generator Loss: 779.038519\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5606 (step 5606): 1.591269\n",
      "Batch #10\tAverage Generator Loss: 675.302933\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5607 (step 5607): 1.439465\n",
      "Batch #10\tAverage Generator Loss: 861.139948\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5608 (step 5608): 1.603408\n",
      "Batch #10\tAverage Generator Loss: 840.039801\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5609 (step 5609): 1.298856\n",
      "Batch #10\tAverage Generator Loss: 731.199268\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5610 (step 5610): 1.539088\n",
      "Batch #10\tAverage Generator Loss: 673.330475\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5611 (step 5611): 1.285272\n",
      "Batch #10\tAverage Generator Loss: 807.164706\tAverage Discriminator Loss: 0.000424\n",
      "\n",
      "Train time for epoch #5612 (step 5612): 1.538206\n",
      "Batch #10\tAverage Generator Loss: 759.733173\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5613 (step 5613): 1.598908\n",
      "Batch #10\tAverage Generator Loss: 741.330753\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #5614 (step 5614): 1.397917\n",
      "Batch #10\tAverage Generator Loss: 634.025087\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #5615 (step 5615): 1.495981\n",
      "Batch #10\tAverage Generator Loss: 837.678549\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #5616 (step 5616): 1.515045\n",
      "Batch #10\tAverage Generator Loss: 727.972372\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #5617 (step 5617): 1.288765\n",
      "Batch #10\tAverage Generator Loss: 714.436859\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #5618 (step 5618): 1.536994\n",
      "Batch #10\tAverage Generator Loss: 820.296109\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #5619 (step 5619): 1.382074\n",
      "Batch #10\tAverage Generator Loss: 681.900317\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #5620 (step 5620): 1.494620\n",
      "Batch #10\tAverage Generator Loss: 685.553937\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #5621 (step 5621): 1.437714\n",
      "Batch #10\tAverage Generator Loss: 721.437085\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #5622 (step 5622): 1.346647\n",
      "Batch #10\tAverage Generator Loss: 714.552756\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #5623 (step 5623): 1.442783\n",
      "Batch #10\tAverage Generator Loss: 819.405548\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #5624 (step 5624): 1.255849\n",
      "Batch #10\tAverage Generator Loss: 755.639300\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #5625 (step 5625): 1.642427\n",
      "Batch #10\tAverage Generator Loss: 827.233167\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #5626 (step 5626): 1.497838\n",
      "Batch #10\tAverage Generator Loss: 851.858057\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #5627 (step 5627): 1.342023\n",
      "Batch #10\tAverage Generator Loss: 744.624149\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #5628 (step 5628): 1.497629\n",
      "Batch #10\tAverage Generator Loss: 759.734284\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #5629 (step 5629): 1.287152\n",
      "Batch #10\tAverage Generator Loss: 783.195410\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #5630 (step 5630): 1.486621\n",
      "Batch #10\tAverage Generator Loss: 726.367719\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5631 (step 5631): 1.343898\n",
      "Batch #10\tAverage Generator Loss: 742.593198\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5632 (step 5632): 1.593016\n",
      "Batch #10\tAverage Generator Loss: 705.573741\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #5633 (step 5633): 1.614910\n",
      "Batch #10\tAverage Generator Loss: 754.123987\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5634 (step 5634): 1.300606\n",
      "Batch #10\tAverage Generator Loss: 783.614653\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5635 (step 5635): 1.499156\n",
      "Batch #10\tAverage Generator Loss: 765.389194\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5636 (step 5636): 1.607029\n",
      "Batch #10\tAverage Generator Loss: 787.861215\tAverage Discriminator Loss: 0.000002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #5637 (step 5637): 1.323931\n",
      "Batch #10\tAverage Generator Loss: 681.153629\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5638 (step 5638): 1.581420\n",
      "Batch #10\tAverage Generator Loss: 722.073363\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5639 (step 5639): 1.459249\n",
      "Batch #10\tAverage Generator Loss: 761.625238\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5640 (step 5640): 1.550505\n",
      "Batch #10\tAverage Generator Loss: 840.886478\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5641 (step 5641): 1.476339\n",
      "Batch #10\tAverage Generator Loss: 690.997568\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5642 (step 5642): 1.325806\n",
      "Batch #10\tAverage Generator Loss: 790.767743\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5643 (step 5643): 1.618129\n",
      "Batch #10\tAverage Generator Loss: 803.018494\tAverage Discriminator Loss: 0.031784\n",
      "\n",
      "Train time for epoch #5644 (step 5644): 1.666025\n",
      "Batch #10\tAverage Generator Loss: 821.355212\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5645 (step 5645): 1.298201\n",
      "Batch #10\tAverage Generator Loss: 911.399069\tAverage Discriminator Loss: 0.007021\n",
      "\n",
      "Train time for epoch #5646 (step 5646): 1.636915\n",
      "Batch #10\tAverage Generator Loss: 1034.836536\tAverage Discriminator Loss: 0.001171\n",
      "\n",
      "Train time for epoch #5647 (step 5647): 1.560708\n",
      "Batch #10\tAverage Generator Loss: 998.654877\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #5648 (step 5648): 1.324293\n",
      "Batch #10\tAverage Generator Loss: 1063.751587\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #5649 (step 5649): 1.575652\n",
      "Batch #10\tAverage Generator Loss: 941.690503\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #5650 (step 5650): 1.280818\n",
      "Batch #10\tAverage Generator Loss: 971.626392\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #5651 (step 5651): 1.664206\n",
      "Batch #10\tAverage Generator Loss: 1062.166309\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #5652 (step 5652): 1.272504\n",
      "Batch #10\tAverage Generator Loss: 853.807869\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #5653 (step 5653): 1.521447\n",
      "Batch #10\tAverage Generator Loss: 1244.989960\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #5654 (step 5654): 1.297241\n",
      "Batch #10\tAverage Generator Loss: 850.302573\tAverage Discriminator Loss: 0.000132\n",
      "\n",
      "Train time for epoch #5655 (step 5655): 1.592508\n",
      "Batch #10\tAverage Generator Loss: 863.540155\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #5656 (step 5656): 1.523767\n",
      "Batch #10\tAverage Generator Loss: 869.206628\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #5657 (step 5657): 1.427480\n",
      "Batch #10\tAverage Generator Loss: 924.096536\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #5658 (step 5658): 1.454398\n",
      "Batch #10\tAverage Generator Loss: 782.672363\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #5659 (step 5659): 1.480001\n",
      "Batch #10\tAverage Generator Loss: 883.335730\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #5660 (step 5660): 1.327029\n",
      "Batch #10\tAverage Generator Loss: 946.794272\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #5661 (step 5661): 1.494133\n",
      "Batch #10\tAverage Generator Loss: 791.544336\tAverage Discriminator Loss: 0.094580\n",
      "\n",
      "Train time for epoch #5662 (step 5662): 1.427320\n",
      "Batch #10\tAverage Generator Loss: 560.862210\tAverage Discriminator Loss: 0.012187\n",
      "\n",
      "Train time for epoch #5663 (step 5663): 1.495829\n",
      "Batch #10\tAverage Generator Loss: 484.723933\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5664 (step 5664): 1.555981\n",
      "Batch #10\tAverage Generator Loss: 476.153867\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5665 (step 5665): 1.288710\n",
      "Batch #10\tAverage Generator Loss: 456.836633\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5666 (step 5666): 1.545030\n",
      "Batch #10\tAverage Generator Loss: 605.298645\tAverage Discriminator Loss: 0.067910\n",
      "\n",
      "Train time for epoch #5667 (step 5667): 1.323272\n",
      "Batch #10\tAverage Generator Loss: 823.326990\tAverage Discriminator Loss: 0.010755\n",
      "\n",
      "Train time for epoch #5668 (step 5668): 1.557305\n",
      "Batch #10\tAverage Generator Loss: 930.390994\tAverage Discriminator Loss: 0.011151\n",
      "\n",
      "Train time for epoch #5669 (step 5669): 1.603808\n",
      "Batch #10\tAverage Generator Loss: 1027.278162\tAverage Discriminator Loss: 0.000846\n",
      "\n",
      "Train time for epoch #5670 (step 5670): 1.284023\n",
      "Batch #10\tAverage Generator Loss: 912.591385\tAverage Discriminator Loss: 0.000023\n",
      "\n",
      "Train time for epoch #5671 (step 5671): 1.661356\n",
      "Batch #10\tAverage Generator Loss: 884.951294\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #5672 (step 5672): 1.575480\n",
      "Batch #10\tAverage Generator Loss: 1025.874066\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #5673 (step 5673): 1.284081\n",
      "Batch #10\tAverage Generator Loss: 957.257526\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #5674 (step 5674): 1.501653\n",
      "Batch #10\tAverage Generator Loss: 950.897211\tAverage Discriminator Loss: 0.007953\n",
      "\n",
      "Train time for epoch #5675 (step 5675): 1.341244\n",
      "Batch #10\tAverage Generator Loss: 859.058054\tAverage Discriminator Loss: 0.000326\n",
      "\n",
      "Train time for epoch #5676 (step 5676): 1.654944\n",
      "Batch #10\tAverage Generator Loss: 1123.571930\tAverage Discriminator Loss: 0.000214\n",
      "\n",
      "Train time for epoch #5677 (step 5677): 1.552037\n",
      "Batch #10\tAverage Generator Loss: 979.124438\tAverage Discriminator Loss: 0.000076\n",
      "\n",
      "Train time for epoch #5678 (step 5678): 1.352123\n",
      "Batch #10\tAverage Generator Loss: 937.385007\tAverage Discriminator Loss: 0.000062\n",
      "\n",
      "Train time for epoch #5679 (step 5679): 1.509468\n",
      "Batch #10\tAverage Generator Loss: 1047.699200\tAverage Discriminator Loss: 0.000025\n",
      "\n",
      "Train time for epoch #5680 (step 5680): 1.338482\n",
      "Batch #10\tAverage Generator Loss: 1038.667935\tAverage Discriminator Loss: 0.000038\n",
      "\n",
      "Train time for epoch #5681 (step 5681): 1.535824\n",
      "Batch #10\tAverage Generator Loss: 1088.525037\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #5682 (step 5682): 1.516872\n",
      "Batch #10\tAverage Generator Loss: 1027.715204\tAverage Discriminator Loss: 0.000031\n",
      "\n",
      "Train time for epoch #5683 (step 5683): 1.388263\n",
      "Batch #10\tAverage Generator Loss: 821.906937\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #5684 (step 5684): 1.510428\n",
      "Batch #10\tAverage Generator Loss: 1049.098688\tAverage Discriminator Loss: 0.000024\n",
      "\n",
      "Train time for epoch #5685 (step 5685): 1.654327\n",
      "Batch #10\tAverage Generator Loss: 986.517044\tAverage Discriminator Loss: 0.000020\n",
      "\n",
      "Train time for epoch #5686 (step 5686): 1.331970\n",
      "Batch #10\tAverage Generator Loss: 1061.238214\tAverage Discriminator Loss: 0.000021\n",
      "\n",
      "Train time for epoch #5687 (step 5687): 1.545777\n",
      "Batch #10\tAverage Generator Loss: 1044.636237\tAverage Discriminator Loss: 0.000021\n",
      "\n",
      "Train time for epoch #5688 (step 5688): 1.331403\n",
      "Batch #10\tAverage Generator Loss: 847.624927\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #5689 (step 5689): 1.545183\n",
      "Batch #10\tAverage Generator Loss: 1060.065955\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #5690 (step 5690): 1.615436\n",
      "Batch #10\tAverage Generator Loss: 1004.038153\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #5691 (step 5691): 1.284305\n",
      "Batch #10\tAverage Generator Loss: 882.506892\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #5692 (step 5692): 1.512112\n",
      "Batch #10\tAverage Generator Loss: 1137.488678\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #5693 (step 5693): 1.290351\n",
      "Batch #10\tAverage Generator Loss: 1031.516144\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #5694 (step 5694): 1.528165\n",
      "Batch #10\tAverage Generator Loss: 938.963724\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #5695 (step 5695): 1.556801\n",
      "Batch #10\tAverage Generator Loss: 1094.703876\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #5696 (step 5696): 1.319315\n",
      "Batch #10\tAverage Generator Loss: 950.066486\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #5697 (step 5697): 1.552204\n",
      "Batch #10\tAverage Generator Loss: 941.000706\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #5698 (step 5698): 1.396712\n",
      "Batch #10\tAverage Generator Loss: 1042.506958\tAverage Discriminator Loss: 0.000009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #5699 (step 5699): 1.554370\n",
      "Batch #10\tAverage Generator Loss: 1044.301447\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #5700 (step 5700): 1.590717\n",
      "Batch #10\tAverage Generator Loss: 1079.244403\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #5701 (step 5701): 1.300470\n",
      "Batch #10\tAverage Generator Loss: 863.987651\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #5702 (step 5702): 1.491629\n",
      "Batch #10\tAverage Generator Loss: 849.794440\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #5703 (step 5703): 1.365932\n",
      "Batch #10\tAverage Generator Loss: 951.887061\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #5704 (step 5704): 1.539659\n",
      "Batch #10\tAverage Generator Loss: 939.271588\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #5705 (step 5705): 1.530456\n",
      "Batch #10\tAverage Generator Loss: 970.497064\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #5706 (step 5706): 1.287475\n",
      "Batch #10\tAverage Generator Loss: 876.062427\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #5707 (step 5707): 1.488493\n",
      "Batch #10\tAverage Generator Loss: 1021.894095\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #5708 (step 5708): 1.294879\n",
      "Batch #10\tAverage Generator Loss: 1032.627277\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #5709 (step 5709): 1.606763\n",
      "Batch #10\tAverage Generator Loss: 1117.778970\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #5710 (step 5710): 1.482826\n",
      "Batch #10\tAverage Generator Loss: 987.926648\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #5711 (step 5711): 1.355469\n",
      "Batch #10\tAverage Generator Loss: 990.943140\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #5712 (step 5712): 1.550936\n",
      "Batch #10\tAverage Generator Loss: 963.265765\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #5713 (step 5713): 1.353845\n",
      "Batch #10\tAverage Generator Loss: 880.370490\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #5714 (step 5714): 1.594783\n",
      "Batch #10\tAverage Generator Loss: 1051.319556\tAverage Discriminator Loss: 0.000055\n",
      "\n",
      "Train time for epoch #5715 (step 5715): 1.510977\n",
      "Batch #10\tAverage Generator Loss: 918.645264\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #5716 (step 5716): 1.289774\n",
      "Batch #10\tAverage Generator Loss: 881.242102\tAverage Discriminator Loss: 0.002613\n",
      "\n",
      "Train time for epoch #5717 (step 5717): 1.646498\n",
      "Batch #10\tAverage Generator Loss: 1030.413968\tAverage Discriminator Loss: 0.000019\n",
      "\n",
      "Train time for epoch #5718 (step 5718): 1.597933\n",
      "Batch #10\tAverage Generator Loss: 960.646429\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #5719 (step 5719): 1.338366\n",
      "Batch #10\tAverage Generator Loss: 895.576526\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #5720 (step 5720): 1.506849\n",
      "Batch #10\tAverage Generator Loss: 875.819397\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #5721 (step 5721): 1.341480\n",
      "Batch #10\tAverage Generator Loss: 1021.333667\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #5722 (step 5722): 1.592719\n",
      "Batch #10\tAverage Generator Loss: 978.633719\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #5723 (step 5723): 1.515582\n",
      "Batch #10\tAverage Generator Loss: 1013.892761\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #5724 (step 5724): 1.290261\n",
      "Batch #10\tAverage Generator Loss: 1085.558374\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #5725 (step 5725): 1.561828\n",
      "Batch #10\tAverage Generator Loss: 1014.193762\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #5726 (step 5726): 1.281545\n",
      "Batch #10\tAverage Generator Loss: 992.291144\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #5727 (step 5727): 1.500408\n",
      "Batch #10\tAverage Generator Loss: 789.960773\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #5728 (step 5728): 1.501925\n",
      "Batch #10\tAverage Generator Loss: 940.564227\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #5729 (step 5729): 1.235430\n",
      "Batch #10\tAverage Generator Loss: 1028.423822\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #5730 (step 5730): 1.549898\n",
      "Batch #10\tAverage Generator Loss: 1102.079706\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #5731 (step 5731): 1.531139\n",
      "Batch #10\tAverage Generator Loss: 986.016736\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #5732 (step 5732): 1.403200\n",
      "Batch #10\tAverage Generator Loss: 851.348370\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #5733 (step 5733): 1.597187\n",
      "Batch #10\tAverage Generator Loss: 985.165338\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #5734 (step 5734): 1.533129\n",
      "Batch #10\tAverage Generator Loss: 930.468979\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #5735 (step 5735): 1.553259\n",
      "Batch #10\tAverage Generator Loss: 1076.272443\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #5736 (step 5736): 1.547681\n",
      "Batch #10\tAverage Generator Loss: 1082.751923\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #5737 (step 5737): 1.338066\n",
      "Batch #10\tAverage Generator Loss: 1025.817630\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #5738 (step 5738): 1.597330\n",
      "Batch #10\tAverage Generator Loss: 1014.745270\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #5739 (step 5739): 1.512325\n",
      "Batch #10\tAverage Generator Loss: 1199.081464\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #5740 (step 5740): 1.375704\n",
      "Batch #10\tAverage Generator Loss: 979.779156\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #5741 (step 5741): 1.483046\n",
      "Batch #10\tAverage Generator Loss: 984.166516\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #5742 (step 5742): 1.288782\n",
      "Batch #10\tAverage Generator Loss: 1056.946454\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #5743 (step 5743): 1.457505\n",
      "Batch #10\tAverage Generator Loss: 868.704547\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #5744 (step 5744): 1.543967\n",
      "Batch #10\tAverage Generator Loss: 1047.879163\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #5745 (step 5745): 1.487218\n",
      "Batch #10\tAverage Generator Loss: 1065.107129\tAverage Discriminator Loss: 0.015612\n",
      "\n",
      "Train time for epoch #5746 (step 5746): 1.495240\n",
      "Batch #10\tAverage Generator Loss: 1052.740063\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5747 (step 5747): 1.334282\n",
      "Batch #10\tAverage Generator Loss: 1009.326215\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5748 (step 5748): 1.499839\n",
      "Batch #10\tAverage Generator Loss: 1022.503033\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5749 (step 5749): 1.641173\n",
      "Batch #10\tAverage Generator Loss: 1037.757642\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5750 (step 5750): 1.377283\n",
      "Batch #10\tAverage Generator Loss: 1159.064716\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5751 (step 5751): 1.509760\n",
      "Batch #10\tAverage Generator Loss: 1011.769952\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5752 (step 5752): 1.290017\n",
      "Batch #10\tAverage Generator Loss: 843.800159\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5753 (step 5753): 1.465517\n",
      "Batch #10\tAverage Generator Loss: 1098.409338\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5754 (step 5754): 1.609115\n",
      "Batch #10\tAverage Generator Loss: 1027.330200\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5755 (step 5755): 1.301683\n",
      "Batch #10\tAverage Generator Loss: 1028.739511\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5756 (step 5756): 1.499526\n",
      "Batch #10\tAverage Generator Loss: 1056.613171\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5757 (step 5757): 1.296194\n",
      "Batch #10\tAverage Generator Loss: 987.176947\tAverage Discriminator Loss: 0.223654\n",
      "\n",
      "Train time for epoch #5758 (step 5758): 1.548652\n",
      "Batch #10\tAverage Generator Loss: 783.798495\tAverage Discriminator Loss: 0.045960\n",
      "\n",
      "Train time for epoch #5759 (step 5759): 1.702161\n",
      "Batch #10\tAverage Generator Loss: 747.900795\tAverage Discriminator Loss: 0.018477\n",
      "\n",
      "Train time for epoch #5760 (step 5760): 1.342937\n",
      "Batch #10\tAverage Generator Loss: 703.512762\tAverage Discriminator Loss: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #5761 (step 5761): 1.504321\n",
      "Batch #10\tAverage Generator Loss: 709.169312\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5762 (step 5762): 1.345904\n",
      "Batch #10\tAverage Generator Loss: 644.394080\tAverage Discriminator Loss: 0.000394\n",
      "\n",
      "Train time for epoch #5763 (step 5763): 1.516494\n",
      "Batch #10\tAverage Generator Loss: 737.390253\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5764 (step 5764): 1.576011\n",
      "Batch #10\tAverage Generator Loss: 847.336090\tAverage Discriminator Loss: 0.241604\n",
      "\n",
      "Train time for epoch #5765 (step 5765): 1.347007\n",
      "Batch #10\tAverage Generator Loss: 1040.184808\tAverage Discriminator Loss: 0.035489\n",
      "\n",
      "Train time for epoch #5766 (step 5766): 1.555580\n",
      "Batch #10\tAverage Generator Loss: 1152.062445\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5767 (step 5767): 1.621630\n",
      "Batch #10\tAverage Generator Loss: 1092.011438\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5768 (step 5768): 1.289222\n",
      "Batch #10\tAverage Generator Loss: 970.437347\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5769 (step 5769): 1.529088\n",
      "Batch #10\tAverage Generator Loss: 1144.244220\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5770 (step 5770): 1.630441\n",
      "Batch #10\tAverage Generator Loss: 1060.604877\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5771 (step 5771): 1.333418\n",
      "Batch #10\tAverage Generator Loss: 986.819550\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5772 (step 5772): 1.557387\n",
      "Batch #10\tAverage Generator Loss: 1462.721606\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5773 (step 5773): 1.334051\n",
      "Batch #10\tAverage Generator Loss: 1085.213324\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #5774 (step 5774): 1.501903\n",
      "Batch #10\tAverage Generator Loss: 1164.926511\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5775 (step 5775): 1.529756\n",
      "Batch #10\tAverage Generator Loss: 1131.379349\tAverage Discriminator Loss: 0.022217\n",
      "\n",
      "Train time for epoch #5776 (step 5776): 1.383529\n",
      "Batch #10\tAverage Generator Loss: 1322.302698\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5777 (step 5777): 1.621590\n",
      "Batch #10\tAverage Generator Loss: 1150.498001\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5778 (step 5778): 1.278466\n",
      "Batch #10\tAverage Generator Loss: 986.280179\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5779 (step 5779): 1.614248\n",
      "Batch #10\tAverage Generator Loss: 983.950751\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5780 (step 5780): 1.595874\n",
      "Batch #10\tAverage Generator Loss: 1001.881500\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5781 (step 5781): 1.286490\n",
      "Batch #10\tAverage Generator Loss: 978.541083\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5782 (step 5782): 1.492888\n",
      "Batch #10\tAverage Generator Loss: 860.837384\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5783 (step 5783): 1.418569\n",
      "Batch #10\tAverage Generator Loss: 972.599615\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5784 (step 5784): 1.539575\n",
      "Batch #10\tAverage Generator Loss: 1000.152463\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5785 (step 5785): 1.487658\n",
      "Batch #10\tAverage Generator Loss: 1035.986627\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5786 (step 5786): 1.513571\n",
      "Batch #10\tAverage Generator Loss: 889.521417\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5787 (step 5787): 1.545204\n",
      "Batch #10\tAverage Generator Loss: 961.822961\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5788 (step 5788): 1.501173\n",
      "Batch #10\tAverage Generator Loss: 894.270178\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5789 (step 5789): 1.363184\n",
      "Batch #10\tAverage Generator Loss: 969.710880\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5790 (step 5790): 1.562414\n",
      "Batch #10\tAverage Generator Loss: 1024.141638\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5791 (step 5791): 1.355004\n",
      "Batch #10\tAverage Generator Loss: 830.636749\tAverage Discriminator Loss: 0.000203\n",
      "\n",
      "Train time for epoch #5792 (step 5792): 1.638933\n",
      "Batch #10\tAverage Generator Loss: 853.777631\tAverage Discriminator Loss: 0.004920\n",
      "\n",
      "Train time for epoch #5793 (step 5793): 1.593461\n",
      "Batch #10\tAverage Generator Loss: 934.687830\tAverage Discriminator Loss: 0.000764\n",
      "\n",
      "Train time for epoch #5794 (step 5794): 1.284558\n",
      "Batch #10\tAverage Generator Loss: 863.277286\tAverage Discriminator Loss: 0.000140\n",
      "\n",
      "Train time for epoch #5795 (step 5795): 1.525759\n",
      "Batch #10\tAverage Generator Loss: 936.289577\tAverage Discriminator Loss: 0.000023\n",
      "\n",
      "Train time for epoch #5796 (step 5796): 1.342477\n",
      "Batch #10\tAverage Generator Loss: 891.626869\tAverage Discriminator Loss: 0.060772\n",
      "\n",
      "Train time for epoch #5797 (step 5797): 1.625344\n",
      "Batch #10\tAverage Generator Loss: 1093.651208\tAverage Discriminator Loss: 0.004949\n",
      "\n",
      "Train time for epoch #5798 (step 5798): 1.580943\n",
      "Batch #10\tAverage Generator Loss: 1026.826395\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #5799 (step 5799): 1.289099\n",
      "Batch #10\tAverage Generator Loss: 998.168573\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #5800 (step 5800): 1.512544\n",
      "Batch #10\tAverage Generator Loss: 941.324890\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #5801 (step 5801): 1.405657\n",
      "Batch #10\tAverage Generator Loss: 938.309595\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5802 (step 5802): 1.564932\n",
      "Batch #10\tAverage Generator Loss: 1041.654718\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5803 (step 5803): 1.541011\n",
      "Batch #10\tAverage Generator Loss: 965.175000\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5804 (step 5804): 1.431069\n",
      "Batch #10\tAverage Generator Loss: 977.484064\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5805 (step 5805): 1.561630\n",
      "Batch #10\tAverage Generator Loss: 1003.256384\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5806 (step 5806): 1.280337\n",
      "Batch #10\tAverage Generator Loss: 884.347235\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5807 (step 5807): 1.503586\n",
      "Batch #10\tAverage Generator Loss: 959.428839\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #5808 (step 5808): 1.622864\n",
      "Batch #10\tAverage Generator Loss: 1030.942041\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5809 (step 5809): 1.296452\n",
      "Batch #10\tAverage Generator Loss: 853.870406\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #5810 (step 5810): 1.672223\n",
      "Batch #10\tAverage Generator Loss: 1025.353998\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #5811 (step 5811): 1.341702\n",
      "Batch #10\tAverage Generator Loss: 1039.509662\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5812 (step 5812): 1.517812\n",
      "Batch #10\tAverage Generator Loss: 1110.289502\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5813 (step 5813): 1.740705\n",
      "Batch #10\tAverage Generator Loss: 977.805920\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #5814 (step 5814): 1.411959\n",
      "Batch #10\tAverage Generator Loss: 995.343512\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5815 (step 5815): 1.511749\n",
      "Batch #10\tAverage Generator Loss: 880.052682\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5816 (step 5816): 1.452358\n",
      "Batch #10\tAverage Generator Loss: 961.003131\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5817 (step 5817): 1.338100\n",
      "Batch #10\tAverage Generator Loss: 1003.987653\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5818 (step 5818): 1.502165\n",
      "Batch #10\tAverage Generator Loss: 968.179103\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5819 (step 5819): 1.370421\n",
      "Batch #10\tAverage Generator Loss: 1015.218250\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5820 (step 5820): 1.493779\n",
      "Batch #10\tAverage Generator Loss: 967.361371\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5821 (step 5821): 1.284792\n",
      "Batch #10\tAverage Generator Loss: 893.132917\tAverage Discriminator Loss: 0.799510\n",
      "\n",
      "Train time for epoch #5822 (step 5822): 1.534355\n",
      "Batch #10\tAverage Generator Loss: 885.341284\tAverage Discriminator Loss: 0.000005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #5823 (step 5823): 1.498527\n",
      "Batch #10\tAverage Generator Loss: 851.894727\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #5824 (step 5824): 1.348693\n",
      "Batch #10\tAverage Generator Loss: 977.919000\tAverage Discriminator Loss: 0.002485\n",
      "\n",
      "Train time for epoch #5825 (step 5825): 1.600574\n",
      "Batch #10\tAverage Generator Loss: 1045.769485\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5826 (step 5826): 1.362740\n",
      "Batch #10\tAverage Generator Loss: 955.102100\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5827 (step 5827): 1.504367\n",
      "Batch #10\tAverage Generator Loss: 808.676382\tAverage Discriminator Loss: 0.131692\n",
      "\n",
      "Train time for epoch #5828 (step 5828): 1.544223\n",
      "Batch #10\tAverage Generator Loss: 745.642615\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #5829 (step 5829): 1.310409\n",
      "Batch #10\tAverage Generator Loss: 738.632306\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #5830 (step 5830): 1.531967\n",
      "Batch #10\tAverage Generator Loss: 750.342178\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #5831 (step 5831): 1.563419\n",
      "Batch #10\tAverage Generator Loss: 700.929837\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #5832 (step 5832): 1.313263\n",
      "Batch #10\tAverage Generator Loss: 801.771860\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5833 (step 5833): 1.523721\n",
      "Batch #10\tAverage Generator Loss: 636.308435\tAverage Discriminator Loss: 0.003919\n",
      "\n",
      "Train time for epoch #5834 (step 5834): 1.352691\n",
      "Batch #10\tAverage Generator Loss: 818.340112\tAverage Discriminator Loss: 0.000778\n",
      "\n",
      "Train time for epoch #5835 (step 5835): 1.498559\n",
      "Batch #10\tAverage Generator Loss: 900.114117\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #5836 (step 5836): 1.598663\n",
      "Batch #10\tAverage Generator Loss: 816.580371\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #5837 (step 5837): 1.287489\n",
      "Batch #10\tAverage Generator Loss: 852.801257\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #5838 (step 5838): 1.466192\n",
      "Batch #10\tAverage Generator Loss: 737.295758\tAverage Discriminator Loss: 0.000092\n",
      "\n",
      "Train time for epoch #5839 (step 5839): 1.381509\n",
      "Batch #10\tAverage Generator Loss: 836.188385\tAverage Discriminator Loss: 0.000057\n",
      "\n",
      "Train time for epoch #5840 (step 5840): 1.624607\n",
      "Batch #10\tAverage Generator Loss: 939.724762\tAverage Discriminator Loss: 0.014818\n",
      "\n",
      "Train time for epoch #5841 (step 5841): 1.347084\n",
      "Batch #10\tAverage Generator Loss: 866.072406\tAverage Discriminator Loss: 0.010642\n",
      "\n",
      "Train time for epoch #5842 (step 5842): 1.497260\n",
      "Batch #10\tAverage Generator Loss: 938.720367\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5843 (step 5843): 1.616879\n",
      "Batch #10\tAverage Generator Loss: 1032.996674\tAverage Discriminator Loss: 0.000048\n",
      "\n",
      "Train time for epoch #5844 (step 5844): 1.319307\n",
      "Batch #10\tAverage Generator Loss: 955.624707\tAverage Discriminator Loss: 0.000131\n",
      "\n",
      "Train time for epoch #5845 (step 5845): 1.508077\n",
      "Batch #10\tAverage Generator Loss: 1033.810287\tAverage Discriminator Loss: 0.000201\n",
      "\n",
      "Train time for epoch #5846 (step 5846): 1.351919\n",
      "Batch #10\tAverage Generator Loss: 953.141364\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #5847 (step 5847): 1.595631\n",
      "Batch #10\tAverage Generator Loss: 999.824689\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #5848 (step 5848): 1.554086\n",
      "Batch #10\tAverage Generator Loss: 950.002032\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #5849 (step 5849): 1.346345\n",
      "Batch #10\tAverage Generator Loss: 964.553302\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5850 (step 5850): 1.511714\n",
      "Batch #10\tAverage Generator Loss: 991.919098\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #5851 (step 5851): 1.369431\n",
      "Batch #10\tAverage Generator Loss: 955.793671\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #5852 (step 5852): 1.562256\n",
      "Batch #10\tAverage Generator Loss: 830.317981\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #5853 (step 5853): 1.420842\n",
      "Batch #10\tAverage Generator Loss: 798.296402\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5854 (step 5854): 1.681808\n",
      "Batch #10\tAverage Generator Loss: 869.845297\tAverage Discriminator Loss: 0.073110\n",
      "\n",
      "Train time for epoch #5855 (step 5855): 1.601243\n",
      "Batch #10\tAverage Generator Loss: 955.101611\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #5856 (step 5856): 1.325104\n",
      "Batch #10\tAverage Generator Loss: 1019.898688\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #5857 (step 5857): 1.502993\n",
      "Batch #10\tAverage Generator Loss: 1011.279437\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #5858 (step 5858): 1.386060\n",
      "Batch #10\tAverage Generator Loss: 1064.933569\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #5859 (step 5859): 1.563061\n",
      "Batch #10\tAverage Generator Loss: 1039.119952\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #5860 (step 5860): 1.342725\n",
      "Batch #10\tAverage Generator Loss: 971.331061\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #5861 (step 5861): 1.559344\n",
      "Batch #10\tAverage Generator Loss: 905.117712\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #5862 (step 5862): 1.624376\n",
      "Batch #10\tAverage Generator Loss: 966.149182\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #5863 (step 5863): 1.395624\n",
      "Batch #10\tAverage Generator Loss: 965.006622\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #5864 (step 5864): 1.553728\n",
      "Batch #10\tAverage Generator Loss: 946.106836\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #5865 (step 5865): 1.475456\n",
      "Batch #10\tAverage Generator Loss: 990.387112\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #5866 (step 5866): 1.458752\n",
      "Batch #10\tAverage Generator Loss: 978.522305\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #5867 (step 5867): 1.542310\n",
      "Batch #10\tAverage Generator Loss: 946.521439\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #5868 (step 5868): 1.355149\n",
      "Batch #10\tAverage Generator Loss: 965.204480\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #5869 (step 5869): 1.635573\n",
      "Batch #10\tAverage Generator Loss: 1000.766467\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5870 (step 5870): 1.343240\n",
      "Batch #10\tAverage Generator Loss: 1101.311285\tAverage Discriminator Loss: 0.001272\n",
      "\n",
      "Train time for epoch #5871 (step 5871): 1.641458\n",
      "Batch #10\tAverage Generator Loss: 896.222235\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #5872 (step 5872): 1.649476\n",
      "Batch #10\tAverage Generator Loss: 1114.460492\tAverage Discriminator Loss: 0.299771\n",
      "\n",
      "Train time for epoch #5873 (step 5873): 1.539913\n",
      "Batch #10\tAverage Generator Loss: 1027.400964\tAverage Discriminator Loss: 0.049511\n",
      "\n",
      "Train time for epoch #5874 (step 5874): 1.619205\n",
      "Batch #10\tAverage Generator Loss: 904.607208\tAverage Discriminator Loss: 0.000032\n",
      "\n",
      "Train time for epoch #5875 (step 5875): 1.297148\n",
      "Batch #10\tAverage Generator Loss: 912.510651\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #5876 (step 5876): 1.667157\n",
      "Batch #10\tAverage Generator Loss: 944.155969\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #5877 (step 5877): 1.450489\n",
      "Batch #10\tAverage Generator Loss: 993.422467\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #5878 (step 5878): 1.519180\n",
      "Batch #10\tAverage Generator Loss: 866.502386\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #5879 (step 5879): 1.550150\n",
      "Batch #10\tAverage Generator Loss: 919.947186\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #5880 (step 5880): 1.470629\n",
      "Batch #10\tAverage Generator Loss: 857.404871\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #5881 (step 5881): 1.511611\n",
      "Batch #10\tAverage Generator Loss: 955.878790\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #5882 (step 5882): 1.373612\n",
      "Batch #10\tAverage Generator Loss: 846.733380\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #5883 (step 5883): 1.504814\n",
      "Batch #10\tAverage Generator Loss: 944.410196\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #5884 (step 5884): 1.621799\n",
      "Batch #10\tAverage Generator Loss: 932.936700\tAverage Discriminator Loss: 0.000006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #5885 (step 5885): 1.326524\n",
      "Batch #10\tAverage Generator Loss: 863.650256\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #5886 (step 5886): 1.571785\n",
      "Batch #10\tAverage Generator Loss: 907.546259\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #5887 (step 5887): 1.376374\n",
      "Batch #10\tAverage Generator Loss: 890.514838\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #5888 (step 5888): 1.516212\n",
      "Batch #10\tAverage Generator Loss: 961.028400\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #5889 (step 5889): 1.466633\n",
      "Batch #10\tAverage Generator Loss: 936.523303\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #5890 (step 5890): 1.284092\n",
      "Batch #10\tAverage Generator Loss: 1037.788019\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #5891 (step 5891): 1.595678\n",
      "Batch #10\tAverage Generator Loss: 873.269464\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #5892 (step 5892): 1.444085\n",
      "Batch #10\tAverage Generator Loss: 924.155661\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #5893 (step 5893): 1.687973\n",
      "Batch #10\tAverage Generator Loss: 858.548203\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #5894 (step 5894): 1.259128\n",
      "Batch #10\tAverage Generator Loss: 858.210532\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #5895 (step 5895): 1.529653\n",
      "Batch #10\tAverage Generator Loss: 767.642310\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #5896 (step 5896): 1.550824\n",
      "Batch #10\tAverage Generator Loss: 957.806384\tAverage Discriminator Loss: 0.000719\n",
      "\n",
      "Train time for epoch #5897 (step 5897): 1.334507\n",
      "Batch #10\tAverage Generator Loss: 897.612488\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #5898 (step 5898): 1.568221\n",
      "Batch #10\tAverage Generator Loss: 893.492792\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #5899 (step 5899): 1.304661\n",
      "Batch #10\tAverage Generator Loss: 826.520715\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #5900 (step 5900): 1.515918\n",
      "Batch #10\tAverage Generator Loss: 1004.184204\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #5901 (step 5901): 1.502824\n",
      "Batch #10\tAverage Generator Loss: 918.992758\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #5902 (step 5902): 1.280713\n",
      "Batch #10\tAverage Generator Loss: 938.303918\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #5903 (step 5903): 1.497874\n",
      "Batch #10\tAverage Generator Loss: 980.666705\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #5904 (step 5904): 1.414938\n",
      "Batch #10\tAverage Generator Loss: 886.480185\tAverage Discriminator Loss: 0.071161\n",
      "\n",
      "Train time for epoch #5905 (step 5905): 1.499614\n",
      "Batch #10\tAverage Generator Loss: 932.014752\tAverage Discriminator Loss: 0.033384\n",
      "\n",
      "Train time for epoch #5906 (step 5906): 1.544450\n",
      "Batch #10\tAverage Generator Loss: 930.802344\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #5907 (step 5907): 1.403297\n",
      "Batch #10\tAverage Generator Loss: 853.022830\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5908 (step 5908): 1.652092\n",
      "Batch #10\tAverage Generator Loss: 802.707477\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #5909 (step 5909): 1.352074\n",
      "Batch #10\tAverage Generator Loss: 798.113605\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #5910 (step 5910): 1.575556\n",
      "Batch #10\tAverage Generator Loss: 889.545663\tAverage Discriminator Loss: 0.011252\n",
      "\n",
      "Train time for epoch #5911 (step 5911): 1.514193\n",
      "Batch #10\tAverage Generator Loss: 833.233041\tAverage Discriminator Loss: 0.019397\n",
      "\n",
      "Train time for epoch #5912 (step 5912): 1.380744\n",
      "Batch #10\tAverage Generator Loss: 843.357730\tAverage Discriminator Loss: 0.009215\n",
      "\n",
      "Train time for epoch #5913 (step 5913): 1.490571\n",
      "Batch #10\tAverage Generator Loss: 889.775500\tAverage Discriminator Loss: 0.001196\n",
      "\n",
      "Train time for epoch #5914 (step 5914): 1.418230\n",
      "Batch #10\tAverage Generator Loss: 898.438141\tAverage Discriminator Loss: 0.000459\n",
      "\n",
      "Train time for epoch #5915 (step 5915): 1.489369\n",
      "Batch #10\tAverage Generator Loss: 836.519968\tAverage Discriminator Loss: 0.000146\n",
      "\n",
      "Train time for epoch #5916 (step 5916): 1.388403\n",
      "Batch #10\tAverage Generator Loss: 743.904025\tAverage Discriminator Loss: 0.000053\n",
      "\n",
      "Train time for epoch #5917 (step 5917): 1.623036\n",
      "Batch #10\tAverage Generator Loss: 903.948688\tAverage Discriminator Loss: 0.000042\n",
      "\n",
      "Train time for epoch #5918 (step 5918): 1.604857\n",
      "Batch #10\tAverage Generator Loss: 869.133191\tAverage Discriminator Loss: 0.000036\n",
      "\n",
      "Train time for epoch #5919 (step 5919): 1.353846\n",
      "Batch #10\tAverage Generator Loss: 873.648590\tAverage Discriminator Loss: 0.000020\n",
      "\n",
      "Train time for epoch #5920 (step 5920): 1.511486\n",
      "Batch #10\tAverage Generator Loss: 816.073608\tAverage Discriminator Loss: 0.000020\n",
      "\n",
      "Train time for epoch #5921 (step 5921): 1.394031\n",
      "Batch #10\tAverage Generator Loss: 840.442920\tAverage Discriminator Loss: 0.000023\n",
      "\n",
      "Train time for epoch #5922 (step 5922): 1.559768\n",
      "Batch #10\tAverage Generator Loss: 815.456149\tAverage Discriminator Loss: 0.000023\n",
      "\n",
      "Train time for epoch #5923 (step 5923): 1.560960\n",
      "Batch #10\tAverage Generator Loss: 781.942752\tAverage Discriminator Loss: 0.000019\n",
      "\n",
      "Train time for epoch #5924 (step 5924): 1.347090\n",
      "Batch #10\tAverage Generator Loss: 807.888306\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #5925 (step 5925): 1.516495\n",
      "Batch #10\tAverage Generator Loss: 827.887842\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #5926 (step 5926): 1.516994\n",
      "Batch #10\tAverage Generator Loss: 769.208859\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #5927 (step 5927): 1.306576\n",
      "Batch #10\tAverage Generator Loss: 887.153699\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #5928 (step 5928): 1.552720\n",
      "Batch #10\tAverage Generator Loss: 897.500668\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #5929 (step 5929): 1.295680\n",
      "Batch #10\tAverage Generator Loss: 851.197723\tAverage Discriminator Loss: 0.003357\n",
      "\n",
      "Train time for epoch #5930 (step 5930): 1.509605\n",
      "Batch #10\tAverage Generator Loss: 963.892407\tAverage Discriminator Loss: 0.005565\n",
      "\n",
      "Train time for epoch #5931 (step 5931): 1.297696\n",
      "Batch #10\tAverage Generator Loss: 975.937711\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #5932 (step 5932): 1.627845\n",
      "Batch #10\tAverage Generator Loss: 879.773676\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #5933 (step 5933): 1.554474\n",
      "Batch #10\tAverage Generator Loss: 984.706281\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #5934 (step 5934): 1.396487\n",
      "Batch #10\tAverage Generator Loss: 1000.151935\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #5935 (step 5935): 1.582408\n",
      "Batch #10\tAverage Generator Loss: 952.499637\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #5936 (step 5936): 1.424487\n",
      "Batch #10\tAverage Generator Loss: 1015.771844\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #5937 (step 5937): 1.564419\n",
      "Batch #10\tAverage Generator Loss: 1005.805469\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #5938 (step 5938): 1.605013\n",
      "Batch #10\tAverage Generator Loss: 1002.042200\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #5939 (step 5939): 1.426396\n",
      "Batch #10\tAverage Generator Loss: 1004.493610\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #5940 (step 5940): 1.504003\n",
      "Batch #10\tAverage Generator Loss: 921.418091\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #5941 (step 5941): 1.295349\n",
      "Batch #10\tAverage Generator Loss: 969.775110\tAverage Discriminator Loss: 0.000053\n",
      "\n",
      "Train time for epoch #5942 (step 5942): 1.517550\n",
      "Batch #10\tAverage Generator Loss: 948.127563\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #5943 (step 5943): 1.285021\n",
      "Batch #10\tAverage Generator Loss: 1005.341534\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #5944 (step 5944): 1.531027\n",
      "Batch #10\tAverage Generator Loss: 880.555856\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #5945 (step 5945): 1.514206\n",
      "Batch #10\tAverage Generator Loss: 1077.488220\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #5946 (step 5946): 1.332949\n",
      "Batch #10\tAverage Generator Loss: 859.797940\tAverage Discriminator Loss: 0.000006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #5947 (step 5947): 1.517238\n",
      "Batch #10\tAverage Generator Loss: 953.234454\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #5948 (step 5948): 1.511050\n",
      "Batch #10\tAverage Generator Loss: 1001.361755\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #5949 (step 5949): 1.622880\n",
      "Batch #10\tAverage Generator Loss: 1030.770679\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #5950 (step 5950): 1.555761\n",
      "Batch #10\tAverage Generator Loss: 915.475510\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #5951 (step 5951): 1.396733\n",
      "Batch #10\tAverage Generator Loss: 937.154199\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #5952 (step 5952): 1.503737\n",
      "Batch #10\tAverage Generator Loss: 962.370081\tAverage Discriminator Loss: 0.000256\n",
      "\n",
      "Train time for epoch #5953 (step 5953): 1.748634\n",
      "Batch #10\tAverage Generator Loss: 988.636621\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #5954 (step 5954): 1.335904\n",
      "Batch #10\tAverage Generator Loss: 838.465759\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #5955 (step 5955): 1.517116\n",
      "Batch #10\tAverage Generator Loss: 958.001837\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #5956 (step 5956): 1.439161\n",
      "Batch #10\tAverage Generator Loss: 904.534955\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #5957 (step 5957): 1.494461\n",
      "Batch #10\tAverage Generator Loss: 858.972931\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #5958 (step 5958): 1.293709\n",
      "Batch #10\tAverage Generator Loss: 746.640442\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #5959 (step 5959): 1.615465\n",
      "Batch #10\tAverage Generator Loss: 946.275299\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #5960 (step 5960): 1.519758\n",
      "Batch #10\tAverage Generator Loss: 1068.398273\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #5961 (step 5961): 1.348047\n",
      "Batch #10\tAverage Generator Loss: 968.814362\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #5962 (step 5962): 1.555149\n",
      "Batch #10\tAverage Generator Loss: 899.341278\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #5963 (step 5963): 1.254271\n",
      "Batch #10\tAverage Generator Loss: 934.568253\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #5964 (step 5964): 1.509857\n",
      "Batch #10\tAverage Generator Loss: 888.703265\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #5965 (step 5965): 1.502687\n",
      "Batch #10\tAverage Generator Loss: 915.673065\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #5966 (step 5966): 1.419408\n",
      "Batch #10\tAverage Generator Loss: 890.787045\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #5967 (step 5967): 1.619225\n",
      "Batch #10\tAverage Generator Loss: 902.964142\tAverage Discriminator Loss: 0.014748\n",
      "\n",
      "Train time for epoch #5968 (step 5968): 1.290303\n",
      "Batch #10\tAverage Generator Loss: 942.044397\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5969 (step 5969): 1.503571\n",
      "Batch #10\tAverage Generator Loss: 1014.152887\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5970 (step 5970): 1.657392\n",
      "Batch #10\tAverage Generator Loss: 1039.008362\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5971 (step 5971): 1.342472\n",
      "Batch #10\tAverage Generator Loss: 1032.365698\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #5972 (step 5972): 1.579190\n",
      "Batch #10\tAverage Generator Loss: 981.180258\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #5973 (step 5973): 1.377455\n",
      "Batch #10\tAverage Generator Loss: 998.902972\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #5974 (step 5974): 1.566892\n",
      "Batch #10\tAverage Generator Loss: 1116.668866\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #5975 (step 5975): 1.394232\n",
      "Batch #10\tAverage Generator Loss: 977.167932\tAverage Discriminator Loss: 0.029685\n",
      "\n",
      "Train time for epoch #5976 (step 5976): 1.580400\n",
      "Batch #10\tAverage Generator Loss: 881.037366\tAverage Discriminator Loss: 0.005769\n",
      "\n",
      "Train time for epoch #5977 (step 5977): 1.543034\n",
      "Batch #10\tAverage Generator Loss: 944.204706\tAverage Discriminator Loss: 0.000061\n",
      "\n",
      "Train time for epoch #5978 (step 5978): 1.296625\n",
      "Batch #10\tAverage Generator Loss: 959.486603\tAverage Discriminator Loss: 0.000020\n",
      "\n",
      "Train time for epoch #5979 (step 5979): 1.533530\n",
      "Batch #10\tAverage Generator Loss: 997.584894\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #5980 (step 5980): 1.286395\n",
      "Batch #10\tAverage Generator Loss: 881.414276\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #5981 (step 5981): 1.501521\n",
      "Batch #10\tAverage Generator Loss: 850.094846\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #5982 (step 5982): 1.539341\n",
      "Batch #10\tAverage Generator Loss: 892.549319\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #5983 (step 5983): 1.499639\n",
      "Batch #10\tAverage Generator Loss: 911.195340\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #5984 (step 5984): 1.905590\n",
      "Batch #10\tAverage Generator Loss: 816.092432\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #5985 (step 5985): 1.318479\n",
      "Batch #10\tAverage Generator Loss: 858.389279\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #5986 (step 5986): 1.547523\n",
      "Batch #10\tAverage Generator Loss: 846.155682\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #5987 (step 5987): 1.518628\n",
      "Batch #10\tAverage Generator Loss: 819.000122\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #5988 (step 5988): 1.393141\n",
      "Batch #10\tAverage Generator Loss: 785.491165\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #5989 (step 5989): 1.571721\n",
      "Batch #10\tAverage Generator Loss: 893.683176\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #5990 (step 5990): 1.290614\n",
      "Batch #10\tAverage Generator Loss: 766.076308\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #5991 (step 5991): 1.490585\n",
      "Batch #10\tAverage Generator Loss: 884.094720\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #5992 (step 5992): 1.552160\n",
      "Batch #10\tAverage Generator Loss: 901.128259\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #5993 (step 5993): 1.287184\n",
      "Batch #10\tAverage Generator Loss: 897.805145\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #5994 (step 5994): 1.664505\n",
      "Batch #10\tAverage Generator Loss: 970.777313\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #5995 (step 5995): 1.343435\n",
      "Batch #10\tAverage Generator Loss: 916.095102\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #5996 (step 5996): 1.547793\n",
      "Batch #10\tAverage Generator Loss: 802.459329\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #5997 (step 5997): 1.541230\n",
      "Batch #10\tAverage Generator Loss: 786.794925\tAverage Discriminator Loss: 0.089572\n",
      "\n",
      "Train time for epoch #5998 (step 5998): 1.301524\n",
      "Batch #10\tAverage Generator Loss: 1012.338275\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #5999 (step 5999): 1.572418\n",
      "Batch #10\tAverage Generator Loss: 1030.857898\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6000 (step 6000): 1.439549\n",
      "Batch #10\tAverage Generator Loss: 969.554913\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6001 (step 6001): 1.506459\n",
      "Batch #10\tAverage Generator Loss: 999.415094\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6002 (step 6002): 1.523100\n",
      "Batch #10\tAverage Generator Loss: 825.732077\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6003 (step 6003): 1.280507\n",
      "Batch #10\tAverage Generator Loss: 962.203668\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6004 (step 6004): 1.680104\n",
      "Batch #10\tAverage Generator Loss: 955.123767\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6005 (step 6005): 1.311512\n",
      "Batch #10\tAverage Generator Loss: 946.535486\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6006 (step 6006): 1.511652\n",
      "Batch #10\tAverage Generator Loss: 921.557013\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6007 (step 6007): 1.509764\n",
      "Batch #10\tAverage Generator Loss: 993.387137\tAverage Discriminator Loss: 0.004044\n",
      "\n",
      "Train time for epoch #6008 (step 6008): 1.391173\n",
      "Batch #10\tAverage Generator Loss: 1042.304767\tAverage Discriminator Loss: 0.000055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #6009 (step 6009): 1.509066\n",
      "Batch #10\tAverage Generator Loss: 962.929803\tAverage Discriminator Loss: 0.000395\n",
      "\n",
      "Train time for epoch #6010 (step 6010): 1.297725\n",
      "Batch #10\tAverage Generator Loss: 1074.960913\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #6011 (step 6011): 1.628283\n",
      "Batch #10\tAverage Generator Loss: 918.729419\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6012 (step 6012): 1.520394\n",
      "Batch #10\tAverage Generator Loss: 994.550711\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6013 (step 6013): 1.342457\n",
      "Batch #10\tAverage Generator Loss: 992.093384\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6014 (step 6014): 1.562217\n",
      "Batch #10\tAverage Generator Loss: 880.494049\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6015 (step 6015): 1.388502\n",
      "Batch #10\tAverage Generator Loss: 924.256412\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6016 (step 6016): 1.513891\n",
      "Batch #10\tAverage Generator Loss: 931.589252\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6017 (step 6017): 1.571525\n",
      "Batch #10\tAverage Generator Loss: 1092.358899\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6018 (step 6018): 1.461155\n",
      "Batch #10\tAverage Generator Loss: 899.791071\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6019 (step 6019): 1.508971\n",
      "Batch #10\tAverage Generator Loss: 1037.437506\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6020 (step 6020): 1.343806\n",
      "Batch #10\tAverage Generator Loss: 871.252838\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6021 (step 6021): 1.610347\n",
      "Batch #10\tAverage Generator Loss: 886.805092\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6022 (step 6022): 1.290058\n",
      "Batch #10\tAverage Generator Loss: 900.195740\tAverage Discriminator Loss: 0.000158\n",
      "\n",
      "Train time for epoch #6023 (step 6023): 1.548543\n",
      "Batch #10\tAverage Generator Loss: 1033.482635\tAverage Discriminator Loss: 0.008213\n",
      "\n",
      "Train time for epoch #6024 (step 6024): 1.520877\n",
      "Batch #10\tAverage Generator Loss: 897.160980\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6025 (step 6025): 1.335157\n",
      "Batch #10\tAverage Generator Loss: 899.434705\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6026 (step 6026): 1.506293\n",
      "Batch #10\tAverage Generator Loss: 851.594714\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6027 (step 6027): 1.433827\n",
      "Batch #10\tAverage Generator Loss: 943.390131\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6028 (step 6028): 1.616223\n",
      "Batch #10\tAverage Generator Loss: 959.308484\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6029 (step 6029): 1.659376\n",
      "Batch #10\tAverage Generator Loss: 882.529532\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6030 (step 6030): 1.554088\n",
      "Batch #10\tAverage Generator Loss: 983.755353\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6031 (step 6031): 1.521806\n",
      "Batch #10\tAverage Generator Loss: 938.735889\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6032 (step 6032): 1.287044\n",
      "Batch #10\tAverage Generator Loss: 1060.271045\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6033 (step 6033): 1.523810\n",
      "Batch #10\tAverage Generator Loss: 916.130920\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6034 (step 6034): 1.621550\n",
      "Batch #10\tAverage Generator Loss: 979.660260\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #6035 (step 6035): 1.296158\n",
      "Batch #10\tAverage Generator Loss: 1036.892114\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #6036 (step 6036): 1.666112\n",
      "Batch #10\tAverage Generator Loss: 846.042645\tAverage Discriminator Loss: 0.001167\n",
      "\n",
      "Train time for epoch #6037 (step 6037): 1.324943\n",
      "Batch #10\tAverage Generator Loss: 843.164120\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #6038 (step 6038): 1.468455\n",
      "Batch #10\tAverage Generator Loss: 917.586209\tAverage Discriminator Loss: 0.000019\n",
      "\n",
      "Train time for epoch #6039 (step 6039): 1.301438\n",
      "Batch #10\tAverage Generator Loss: 834.679648\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #6040 (step 6040): 1.520489\n",
      "Batch #10\tAverage Generator Loss: 921.684863\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #6041 (step 6041): 1.597512\n",
      "Batch #10\tAverage Generator Loss: 759.284305\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #6042 (step 6042): 1.294461\n",
      "Batch #10\tAverage Generator Loss: 888.039923\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #6043 (step 6043): 1.700476\n",
      "Batch #10\tAverage Generator Loss: 971.671216\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #6044 (step 6044): 1.341422\n",
      "Batch #10\tAverage Generator Loss: 776.455533\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #6045 (step 6045): 1.522692\n",
      "Batch #10\tAverage Generator Loss: 791.938312\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #6046 (step 6046): 1.516027\n",
      "Batch #10\tAverage Generator Loss: 873.789737\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #6047 (step 6047): 1.237646\n",
      "Batch #10\tAverage Generator Loss: 964.213568\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #6048 (step 6048): 1.521674\n",
      "Batch #10\tAverage Generator Loss: 863.199451\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #6049 (step 6049): 1.291110\n",
      "Batch #10\tAverage Generator Loss: 814.120663\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #6050 (step 6050): 1.491053\n",
      "Batch #10\tAverage Generator Loss: 931.410486\tAverage Discriminator Loss: 0.001579\n",
      "\n",
      "Train time for epoch #6051 (step 6051): 1.253313\n",
      "Batch #10\tAverage Generator Loss: 911.388977\tAverage Discriminator Loss: 0.000187\n",
      "\n",
      "Train time for epoch #6052 (step 6052): 1.476393\n",
      "Batch #10\tAverage Generator Loss: 966.954321\tAverage Discriminator Loss: 0.000164\n",
      "\n",
      "Train time for epoch #6053 (step 6053): 1.399134\n",
      "Batch #10\tAverage Generator Loss: 955.033850\tAverage Discriminator Loss: 0.000087\n",
      "\n",
      "Train time for epoch #6054 (step 6054): 1.754177\n",
      "Batch #10\tAverage Generator Loss: 1006.325803\tAverage Discriminator Loss: 0.000040\n",
      "\n",
      "Train time for epoch #6055 (step 6055): 1.572562\n",
      "Batch #10\tAverage Generator Loss: 963.465198\tAverage Discriminator Loss: 0.000032\n",
      "\n",
      "Train time for epoch #6056 (step 6056): 1.278132\n",
      "Batch #10\tAverage Generator Loss: 883.892499\tAverage Discriminator Loss: 0.000026\n",
      "\n",
      "Train time for epoch #6057 (step 6057): 1.620933\n",
      "Batch #10\tAverage Generator Loss: 968.103723\tAverage Discriminator Loss: 0.000025\n",
      "\n",
      "Train time for epoch #6058 (step 6058): 1.357675\n",
      "Batch #10\tAverage Generator Loss: 979.826550\tAverage Discriminator Loss: 0.000066\n",
      "\n",
      "Train time for epoch #6059 (step 6059): 1.502992\n",
      "Batch #10\tAverage Generator Loss: 954.358521\tAverage Discriminator Loss: 0.000084\n",
      "\n",
      "Train time for epoch #6060 (step 6060): 1.517592\n",
      "Batch #10\tAverage Generator Loss: 918.237494\tAverage Discriminator Loss: 0.000019\n",
      "\n",
      "Train time for epoch #6061 (step 6061): 1.333728\n",
      "Batch #10\tAverage Generator Loss: 931.131897\tAverage Discriminator Loss: 0.000021\n",
      "\n",
      "Train time for epoch #6062 (step 6062): 1.564092\n",
      "Batch #10\tAverage Generator Loss: 1036.224323\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #6063 (step 6063): 1.290238\n",
      "Batch #10\tAverage Generator Loss: 1012.711102\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #6064 (step 6064): 1.492595\n",
      "Batch #10\tAverage Generator Loss: 847.588586\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #6065 (step 6065): 1.547484\n",
      "Batch #10\tAverage Generator Loss: 960.390533\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #6066 (step 6066): 1.333161\n",
      "Batch #10\tAverage Generator Loss: 974.156354\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #6067 (step 6067): 1.512178\n",
      "Batch #10\tAverage Generator Loss: 1057.758472\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #6068 (step 6068): 1.318030\n",
      "Batch #10\tAverage Generator Loss: 952.482172\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #6069 (step 6069): 1.788618\n",
      "Batch #10\tAverage Generator Loss: 1010.290228\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #6070 (step 6070): 1.287388\n",
      "Batch #10\tAverage Generator Loss: 905.502344\tAverage Discriminator Loss: 0.000008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #6071 (step 6071): 1.546203\n",
      "Batch #10\tAverage Generator Loss: 1021.840289\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #6072 (step 6072): 1.507307\n",
      "Batch #10\tAverage Generator Loss: 915.480441\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #6073 (step 6073): 1.349108\n",
      "Batch #10\tAverage Generator Loss: 902.773401\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #6074 (step 6074): 1.484208\n",
      "Batch #10\tAverage Generator Loss: 903.901035\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #6075 (step 6075): 1.549546\n",
      "Batch #10\tAverage Generator Loss: 1132.242303\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #6076 (step 6076): 1.397380\n",
      "Batch #10\tAverage Generator Loss: 966.755719\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #6077 (step 6077): 1.732020\n",
      "Batch #10\tAverage Generator Loss: 904.592456\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #6078 (step 6078): 1.371508\n",
      "Batch #10\tAverage Generator Loss: 884.973215\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #6079 (step 6079): 1.562899\n",
      "Batch #10\tAverage Generator Loss: 960.032843\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #6080 (step 6080): 1.367118\n",
      "Batch #10\tAverage Generator Loss: 916.273444\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #6081 (step 6081): 1.581926\n",
      "Batch #10\tAverage Generator Loss: 941.688409\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #6082 (step 6082): 1.590523\n",
      "Batch #10\tAverage Generator Loss: 1151.305292\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #6083 (step 6083): 1.359790\n",
      "Batch #10\tAverage Generator Loss: 1007.613263\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #6084 (step 6084): 1.637882\n",
      "Batch #10\tAverage Generator Loss: 1033.646252\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #6085 (step 6085): 1.300436\n",
      "Batch #10\tAverage Generator Loss: 970.651166\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #6086 (step 6086): 1.512353\n",
      "Batch #10\tAverage Generator Loss: 921.935425\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #6087 (step 6087): 1.585373\n",
      "Batch #10\tAverage Generator Loss: 833.359238\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #6088 (step 6088): 1.310389\n",
      "Batch #10\tAverage Generator Loss: 957.497815\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6089 (step 6089): 1.676937\n",
      "Batch #10\tAverage Generator Loss: 1066.133600\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6090 (step 6090): 1.275788\n",
      "Batch #10\tAverage Generator Loss: 883.885498\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6091 (step 6091): 1.532360\n",
      "Batch #10\tAverage Generator Loss: 1005.194836\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #6092 (step 6092): 1.394983\n",
      "Batch #10\tAverage Generator Loss: 971.192609\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6093 (step 6093): 1.525470\n",
      "Batch #10\tAverage Generator Loss: 988.498578\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6094 (step 6094): 1.579371\n",
      "Batch #10\tAverage Generator Loss: 958.618060\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #6095 (step 6095): 1.330932\n",
      "Batch #10\tAverage Generator Loss: 963.047284\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #6096 (step 6096): 1.515765\n",
      "Batch #10\tAverage Generator Loss: 1050.356104\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #6097 (step 6097): 1.331775\n",
      "Batch #10\tAverage Generator Loss: 949.646185\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #6098 (step 6098): 1.547977\n",
      "Batch #10\tAverage Generator Loss: 983.220215\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6099 (step 6099): 1.535661\n",
      "Batch #10\tAverage Generator Loss: 921.656436\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6100 (step 6100): 1.293247\n",
      "Batch #10\tAverage Generator Loss: 923.941724\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #6101 (step 6101): 1.556558\n",
      "Batch #10\tAverage Generator Loss: 900.463757\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6102 (step 6102): 1.342860\n",
      "Batch #10\tAverage Generator Loss: 977.265002\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6103 (step 6103): 1.513751\n",
      "Batch #10\tAverage Generator Loss: 877.425555\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6104 (step 6104): 1.402007\n",
      "Batch #10\tAverage Generator Loss: 831.293323\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6105 (step 6105): 1.577972\n",
      "Batch #10\tAverage Generator Loss: 1061.455377\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6106 (step 6106): 1.333824\n",
      "Batch #10\tAverage Generator Loss: 1071.462927\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6107 (step 6107): 1.643508\n",
      "Batch #10\tAverage Generator Loss: 878.290604\tAverage Discriminator Loss: 0.015440\n",
      "\n",
      "Train time for epoch #6108 (step 6108): 1.563567\n",
      "Batch #10\tAverage Generator Loss: 955.044745\tAverage Discriminator Loss: 0.020770\n",
      "\n",
      "Train time for epoch #6109 (step 6109): 1.318455\n",
      "Batch #10\tAverage Generator Loss: 912.673853\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6110 (step 6110): 1.647262\n",
      "Batch #10\tAverage Generator Loss: 975.061530\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6111 (step 6111): 1.285754\n",
      "Batch #10\tAverage Generator Loss: 1134.990619\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6112 (step 6112): 1.604915\n",
      "Batch #10\tAverage Generator Loss: 1075.855719\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6113 (step 6113): 1.278452\n",
      "Batch #10\tAverage Generator Loss: 1045.369818\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6114 (step 6114): 1.661694\n",
      "Batch #10\tAverage Generator Loss: 1010.023773\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6115 (step 6115): 1.521069\n",
      "Batch #10\tAverage Generator Loss: 919.689459\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6116 (step 6116): 1.517271\n",
      "Batch #10\tAverage Generator Loss: 945.084464\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6117 (step 6117): 1.570642\n",
      "Batch #10\tAverage Generator Loss: 1067.276086\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6118 (step 6118): 1.416322\n",
      "Batch #10\tAverage Generator Loss: 1120.473444\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6119 (step 6119): 1.703494\n",
      "Batch #10\tAverage Generator Loss: 1010.331738\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6120 (step 6120): 1.565700\n",
      "Batch #10\tAverage Generator Loss: 989.258994\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6121 (step 6121): 1.365864\n",
      "Batch #10\tAverage Generator Loss: 1020.790479\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6122 (step 6122): 1.558117\n",
      "Batch #10\tAverage Generator Loss: 1018.570538\tAverage Discriminator Loss: 0.163489\n",
      "\n",
      "Train time for epoch #6123 (step 6123): 1.285414\n",
      "Batch #10\tAverage Generator Loss: 820.189166\tAverage Discriminator Loss: 0.000047\n",
      "\n",
      "Train time for epoch #6124 (step 6124): 1.526365\n",
      "Batch #10\tAverage Generator Loss: 670.693558\tAverage Discriminator Loss: 0.002725\n",
      "\n",
      "Train time for epoch #6125 (step 6125): 1.540242\n",
      "Batch #10\tAverage Generator Loss: 797.233093\tAverage Discriminator Loss: 0.000265\n",
      "\n",
      "Train time for epoch #6126 (step 6126): 1.240877\n",
      "Batch #10\tAverage Generator Loss: 1077.345770\tAverage Discriminator Loss: 0.000030\n",
      "\n",
      "Train time for epoch #6127 (step 6127): 1.552420\n",
      "Batch #10\tAverage Generator Loss: 1212.904797\tAverage Discriminator Loss: 0.000028\n",
      "\n",
      "Train time for epoch #6128 (step 6128): 1.290701\n",
      "Batch #10\tAverage Generator Loss: 955.927176\tAverage Discriminator Loss: 0.000021\n",
      "\n",
      "Train time for epoch #6129 (step 6129): 1.516142\n",
      "Batch #10\tAverage Generator Loss: 1067.969299\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #6130 (step 6130): 1.378715\n",
      "Batch #10\tAverage Generator Loss: 814.250317\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #6131 (step 6131): 1.510589\n",
      "Batch #10\tAverage Generator Loss: 982.533978\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #6132 (step 6132): 1.528128\n",
      "Batch #10\tAverage Generator Loss: 978.941077\tAverage Discriminator Loss: 0.000011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #6133 (step 6133): 1.411884\n",
      "Batch #10\tAverage Generator Loss: 894.479602\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #6134 (step 6134): 1.845126\n",
      "Batch #10\tAverage Generator Loss: 1021.628064\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #6135 (step 6135): 1.295817\n",
      "Batch #10\tAverage Generator Loss: 954.092526\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6136 (step 6136): 1.508480\n",
      "Batch #10\tAverage Generator Loss: 1108.374536\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #6137 (step 6137): 1.611805\n",
      "Batch #10\tAverage Generator Loss: 1123.138324\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6138 (step 6138): 1.347016\n",
      "Batch #10\tAverage Generator Loss: 1055.704749\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #6139 (step 6139): 1.530560\n",
      "Batch #10\tAverage Generator Loss: 906.710699\tAverage Discriminator Loss: 0.009406\n",
      "\n",
      "Train time for epoch #6140 (step 6140): 1.469495\n",
      "Batch #10\tAverage Generator Loss: 1115.078638\tAverage Discriminator Loss: 0.000649\n",
      "\n",
      "Train time for epoch #6141 (step 6141): 1.542156\n",
      "Batch #10\tAverage Generator Loss: 942.392291\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #6142 (step 6142): 1.337443\n",
      "Batch #10\tAverage Generator Loss: 1178.561621\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6143 (step 6143): 1.467246\n",
      "Batch #10\tAverage Generator Loss: 1102.760095\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6144 (step 6144): 1.360505\n",
      "Batch #10\tAverage Generator Loss: 1037.766931\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6145 (step 6145): 1.461028\n",
      "Batch #10\tAverage Generator Loss: 1135.333167\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6146 (step 6146): 1.526772\n",
      "Batch #10\tAverage Generator Loss: 1008.515875\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6147 (step 6147): 1.349577\n",
      "Batch #10\tAverage Generator Loss: 1242.207745\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6148 (step 6148): 1.511532\n",
      "Batch #10\tAverage Generator Loss: 1107.779791\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6149 (step 6149): 1.289105\n",
      "Batch #10\tAverage Generator Loss: 1071.596240\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6150 (step 6150): 1.739209\n",
      "Batch #10\tAverage Generator Loss: 927.344629\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6151 (step 6151): 1.589177\n",
      "Batch #10\tAverage Generator Loss: 1064.355557\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6152 (step 6152): 1.409967\n",
      "Batch #10\tAverage Generator Loss: 1217.713757\tAverage Discriminator Loss: 0.000022\n",
      "\n",
      "Train time for epoch #6153 (step 6153): 1.518237\n",
      "Batch #10\tAverage Generator Loss: 1455.789597\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6154 (step 6154): 1.288220\n",
      "Batch #10\tAverage Generator Loss: 1296.370923\tAverage Discriminator Loss: 0.002944\n",
      "\n",
      "Train time for epoch #6155 (step 6155): 1.560124\n",
      "Batch #10\tAverage Generator Loss: 1114.904999\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6156 (step 6156): 1.516656\n",
      "Batch #10\tAverage Generator Loss: 1147.476581\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6157 (step 6157): 1.336381\n",
      "Batch #10\tAverage Generator Loss: 1101.329584\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #6158 (step 6158): 1.524076\n",
      "Batch #10\tAverage Generator Loss: 1147.729620\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6159 (step 6159): 1.344631\n",
      "Batch #10\tAverage Generator Loss: 1179.314832\tAverage Discriminator Loss: 0.000033\n",
      "\n",
      "Train time for epoch #6160 (step 6160): 1.606740\n",
      "Batch #10\tAverage Generator Loss: 975.843622\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6161 (step 6161): 1.298090\n",
      "Batch #10\tAverage Generator Loss: 1014.072064\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6162 (step 6162): 1.567302\n",
      "Batch #10\tAverage Generator Loss: 1080.590747\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6163 (step 6163): 1.515583\n",
      "Batch #10\tAverage Generator Loss: 1189.024329\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6164 (step 6164): 1.494371\n",
      "Batch #10\tAverage Generator Loss: 1039.909644\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6165 (step 6165): 1.567527\n",
      "Batch #10\tAverage Generator Loss: 979.132874\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6166 (step 6166): 1.374111\n",
      "Batch #10\tAverage Generator Loss: 1122.002087\tAverage Discriminator Loss: 0.001707\n",
      "\n",
      "Train time for epoch #6167 (step 6167): 1.695800\n",
      "Batch #10\tAverage Generator Loss: 1112.517877\tAverage Discriminator Loss: 0.000110\n",
      "\n",
      "Train time for epoch #6168 (step 6168): 1.368216\n",
      "Batch #10\tAverage Generator Loss: 1035.711005\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #6169 (step 6169): 1.584068\n",
      "Batch #10\tAverage Generator Loss: 1127.050885\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6170 (step 6170): 1.663824\n",
      "Batch #10\tAverage Generator Loss: 1052.599030\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6171 (step 6171): 1.296584\n",
      "Batch #10\tAverage Generator Loss: 1279.917975\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6172 (step 6172): 1.468295\n",
      "Batch #10\tAverage Generator Loss: 1230.402472\tAverage Discriminator Loss: 0.008868\n",
      "\n",
      "Train time for epoch #6173 (step 6173): 1.384920\n",
      "Batch #10\tAverage Generator Loss: 1085.800781\tAverage Discriminator Loss: 0.003736\n",
      "\n",
      "Train time for epoch #6174 (step 6174): 1.514205\n",
      "Batch #10\tAverage Generator Loss: 954.820264\tAverage Discriminator Loss: 0.120787\n",
      "\n",
      "Train time for epoch #6175 (step 6175): 1.622206\n",
      "Batch #10\tAverage Generator Loss: 1023.489963\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #6176 (step 6176): 1.402547\n",
      "Batch #10\tAverage Generator Loss: 1136.637402\tAverage Discriminator Loss: 0.187645\n",
      "\n",
      "Train time for epoch #6177 (step 6177): 1.560713\n",
      "Batch #10\tAverage Generator Loss: 1149.785138\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6178 (step 6178): 1.425919\n",
      "Batch #10\tAverage Generator Loss: 979.907388\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6179 (step 6179): 1.579478\n",
      "Batch #10\tAverage Generator Loss: 1147.748575\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6180 (step 6180): 1.659601\n",
      "Batch #10\tAverage Generator Loss: 1026.528714\tAverage Discriminator Loss: 0.059250\n",
      "\n",
      "Train time for epoch #6181 (step 6181): 1.343483\n",
      "Batch #10\tAverage Generator Loss: 1040.512988\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6182 (step 6182): 1.580909\n",
      "Batch #10\tAverage Generator Loss: 1297.714618\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #6183 (step 6183): 1.599864\n",
      "Batch #10\tAverage Generator Loss: 1098.157397\tAverage Discriminator Loss: 0.000023\n",
      "\n",
      "Train time for epoch #6184 (step 6184): 1.286469\n",
      "Batch #10\tAverage Generator Loss: 1061.183990\tAverage Discriminator Loss: 0.000020\n",
      "\n",
      "Train time for epoch #6185 (step 6185): 1.575493\n",
      "Batch #10\tAverage Generator Loss: 997.134648\tAverage Discriminator Loss: 0.000023\n",
      "\n",
      "Train time for epoch #6186 (step 6186): 1.237115\n",
      "Batch #10\tAverage Generator Loss: 1150.812372\tAverage Discriminator Loss: 0.000022\n",
      "\n",
      "Train time for epoch #6187 (step 6187): 1.520306\n",
      "Batch #10\tAverage Generator Loss: 1154.770605\tAverage Discriminator Loss: 0.000020\n",
      "\n",
      "Train time for epoch #6188 (step 6188): 1.357487\n",
      "Batch #10\tAverage Generator Loss: 1177.694556\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #6189 (step 6189): 1.500056\n",
      "Batch #10\tAverage Generator Loss: 972.643373\tAverage Discriminator Loss: 0.000023\n",
      "\n",
      "Train time for epoch #6190 (step 6190): 1.401009\n",
      "Batch #10\tAverage Generator Loss: 1196.260193\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #6191 (step 6191): 1.609330\n",
      "Batch #10\tAverage Generator Loss: 1064.082205\tAverage Discriminator Loss: 0.010864\n",
      "\n",
      "Train time for epoch #6192 (step 6192): 1.608465\n",
      "Batch #10\tAverage Generator Loss: 1125.523535\tAverage Discriminator Loss: 0.003738\n",
      "\n",
      "Train time for epoch #6193 (step 6193): 1.294964\n",
      "Batch #10\tAverage Generator Loss: 865.212842\tAverage Discriminator Loss: 0.000269\n",
      "\n",
      "Train time for epoch #6194 (step 6194): 1.574073\n",
      "Batch #10\tAverage Generator Loss: 853.078375\tAverage Discriminator Loss: 0.000056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #6195 (step 6195): 1.292475\n",
      "Batch #10\tAverage Generator Loss: 889.243582\tAverage Discriminator Loss: 0.000024\n",
      "\n",
      "Train time for epoch #6196 (step 6196): 1.557857\n",
      "Batch #10\tAverage Generator Loss: 980.696375\tAverage Discriminator Loss: 0.000024\n",
      "\n",
      "Train time for epoch #6197 (step 6197): 1.529173\n",
      "Batch #10\tAverage Generator Loss: 870.439281\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #6198 (step 6198): 1.339906\n",
      "Batch #10\tAverage Generator Loss: 1034.726685\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #6199 (step 6199): 1.519506\n",
      "Batch #10\tAverage Generator Loss: 881.439072\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #6200 (step 6200): 1.347385\n",
      "Batch #10\tAverage Generator Loss: 1032.647214\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #6201 (step 6201): 1.603364\n",
      "Batch #10\tAverage Generator Loss: 917.345178\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #6202 (step 6202): 1.336544\n",
      "Batch #10\tAverage Generator Loss: 1040.101483\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #6203 (step 6203): 1.606311\n",
      "Batch #10\tAverage Generator Loss: 931.081641\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #6204 (step 6204): 1.705515\n",
      "Batch #10\tAverage Generator Loss: 959.469910\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #6205 (step 6205): 1.296506\n",
      "Batch #10\tAverage Generator Loss: 940.828851\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #6206 (step 6206): 1.523824\n",
      "Batch #10\tAverage Generator Loss: 843.669556\tAverage Discriminator Loss: 0.000029\n",
      "\n",
      "Train time for epoch #6207 (step 6207): 1.286784\n",
      "Batch #10\tAverage Generator Loss: 922.244644\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #6208 (step 6208): 1.586723\n",
      "Batch #10\tAverage Generator Loss: 1013.097778\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #6209 (step 6209): 1.560258\n",
      "Batch #10\tAverage Generator Loss: 848.775909\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #6210 (step 6210): 1.364382\n",
      "Batch #10\tAverage Generator Loss: 842.043338\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #6211 (step 6211): 1.659697\n",
      "Batch #10\tAverage Generator Loss: 926.760678\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #6212 (step 6212): 1.511850\n",
      "Batch #10\tAverage Generator Loss: 826.868179\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #6213 (step 6213): 1.334419\n",
      "Batch #10\tAverage Generator Loss: 1111.221423\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6214 (step 6214): 1.599776\n",
      "Batch #10\tAverage Generator Loss: 1001.274826\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6215 (step 6215): 1.340665\n",
      "Batch #10\tAverage Generator Loss: 957.347064\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6216 (step 6216): 1.525585\n",
      "Batch #10\tAverage Generator Loss: 909.262015\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #6217 (step 6217): 1.378595\n",
      "Batch #10\tAverage Generator Loss: 986.776437\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #6218 (step 6218): 1.567014\n",
      "Batch #10\tAverage Generator Loss: 910.808301\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6219 (step 6219): 1.400824\n",
      "Batch #10\tAverage Generator Loss: 862.683151\tAverage Discriminator Loss: 0.000152\n",
      "\n",
      "Train time for epoch #6220 (step 6220): 1.553013\n",
      "Batch #10\tAverage Generator Loss: 801.449725\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #6221 (step 6221): 1.502215\n",
      "Batch #10\tAverage Generator Loss: 919.674841\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #6222 (step 6222): 1.347807\n",
      "Batch #10\tAverage Generator Loss: 858.744627\tAverage Discriminator Loss: 0.084328\n",
      "\n",
      "Train time for epoch #6223 (step 6223): 1.726905\n",
      "Batch #10\tAverage Generator Loss: 953.572717\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6224 (step 6224): 1.419646\n",
      "Batch #10\tAverage Generator Loss: 1281.860602\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6225 (step 6225): 1.719236\n",
      "Batch #10\tAverage Generator Loss: 1186.413873\tAverage Discriminator Loss: 0.037835\n",
      "\n",
      "Train time for epoch #6226 (step 6226): 1.477793\n",
      "Batch #10\tAverage Generator Loss: 1140.653607\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6227 (step 6227): 1.521668\n",
      "Batch #10\tAverage Generator Loss: 1120.986255\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #6228 (step 6228): 1.571358\n",
      "Batch #10\tAverage Generator Loss: 1220.477362\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6229 (step 6229): 1.340341\n",
      "Batch #10\tAverage Generator Loss: 1253.401166\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6230 (step 6230): 1.605815\n",
      "Batch #10\tAverage Generator Loss: 1057.924567\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6231 (step 6231): 1.644239\n",
      "Batch #10\tAverage Generator Loss: 1286.033893\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6232 (step 6232): 1.407544\n",
      "Batch #10\tAverage Generator Loss: 1233.371692\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6233 (step 6233): 1.588773\n",
      "Batch #10\tAverage Generator Loss: 1237.974005\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6234 (step 6234): 1.288265\n",
      "Batch #10\tAverage Generator Loss: 999.541599\tAverage Discriminator Loss: 0.017816\n",
      "\n",
      "Train time for epoch #6235 (step 6235): 1.668025\n",
      "Batch #10\tAverage Generator Loss: 1306.421851\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6236 (step 6236): 1.298550\n",
      "Batch #10\tAverage Generator Loss: 1201.462811\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #6237 (step 6237): 1.710043\n",
      "Batch #10\tAverage Generator Loss: 1075.305029\tAverage Discriminator Loss: 0.009077\n",
      "\n",
      "Train time for epoch #6238 (step 6238): 1.309127\n",
      "Batch #10\tAverage Generator Loss: 1172.587732\tAverage Discriminator Loss: 0.007775\n",
      "\n",
      "Train time for epoch #6239 (step 6239): 1.555067\n",
      "Batch #10\tAverage Generator Loss: 1189.423932\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #6240 (step 6240): 1.298599\n",
      "Batch #10\tAverage Generator Loss: 1377.993216\tAverage Discriminator Loss: 0.721776\n",
      "\n",
      "Train time for epoch #6241 (step 6241): 1.490233\n",
      "Batch #10\tAverage Generator Loss: 1482.251093\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6242 (step 6242): 1.593894\n",
      "Batch #10\tAverage Generator Loss: 1400.311597\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6243 (step 6243): 1.433070\n",
      "Batch #10\tAverage Generator Loss: 1649.120380\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6244 (step 6244): 1.610738\n",
      "Batch #10\tAverage Generator Loss: 1489.471759\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6245 (step 6245): 1.340334\n",
      "Batch #10\tAverage Generator Loss: 1643.201379\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6246 (step 6246): 1.486976\n",
      "Batch #10\tAverage Generator Loss: 1641.103442\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6247 (step 6247): 1.367270\n",
      "Batch #10\tAverage Generator Loss: 1569.889691\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6248 (step 6248): 1.517266\n",
      "Batch #10\tAverage Generator Loss: 1416.587811\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6249 (step 6249): 1.523909\n",
      "Batch #10\tAverage Generator Loss: 1497.695770\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6250 (step 6250): 1.377836\n",
      "Batch #10\tAverage Generator Loss: 1431.067725\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6251 (step 6251): 1.648228\n",
      "Batch #10\tAverage Generator Loss: 1576.204578\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6252 (step 6252): 1.571282\n",
      "Batch #10\tAverage Generator Loss: 1371.934314\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6253 (step 6253): 1.312904\n",
      "Batch #10\tAverage Generator Loss: 1487.430890\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6254 (step 6254): 1.562609\n",
      "Batch #10\tAverage Generator Loss: 1485.912140\tAverage Discriminator Loss: 0.011603\n",
      "\n",
      "Train time for epoch #6255 (step 6255): 1.395130\n",
      "Batch #10\tAverage Generator Loss: 1349.343005\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6256 (step 6256): 1.608806\n",
      "Batch #10\tAverage Generator Loss: 1411.823828\tAverage Discriminator Loss: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #6257 (step 6257): 1.516608\n",
      "Batch #10\tAverage Generator Loss: 1389.760394\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6258 (step 6258): 1.352096\n",
      "Batch #10\tAverage Generator Loss: 1499.665399\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6259 (step 6259): 1.782065\n",
      "Batch #10\tAverage Generator Loss: 1425.827435\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6260 (step 6260): 1.344339\n",
      "Batch #10\tAverage Generator Loss: 1738.041479\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6261 (step 6261): 1.533853\n",
      "Batch #10\tAverage Generator Loss: 1329.337994\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6262 (step 6262): 1.303594\n",
      "Batch #10\tAverage Generator Loss: 1401.444604\tAverage Discriminator Loss: 0.003408\n",
      "\n",
      "Train time for epoch #6263 (step 6263): 1.494085\n",
      "Batch #10\tAverage Generator Loss: 1397.106738\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #6264 (step 6264): 1.561609\n",
      "Batch #10\tAverage Generator Loss: 1596.172186\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6265 (step 6265): 1.296812\n",
      "Batch #10\tAverage Generator Loss: 1502.175397\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6266 (step 6266): 1.572730\n",
      "Batch #10\tAverage Generator Loss: 1473.774243\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6267 (step 6267): 1.452210\n",
      "Batch #10\tAverage Generator Loss: 1463.990613\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6268 (step 6268): 1.521448\n",
      "Batch #10\tAverage Generator Loss: 1330.026855\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6269 (step 6269): 1.693248\n",
      "Batch #10\tAverage Generator Loss: 1454.394510\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6270 (step 6270): 1.240869\n",
      "Batch #10\tAverage Generator Loss: 1454.287927\tAverage Discriminator Loss: 0.000326\n",
      "\n",
      "Train time for epoch #6271 (step 6271): 1.515140\n",
      "Batch #10\tAverage Generator Loss: 1606.171710\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6272 (step 6272): 1.332022\n",
      "Batch #10\tAverage Generator Loss: 1614.638867\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6273 (step 6273): 1.615137\n",
      "Batch #10\tAverage Generator Loss: 1589.126123\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6274 (step 6274): 1.523743\n",
      "Batch #10\tAverage Generator Loss: 1390.817502\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6275 (step 6275): 1.281987\n",
      "Batch #10\tAverage Generator Loss: 1261.031708\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6276 (step 6276): 1.716128\n",
      "Batch #10\tAverage Generator Loss: 1374.852820\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6277 (step 6277): 1.380985\n",
      "Batch #10\tAverage Generator Loss: 1497.980872\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6278 (step 6278): 1.531068\n",
      "Batch #10\tAverage Generator Loss: 1368.338855\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6279 (step 6279): 1.303330\n",
      "Batch #10\tAverage Generator Loss: 1485.332672\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6280 (step 6280): 1.575408\n",
      "Batch #10\tAverage Generator Loss: 1383.407208\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6281 (step 6281): 1.566840\n",
      "Batch #10\tAverage Generator Loss: 1536.178735\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6282 (step 6282): 1.296410\n",
      "Batch #10\tAverage Generator Loss: 1443.721387\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6283 (step 6283): 1.744818\n",
      "Batch #10\tAverage Generator Loss: 1427.467120\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6284 (step 6284): 1.296973\n",
      "Batch #10\tAverage Generator Loss: 1541.541290\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6285 (step 6285): 1.541203\n",
      "Batch #10\tAverage Generator Loss: 1433.223108\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6286 (step 6286): 1.346872\n",
      "Batch #10\tAverage Generator Loss: 1408.532666\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6287 (step 6287): 1.478599\n",
      "Batch #10\tAverage Generator Loss: 1446.594519\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6288 (step 6288): 1.546291\n",
      "Batch #10\tAverage Generator Loss: 1413.919098\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6289 (step 6289): 1.330103\n",
      "Batch #10\tAverage Generator Loss: 1430.030829\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6290 (step 6290): 1.489415\n",
      "Batch #10\tAverage Generator Loss: 1359.395129\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6291 (step 6291): 1.440501\n",
      "Batch #10\tAverage Generator Loss: 1342.492267\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6292 (step 6292): 1.630139\n",
      "Batch #10\tAverage Generator Loss: 1408.031451\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6293 (step 6293): 1.619073\n",
      "Batch #10\tAverage Generator Loss: 1654.271191\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6294 (step 6294): 1.334752\n",
      "Batch #10\tAverage Generator Loss: 1418.138147\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6295 (step 6295): 1.547576\n",
      "Batch #10\tAverage Generator Loss: 1353.531366\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6296 (step 6296): 1.401501\n",
      "Batch #10\tAverage Generator Loss: 1517.200092\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6297 (step 6297): 1.503114\n",
      "Batch #10\tAverage Generator Loss: 1337.413605\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6298 (step 6298): 1.394977\n",
      "Batch #10\tAverage Generator Loss: 1585.942596\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6299 (step 6299): 1.534033\n",
      "Batch #10\tAverage Generator Loss: 1486.123853\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6300 (step 6300): 1.404526\n",
      "Batch #10\tAverage Generator Loss: 1404.641718\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6301 (step 6301): 1.594944\n",
      "Batch #10\tAverage Generator Loss: 1674.817090\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6302 (step 6302): 1.520828\n",
      "Batch #10\tAverage Generator Loss: 1588.259033\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6303 (step 6303): 1.285819\n",
      "Batch #10\tAverage Generator Loss: 1467.562622\tAverage Discriminator Loss: 0.103500\n",
      "\n",
      "Train time for epoch #6304 (step 6304): 1.555198\n",
      "Batch #10\tAverage Generator Loss: 1497.908118\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6305 (step 6305): 1.296794\n",
      "Batch #10\tAverage Generator Loss: 1365.178198\tAverage Discriminator Loss: 0.000019\n",
      "\n",
      "Train time for epoch #6306 (step 6306): 1.514819\n",
      "Batch #10\tAverage Generator Loss: 1520.937866\tAverage Discriminator Loss: 0.021237\n",
      "\n",
      "Train time for epoch #6307 (step 6307): 1.519119\n",
      "Batch #10\tAverage Generator Loss: 1315.831158\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #6308 (step 6308): 1.277395\n",
      "Batch #10\tAverage Generator Loss: 1312.591730\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6309 (step 6309): 1.571441\n",
      "Batch #10\tAverage Generator Loss: 1212.114783\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6310 (step 6310): 1.306175\n",
      "Batch #10\tAverage Generator Loss: 1444.029517\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6311 (step 6311): 1.538852\n",
      "Batch #10\tAverage Generator Loss: 1302.186096\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6312 (step 6312): 1.575357\n",
      "Batch #10\tAverage Generator Loss: 1512.332043\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6313 (step 6313): 1.295675\n",
      "Batch #10\tAverage Generator Loss: 1396.834412\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6314 (step 6314): 1.522789\n",
      "Batch #10\tAverage Generator Loss: 1295.124957\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6315 (step 6315): 1.376021\n",
      "Batch #10\tAverage Generator Loss: 1271.618585\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6316 (step 6316): 1.601555\n",
      "Batch #10\tAverage Generator Loss: 1470.368701\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6317 (step 6317): 1.679456\n",
      "Batch #10\tAverage Generator Loss: 1316.756970\tAverage Discriminator Loss: 0.013175\n",
      "\n",
      "Train time for epoch #6318 (step 6318): 1.341331\n",
      "Batch #10\tAverage Generator Loss: 1398.915906\tAverage Discriminator Loss: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #6319 (step 6319): 1.583766\n",
      "Batch #10\tAverage Generator Loss: 1359.790930\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6320 (step 6320): 1.294050\n",
      "Batch #10\tAverage Generator Loss: 1399.436127\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6321 (step 6321): 1.541561\n",
      "Batch #10\tAverage Generator Loss: 1316.460675\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6322 (step 6322): 1.289609\n",
      "Batch #10\tAverage Generator Loss: 1285.128839\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6323 (step 6323): 1.530894\n",
      "Batch #10\tAverage Generator Loss: 1206.433994\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6324 (step 6324): 1.291824\n",
      "Batch #10\tAverage Generator Loss: 1238.612885\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6325 (step 6325): 1.586909\n",
      "Batch #10\tAverage Generator Loss: 1501.273657\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6326 (step 6326): 1.596547\n",
      "Batch #10\tAverage Generator Loss: 1496.705713\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6327 (step 6327): 1.294758\n",
      "Batch #10\tAverage Generator Loss: 1464.869305\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6328 (step 6328): 1.580685\n",
      "Batch #10\tAverage Generator Loss: 1415.464130\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6329 (step 6329): 1.304898\n",
      "Batch #10\tAverage Generator Loss: 1412.602844\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6330 (step 6330): 1.573202\n",
      "Batch #10\tAverage Generator Loss: 1300.310583\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6331 (step 6331): 1.534569\n",
      "Batch #10\tAverage Generator Loss: 1222.108282\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6332 (step 6332): 1.356616\n",
      "Batch #10\tAverage Generator Loss: 1484.151471\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6333 (step 6333): 1.535197\n",
      "Batch #10\tAverage Generator Loss: 1454.520752\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6334 (step 6334): 1.326615\n",
      "Batch #10\tAverage Generator Loss: 1356.052878\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6335 (step 6335): 1.595815\n",
      "Batch #10\tAverage Generator Loss: 1319.253442\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6336 (step 6336): 1.287103\n",
      "Batch #10\tAverage Generator Loss: 1283.735968\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6337 (step 6337): 1.524376\n",
      "Batch #10\tAverage Generator Loss: 1262.699542\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6338 (step 6338): 1.571594\n",
      "Batch #10\tAverage Generator Loss: 1398.475482\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6339 (step 6339): 1.302421\n",
      "Batch #10\tAverage Generator Loss: 1147.127692\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6340 (step 6340): 1.524356\n",
      "Batch #10\tAverage Generator Loss: 1412.822717\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6341 (step 6341): 1.280416\n",
      "Batch #10\tAverage Generator Loss: 1399.122357\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6342 (step 6342): 1.467310\n",
      "Batch #10\tAverage Generator Loss: 1436.274445\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6343 (step 6343): 1.566468\n",
      "Batch #10\tAverage Generator Loss: 1513.598291\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6344 (step 6344): 1.331485\n",
      "Batch #10\tAverage Generator Loss: 1392.190295\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6345 (step 6345): 1.557825\n",
      "Batch #10\tAverage Generator Loss: 1219.472888\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6346 (step 6346): 1.399722\n",
      "Batch #10\tAverage Generator Loss: 1447.942102\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6347 (step 6347): 1.523348\n",
      "Batch #10\tAverage Generator Loss: 1591.324817\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6348 (step 6348): 1.298188\n",
      "Batch #10\tAverage Generator Loss: 1159.678998\tAverage Discriminator Loss: 0.063243\n",
      "\n",
      "Train time for epoch #6349 (step 6349): 1.638284\n",
      "Batch #10\tAverage Generator Loss: 1407.546448\tAverage Discriminator Loss: 0.006192\n",
      "\n",
      "Train time for epoch #6350 (step 6350): 1.632350\n",
      "Batch #10\tAverage Generator Loss: 1177.397900\tAverage Discriminator Loss: 0.000026\n",
      "\n",
      "Train time for epoch #6351 (step 6351): 1.341110\n",
      "Batch #10\tAverage Generator Loss: 1188.294269\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #6352 (step 6352): 1.649805\n",
      "Batch #10\tAverage Generator Loss: 1147.729108\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #6353 (step 6353): 1.290523\n",
      "Batch #10\tAverage Generator Loss: 1081.617819\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #6354 (step 6354): 1.686738\n",
      "Batch #10\tAverage Generator Loss: 1368.506067\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #6355 (step 6355): 1.462388\n",
      "Batch #10\tAverage Generator Loss: 1248.232770\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #6356 (step 6356): 1.644851\n",
      "Batch #10\tAverage Generator Loss: 1157.141650\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6357 (step 6357): 1.529165\n",
      "Batch #10\tAverage Generator Loss: 1347.588043\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #6358 (step 6358): 1.403091\n",
      "Batch #10\tAverage Generator Loss: 1151.904578\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6359 (step 6359): 1.627941\n",
      "Batch #10\tAverage Generator Loss: 1344.284106\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #6360 (step 6360): 1.392727\n",
      "Batch #10\tAverage Generator Loss: 1154.140204\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #6361 (step 6361): 1.609234\n",
      "Batch #10\tAverage Generator Loss: 1291.881335\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #6362 (step 6362): 1.344705\n",
      "Batch #10\tAverage Generator Loss: 1185.417157\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6363 (step 6363): 1.535204\n",
      "Batch #10\tAverage Generator Loss: 1310.110986\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6364 (step 6364): 1.565498\n",
      "Batch #10\tAverage Generator Loss: 1266.074396\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #6365 (step 6365): 1.347942\n",
      "Batch #10\tAverage Generator Loss: 1279.461377\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6366 (step 6366): 1.595659\n",
      "Batch #10\tAverage Generator Loss: 1216.851660\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #6367 (step 6367): 1.568966\n",
      "Batch #10\tAverage Generator Loss: 1341.398822\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #6368 (step 6368): 1.346528\n",
      "Batch #10\tAverage Generator Loss: 1356.119153\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #6369 (step 6369): 1.537201\n",
      "Batch #10\tAverage Generator Loss: 1243.947052\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #6370 (step 6370): 1.343860\n",
      "Batch #10\tAverage Generator Loss: 1124.175604\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6371 (step 6371): 1.528899\n",
      "Batch #10\tAverage Generator Loss: 1213.453357\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #6372 (step 6372): 1.351030\n",
      "Batch #10\tAverage Generator Loss: 1143.510632\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6373 (step 6373): 1.572825\n",
      "Batch #10\tAverage Generator Loss: 1399.658777\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #6374 (step 6374): 1.463591\n",
      "Batch #10\tAverage Generator Loss: 1209.322900\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #6375 (step 6375): 1.574658\n",
      "Batch #10\tAverage Generator Loss: 1332.306610\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #6376 (step 6376): 1.290512\n",
      "Batch #10\tAverage Generator Loss: 1313.370746\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #6377 (step 6377): 1.505476\n",
      "Batch #10\tAverage Generator Loss: 1284.839288\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6378 (step 6378): 1.585314\n",
      "Batch #10\tAverage Generator Loss: 1176.603900\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #6379 (step 6379): 1.400651\n",
      "Batch #10\tAverage Generator Loss: 1217.685327\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #6380 (step 6380): 1.604925\n",
      "Batch #10\tAverage Generator Loss: 1099.706110\tAverage Discriminator Loss: 0.000007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #6381 (step 6381): 1.320189\n",
      "Batch #10\tAverage Generator Loss: 1324.610803\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6382 (step 6382): 1.627620\n",
      "Batch #10\tAverage Generator Loss: 1147.300488\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6383 (step 6383): 1.525902\n",
      "Batch #10\tAverage Generator Loss: 1099.407141\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #6384 (step 6384): 1.332927\n",
      "Batch #10\tAverage Generator Loss: 1233.886768\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #6385 (step 6385): 1.558466\n",
      "Batch #10\tAverage Generator Loss: 1299.616003\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6386 (step 6386): 1.287256\n",
      "Batch #10\tAverage Generator Loss: 1259.005127\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6387 (step 6387): 1.576661\n",
      "Batch #10\tAverage Generator Loss: 1158.129074\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6388 (step 6388): 1.398406\n",
      "Batch #10\tAverage Generator Loss: 1196.864899\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6389 (step 6389): 1.670752\n",
      "Batch #10\tAverage Generator Loss: 1286.496808\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6390 (step 6390): 1.380113\n",
      "Batch #10\tAverage Generator Loss: 1151.685040\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6391 (step 6391): 1.575751\n",
      "Batch #10\tAverage Generator Loss: 1312.152875\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6392 (step 6392): 1.549965\n",
      "Batch #10\tAverage Generator Loss: 1277.223639\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6393 (step 6393): 1.338714\n",
      "Batch #10\tAverage Generator Loss: 1171.941754\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6394 (step 6394): 1.562269\n",
      "Batch #10\tAverage Generator Loss: 1168.691400\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6395 (step 6395): 1.334707\n",
      "Batch #10\tAverage Generator Loss: 1347.761072\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6396 (step 6396): 1.626820\n",
      "Batch #10\tAverage Generator Loss: 1206.381482\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6397 (step 6397): 1.280673\n",
      "Batch #10\tAverage Generator Loss: 1039.523645\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6398 (step 6398): 1.486934\n",
      "Batch #10\tAverage Generator Loss: 1285.718579\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6399 (step 6399): 1.583532\n",
      "Batch #10\tAverage Generator Loss: 1283.092114\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6400 (step 6400): 1.360101\n",
      "Batch #10\tAverage Generator Loss: 1254.740259\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6401 (step 6401): 1.624135\n",
      "Batch #10\tAverage Generator Loss: 1391.661823\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6402 (step 6402): 1.344702\n",
      "Batch #10\tAverage Generator Loss: 1303.467413\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6403 (step 6403): 1.624568\n",
      "Batch #10\tAverage Generator Loss: 1134.077872\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6404 (step 6404): 1.575445\n",
      "Batch #10\tAverage Generator Loss: 1314.346698\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6405 (step 6405): 1.443492\n",
      "Batch #10\tAverage Generator Loss: 1147.449042\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6406 (step 6406): 1.548390\n",
      "Batch #10\tAverage Generator Loss: 1311.735333\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #6407 (step 6407): 1.348067\n",
      "Batch #10\tAverage Generator Loss: 1146.797906\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6408 (step 6408): 1.532129\n",
      "Batch #10\tAverage Generator Loss: 1167.267078\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6409 (step 6409): 1.277685\n",
      "Batch #10\tAverage Generator Loss: 1308.928625\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6410 (step 6410): 1.531358\n",
      "Batch #10\tAverage Generator Loss: 1014.535553\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6411 (step 6411): 1.347565\n",
      "Batch #10\tAverage Generator Loss: 1275.197900\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6412 (step 6412): 1.583865\n",
      "Batch #10\tAverage Generator Loss: 1198.825995\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6413 (step 6413): 1.341377\n",
      "Batch #10\tAverage Generator Loss: 1231.790533\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6414 (step 6414): 1.582839\n",
      "Batch #10\tAverage Generator Loss: 1230.013531\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6415 (step 6415): 1.634445\n",
      "Batch #10\tAverage Generator Loss: 1151.329956\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6416 (step 6416): 1.462925\n",
      "Batch #10\tAverage Generator Loss: 1247.581976\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6417 (step 6417): 1.570618\n",
      "Batch #10\tAverage Generator Loss: 1346.489063\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6418 (step 6418): 1.294891\n",
      "Batch #10\tAverage Generator Loss: 1182.635461\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6419 (step 6419): 1.589192\n",
      "Batch #10\tAverage Generator Loss: 1373.972180\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6420 (step 6420): 1.356924\n",
      "Batch #10\tAverage Generator Loss: 1168.673743\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6421 (step 6421): 1.622025\n",
      "Batch #10\tAverage Generator Loss: 1269.832074\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6422 (step 6422): 1.582888\n",
      "Batch #10\tAverage Generator Loss: 1137.006659\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6423 (step 6423): 1.287451\n",
      "Batch #10\tAverage Generator Loss: 1242.628723\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6424 (step 6424): 1.597504\n",
      "Batch #10\tAverage Generator Loss: 1401.188245\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6425 (step 6425): 1.301479\n",
      "Batch #10\tAverage Generator Loss: 1207.664996\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6426 (step 6426): 1.528870\n",
      "Batch #10\tAverage Generator Loss: 1189.704428\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6427 (step 6427): 1.298126\n",
      "Batch #10\tAverage Generator Loss: 1125.733914\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6428 (step 6428): 1.518853\n",
      "Batch #10\tAverage Generator Loss: 1106.795395\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6429 (step 6429): 1.326259\n",
      "Batch #10\tAverage Generator Loss: 1322.300049\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6430 (step 6430): 1.510524\n",
      "Batch #10\tAverage Generator Loss: 1369.117438\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6431 (step 6431): 1.432454\n",
      "Batch #10\tAverage Generator Loss: 1208.890350\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6432 (step 6432): 1.579697\n",
      "Batch #10\tAverage Generator Loss: 1198.981427\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6433 (step 6433): 1.606108\n",
      "Batch #10\tAverage Generator Loss: 1264.177246\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6434 (step 6434): 1.396185\n",
      "Batch #10\tAverage Generator Loss: 1166.276611\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6435 (step 6435): 1.534431\n",
      "Batch #10\tAverage Generator Loss: 1231.757019\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6436 (step 6436): 1.262145\n",
      "Batch #10\tAverage Generator Loss: 1367.785602\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6437 (step 6437): 1.592512\n",
      "Batch #10\tAverage Generator Loss: 1326.528265\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6438 (step 6438): 1.346397\n",
      "Batch #10\tAverage Generator Loss: 1115.085809\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6439 (step 6439): 1.655535\n",
      "Batch #10\tAverage Generator Loss: 1115.274542\tAverage Discriminator Loss: 0.041336\n",
      "\n",
      "Train time for epoch #6440 (step 6440): 1.594868\n",
      "Batch #10\tAverage Generator Loss: 1116.913165\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6441 (step 6441): 1.376350\n",
      "Batch #10\tAverage Generator Loss: 1193.197656\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6442 (step 6442): 1.649534\n",
      "Batch #10\tAverage Generator Loss: 1239.411267\tAverage Discriminator Loss: 0.000320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #6443 (step 6443): 1.388289\n",
      "Batch #10\tAverage Generator Loss: 1057.357343\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6444 (step 6444): 1.594094\n",
      "Batch #10\tAverage Generator Loss: 1187.712158\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6445 (step 6445): 1.369453\n",
      "Batch #10\tAverage Generator Loss: 1240.742151\tAverage Discriminator Loss: 0.009313\n",
      "\n",
      "Train time for epoch #6446 (step 6446): 1.515159\n",
      "Batch #10\tAverage Generator Loss: 1122.980096\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6447 (step 6447): 1.577847\n",
      "Batch #10\tAverage Generator Loss: 1130.506860\tAverage Discriminator Loss: 0.001586\n",
      "\n",
      "Train time for epoch #6448 (step 6448): 1.390014\n",
      "Batch #10\tAverage Generator Loss: 1025.027682\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6449 (step 6449): 1.527415\n",
      "Batch #10\tAverage Generator Loss: 1163.970874\tAverage Discriminator Loss: 0.003332\n",
      "\n",
      "Train time for epoch #6450 (step 6450): 1.601015\n",
      "Batch #10\tAverage Generator Loss: 1189.550684\tAverage Discriminator Loss: 0.000147\n",
      "\n",
      "Train time for epoch #6451 (step 6451): 1.285434\n",
      "Batch #10\tAverage Generator Loss: 1143.014105\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #6452 (step 6452): 1.541582\n",
      "Batch #10\tAverage Generator Loss: 1072.843884\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6453 (step 6453): 1.374237\n",
      "Batch #10\tAverage Generator Loss: 1194.869574\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6454 (step 6454): 1.618158\n",
      "Batch #10\tAverage Generator Loss: 1036.562415\tAverage Discriminator Loss: 0.020758\n",
      "\n",
      "Train time for epoch #6455 (step 6455): 1.343729\n",
      "Batch #10\tAverage Generator Loss: 1126.285767\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6456 (step 6456): 1.531556\n",
      "Batch #10\tAverage Generator Loss: 1097.423077\tAverage Discriminator Loss: 0.182357\n",
      "\n",
      "Train time for epoch #6457 (step 6457): 1.566557\n",
      "Batch #10\tAverage Generator Loss: 827.817276\tAverage Discriminator Loss: 0.204859\n",
      "\n",
      "Train time for epoch #6458 (step 6458): 1.338192\n",
      "Batch #10\tAverage Generator Loss: 876.617163\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #6459 (step 6459): 1.633811\n",
      "Batch #10\tAverage Generator Loss: 835.092944\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6460 (step 6460): 1.303767\n",
      "Batch #10\tAverage Generator Loss: 782.925212\tAverage Discriminator Loss: 0.037784\n",
      "\n",
      "Train time for epoch #6461 (step 6461): 1.562151\n",
      "Batch #10\tAverage Generator Loss: 955.575812\tAverage Discriminator Loss: 0.004595\n",
      "\n",
      "Train time for epoch #6462 (step 6462): 1.390987\n",
      "Batch #10\tAverage Generator Loss: 930.467545\tAverage Discriminator Loss: 0.000032\n",
      "\n",
      "Train time for epoch #6463 (step 6463): 1.677953\n",
      "Batch #10\tAverage Generator Loss: 977.680713\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #6464 (step 6464): 1.291549\n",
      "Batch #10\tAverage Generator Loss: 820.181030\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #6465 (step 6465): 1.521151\n",
      "Batch #10\tAverage Generator Loss: 863.181378\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #6466 (step 6466): 1.343397\n",
      "Batch #10\tAverage Generator Loss: 906.835767\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #6467 (step 6467): 1.589710\n",
      "Batch #10\tAverage Generator Loss: 799.430005\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #6468 (step 6468): 1.566990\n",
      "Batch #10\tAverage Generator Loss: 957.352698\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #6469 (step 6469): 1.421266\n",
      "Batch #10\tAverage Generator Loss: 861.110229\tAverage Discriminator Loss: 0.002139\n",
      "\n",
      "Train time for epoch #6470 (step 6470): 1.574870\n",
      "Batch #10\tAverage Generator Loss: 844.912421\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #6471 (step 6471): 1.285364\n",
      "Batch #10\tAverage Generator Loss: 866.841345\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #6472 (step 6472): 1.616221\n",
      "Batch #10\tAverage Generator Loss: 849.066357\tAverage Discriminator Loss: 0.000023\n",
      "\n",
      "Train time for epoch #6473 (step 6473): 1.288780\n",
      "Batch #10\tAverage Generator Loss: 871.065796\tAverage Discriminator Loss: 0.000019\n",
      "\n",
      "Train time for epoch #6474 (step 6474): 1.622866\n",
      "Batch #10\tAverage Generator Loss: 896.865942\tAverage Discriminator Loss: 0.000032\n",
      "\n",
      "Train time for epoch #6475 (step 6475): 1.549554\n",
      "Batch #10\tAverage Generator Loss: 814.838849\tAverage Discriminator Loss: 0.000446\n",
      "\n",
      "Train time for epoch #6476 (step 6476): 1.529840\n",
      "Batch #10\tAverage Generator Loss: 815.271130\tAverage Discriminator Loss: 0.000081\n",
      "\n",
      "Train time for epoch #6477 (step 6477): 1.648653\n",
      "Batch #10\tAverage Generator Loss: 863.819250\tAverage Discriminator Loss: 0.000172\n",
      "\n",
      "Train time for epoch #6478 (step 6478): 1.278113\n",
      "Batch #10\tAverage Generator Loss: 874.401260\tAverage Discriminator Loss: 0.000031\n",
      "\n",
      "Train time for epoch #6479 (step 6479): 1.544803\n",
      "Batch #10\tAverage Generator Loss: 885.864923\tAverage Discriminator Loss: 0.000030\n",
      "\n",
      "Train time for epoch #6480 (step 6480): 1.338690\n",
      "Batch #10\tAverage Generator Loss: 904.211624\tAverage Discriminator Loss: 0.005529\n",
      "\n",
      "Train time for epoch #6481 (step 6481): 1.534014\n",
      "Batch #10\tAverage Generator Loss: 844.610327\tAverage Discriminator Loss: 0.000103\n",
      "\n",
      "Train time for epoch #6482 (step 6482): 1.334932\n",
      "Batch #10\tAverage Generator Loss: 924.354608\tAverage Discriminator Loss: 0.002502\n",
      "\n",
      "Train time for epoch #6483 (step 6483): 1.601131\n",
      "Batch #10\tAverage Generator Loss: 926.435919\tAverage Discriminator Loss: 0.000288\n",
      "\n",
      "Train time for epoch #6484 (step 6484): 1.575319\n",
      "Batch #10\tAverage Generator Loss: 922.985187\tAverage Discriminator Loss: 0.000096\n",
      "\n",
      "Train time for epoch #6485 (step 6485): 1.379236\n",
      "Batch #10\tAverage Generator Loss: 914.407538\tAverage Discriminator Loss: 0.000075\n",
      "\n",
      "Train time for epoch #6486 (step 6486): 1.634818\n",
      "Batch #10\tAverage Generator Loss: 846.296228\tAverage Discriminator Loss: 0.006407\n",
      "\n",
      "Train time for epoch #6487 (step 6487): 1.388528\n",
      "Batch #10\tAverage Generator Loss: 855.251196\tAverage Discriminator Loss: 0.000159\n",
      "\n",
      "Train time for epoch #6488 (step 6488): 1.532854\n",
      "Batch #10\tAverage Generator Loss: 993.994635\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #6489 (step 6489): 1.356942\n",
      "Batch #10\tAverage Generator Loss: 928.459970\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6490 (step 6490): 1.617692\n",
      "Batch #10\tAverage Generator Loss: 956.418768\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6491 (step 6491): 1.351861\n",
      "Batch #10\tAverage Generator Loss: 1011.393536\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6492 (step 6492): 1.595886\n",
      "Batch #10\tAverage Generator Loss: 936.492297\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6493 (step 6493): 1.577314\n",
      "Batch #10\tAverage Generator Loss: 1013.690192\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6494 (step 6494): 1.336941\n",
      "Batch #10\tAverage Generator Loss: 982.023334\tAverage Discriminator Loss: 0.004345\n",
      "\n",
      "Train time for epoch #6495 (step 6495): 1.575393\n",
      "Batch #10\tAverage Generator Loss: 977.581512\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #6496 (step 6496): 1.297134\n",
      "Batch #10\tAverage Generator Loss: 966.781592\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6497 (step 6497): 1.518171\n",
      "Batch #10\tAverage Generator Loss: 916.406519\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6498 (step 6498): 1.340741\n",
      "Batch #10\tAverage Generator Loss: 838.147079\tAverage Discriminator Loss: 0.060830\n",
      "\n",
      "Train time for epoch #6499 (step 6499): 1.706773\n",
      "Batch #10\tAverage Generator Loss: 857.481650\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6500 (step 6500): 1.513533\n",
      "Batch #10\tAverage Generator Loss: 954.066827\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6501 (step 6501): 1.288807\n",
      "Batch #10\tAverage Generator Loss: 779.266614\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6502 (step 6502): 1.523313\n",
      "Batch #10\tAverage Generator Loss: 922.281659\tAverage Discriminator Loss: 0.008388\n",
      "\n",
      "Train time for epoch #6503 (step 6503): 1.334857\n",
      "Batch #10\tAverage Generator Loss: 869.360181\tAverage Discriminator Loss: 0.000031\n",
      "\n",
      "Train time for epoch #6504 (step 6504): 1.516710\n",
      "Batch #10\tAverage Generator Loss: 848.985010\tAverage Discriminator Loss: 0.001645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #6505 (step 6505): 1.303008\n",
      "Batch #10\tAverage Generator Loss: 876.989069\tAverage Discriminator Loss: 0.000020\n",
      "\n",
      "Train time for epoch #6506 (step 6506): 1.521417\n",
      "Batch #10\tAverage Generator Loss: 851.301349\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #6507 (step 6507): 1.292711\n",
      "Batch #10\tAverage Generator Loss: 856.545654\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #6508 (step 6508): 1.532454\n",
      "Batch #10\tAverage Generator Loss: 771.858527\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #6509 (step 6509): 1.566645\n",
      "Batch #10\tAverage Generator Loss: 752.928503\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #6510 (step 6510): 1.345482\n",
      "Batch #10\tAverage Generator Loss: 865.691486\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #6511 (step 6511): 1.535895\n",
      "Batch #10\tAverage Generator Loss: 891.870593\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #6512 (step 6512): 1.300030\n",
      "Batch #10\tAverage Generator Loss: 749.425476\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #6513 (step 6513): 1.640913\n",
      "Batch #10\tAverage Generator Loss: 793.723199\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #6514 (step 6514): 1.342044\n",
      "Batch #10\tAverage Generator Loss: 913.422430\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #6515 (step 6515): 1.632964\n",
      "Batch #10\tAverage Generator Loss: 854.496417\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #6516 (step 6516): 1.601985\n",
      "Batch #10\tAverage Generator Loss: 819.350244\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #6517 (step 6517): 1.352404\n",
      "Batch #10\tAverage Generator Loss: 860.376367\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #6518 (step 6518): 1.651556\n",
      "Batch #10\tAverage Generator Loss: 853.673404\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #6519 (step 6519): 1.324455\n",
      "Batch #10\tAverage Generator Loss: 912.174121\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #6520 (step 6520): 1.534674\n",
      "Batch #10\tAverage Generator Loss: 891.748187\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #6521 (step 6521): 1.287299\n",
      "Batch #10\tAverage Generator Loss: 856.963171\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #6522 (step 6522): 1.588673\n",
      "Batch #10\tAverage Generator Loss: 779.618799\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #6523 (step 6523): 1.333897\n",
      "Batch #10\tAverage Generator Loss: 858.889273\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #6524 (step 6524): 1.572058\n",
      "Batch #10\tAverage Generator Loss: 882.529022\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #6525 (step 6525): 1.536414\n",
      "Batch #10\tAverage Generator Loss: 881.238693\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #6526 (step 6526): 1.333118\n",
      "Batch #10\tAverage Generator Loss: 839.823987\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #6527 (step 6527): 1.539327\n",
      "Batch #10\tAverage Generator Loss: 859.935596\tAverage Discriminator Loss: 0.000124\n",
      "\n",
      "Train time for epoch #6528 (step 6528): 1.363568\n",
      "Batch #10\tAverage Generator Loss: 770.413065\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #6529 (step 6529): 1.583675\n",
      "Batch #10\tAverage Generator Loss: 863.383661\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #6530 (step 6530): 1.295358\n",
      "Batch #10\tAverage Generator Loss: 839.974207\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #6531 (step 6531): 1.605025\n",
      "Batch #10\tAverage Generator Loss: 915.593427\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #6532 (step 6532): 1.422101\n",
      "Batch #10\tAverage Generator Loss: 921.925623\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #6533 (step 6533): 1.571635\n",
      "Batch #10\tAverage Generator Loss: 877.265814\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #6534 (step 6534): 1.418308\n",
      "Batch #10\tAverage Generator Loss: 845.100146\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #6535 (step 6535): 1.563646\n",
      "Batch #10\tAverage Generator Loss: 921.933740\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #6536 (step 6536): 1.545366\n",
      "Batch #10\tAverage Generator Loss: 841.658069\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #6537 (step 6537): 1.299596\n",
      "Batch #10\tAverage Generator Loss: 887.355023\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #6538 (step 6538): 1.517108\n",
      "Batch #10\tAverage Generator Loss: 821.018021\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #6539 (step 6539): 1.452628\n",
      "Batch #10\tAverage Generator Loss: 872.408157\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #6540 (step 6540): 1.566258\n",
      "Batch #10\tAverage Generator Loss: 881.115173\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #6541 (step 6541): 1.256637\n",
      "Batch #10\tAverage Generator Loss: 852.985205\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #6542 (step 6542): 1.588073\n",
      "Batch #10\tAverage Generator Loss: 932.900394\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #6543 (step 6543): 1.337240\n",
      "Batch #10\tAverage Generator Loss: 819.085443\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #6544 (step 6544): 1.581759\n",
      "Batch #10\tAverage Generator Loss: 832.946857\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #6545 (step 6545): 1.518370\n",
      "Batch #10\tAverage Generator Loss: 790.235440\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #6546 (step 6546): 1.325557\n",
      "Batch #10\tAverage Generator Loss: 808.807764\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #6547 (step 6547): 1.543210\n",
      "Batch #10\tAverage Generator Loss: 807.592426\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #6548 (step 6548): 1.330222\n",
      "Batch #10\tAverage Generator Loss: 882.761133\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #6549 (step 6549): 1.601315\n",
      "Batch #10\tAverage Generator Loss: 857.286166\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #6550 (step 6550): 1.377349\n",
      "Batch #10\tAverage Generator Loss: 788.051364\tAverage Discriminator Loss: 0.003511\n",
      "\n",
      "Train time for epoch #6551 (step 6551): 1.544043\n",
      "Batch #10\tAverage Generator Loss: 835.326938\tAverage Discriminator Loss: 0.000492\n",
      "\n",
      "Train time for epoch #6552 (step 6552): 1.289466\n",
      "Batch #10\tAverage Generator Loss: 828.262579\tAverage Discriminator Loss: 0.000026\n",
      "\n",
      "Train time for epoch #6553 (step 6553): 1.595186\n",
      "Batch #10\tAverage Generator Loss: 926.203577\tAverage Discriminator Loss: 0.000029\n",
      "\n",
      "Train time for epoch #6554 (step 6554): 1.579686\n",
      "Batch #10\tAverage Generator Loss: 839.274615\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #6555 (step 6555): 1.330266\n",
      "Batch #10\tAverage Generator Loss: 832.848172\tAverage Discriminator Loss: 0.000020\n",
      "\n",
      "Train time for epoch #6556 (step 6556): 1.554682\n",
      "Batch #10\tAverage Generator Loss: 856.868768\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #6557 (step 6557): 1.298626\n",
      "Batch #10\tAverage Generator Loss: 802.999579\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #6558 (step 6558): 1.568648\n",
      "Batch #10\tAverage Generator Loss: 871.392773\tAverage Discriminator Loss: 0.000323\n",
      "\n",
      "Train time for epoch #6559 (step 6559): 1.346357\n",
      "Batch #10\tAverage Generator Loss: 925.638074\tAverage Discriminator Loss: 0.000028\n",
      "\n",
      "Train time for epoch #6560 (step 6560): 1.524580\n",
      "Batch #10\tAverage Generator Loss: 898.143463\tAverage Discriminator Loss: 0.000022\n",
      "\n",
      "Train time for epoch #6561 (step 6561): 1.279736\n",
      "Batch #10\tAverage Generator Loss: 902.675348\tAverage Discriminator Loss: 0.000024\n",
      "\n",
      "Train time for epoch #6562 (step 6562): 1.708803\n",
      "Batch #10\tAverage Generator Loss: 878.216779\tAverage Discriminator Loss: 0.003098\n",
      "\n",
      "Train time for epoch #6563 (step 6563): 1.652981\n",
      "Batch #10\tAverage Generator Loss: 889.720923\tAverage Discriminator Loss: 0.000331\n",
      "\n",
      "Train time for epoch #6564 (step 6564): 1.292245\n",
      "Batch #10\tAverage Generator Loss: 847.868427\tAverage Discriminator Loss: 0.000232\n",
      "\n",
      "Train time for epoch #6565 (step 6565): 1.705823\n",
      "Batch #10\tAverage Generator Loss: 863.757831\tAverage Discriminator Loss: 0.000095\n",
      "\n",
      "Train time for epoch #6566 (step 6566): 1.455511\n",
      "Batch #10\tAverage Generator Loss: 926.616486\tAverage Discriminator Loss: 0.000064\n",
      "\n",
      "Train time for epoch #6567 (step 6567): 1.523852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 922.275311\tAverage Discriminator Loss: 0.000046\n",
      "\n",
      "Train time for epoch #6568 (step 6568): 1.235600\n",
      "Batch #10\tAverage Generator Loss: 912.970065\tAverage Discriminator Loss: 0.000037\n",
      "\n",
      "Train time for epoch #6569 (step 6569): 1.483332\n",
      "Batch #10\tAverage Generator Loss: 838.969907\tAverage Discriminator Loss: 0.008298\n",
      "\n",
      "Train time for epoch #6570 (step 6570): 1.522546\n",
      "Batch #10\tAverage Generator Loss: 836.478885\tAverage Discriminator Loss: 0.000580\n",
      "\n",
      "Train time for epoch #6571 (step 6571): 1.285918\n",
      "Batch #10\tAverage Generator Loss: 887.875909\tAverage Discriminator Loss: 0.000182\n",
      "\n",
      "Train time for epoch #6572 (step 6572): 1.646416\n",
      "Batch #10\tAverage Generator Loss: 863.554645\tAverage Discriminator Loss: 0.000054\n",
      "\n",
      "Train time for epoch #6573 (step 6573): 1.517011\n",
      "Batch #10\tAverage Generator Loss: 894.618323\tAverage Discriminator Loss: 0.000035\n",
      "\n",
      "Train time for epoch #6574 (step 6574): 1.710991\n",
      "Batch #10\tAverage Generator Loss: 936.606995\tAverage Discriminator Loss: 0.000026\n",
      "\n",
      "Train time for epoch #6575 (step 6575): 1.289501\n",
      "Batch #10\tAverage Generator Loss: 835.846179\tAverage Discriminator Loss: 0.000026\n",
      "\n",
      "Train time for epoch #6576 (step 6576): 1.519265\n",
      "Batch #10\tAverage Generator Loss: 841.251416\tAverage Discriminator Loss: 0.000021\n",
      "\n",
      "Train time for epoch #6577 (step 6577): 1.284051\n",
      "Batch #10\tAverage Generator Loss: 820.240842\tAverage Discriminator Loss: 0.000021\n",
      "\n",
      "Train time for epoch #6578 (step 6578): 1.626242\n",
      "Batch #10\tAverage Generator Loss: 901.963269\tAverage Discriminator Loss: 0.000021\n",
      "\n",
      "Train time for epoch #6579 (step 6579): 1.577371\n",
      "Batch #10\tAverage Generator Loss: 927.938562\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #6580 (step 6580): 1.267301\n",
      "Batch #10\tAverage Generator Loss: 872.816266\tAverage Discriminator Loss: 0.000024\n",
      "\n",
      "Train time for epoch #6581 (step 6581): 1.514696\n",
      "Batch #10\tAverage Generator Loss: 939.014325\tAverage Discriminator Loss: 0.000019\n",
      "\n",
      "Train time for epoch #6582 (step 6582): 1.397047\n",
      "Batch #10\tAverage Generator Loss: 938.605942\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #6583 (step 6583): 1.571172\n",
      "Batch #10\tAverage Generator Loss: 843.428104\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #6584 (step 6584): 1.397508\n",
      "Batch #10\tAverage Generator Loss: 872.330817\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #6585 (step 6585): 1.628824\n",
      "Batch #10\tAverage Generator Loss: 865.024329\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #6586 (step 6586): 1.246929\n",
      "Batch #10\tAverage Generator Loss: 794.459637\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #6587 (step 6587): 1.527557\n",
      "Batch #10\tAverage Generator Loss: 878.318604\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #6588 (step 6588): 1.388677\n",
      "Batch #10\tAverage Generator Loss: 800.027679\tAverage Discriminator Loss: 0.000025\n",
      "\n",
      "Train time for epoch #6589 (step 6589): 1.583097\n",
      "Batch #10\tAverage Generator Loss: 857.634988\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #6590 (step 6590): 1.628068\n",
      "Batch #10\tAverage Generator Loss: 880.585565\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #6591 (step 6591): 1.290831\n",
      "Batch #10\tAverage Generator Loss: 899.810767\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #6592 (step 6592): 1.593307\n",
      "Batch #10\tAverage Generator Loss: 939.615350\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #6593 (step 6593): 1.331330\n",
      "Batch #10\tAverage Generator Loss: 928.056030\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #6594 (step 6594): 1.555110\n",
      "Batch #10\tAverage Generator Loss: 925.396008\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #6595 (step 6595): 1.448662\n",
      "Batch #10\tAverage Generator Loss: 900.608636\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #6596 (step 6596): 1.565583\n",
      "Batch #10\tAverage Generator Loss: 955.169318\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #6597 (step 6597): 1.626086\n",
      "Batch #10\tAverage Generator Loss: 953.493536\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #6598 (step 6598): 1.451820\n",
      "Batch #10\tAverage Generator Loss: 868.582620\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #6599 (step 6599): 1.527193\n",
      "Batch #10\tAverage Generator Loss: 896.768033\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #6600 (step 6600): 1.289560\n",
      "Batch #10\tAverage Generator Loss: 917.619598\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #6601 (step 6601): 1.539035\n",
      "Batch #10\tAverage Generator Loss: 873.493967\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #6602 (step 6602): 1.386872\n",
      "Batch #10\tAverage Generator Loss: 944.979608\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #6603 (step 6603): 1.672252\n",
      "Batch #10\tAverage Generator Loss: 885.195715\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #6604 (step 6604): 1.681905\n",
      "Batch #10\tAverage Generator Loss: 863.285706\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #6605 (step 6605): 1.353832\n",
      "Batch #10\tAverage Generator Loss: 951.431537\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #6606 (step 6606): 1.552122\n",
      "Batch #10\tAverage Generator Loss: 997.510144\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #6607 (step 6607): 1.447587\n",
      "Batch #10\tAverage Generator Loss: 852.512442\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #6608 (step 6608): 1.483961\n",
      "Batch #10\tAverage Generator Loss: 912.479932\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #6609 (step 6609): 1.286611\n",
      "Batch #10\tAverage Generator Loss: 861.983499\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #6610 (step 6610): 1.589394\n",
      "Batch #10\tAverage Generator Loss: 913.124048\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #6611 (step 6611): 1.380265\n",
      "Batch #10\tAverage Generator Loss: 821.670081\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #6612 (step 6612): 1.548993\n",
      "Batch #10\tAverage Generator Loss: 989.039258\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #6613 (step 6613): 1.344336\n",
      "Batch #10\tAverage Generator Loss: 921.492963\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #6614 (step 6614): 1.720017\n",
      "Batch #10\tAverage Generator Loss: 844.528967\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #6615 (step 6615): 1.678250\n",
      "Batch #10\tAverage Generator Loss: 931.317737\tAverage Discriminator Loss: 0.002050\n",
      "\n",
      "Train time for epoch #6616 (step 6616): 1.339674\n",
      "Batch #10\tAverage Generator Loss: 850.415372\tAverage Discriminator Loss: 0.000641\n",
      "\n",
      "Train time for epoch #6617 (step 6617): 1.529996\n",
      "Batch #10\tAverage Generator Loss: 973.614227\tAverage Discriminator Loss: 0.000079\n",
      "\n",
      "Train time for epoch #6618 (step 6618): 1.287335\n",
      "Batch #10\tAverage Generator Loss: 913.737170\tAverage Discriminator Loss: 0.000028\n",
      "\n",
      "Train time for epoch #6619 (step 6619): 1.524661\n",
      "Batch #10\tAverage Generator Loss: 994.116528\tAverage Discriminator Loss: 0.000028\n",
      "\n",
      "Train time for epoch #6620 (step 6620): 1.294816\n",
      "Batch #10\tAverage Generator Loss: 872.728619\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #6621 (step 6621): 1.566110\n",
      "Batch #10\tAverage Generator Loss: 842.632471\tAverage Discriminator Loss: 0.000021\n",
      "\n",
      "Train time for epoch #6622 (step 6622): 1.341373\n",
      "Batch #10\tAverage Generator Loss: 1074.677972\tAverage Discriminator Loss: 0.000185\n",
      "\n",
      "Train time for epoch #6623 (step 6623): 1.570149\n",
      "Batch #10\tAverage Generator Loss: 1010.567847\tAverage Discriminator Loss: 0.000835\n",
      "\n",
      "Train time for epoch #6624 (step 6624): 1.545405\n",
      "Batch #10\tAverage Generator Loss: 868.005359\tAverage Discriminator Loss: 0.000025\n",
      "\n",
      "Train time for epoch #6625 (step 6625): 1.338984\n",
      "Batch #10\tAverage Generator Loss: 948.791119\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #6626 (step 6626): 1.629684\n",
      "Batch #10\tAverage Generator Loss: 985.693451\tAverage Discriminator Loss: 0.000020\n",
      "\n",
      "Train time for epoch #6627 (step 6627): 1.455098\n",
      "Batch #10\tAverage Generator Loss: 866.194690\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #6628 (step 6628): 1.602104\n",
      "Batch #10\tAverage Generator Loss: 806.427623\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #6629 (step 6629): 1.341332\n",
      "Batch #10\tAverage Generator Loss: 908.863611\tAverage Discriminator Loss: 0.000015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #6630 (step 6630): 1.496865\n",
      "Batch #10\tAverage Generator Loss: 1021.732562\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #6631 (step 6631): 1.629957\n",
      "Batch #10\tAverage Generator Loss: 894.151044\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #6632 (step 6632): 1.272406\n",
      "Batch #10\tAverage Generator Loss: 1078.757208\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #6633 (step 6633): 1.614847\n",
      "Batch #10\tAverage Generator Loss: 908.443130\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #6634 (step 6634): 1.393883\n",
      "Batch #10\tAverage Generator Loss: 997.194595\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #6635 (step 6635): 1.636407\n",
      "Batch #10\tAverage Generator Loss: 887.846881\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #6636 (step 6636): 1.357756\n",
      "Batch #10\tAverage Generator Loss: 1009.224637\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #6637 (step 6637): 1.667454\n",
      "Batch #10\tAverage Generator Loss: 1125.848822\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #6638 (step 6638): 1.624968\n",
      "Batch #10\tAverage Generator Loss: 1010.735907\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #6639 (step 6639): 1.294991\n",
      "Batch #10\tAverage Generator Loss: 977.818988\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #6640 (step 6640): 1.649138\n",
      "Batch #10\tAverage Generator Loss: 1011.294409\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #6641 (step 6641): 1.322495\n",
      "Batch #10\tAverage Generator Loss: 972.100250\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #6642 (step 6642): 1.494461\n",
      "Batch #10\tAverage Generator Loss: 948.569238\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #6643 (step 6643): 1.466502\n",
      "Batch #10\tAverage Generator Loss: 928.577606\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #6644 (step 6644): 1.530570\n",
      "Batch #10\tAverage Generator Loss: 973.798102\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #6645 (step 6645): 1.532225\n",
      "Batch #10\tAverage Generator Loss: 969.997607\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #6646 (step 6646): 1.281539\n",
      "Batch #10\tAverage Generator Loss: 1012.245355\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #6647 (step 6647): 1.556955\n",
      "Batch #10\tAverage Generator Loss: 879.868518\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #6648 (step 6648): 1.293404\n",
      "Batch #10\tAverage Generator Loss: 973.625781\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #6649 (step 6649): 1.607188\n",
      "Batch #10\tAverage Generator Loss: 952.711469\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6650 (step 6650): 1.319901\n",
      "Batch #10\tAverage Generator Loss: 934.162842\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #6651 (step 6651): 1.538293\n",
      "Batch #10\tAverage Generator Loss: 1015.214520\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #6652 (step 6652): 1.474505\n",
      "Batch #10\tAverage Generator Loss: 1001.664575\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #6653 (step 6653): 1.607519\n",
      "Batch #10\tAverage Generator Loss: 1019.532361\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #6654 (step 6654): 1.538039\n",
      "Batch #10\tAverage Generator Loss: 975.061237\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #6655 (step 6655): 1.435105\n",
      "Batch #10\tAverage Generator Loss: 1024.243384\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #6656 (step 6656): 1.576578\n",
      "Batch #10\tAverage Generator Loss: 979.080408\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #6657 (step 6657): 1.274201\n",
      "Batch #10\tAverage Generator Loss: 1001.875476\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #6658 (step 6658): 1.532415\n",
      "Batch #10\tAverage Generator Loss: 903.413513\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #6659 (step 6659): 1.319488\n",
      "Batch #10\tAverage Generator Loss: 1001.688080\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #6660 (step 6660): 1.619299\n",
      "Batch #10\tAverage Generator Loss: 1016.886938\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #6661 (step 6661): 1.534793\n",
      "Batch #10\tAverage Generator Loss: 939.761389\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #6662 (step 6662): 1.370873\n",
      "Batch #10\tAverage Generator Loss: 948.719714\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #6663 (step 6663): 1.508822\n",
      "Batch #10\tAverage Generator Loss: 1060.165503\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6664 (step 6664): 1.309950\n",
      "Batch #10\tAverage Generator Loss: 914.738947\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6665 (step 6665): 1.539879\n",
      "Batch #10\tAverage Generator Loss: 930.227032\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6666 (step 6666): 1.306977\n",
      "Batch #10\tAverage Generator Loss: 970.277197\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6667 (step 6667): 1.630865\n",
      "Batch #10\tAverage Generator Loss: 959.360162\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6668 (step 6668): 1.647114\n",
      "Batch #10\tAverage Generator Loss: 916.704739\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6669 (step 6669): 1.300892\n",
      "Batch #10\tAverage Generator Loss: 945.004736\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #6670 (step 6670): 1.561562\n",
      "Batch #10\tAverage Generator Loss: 871.131329\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6671 (step 6671): 1.296481\n",
      "Batch #10\tAverage Generator Loss: 906.092776\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #6672 (step 6672): 1.526116\n",
      "Batch #10\tAverage Generator Loss: 924.980768\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6673 (step 6673): 1.319693\n",
      "Batch #10\tAverage Generator Loss: 955.483588\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6674 (step 6674): 1.558887\n",
      "Batch #10\tAverage Generator Loss: 910.112048\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6675 (step 6675): 1.400851\n",
      "Batch #10\tAverage Generator Loss: 894.031024\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6676 (step 6676): 1.653822\n",
      "Batch #10\tAverage Generator Loss: 1007.105566\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6677 (step 6677): 1.441770\n",
      "Batch #10\tAverage Generator Loss: 976.177686\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6678 (step 6678): 1.516610\n",
      "Batch #10\tAverage Generator Loss: 978.453815\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6679 (step 6679): 1.572034\n",
      "Batch #10\tAverage Generator Loss: 906.893103\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6680 (step 6680): 1.284225\n",
      "Batch #10\tAverage Generator Loss: 1002.339716\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6681 (step 6681): 1.583338\n",
      "Batch #10\tAverage Generator Loss: 1019.853259\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6682 (step 6682): 1.379712\n",
      "Batch #10\tAverage Generator Loss: 989.436963\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6683 (step 6683): 1.587355\n",
      "Batch #10\tAverage Generator Loss: 921.563531\tAverage Discriminator Loss: 0.000235\n",
      "\n",
      "Train time for epoch #6684 (step 6684): 1.339987\n",
      "Batch #10\tAverage Generator Loss: 932.821466\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #6685 (step 6685): 1.539111\n",
      "Batch #10\tAverage Generator Loss: 962.060938\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #6686 (step 6686): 1.614725\n",
      "Batch #10\tAverage Generator Loss: 918.775497\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #6687 (step 6687): 1.436122\n",
      "Batch #10\tAverage Generator Loss: 891.470850\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #6688 (step 6688): 1.665492\n",
      "Batch #10\tAverage Generator Loss: 931.981921\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #6689 (step 6689): 1.284787\n",
      "Batch #10\tAverage Generator Loss: 937.546985\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #6690 (step 6690): 1.595106\n",
      "Batch #10\tAverage Generator Loss: 951.371832\tAverage Discriminator Loss: 0.002631\n",
      "\n",
      "Train time for epoch #6691 (step 6691): 1.621384\n",
      "Batch #10\tAverage Generator Loss: 911.166382\tAverage Discriminator Loss: 0.001549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #6692 (step 6692): 1.304244\n",
      "Batch #10\tAverage Generator Loss: 965.283795\tAverage Discriminator Loss: 0.000022\n",
      "\n",
      "Train time for epoch #6693 (step 6693): 1.591557\n",
      "Batch #10\tAverage Generator Loss: 882.383038\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #6694 (step 6694): 1.340594\n",
      "Batch #10\tAverage Generator Loss: 962.577655\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #6695 (step 6695): 1.578614\n",
      "Batch #10\tAverage Generator Loss: 872.270251\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #6696 (step 6696): 1.639950\n",
      "Batch #10\tAverage Generator Loss: 849.393900\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6697 (step 6697): 1.457544\n",
      "Batch #10\tAverage Generator Loss: 1036.708594\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #6698 (step 6698): 1.674105\n",
      "Batch #10\tAverage Generator Loss: 800.754315\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #6699 (step 6699): 1.328131\n",
      "Batch #10\tAverage Generator Loss: 942.278186\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #6700 (step 6700): 1.530125\n",
      "Batch #10\tAverage Generator Loss: 933.707095\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #6701 (step 6701): 1.440899\n",
      "Batch #10\tAverage Generator Loss: 911.818732\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #6702 (step 6702): 1.525943\n",
      "Batch #10\tAverage Generator Loss: 850.596338\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6703 (step 6703): 1.334540\n",
      "Batch #10\tAverage Generator Loss: 965.926953\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #6704 (step 6704): 1.483563\n",
      "Batch #10\tAverage Generator Loss: 928.893057\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #6705 (step 6705): 1.331710\n",
      "Batch #10\tAverage Generator Loss: 1038.697961\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #6706 (step 6706): 1.470167\n",
      "Batch #10\tAverage Generator Loss: 999.578870\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #6707 (step 6707): 1.575732\n",
      "Batch #10\tAverage Generator Loss: 930.670496\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #6708 (step 6708): 1.288318\n",
      "Batch #10\tAverage Generator Loss: 935.526312\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6709 (step 6709): 1.518402\n",
      "Batch #10\tAverage Generator Loss: 939.772046\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #6710 (step 6710): 1.376200\n",
      "Batch #10\tAverage Generator Loss: 888.365765\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6711 (step 6711): 1.537255\n",
      "Batch #10\tAverage Generator Loss: 869.969736\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6712 (step 6712): 1.304775\n",
      "Batch #10\tAverage Generator Loss: 861.496555\tAverage Discriminator Loss: 0.000065\n",
      "\n",
      "Train time for epoch #6713 (step 6713): 1.580430\n",
      "Batch #10\tAverage Generator Loss: 938.203278\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #6714 (step 6714): 1.337596\n",
      "Batch #10\tAverage Generator Loss: 900.759543\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #6715 (step 6715): 1.602269\n",
      "Batch #10\tAverage Generator Loss: 897.566873\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6716 (step 6716): 1.297721\n",
      "Batch #10\tAverage Generator Loss: 871.012790\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6717 (step 6717): 1.532415\n",
      "Batch #10\tAverage Generator Loss: 978.591064\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #6718 (step 6718): 1.639332\n",
      "Batch #10\tAverage Generator Loss: 969.640924\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6719 (step 6719): 1.311072\n",
      "Batch #10\tAverage Generator Loss: 921.979065\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #6720 (step 6720): 1.549792\n",
      "Batch #10\tAverage Generator Loss: 928.343866\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #6721 (step 6721): 1.329619\n",
      "Batch #10\tAverage Generator Loss: 949.656604\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #6722 (step 6722): 1.562186\n",
      "Batch #10\tAverage Generator Loss: 859.324677\tAverage Discriminator Loss: 0.012184\n",
      "\n",
      "Train time for epoch #6723 (step 6723): 1.394234\n",
      "Batch #10\tAverage Generator Loss: 909.923297\tAverage Discriminator Loss: 0.004413\n",
      "\n",
      "Train time for epoch #6724 (step 6724): 1.701991\n",
      "Batch #10\tAverage Generator Loss: 765.288245\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6725 (step 6725): 1.327945\n",
      "Batch #10\tAverage Generator Loss: 734.085745\tAverage Discriminator Loss: 0.054846\n",
      "\n",
      "Train time for epoch #6726 (step 6726): 1.532724\n",
      "Batch #10\tAverage Generator Loss: 742.892068\tAverage Discriminator Loss: 0.822875\n",
      "\n",
      "Train time for epoch #6727 (step 6727): 1.301577\n",
      "Batch #10\tAverage Generator Loss: 907.497833\tAverage Discriminator Loss: 0.008124\n",
      "\n",
      "Train time for epoch #6728 (step 6728): 1.594118\n",
      "Batch #10\tAverage Generator Loss: 653.905084\tAverage Discriminator Loss: 0.108595\n",
      "\n",
      "Train time for epoch #6729 (step 6729): 1.601753\n",
      "Batch #10\tAverage Generator Loss: 1392.793799\tAverage Discriminator Loss: 0.018038\n",
      "\n",
      "Train time for epoch #6730 (step 6730): 1.330645\n",
      "Batch #10\tAverage Generator Loss: 1525.398932\tAverage Discriminator Loss: 0.000040\n",
      "\n",
      "Train time for epoch #6731 (step 6731): 1.662108\n",
      "Batch #10\tAverage Generator Loss: 1280.703894\tAverage Discriminator Loss: 0.000104\n",
      "\n",
      "Train time for epoch #6732 (step 6732): 1.321237\n",
      "Batch #10\tAverage Generator Loss: 1576.444513\tAverage Discriminator Loss: 0.000100\n",
      "\n",
      "Train time for epoch #6733 (step 6733): 1.656307\n",
      "Batch #10\tAverage Generator Loss: 1752.345386\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #6734 (step 6734): 1.298523\n",
      "Batch #10\tAverage Generator Loss: 1739.352637\tAverage Discriminator Loss: 0.000297\n",
      "\n",
      "Train time for epoch #6735 (step 6735): 1.555713\n",
      "Batch #10\tAverage Generator Loss: 1787.600745\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6736 (step 6736): 1.374747\n",
      "Batch #10\tAverage Generator Loss: 1448.202240\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6737 (step 6737): 1.544231\n",
      "Batch #10\tAverage Generator Loss: 1414.025140\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6738 (step 6738): 1.602373\n",
      "Batch #10\tAverage Generator Loss: 1407.052020\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6739 (step 6739): 1.293986\n",
      "Batch #10\tAverage Generator Loss: 1489.027899\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6740 (step 6740): 1.593184\n",
      "Batch #10\tAverage Generator Loss: 1576.398041\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6741 (step 6741): 1.349430\n",
      "Batch #10\tAverage Generator Loss: 1545.347491\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6742 (step 6742): 1.536729\n",
      "Batch #10\tAverage Generator Loss: 1516.852917\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6743 (step 6743): 1.375596\n",
      "Batch #10\tAverage Generator Loss: 1601.566284\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6744 (step 6744): 1.574788\n",
      "Batch #10\tAverage Generator Loss: 1831.948560\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6745 (step 6745): 1.622955\n",
      "Batch #10\tAverage Generator Loss: 1840.810327\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6746 (step 6746): 1.314669\n",
      "Batch #10\tAverage Generator Loss: 1824.419531\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6747 (step 6747): 1.623834\n",
      "Batch #10\tAverage Generator Loss: 1741.273804\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6748 (step 6748): 1.492409\n",
      "Batch #10\tAverage Generator Loss: 1548.712115\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6749 (step 6749): 1.626652\n",
      "Batch #10\tAverage Generator Loss: 1501.159625\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6750 (step 6750): 1.405871\n",
      "Batch #10\tAverage Generator Loss: 1594.577478\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6751 (step 6751): 1.574027\n",
      "Batch #10\tAverage Generator Loss: 1325.017743\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6752 (step 6752): 1.462950\n",
      "Batch #10\tAverage Generator Loss: 1566.467621\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6753 (step 6753): 1.697212\n",
      "Batch #10\tAverage Generator Loss: 1565.013727\tAverage Discriminator Loss: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #6754 (step 6754): 1.322444\n",
      "Batch #10\tAverage Generator Loss: 1509.206030\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6755 (step 6755): 1.547514\n",
      "Batch #10\tAverage Generator Loss: 1673.122351\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6756 (step 6756): 1.382066\n",
      "Batch #10\tAverage Generator Loss: 1721.060242\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6757 (step 6757): 1.532418\n",
      "Batch #10\tAverage Generator Loss: 1437.979187\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6758 (step 6758): 1.651816\n",
      "Batch #10\tAverage Generator Loss: 1440.675348\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6759 (step 6759): 1.437430\n",
      "Batch #10\tAverage Generator Loss: 1438.937622\tAverage Discriminator Loss: 0.013920\n",
      "\n",
      "Train time for epoch #6760 (step 6760): 1.543465\n",
      "Batch #10\tAverage Generator Loss: 1677.246045\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6761 (step 6761): 1.289773\n",
      "Batch #10\tAverage Generator Loss: 1398.995618\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6762 (step 6762): 1.583354\n",
      "Batch #10\tAverage Generator Loss: 1557.729816\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6763 (step 6763): 1.291123\n",
      "Batch #10\tAverage Generator Loss: 1610.861121\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6764 (step 6764): 1.595492\n",
      "Batch #10\tAverage Generator Loss: 1565.722583\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6765 (step 6765): 1.478685\n",
      "Batch #10\tAverage Generator Loss: 1613.502496\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6766 (step 6766): 1.549241\n",
      "Batch #10\tAverage Generator Loss: 1404.783704\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6767 (step 6767): 1.302320\n",
      "Batch #10\tAverage Generator Loss: 1699.927161\tAverage Discriminator Loss: 0.003562\n",
      "\n",
      "Train time for epoch #6768 (step 6768): 1.628272\n",
      "Batch #10\tAverage Generator Loss: 1786.563837\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #6769 (step 6769): 1.533299\n",
      "Batch #10\tAverage Generator Loss: 1534.221130\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6770 (step 6770): 1.300262\n",
      "Batch #10\tAverage Generator Loss: 1533.337531\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6771 (step 6771): 1.550534\n",
      "Batch #10\tAverage Generator Loss: 1334.673914\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6772 (step 6772): 1.372917\n",
      "Batch #10\tAverage Generator Loss: 1416.554843\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6773 (step 6773): 1.543565\n",
      "Batch #10\tAverage Generator Loss: 1465.492090\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6774 (step 6774): 1.393712\n",
      "Batch #10\tAverage Generator Loss: 1431.582587\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6775 (step 6775): 1.563176\n",
      "Batch #10\tAverage Generator Loss: 1494.590186\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6776 (step 6776): 1.340466\n",
      "Batch #10\tAverage Generator Loss: 1320.744391\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6777 (step 6777): 1.540763\n",
      "Batch #10\tAverage Generator Loss: 1439.964911\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6778 (step 6778): 1.582389\n",
      "Batch #10\tAverage Generator Loss: 1312.684509\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6779 (step 6779): 1.385418\n",
      "Batch #10\tAverage Generator Loss: 1420.973395\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6780 (step 6780): 1.586564\n",
      "Batch #10\tAverage Generator Loss: 1432.963379\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6781 (step 6781): 1.278601\n",
      "Batch #10\tAverage Generator Loss: 1254.152380\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6782 (step 6782): 1.515803\n",
      "Batch #10\tAverage Generator Loss: 1234.419641\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6783 (step 6783): 1.418143\n",
      "Batch #10\tAverage Generator Loss: 1275.615997\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6784 (step 6784): 1.551926\n",
      "Batch #10\tAverage Generator Loss: 1356.423364\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6785 (step 6785): 1.302246\n",
      "Batch #10\tAverage Generator Loss: 1465.234967\tAverage Discriminator Loss: 0.001944\n",
      "\n",
      "Train time for epoch #6786 (step 6786): 1.530340\n",
      "Batch #10\tAverage Generator Loss: 1447.820422\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6787 (step 6787): 1.286731\n",
      "Batch #10\tAverage Generator Loss: 1382.627032\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6788 (step 6788): 1.658366\n",
      "Batch #10\tAverage Generator Loss: 1348.597238\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6789 (step 6789): 1.562226\n",
      "Batch #10\tAverage Generator Loss: 1300.948334\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6790 (step 6790): 1.345752\n",
      "Batch #10\tAverage Generator Loss: 1349.038849\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6791 (step 6791): 1.577741\n",
      "Batch #10\tAverage Generator Loss: 1423.242499\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6792 (step 6792): 1.413453\n",
      "Batch #10\tAverage Generator Loss: 1412.570715\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6793 (step 6793): 1.594421\n",
      "Batch #10\tAverage Generator Loss: 1558.372729\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6794 (step 6794): 1.296112\n",
      "Batch #10\tAverage Generator Loss: 1354.692981\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6795 (step 6795): 1.540549\n",
      "Batch #10\tAverage Generator Loss: 1465.007220\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6796 (step 6796): 1.335414\n",
      "Batch #10\tAverage Generator Loss: 1482.524231\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6797 (step 6797): 1.543432\n",
      "Batch #10\tAverage Generator Loss: 1472.425708\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6798 (step 6798): 1.295940\n",
      "Batch #10\tAverage Generator Loss: 1342.443170\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6799 (step 6799): 1.791967\n",
      "Batch #10\tAverage Generator Loss: 1205.777191\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6800 (step 6800): 1.309813\n",
      "Batch #10\tAverage Generator Loss: 1458.291425\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #6801 (step 6801): 1.638465\n",
      "Batch #10\tAverage Generator Loss: 1465.866174\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6802 (step 6802): 1.520611\n",
      "Batch #10\tAverage Generator Loss: 1506.963330\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6803 (step 6803): 1.291810\n",
      "Batch #10\tAverage Generator Loss: 1464.537341\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6804 (step 6804): 1.534706\n",
      "Batch #10\tAverage Generator Loss: 1504.937250\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6805 (step 6805): 1.500079\n",
      "Batch #10\tAverage Generator Loss: 1453.511707\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6806 (step 6806): 1.647593\n",
      "Batch #10\tAverage Generator Loss: 1469.244910\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6807 (step 6807): 1.347243\n",
      "Batch #10\tAverage Generator Loss: 1500.296930\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6808 (step 6808): 1.548469\n",
      "Batch #10\tAverage Generator Loss: 1442.197424\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6809 (step 6809): 1.657724\n",
      "Batch #10\tAverage Generator Loss: 1441.720959\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6810 (step 6810): 1.448459\n",
      "Batch #10\tAverage Generator Loss: 1166.693646\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6811 (step 6811): 1.633002\n",
      "Batch #10\tAverage Generator Loss: 1453.402393\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6812 (step 6812): 1.325376\n",
      "Batch #10\tAverage Generator Loss: 1342.077618\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6813 (step 6813): 1.647274\n",
      "Batch #10\tAverage Generator Loss: 1431.546582\tAverage Discriminator Loss: 0.016051\n",
      "\n",
      "Train time for epoch #6814 (step 6814): 1.308470\n",
      "Batch #10\tAverage Generator Loss: 1363.091833\tAverage Discriminator Loss: 0.000035\n",
      "\n",
      "Train time for epoch #6815 (step 6815): 1.490450\n",
      "Batch #10\tAverage Generator Loss: 1240.734308\tAverage Discriminator Loss: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #6816 (step 6816): 1.482866\n",
      "Batch #10\tAverage Generator Loss: 1485.241620\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6817 (step 6817): 1.347625\n",
      "Batch #10\tAverage Generator Loss: 1242.235190\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6818 (step 6818): 1.541993\n",
      "Batch #10\tAverage Generator Loss: 1314.367462\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6819 (step 6819): 1.364672\n",
      "Batch #10\tAverage Generator Loss: 1220.378210\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6820 (step 6820): 1.622169\n",
      "Batch #10\tAverage Generator Loss: 1466.495923\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6821 (step 6821): 1.393548\n",
      "Batch #10\tAverage Generator Loss: 1367.889209\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6822 (step 6822): 1.534313\n",
      "Batch #10\tAverage Generator Loss: 1271.022778\tAverage Discriminator Loss: 0.017855\n",
      "\n",
      "Train time for epoch #6823 (step 6823): 1.325904\n",
      "Batch #10\tAverage Generator Loss: 1283.646173\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6824 (step 6824): 1.583675\n",
      "Batch #10\tAverage Generator Loss: 1313.995935\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6825 (step 6825): 1.294420\n",
      "Batch #10\tAverage Generator Loss: 1512.343585\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6826 (step 6826): 1.546231\n",
      "Batch #10\tAverage Generator Loss: 1341.336676\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6827 (step 6827): 1.241266\n",
      "Batch #10\tAverage Generator Loss: 1349.135553\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6828 (step 6828): 1.630421\n",
      "Batch #10\tAverage Generator Loss: 1258.628156\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6829 (step 6829): 1.306008\n",
      "Batch #10\tAverage Generator Loss: 1301.466956\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6830 (step 6830): 1.633061\n",
      "Batch #10\tAverage Generator Loss: 1350.253943\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6831 (step 6831): 1.595730\n",
      "Batch #10\tAverage Generator Loss: 1330.720691\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6832 (step 6832): 1.278936\n",
      "Batch #10\tAverage Generator Loss: 1287.992035\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6833 (step 6833): 1.664855\n",
      "Batch #10\tAverage Generator Loss: 1344.626050\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6834 (step 6834): 1.513221\n",
      "Batch #10\tAverage Generator Loss: 1281.163733\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6835 (step 6835): 1.611657\n",
      "Batch #10\tAverage Generator Loss: 1416.537750\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6836 (step 6836): 1.390337\n",
      "Batch #10\tAverage Generator Loss: 1295.847198\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6837 (step 6837): 1.631509\n",
      "Batch #10\tAverage Generator Loss: 1372.397290\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6838 (step 6838): 1.334943\n",
      "Batch #10\tAverage Generator Loss: 1299.960461\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6839 (step 6839): 1.536951\n",
      "Batch #10\tAverage Generator Loss: 1312.672607\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6840 (step 6840): 1.243711\n",
      "Batch #10\tAverage Generator Loss: 1255.887512\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6841 (step 6841): 1.796669\n",
      "Batch #10\tAverage Generator Loss: 1232.322723\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6842 (step 6842): 1.764002\n",
      "Batch #10\tAverage Generator Loss: 1130.299210\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6843 (step 6843): 1.353968\n",
      "Batch #10\tAverage Generator Loss: 1368.158936\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6844 (step 6844): 1.530536\n",
      "Batch #10\tAverage Generator Loss: 1295.032422\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6845 (step 6845): 1.413865\n",
      "Batch #10\tAverage Generator Loss: 1277.325885\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6846 (step 6846): 1.586400\n",
      "Batch #10\tAverage Generator Loss: 1297.819330\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6847 (step 6847): 1.344735\n",
      "Batch #10\tAverage Generator Loss: 1254.604993\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6848 (step 6848): 1.654811\n",
      "Batch #10\tAverage Generator Loss: 1356.999640\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6849 (step 6849): 1.626995\n",
      "Batch #10\tAverage Generator Loss: 1185.735641\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6850 (step 6850): 1.326019\n",
      "Batch #10\tAverage Generator Loss: 1457.027991\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6851 (step 6851): 1.549755\n",
      "Batch #10\tAverage Generator Loss: 1234.561560\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6852 (step 6852): 1.289332\n",
      "Batch #10\tAverage Generator Loss: 1282.527307\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #6853 (step 6853): 1.742970\n",
      "Batch #10\tAverage Generator Loss: 1382.847351\tAverage Discriminator Loss: 0.000272\n",
      "\n",
      "Train time for epoch #6854 (step 6854): 1.290553\n",
      "Batch #10\tAverage Generator Loss: 1267.831439\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #6855 (step 6855): 1.598194\n",
      "Batch #10\tAverage Generator Loss: 1398.826593\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #6856 (step 6856): 1.290457\n",
      "Batch #10\tAverage Generator Loss: 1297.706659\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #6857 (step 6857): 1.531625\n",
      "Batch #10\tAverage Generator Loss: 1312.891022\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #6858 (step 6858): 1.294788\n",
      "Batch #10\tAverage Generator Loss: 1314.654010\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #6859 (step 6859): 1.592717\n",
      "Batch #10\tAverage Generator Loss: 1284.151001\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6860 (step 6860): 1.317578\n",
      "Batch #10\tAverage Generator Loss: 1303.103735\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6861 (step 6861): 1.601599\n",
      "Batch #10\tAverage Generator Loss: 1398.617834\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6862 (step 6862): 1.625164\n",
      "Batch #10\tAverage Generator Loss: 1266.907465\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6863 (step 6863): 1.353600\n",
      "Batch #10\tAverage Generator Loss: 1313.772064\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6864 (step 6864): 1.641900\n",
      "Batch #10\tAverage Generator Loss: 1018.173041\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6865 (step 6865): 1.373792\n",
      "Batch #10\tAverage Generator Loss: 1295.885754\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6866 (step 6866): 1.584391\n",
      "Batch #10\tAverage Generator Loss: 1353.900348\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6867 (step 6867): 1.354061\n",
      "Batch #10\tAverage Generator Loss: 1186.842096\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6868 (step 6868): 1.552200\n",
      "Batch #10\tAverage Generator Loss: 1280.854242\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6869 (step 6869): 1.505947\n",
      "Batch #10\tAverage Generator Loss: 1316.733563\tAverage Discriminator Loss: 0.000489\n",
      "\n",
      "Train time for epoch #6870 (step 6870): 1.637383\n",
      "Batch #10\tAverage Generator Loss: 1251.477399\tAverage Discriminator Loss: 0.000120\n",
      "\n",
      "Train time for epoch #6871 (step 6871): 1.390144\n",
      "Batch #10\tAverage Generator Loss: 1329.573309\tAverage Discriminator Loss: 0.000042\n",
      "\n",
      "Train time for epoch #6872 (step 6872): 1.604988\n",
      "Batch #10\tAverage Generator Loss: 1260.782074\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #6873 (step 6873): 1.616672\n",
      "Batch #10\tAverage Generator Loss: 1433.707690\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #6874 (step 6874): 1.352399\n",
      "Batch #10\tAverage Generator Loss: 1284.362805\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #6875 (step 6875): 1.632434\n",
      "Batch #10\tAverage Generator Loss: 1295.358856\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #6876 (step 6876): 1.318139\n",
      "Batch #10\tAverage Generator Loss: 1455.584332\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #6877 (step 6877): 1.563333\n",
      "Batch #10\tAverage Generator Loss: 1284.021838\tAverage Discriminator Loss: 0.000006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #6878 (step 6878): 1.451541\n",
      "Batch #10\tAverage Generator Loss: 1317.026917\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #6879 (step 6879): 1.547489\n",
      "Batch #10\tAverage Generator Loss: 1413.443054\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #6880 (step 6880): 1.281740\n",
      "Batch #10\tAverage Generator Loss: 1296.401300\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #6881 (step 6881): 1.553683\n",
      "Batch #10\tAverage Generator Loss: 1244.403613\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6882 (step 6882): 1.282799\n",
      "Batch #10\tAverage Generator Loss: 1253.105829\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6883 (step 6883): 1.557636\n",
      "Batch #10\tAverage Generator Loss: 1370.215082\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6884 (step 6884): 1.609836\n",
      "Batch #10\tAverage Generator Loss: 1401.141150\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6885 (step 6885): 1.288712\n",
      "Batch #10\tAverage Generator Loss: 1377.841528\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6886 (step 6886): 1.601146\n",
      "Batch #10\tAverage Generator Loss: 1457.635419\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6887 (step 6887): 1.347355\n",
      "Batch #10\tAverage Generator Loss: 1476.212561\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6888 (step 6888): 1.635363\n",
      "Batch #10\tAverage Generator Loss: 1304.862250\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6889 (step 6889): 1.474970\n",
      "Batch #10\tAverage Generator Loss: 1385.588342\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6890 (step 6890): 1.644891\n",
      "Batch #10\tAverage Generator Loss: 1243.947534\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6891 (step 6891): 1.292630\n",
      "Batch #10\tAverage Generator Loss: 1272.958112\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6892 (step 6892): 1.617938\n",
      "Batch #10\tAverage Generator Loss: 1402.664996\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6893 (step 6893): 1.561456\n",
      "Batch #10\tAverage Generator Loss: 1423.095886\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6894 (step 6894): 1.348082\n",
      "Batch #10\tAverage Generator Loss: 1381.830750\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6895 (step 6895): 1.783836\n",
      "Batch #10\tAverage Generator Loss: 1373.306732\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6896 (step 6896): 1.329516\n",
      "Batch #10\tAverage Generator Loss: 1389.576758\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6897 (step 6897): 1.635284\n",
      "Batch #10\tAverage Generator Loss: 1383.630640\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6898 (step 6898): 1.323052\n",
      "Batch #10\tAverage Generator Loss: 1370.150000\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6899 (step 6899): 1.589721\n",
      "Batch #10\tAverage Generator Loss: 1251.125482\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6900 (step 6900): 1.303890\n",
      "Batch #10\tAverage Generator Loss: 1477.167029\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6901 (step 6901): 1.670382\n",
      "Batch #10\tAverage Generator Loss: 1333.555640\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #6902 (step 6902): 1.369008\n",
      "Batch #10\tAverage Generator Loss: 1305.429767\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6903 (step 6903): 1.574066\n",
      "Batch #10\tAverage Generator Loss: 1413.295984\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6904 (step 6904): 1.296345\n",
      "Batch #10\tAverage Generator Loss: 1325.349988\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6905 (step 6905): 1.541381\n",
      "Batch #10\tAverage Generator Loss: 1183.343512\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6906 (step 6906): 1.281862\n",
      "Batch #10\tAverage Generator Loss: 1261.339197\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6907 (step 6907): 1.637758\n",
      "Batch #10\tAverage Generator Loss: 1287.381250\tAverage Discriminator Loss: 0.001685\n",
      "\n",
      "Train time for epoch #6908 (step 6908): 1.666249\n",
      "Batch #10\tAverage Generator Loss: 1402.835779\tAverage Discriminator Loss: 0.000092\n",
      "\n",
      "Train time for epoch #6909 (step 6909): 1.428457\n",
      "Batch #10\tAverage Generator Loss: 1416.187897\tAverage Discriminator Loss: 0.277519\n",
      "\n",
      "Train time for epoch #6910 (step 6910): 1.623548\n",
      "Batch #10\tAverage Generator Loss: 1285.594873\tAverage Discriminator Loss: 0.000037\n",
      "\n",
      "Train time for epoch #6911 (step 6911): 1.287834\n",
      "Batch #10\tAverage Generator Loss: 1132.183240\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6912 (step 6912): 1.584786\n",
      "Batch #10\tAverage Generator Loss: 1272.606573\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6913 (step 6913): 1.377951\n",
      "Batch #10\tAverage Generator Loss: 1075.122247\tAverage Discriminator Loss: 0.283084\n",
      "\n",
      "Train time for epoch #6914 (step 6914): 1.557167\n",
      "Batch #10\tAverage Generator Loss: 923.604504\tAverage Discriminator Loss: 0.006646\n",
      "\n",
      "Train time for epoch #6915 (step 6915): 1.393151\n",
      "Batch #10\tAverage Generator Loss: 978.367761\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6916 (step 6916): 1.602032\n",
      "Batch #10\tAverage Generator Loss: 1102.952496\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6917 (step 6917): 1.546829\n",
      "Batch #10\tAverage Generator Loss: 1079.245715\tAverage Discriminator Loss: 0.050510\n",
      "\n",
      "Train time for epoch #6918 (step 6918): 1.540613\n",
      "Batch #10\tAverage Generator Loss: 1222.467847\tAverage Discriminator Loss: 0.000506\n",
      "\n",
      "Train time for epoch #6919 (step 6919): 1.617032\n",
      "Batch #10\tAverage Generator Loss: 988.890411\tAverage Discriminator Loss: 0.002193\n",
      "\n",
      "Train time for epoch #6920 (step 6920): 1.292479\n",
      "Batch #10\tAverage Generator Loss: 1083.358618\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6921 (step 6921): 1.602607\n",
      "Batch #10\tAverage Generator Loss: 1127.339337\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6922 (step 6922): 1.354208\n",
      "Batch #10\tAverage Generator Loss: 1121.664728\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6923 (step 6923): 1.697617\n",
      "Batch #10\tAverage Generator Loss: 1009.292236\tAverage Discriminator Loss: 0.191045\n",
      "\n",
      "Train time for epoch #6924 (step 6924): 1.304401\n",
      "Batch #10\tAverage Generator Loss: 926.133966\tAverage Discriminator Loss: 0.035750\n",
      "\n",
      "Train time for epoch #6925 (step 6925): 1.581297\n",
      "Batch #10\tAverage Generator Loss: 823.801709\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6926 (step 6926): 1.289416\n",
      "Batch #10\tAverage Generator Loss: 803.741016\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6927 (step 6927): 1.557885\n",
      "Batch #10\tAverage Generator Loss: 795.715884\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6928 (step 6928): 1.540156\n",
      "Batch #10\tAverage Generator Loss: 699.001395\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6929 (step 6929): 1.322538\n",
      "Batch #10\tAverage Generator Loss: 834.790863\tAverage Discriminator Loss: 0.001256\n",
      "\n",
      "Train time for epoch #6930 (step 6930): 1.542431\n",
      "Batch #10\tAverage Generator Loss: 829.848294\tAverage Discriminator Loss: 0.000044\n",
      "\n",
      "Train time for epoch #6931 (step 6931): 1.371490\n",
      "Batch #10\tAverage Generator Loss: 754.656393\tAverage Discriminator Loss: 0.001332\n",
      "\n",
      "Train time for epoch #6932 (step 6932): 1.669130\n",
      "Batch #10\tAverage Generator Loss: 795.575470\tAverage Discriminator Loss: 0.000147\n",
      "\n",
      "Train time for epoch #6933 (step 6933): 1.394019\n",
      "Batch #10\tAverage Generator Loss: 836.626056\tAverage Discriminator Loss: 0.000025\n",
      "\n",
      "Train time for epoch #6934 (step 6934): 1.483871\n",
      "Batch #10\tAverage Generator Loss: 842.490363\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #6935 (step 6935): 1.436621\n",
      "Batch #10\tAverage Generator Loss: 831.710724\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #6936 (step 6936): 1.639575\n",
      "Batch #10\tAverage Generator Loss: 832.447430\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #6937 (step 6937): 1.352186\n",
      "Batch #10\tAverage Generator Loss: 843.863959\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #6938 (step 6938): 1.534868\n",
      "Batch #10\tAverage Generator Loss: 898.441248\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #6939 (step 6939): 1.373101\n",
      "Batch #10\tAverage Generator Loss: 882.960764\tAverage Discriminator Loss: 0.000513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #6940 (step 6940): 1.528630\n",
      "Batch #10\tAverage Generator Loss: 813.432373\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #6941 (step 6941): 1.541959\n",
      "Batch #10\tAverage Generator Loss: 937.622595\tAverage Discriminator Loss: 0.000031\n",
      "\n",
      "Train time for epoch #6942 (step 6942): 1.333138\n",
      "Batch #10\tAverage Generator Loss: 842.356494\tAverage Discriminator Loss: 0.000024\n",
      "\n",
      "Train time for epoch #6943 (step 6943): 1.590633\n",
      "Batch #10\tAverage Generator Loss: 823.443356\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #6944 (step 6944): 1.353253\n",
      "Batch #10\tAverage Generator Loss: 773.039087\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #6945 (step 6945): 1.632995\n",
      "Batch #10\tAverage Generator Loss: 835.551144\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #6946 (step 6946): 1.246936\n",
      "Batch #10\tAverage Generator Loss: 767.925046\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #6947 (step 6947): 1.660233\n",
      "Batch #10\tAverage Generator Loss: 845.945947\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #6948 (step 6948): 1.395193\n",
      "Batch #10\tAverage Generator Loss: 841.003046\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #6949 (step 6949): 1.648063\n",
      "Batch #10\tAverage Generator Loss: 788.646829\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #6950 (step 6950): 1.395927\n",
      "Batch #10\tAverage Generator Loss: 819.118365\tAverage Discriminator Loss: 0.006213\n",
      "\n",
      "Train time for epoch #6951 (step 6951): 1.650930\n",
      "Batch #10\tAverage Generator Loss: 897.400568\tAverage Discriminator Loss: 0.000495\n",
      "\n",
      "Train time for epoch #6952 (step 6952): 1.343283\n",
      "Batch #10\tAverage Generator Loss: 829.349792\tAverage Discriminator Loss: 0.000088\n",
      "\n",
      "Train time for epoch #6953 (step 6953): 1.566493\n",
      "Batch #10\tAverage Generator Loss: 811.554950\tAverage Discriminator Loss: 0.000042\n",
      "\n",
      "Train time for epoch #6954 (step 6954): 1.555191\n",
      "Batch #10\tAverage Generator Loss: 965.884479\tAverage Discriminator Loss: 0.000030\n",
      "\n",
      "Train time for epoch #6955 (step 6955): 1.376560\n",
      "Batch #10\tAverage Generator Loss: 903.277472\tAverage Discriminator Loss: 0.000037\n",
      "\n",
      "Train time for epoch #6956 (step 6956): 1.596680\n",
      "Batch #10\tAverage Generator Loss: 775.384464\tAverage Discriminator Loss: 0.000032\n",
      "\n",
      "Train time for epoch #6957 (step 6957): 1.326486\n",
      "Batch #10\tAverage Generator Loss: 791.945953\tAverage Discriminator Loss: 0.000021\n",
      "\n",
      "Train time for epoch #6958 (step 6958): 1.597116\n",
      "Batch #10\tAverage Generator Loss: 888.557098\tAverage Discriminator Loss: 0.000024\n",
      "\n",
      "Train time for epoch #6959 (step 6959): 1.278742\n",
      "Batch #10\tAverage Generator Loss: 916.400183\tAverage Discriminator Loss: 0.000019\n",
      "\n",
      "Train time for epoch #6960 (step 6960): 1.655729\n",
      "Batch #10\tAverage Generator Loss: 798.046332\tAverage Discriminator Loss: 0.000019\n",
      "\n",
      "Train time for epoch #6961 (step 6961): 1.345649\n",
      "Batch #10\tAverage Generator Loss: 849.530829\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #6962 (step 6962): 1.637463\n",
      "Batch #10\tAverage Generator Loss: 836.387680\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #6963 (step 6963): 1.546404\n",
      "Batch #10\tAverage Generator Loss: 928.848340\tAverage Discriminator Loss: 0.001033\n",
      "\n",
      "Train time for epoch #6964 (step 6964): 1.345845\n",
      "Batch #10\tAverage Generator Loss: 1017.284052\tAverage Discriminator Loss: 0.002966\n",
      "\n",
      "Train time for epoch #6965 (step 6965): 1.605912\n",
      "Batch #10\tAverage Generator Loss: 1016.246594\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #6966 (step 6966): 1.376144\n",
      "Batch #10\tAverage Generator Loss: 1041.512128\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6967 (step 6967): 1.561433\n",
      "Batch #10\tAverage Generator Loss: 915.978549\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6968 (step 6968): 1.428981\n",
      "Batch #10\tAverage Generator Loss: 1071.301196\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6969 (step 6969): 1.561153\n",
      "Batch #10\tAverage Generator Loss: 1100.061517\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6970 (step 6970): 1.456944\n",
      "Batch #10\tAverage Generator Loss: 1018.055566\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6971 (step 6971): 1.568892\n",
      "Batch #10\tAverage Generator Loss: 1010.105634\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6972 (step 6972): 1.289104\n",
      "Batch #10\tAverage Generator Loss: 984.886829\tAverage Discriminator Loss: 0.007327\n",
      "\n",
      "Train time for epoch #6973 (step 6973): 1.647130\n",
      "Batch #10\tAverage Generator Loss: 1118.015387\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6974 (step 6974): 1.617782\n",
      "Batch #10\tAverage Generator Loss: 1041.739130\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6975 (step 6975): 1.291005\n",
      "Batch #10\tAverage Generator Loss: 954.703174\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6976 (step 6976): 1.595728\n",
      "Batch #10\tAverage Generator Loss: 945.849835\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6977 (step 6977): 1.336344\n",
      "Batch #10\tAverage Generator Loss: 939.245367\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6978 (step 6978): 1.589344\n",
      "Batch #10\tAverage Generator Loss: 1002.144443\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6979 (step 6979): 1.388008\n",
      "Batch #10\tAverage Generator Loss: 1062.981232\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6980 (step 6980): 1.510450\n",
      "Batch #10\tAverage Generator Loss: 1003.095648\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6981 (step 6981): 1.293481\n",
      "Batch #10\tAverage Generator Loss: 1045.367896\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6982 (step 6982): 1.643364\n",
      "Batch #10\tAverage Generator Loss: 1047.082526\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6983 (step 6983): 1.434778\n",
      "Batch #10\tAverage Generator Loss: 1047.859174\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6984 (step 6984): 1.640906\n",
      "Batch #10\tAverage Generator Loss: 1130.443164\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6985 (step 6985): 1.294560\n",
      "Batch #10\tAverage Generator Loss: 948.231287\tAverage Discriminator Loss: 0.000151\n",
      "\n",
      "Train time for epoch #6986 (step 6986): 1.540042\n",
      "Batch #10\tAverage Generator Loss: 961.287433\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6987 (step 6987): 1.300366\n",
      "Batch #10\tAverage Generator Loss: 981.072668\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6988 (step 6988): 1.686714\n",
      "Batch #10\tAverage Generator Loss: 938.282947\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6989 (step 6989): 1.251170\n",
      "Batch #10\tAverage Generator Loss: 1105.361951\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6990 (step 6990): 1.590069\n",
      "Batch #10\tAverage Generator Loss: 977.979578\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6991 (step 6991): 1.709963\n",
      "Batch #10\tAverage Generator Loss: 1104.764832\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6992 (step 6992): 1.293676\n",
      "Batch #10\tAverage Generator Loss: 1122.434241\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6993 (step 6993): 1.607996\n",
      "Batch #10\tAverage Generator Loss: 1070.811841\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6994 (step 6994): 1.399736\n",
      "Batch #10\tAverage Generator Loss: 1163.484558\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6995 (step 6995): 1.547866\n",
      "Batch #10\tAverage Generator Loss: 881.090555\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6996 (step 6996): 1.332983\n",
      "Batch #10\tAverage Generator Loss: 1000.038239\tAverage Discriminator Loss: 0.000043\n",
      "\n",
      "Train time for epoch #6997 (step 6997): 1.620378\n",
      "Batch #10\tAverage Generator Loss: 1082.908392\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #6998 (step 6998): 1.333080\n",
      "Batch #10\tAverage Generator Loss: 1127.903986\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #6999 (step 6999): 1.535797\n",
      "Batch #10\tAverage Generator Loss: 1138.559174\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7000 (step 7000): 1.581494\n",
      "Batch #10\tAverage Generator Loss: 1064.476556\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7001 (step 7001): 1.540378\n",
      "Batch #10\tAverage Generator Loss: 992.894843\tAverage Discriminator Loss: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #7002 (step 7002): 1.329760\n",
      "Batch #10\tAverage Generator Loss: 1048.951520\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7003 (step 7003): 1.625603\n",
      "Batch #10\tAverage Generator Loss: 1062.085065\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7004 (step 7004): 1.558545\n",
      "Batch #10\tAverage Generator Loss: 1015.204773\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7005 (step 7005): 1.286350\n",
      "Batch #10\tAverage Generator Loss: 970.304382\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7006 (step 7006): 1.637460\n",
      "Batch #10\tAverage Generator Loss: 1052.152289\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7007 (step 7007): 1.275811\n",
      "Batch #10\tAverage Generator Loss: 1202.715167\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #7008 (step 7008): 1.555322\n",
      "Batch #10\tAverage Generator Loss: 870.993130\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7009 (step 7009): 1.477525\n",
      "Batch #10\tAverage Generator Loss: 1079.891095\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7010 (step 7010): 1.597513\n",
      "Batch #10\tAverage Generator Loss: 986.794775\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #7011 (step 7011): 1.363436\n",
      "Batch #10\tAverage Generator Loss: 952.915189\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7012 (step 7012): 1.870137\n",
      "Batch #10\tAverage Generator Loss: 1079.932281\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7013 (step 7013): 1.324716\n",
      "Batch #10\tAverage Generator Loss: 1016.763013\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7014 (step 7014): 1.560976\n",
      "Batch #10\tAverage Generator Loss: 955.254556\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7015 (step 7015): 1.258693\n",
      "Batch #10\tAverage Generator Loss: 1131.854248\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7016 (step 7016): 1.567374\n",
      "Batch #10\tAverage Generator Loss: 1007.968134\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7017 (step 7017): 1.335371\n",
      "Batch #10\tAverage Generator Loss: 937.096075\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7018 (step 7018): 1.538347\n",
      "Batch #10\tAverage Generator Loss: 1006.708777\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7019 (step 7019): 1.377267\n",
      "Batch #10\tAverage Generator Loss: 921.870752\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7020 (step 7020): 1.648862\n",
      "Batch #10\tAverage Generator Loss: 1103.093665\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7021 (step 7021): 1.588083\n",
      "Batch #10\tAverage Generator Loss: 1049.408130\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7022 (step 7022): 1.343480\n",
      "Batch #10\tAverage Generator Loss: 1028.778973\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7023 (step 7023): 1.593028\n",
      "Batch #10\tAverage Generator Loss: 1038.466223\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7024 (step 7024): 1.344552\n",
      "Batch #10\tAverage Generator Loss: 989.823279\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7025 (step 7025): 1.574192\n",
      "Batch #10\tAverage Generator Loss: 1105.682660\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7026 (step 7026): 1.388716\n",
      "Batch #10\tAverage Generator Loss: 919.725967\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7027 (step 7027): 1.568221\n",
      "Batch #10\tAverage Generator Loss: 1096.589441\tAverage Discriminator Loss: 0.031814\n",
      "\n",
      "Train time for epoch #7028 (step 7028): 1.442415\n",
      "Batch #10\tAverage Generator Loss: 1126.478271\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #7029 (step 7029): 1.553766\n",
      "Batch #10\tAverage Generator Loss: 1088.186743\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7030 (step 7030): 1.285898\n",
      "Batch #10\tAverage Generator Loss: 1074.537903\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #7031 (step 7031): 1.616015\n",
      "Batch #10\tAverage Generator Loss: 1118.908356\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7032 (step 7032): 1.739900\n",
      "Batch #10\tAverage Generator Loss: 1061.060880\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7033 (step 7033): 1.323414\n",
      "Batch #10\tAverage Generator Loss: 1054.199725\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7034 (step 7034): 1.548913\n",
      "Batch #10\tAverage Generator Loss: 1028.319559\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7035 (step 7035): 1.322918\n",
      "Batch #10\tAverage Generator Loss: 1113.669940\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7036 (step 7036): 1.647896\n",
      "Batch #10\tAverage Generator Loss: 1000.351190\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7037 (step 7037): 1.357981\n",
      "Batch #10\tAverage Generator Loss: 1036.672339\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7038 (step 7038): 1.551474\n",
      "Batch #10\tAverage Generator Loss: 986.170697\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7039 (step 7039): 1.391314\n",
      "Batch #10\tAverage Generator Loss: 1057.274054\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7040 (step 7040): 1.592584\n",
      "Batch #10\tAverage Generator Loss: 960.162875\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7041 (step 7041): 1.292847\n",
      "Batch #10\tAverage Generator Loss: 945.461008\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7042 (step 7042): 1.599227\n",
      "Batch #10\tAverage Generator Loss: 1017.127884\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #7043 (step 7043): 1.381084\n",
      "Batch #10\tAverage Generator Loss: 997.682397\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7044 (step 7044): 1.702830\n",
      "Batch #10\tAverage Generator Loss: 1043.576224\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7045 (step 7045): 1.626477\n",
      "Batch #10\tAverage Generator Loss: 1087.528320\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7046 (step 7046): 1.344914\n",
      "Batch #10\tAverage Generator Loss: 938.382703\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7047 (step 7047): 1.535488\n",
      "Batch #10\tAverage Generator Loss: 1097.822510\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #7048 (step 7048): 1.304563\n",
      "Batch #10\tAverage Generator Loss: 1024.791064\tAverage Discriminator Loss: 0.000110\n",
      "\n",
      "Train time for epoch #7049 (step 7049): 1.579623\n",
      "Batch #10\tAverage Generator Loss: 1062.209705\tAverage Discriminator Loss: 0.000057\n",
      "\n",
      "Train time for epoch #7050 (step 7050): 1.389907\n",
      "Batch #10\tAverage Generator Loss: 1083.725372\tAverage Discriminator Loss: 0.000042\n",
      "\n",
      "Train time for epoch #7051 (step 7051): 1.542990\n",
      "Batch #10\tAverage Generator Loss: 1150.253027\tAverage Discriminator Loss: 0.000030\n",
      "\n",
      "Train time for epoch #7052 (step 7052): 1.296999\n",
      "Batch #10\tAverage Generator Loss: 1071.910822\tAverage Discriminator Loss: 0.000026\n",
      "\n",
      "Train time for epoch #7053 (step 7053): 1.591753\n",
      "Batch #10\tAverage Generator Loss: 1228.961591\tAverage Discriminator Loss: 0.000021\n",
      "\n",
      "Train time for epoch #7054 (step 7054): 1.412293\n",
      "Batch #10\tAverage Generator Loss: 1116.796564\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #7055 (step 7055): 1.622489\n",
      "Batch #10\tAverage Generator Loss: 1115.393896\tAverage Discriminator Loss: 0.001179\n",
      "\n",
      "Train time for epoch #7056 (step 7056): 1.421084\n",
      "Batch #10\tAverage Generator Loss: 1113.857721\tAverage Discriminator Loss: 0.000037\n",
      "\n",
      "Train time for epoch #7057 (step 7057): 1.544412\n",
      "Batch #10\tAverage Generator Loss: 1005.506381\tAverage Discriminator Loss: 0.000036\n",
      "\n",
      "Train time for epoch #7058 (step 7058): 1.314949\n",
      "Batch #10\tAverage Generator Loss: 1192.464868\tAverage Discriminator Loss: 0.000043\n",
      "\n",
      "Train time for epoch #7059 (step 7059): 1.542707\n",
      "Batch #10\tAverage Generator Loss: 1015.609973\tAverage Discriminator Loss: 0.000030\n",
      "\n",
      "Train time for epoch #7060 (step 7060): 1.247456\n",
      "Batch #10\tAverage Generator Loss: 1074.118622\tAverage Discriminator Loss: 0.000027\n",
      "\n",
      "Train time for epoch #7061 (step 7061): 1.548004\n",
      "Batch #10\tAverage Generator Loss: 1040.665521\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #7062 (step 7062): 1.293051\n",
      "Batch #10\tAverage Generator Loss: 1086.802637\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #7063 (step 7063): 1.580003\n",
      "Batch #10\tAverage Generator Loss: 1147.941827\tAverage Discriminator Loss: 0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #7064 (step 7064): 1.602260\n",
      "Batch #10\tAverage Generator Loss: 1158.032300\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #7065 (step 7065): 1.351560\n",
      "Batch #10\tAverage Generator Loss: 1104.941669\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #7066 (step 7066): 1.636626\n",
      "Batch #10\tAverage Generator Loss: 1166.463916\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #7067 (step 7067): 1.451661\n",
      "Batch #10\tAverage Generator Loss: 987.592603\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #7068 (step 7068): 1.683780\n",
      "Batch #10\tAverage Generator Loss: 1059.034387\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #7069 (step 7069): 1.441079\n",
      "Batch #10\tAverage Generator Loss: 1119.715179\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #7070 (step 7070): 1.677470\n",
      "Batch #10\tAverage Generator Loss: 1051.463281\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #7071 (step 7071): 1.291345\n",
      "Batch #10\tAverage Generator Loss: 1124.966132\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #7072 (step 7072): 1.611179\n",
      "Batch #10\tAverage Generator Loss: 945.336703\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #7073 (step 7073): 1.322881\n",
      "Batch #10\tAverage Generator Loss: 1058.123730\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #7074 (step 7074): 1.757145\n",
      "Batch #10\tAverage Generator Loss: 1093.294086\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #7075 (step 7075): 1.391402\n",
      "Batch #10\tAverage Generator Loss: 1041.365497\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #7076 (step 7076): 1.613664\n",
      "Batch #10\tAverage Generator Loss: 1156.800262\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #7077 (step 7077): 1.496959\n",
      "Batch #10\tAverage Generator Loss: 1144.109351\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #7078 (step 7078): 1.539596\n",
      "Batch #10\tAverage Generator Loss: 1295.381781\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #7079 (step 7079): 1.613147\n",
      "Batch #10\tAverage Generator Loss: 1101.046472\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #7080 (step 7080): 1.343503\n",
      "Batch #10\tAverage Generator Loss: 1086.301306\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #7081 (step 7081): 1.576015\n",
      "Batch #10\tAverage Generator Loss: 1107.618420\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #7082 (step 7082): 1.359227\n",
      "Batch #10\tAverage Generator Loss: 1128.674396\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #7083 (step 7083): 1.558024\n",
      "Batch #10\tAverage Generator Loss: 1091.777881\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #7084 (step 7084): 1.392827\n",
      "Batch #10\tAverage Generator Loss: 1152.377713\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #7085 (step 7085): 1.569496\n",
      "Batch #10\tAverage Generator Loss: 1162.294196\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #7086 (step 7086): 1.288498\n",
      "Batch #10\tAverage Generator Loss: 1085.449115\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #7087 (step 7087): 1.570852\n",
      "Batch #10\tAverage Generator Loss: 1215.025397\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #7088 (step 7088): 1.381370\n",
      "Batch #10\tAverage Generator Loss: 1175.078461\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #7089 (step 7089): 1.560562\n",
      "Batch #10\tAverage Generator Loss: 1123.961267\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #7090 (step 7090): 1.353254\n",
      "Batch #10\tAverage Generator Loss: 1121.068488\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7091 (step 7091): 1.573403\n",
      "Batch #10\tAverage Generator Loss: 1151.912012\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #7092 (step 7092): 1.600612\n",
      "Batch #10\tAverage Generator Loss: 1095.579871\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #7093 (step 7093): 1.354301\n",
      "Batch #10\tAverage Generator Loss: 1223.748840\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #7094 (step 7094): 1.652841\n",
      "Batch #10\tAverage Generator Loss: 1104.836304\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #7095 (step 7095): 1.307040\n",
      "Batch #10\tAverage Generator Loss: 1049.503357\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #7096 (step 7096): 1.545469\n",
      "Batch #10\tAverage Generator Loss: 1062.612289\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #7097 (step 7097): 1.252779\n",
      "Batch #10\tAverage Generator Loss: 1076.943146\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #7098 (step 7098): 1.550000\n",
      "Batch #10\tAverage Generator Loss: 1183.096790\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #7099 (step 7099): 1.456342\n",
      "Batch #10\tAverage Generator Loss: 1114.498700\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #7100 (step 7100): 1.570509\n",
      "Batch #10\tAverage Generator Loss: 956.614105\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7101 (step 7101): 1.296468\n",
      "Batch #10\tAverage Generator Loss: 1251.963947\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #7102 (step 7102): 1.598011\n",
      "Batch #10\tAverage Generator Loss: 1154.314270\tAverage Discriminator Loss: 0.000053\n",
      "\n",
      "Train time for epoch #7103 (step 7103): 1.557045\n",
      "Batch #10\tAverage Generator Loss: 968.285809\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #7104 (step 7104): 1.328722\n",
      "Batch #10\tAverage Generator Loss: 1297.389966\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #7105 (step 7105): 1.578249\n",
      "Batch #10\tAverage Generator Loss: 1190.151056\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #7106 (step 7106): 1.317330\n",
      "Batch #10\tAverage Generator Loss: 1166.351917\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7107 (step 7107): 1.594736\n",
      "Batch #10\tAverage Generator Loss: 1040.465729\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #7108 (step 7108): 1.386061\n",
      "Batch #10\tAverage Generator Loss: 1111.015491\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7109 (step 7109): 1.577766\n",
      "Batch #10\tAverage Generator Loss: 1200.796075\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #7110 (step 7110): 1.477052\n",
      "Batch #10\tAverage Generator Loss: 1129.027356\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7111 (step 7111): 1.532727\n",
      "Batch #10\tAverage Generator Loss: 1204.263031\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7112 (step 7112): 1.336642\n",
      "Batch #10\tAverage Generator Loss: 1204.140271\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #7113 (step 7113): 1.559393\n",
      "Batch #10\tAverage Generator Loss: 1078.708911\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7114 (step 7114): 1.357613\n",
      "Batch #10\tAverage Generator Loss: 1093.343610\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7115 (step 7115): 1.673479\n",
      "Batch #10\tAverage Generator Loss: 1196.762140\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #7116 (step 7116): 1.343800\n",
      "Batch #10\tAverage Generator Loss: 906.683218\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #7117 (step 7117): 1.601584\n",
      "Batch #10\tAverage Generator Loss: 1131.475677\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7118 (step 7118): 1.713968\n",
      "Batch #10\tAverage Generator Loss: 1162.082959\tAverage Discriminator Loss: 0.005240\n",
      "\n",
      "Train time for epoch #7119 (step 7119): 1.410793\n",
      "Batch #10\tAverage Generator Loss: 1144.388910\tAverage Discriminator Loss: 0.000237\n",
      "\n",
      "Train time for epoch #7120 (step 7120): 1.538709\n",
      "Batch #10\tAverage Generator Loss: 1065.671283\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #7121 (step 7121): 1.366189\n",
      "Batch #10\tAverage Generator Loss: 1177.840173\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7122 (step 7122): 1.644638\n",
      "Batch #10\tAverage Generator Loss: 997.782812\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7123 (step 7123): 1.344215\n",
      "Batch #10\tAverage Generator Loss: 1171.264404\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7124 (step 7124): 1.582973\n",
      "Batch #10\tAverage Generator Loss: 1113.515576\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7125 (step 7125): 1.344870\n",
      "Batch #10\tAverage Generator Loss: 1095.168634\tAverage Discriminator Loss: 0.000001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #7126 (step 7126): 1.644706\n",
      "Batch #10\tAverage Generator Loss: 1067.524957\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7127 (step 7127): 1.386551\n",
      "Batch #10\tAverage Generator Loss: 1114.992722\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7128 (step 7128): 1.540413\n",
      "Batch #10\tAverage Generator Loss: 1245.723743\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7129 (step 7129): 1.296824\n",
      "Batch #10\tAverage Generator Loss: 1167.188379\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7130 (step 7130): 1.604849\n",
      "Batch #10\tAverage Generator Loss: 1130.604327\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7131 (step 7131): 1.345062\n",
      "Batch #10\tAverage Generator Loss: 1193.861774\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7132 (step 7132): 1.554694\n",
      "Batch #10\tAverage Generator Loss: 1082.584247\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7133 (step 7133): 1.332089\n",
      "Batch #10\tAverage Generator Loss: 1068.350305\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7134 (step 7134): 1.537717\n",
      "Batch #10\tAverage Generator Loss: 1078.894763\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7135 (step 7135): 1.344559\n",
      "Batch #10\tAverage Generator Loss: 1142.180774\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7136 (step 7136): 1.597352\n",
      "Batch #10\tAverage Generator Loss: 1123.394720\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7137 (step 7137): 1.691236\n",
      "Batch #10\tAverage Generator Loss: 1298.781580\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7138 (step 7138): 1.285460\n",
      "Batch #10\tAverage Generator Loss: 1069.135876\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7139 (step 7139): 1.740873\n",
      "Batch #10\tAverage Generator Loss: 1302.299487\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7140 (step 7140): 1.337995\n",
      "Batch #10\tAverage Generator Loss: 1116.852899\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7141 (step 7141): 1.539671\n",
      "Batch #10\tAverage Generator Loss: 1139.869696\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7142 (step 7142): 1.344089\n",
      "Batch #10\tAverage Generator Loss: 1300.519208\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7143 (step 7143): 1.539597\n",
      "Batch #10\tAverage Generator Loss: 1076.552841\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #7144 (step 7144): 1.294478\n",
      "Batch #10\tAverage Generator Loss: 1331.049103\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7145 (step 7145): 1.592141\n",
      "Batch #10\tAverage Generator Loss: 1055.942572\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7146 (step 7146): 1.387623\n",
      "Batch #10\tAverage Generator Loss: 1094.132431\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7147 (step 7147): 1.527861\n",
      "Batch #10\tAverage Generator Loss: 1282.639868\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7148 (step 7148): 1.390752\n",
      "Batch #10\tAverage Generator Loss: 1185.468500\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7149 (step 7149): 1.599572\n",
      "Batch #10\tAverage Generator Loss: 1061.637109\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7150 (step 7150): 1.596341\n",
      "Batch #10\tAverage Generator Loss: 1172.423962\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7151 (step 7151): 1.327355\n",
      "Batch #10\tAverage Generator Loss: 1203.361896\tAverage Discriminator Loss: 0.054814\n",
      "\n",
      "Train time for epoch #7152 (step 7152): 1.555094\n",
      "Batch #10\tAverage Generator Loss: 1170.690466\tAverage Discriminator Loss: 0.000984\n",
      "\n",
      "Train time for epoch #7153 (step 7153): 1.486594\n",
      "Batch #10\tAverage Generator Loss: 1038.077686\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7154 (step 7154): 1.548008\n",
      "Batch #10\tAverage Generator Loss: 1040.735596\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #7155 (step 7155): 1.335207\n",
      "Batch #10\tAverage Generator Loss: 1147.814972\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7156 (step 7156): 1.537182\n",
      "Batch #10\tAverage Generator Loss: 973.450421\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7157 (step 7157): 1.319835\n",
      "Batch #10\tAverage Generator Loss: 1126.451917\tAverage Discriminator Loss: 0.003749\n",
      "\n",
      "Train time for epoch #7158 (step 7158): 1.618710\n",
      "Batch #10\tAverage Generator Loss: 1736.856665\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7159 (step 7159): 1.278633\n",
      "Batch #10\tAverage Generator Loss: 2232.678564\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7160 (step 7160): 1.542963\n",
      "Batch #10\tAverage Generator Loss: 2257.457434\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7161 (step 7161): 1.274353\n",
      "Batch #10\tAverage Generator Loss: 2067.973169\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7162 (step 7162): 1.537353\n",
      "Batch #10\tAverage Generator Loss: 2128.383624\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7163 (step 7163): 1.642113\n",
      "Batch #10\tAverage Generator Loss: 2471.671021\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7164 (step 7164): 1.385984\n",
      "Batch #10\tAverage Generator Loss: 2055.685388\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7165 (step 7165): 1.648372\n",
      "Batch #10\tAverage Generator Loss: 2280.963232\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7166 (step 7166): 1.388601\n",
      "Batch #10\tAverage Generator Loss: 2342.018170\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7167 (step 7167): 1.687576\n",
      "Batch #10\tAverage Generator Loss: 2540.843823\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7168 (step 7168): 1.379458\n",
      "Batch #10\tAverage Generator Loss: 2216.740741\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7169 (step 7169): 1.543673\n",
      "Batch #10\tAverage Generator Loss: 2329.612671\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7170 (step 7170): 1.390018\n",
      "Batch #10\tAverage Generator Loss: 1985.621167\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7171 (step 7171): 1.712792\n",
      "Batch #10\tAverage Generator Loss: 2585.010291\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7172 (step 7172): 1.417641\n",
      "Batch #10\tAverage Generator Loss: 2146.600110\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7173 (step 7173): 1.533315\n",
      "Batch #10\tAverage Generator Loss: 2341.744690\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7174 (step 7174): 1.479262\n",
      "Batch #10\tAverage Generator Loss: 1849.904840\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7175 (step 7175): 1.552714\n",
      "Batch #10\tAverage Generator Loss: 2129.913190\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7176 (step 7176): 1.298745\n",
      "Batch #10\tAverage Generator Loss: 2053.455225\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7177 (step 7177): 1.584870\n",
      "Batch #10\tAverage Generator Loss: 2190.568762\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7178 (step 7178): 1.390066\n",
      "Batch #10\tAverage Generator Loss: 2143.696655\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7179 (step 7179): 1.699463\n",
      "Batch #10\tAverage Generator Loss: 1824.418161\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7180 (step 7180): 1.299453\n",
      "Batch #10\tAverage Generator Loss: 1797.063776\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7181 (step 7181): 1.545328\n",
      "Batch #10\tAverage Generator Loss: 1776.445807\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7182 (step 7182): 1.528227\n",
      "Batch #10\tAverage Generator Loss: 1934.288379\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7183 (step 7183): 1.308389\n",
      "Batch #10\tAverage Generator Loss: 2077.099353\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7184 (step 7184): 1.753913\n",
      "Batch #10\tAverage Generator Loss: 2093.358643\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7185 (step 7185): 1.400137\n",
      "Batch #10\tAverage Generator Loss: 1827.527466\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7186 (step 7186): 1.553607\n",
      "Batch #10\tAverage Generator Loss: 2014.552783\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7187 (step 7187): 1.292444\n",
      "Batch #10\tAverage Generator Loss: 1725.515955\tAverage Discriminator Loss: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #7188 (step 7188): 1.554873\n",
      "Batch #10\tAverage Generator Loss: 1923.892413\tAverage Discriminator Loss: 0.060820\n",
      "\n",
      "Train time for epoch #7189 (step 7189): 1.290522\n",
      "Batch #10\tAverage Generator Loss: 1654.271640\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #7190 (step 7190): 1.605140\n",
      "Batch #10\tAverage Generator Loss: 1819.978711\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #7191 (step 7191): 1.346054\n",
      "Batch #10\tAverage Generator Loss: 1579.286212\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #7192 (step 7192): 1.595793\n",
      "Batch #10\tAverage Generator Loss: 1720.279199\tAverage Discriminator Loss: 0.000020\n",
      "\n",
      "Train time for epoch #7193 (step 7193): 1.314127\n",
      "Batch #10\tAverage Generator Loss: 1671.246533\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #7194 (step 7194): 1.637967\n",
      "Batch #10\tAverage Generator Loss: 1807.971997\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #7195 (step 7195): 1.338927\n",
      "Batch #10\tAverage Generator Loss: 1751.667090\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #7196 (step 7196): 1.630029\n",
      "Batch #10\tAverage Generator Loss: 1818.577527\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #7197 (step 7197): 1.332157\n",
      "Batch #10\tAverage Generator Loss: 1829.293091\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #7198 (step 7198): 1.555898\n",
      "Batch #10\tAverage Generator Loss: 1696.657129\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #7199 (step 7199): 1.291029\n",
      "Batch #10\tAverage Generator Loss: 1643.902942\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #7200 (step 7200): 1.619770\n",
      "Batch #10\tAverage Generator Loss: 1311.477448\tAverage Discriminator Loss: 0.313085\n",
      "\n",
      "Train time for epoch #7201 (step 7201): 1.628674\n",
      "Batch #10\tAverage Generator Loss: 1087.131897\tAverage Discriminator Loss: 0.000894\n",
      "\n",
      "Train time for epoch #7202 (step 7202): 1.464577\n",
      "Batch #10\tAverage Generator Loss: 1122.997363\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #7203 (step 7203): 1.610764\n",
      "Batch #10\tAverage Generator Loss: 994.154120\tAverage Discriminator Loss: 0.042566\n",
      "\n",
      "Train time for epoch #7204 (step 7204): 1.409798\n",
      "Batch #10\tAverage Generator Loss: 1136.762726\tAverage Discriminator Loss: 0.013649\n",
      "\n",
      "Train time for epoch #7205 (step 7205): 1.531302\n",
      "Batch #10\tAverage Generator Loss: 1439.106836\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7206 (step 7206): 1.326960\n",
      "Batch #10\tAverage Generator Loss: 1070.313239\tAverage Discriminator Loss: 0.309670\n",
      "\n",
      "Train time for epoch #7207 (step 7207): 1.574906\n",
      "Batch #10\tAverage Generator Loss: 1085.542035\tAverage Discriminator Loss: 0.328708\n",
      "\n",
      "Train time for epoch #7208 (step 7208): 1.339970\n",
      "Batch #10\tAverage Generator Loss: 1158.445575\tAverage Discriminator Loss: 0.000657\n",
      "\n",
      "Train time for epoch #7209 (step 7209): 1.718970\n",
      "Batch #10\tAverage Generator Loss: 1190.055466\tAverage Discriminator Loss: 0.002576\n",
      "\n",
      "Train time for epoch #7210 (step 7210): 1.609725\n",
      "Batch #10\tAverage Generator Loss: 1277.162726\tAverage Discriminator Loss: 0.000103\n",
      "\n",
      "Train time for epoch #7211 (step 7211): 1.234016\n",
      "Batch #10\tAverage Generator Loss: 1103.634180\tAverage Discriminator Loss: 0.000185\n",
      "\n",
      "Train time for epoch #7212 (step 7212): 1.555081\n",
      "Batch #10\tAverage Generator Loss: 1330.529358\tAverage Discriminator Loss: 0.000062\n",
      "\n",
      "Train time for epoch #7213 (step 7213): 1.282783\n",
      "Batch #10\tAverage Generator Loss: 1001.273569\tAverage Discriminator Loss: 0.109955\n",
      "\n",
      "Train time for epoch #7214 (step 7214): 1.586497\n",
      "Batch #10\tAverage Generator Loss: 1011.188269\tAverage Discriminator Loss: 0.026352\n",
      "\n",
      "Train time for epoch #7215 (step 7215): 1.280217\n",
      "Batch #10\tAverage Generator Loss: 1198.129669\tAverage Discriminator Loss: 0.007560\n",
      "\n",
      "Train time for epoch #7216 (step 7216): 1.579430\n",
      "Batch #10\tAverage Generator Loss: 1071.597388\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #7217 (step 7217): 1.290752\n",
      "Batch #10\tAverage Generator Loss: 1060.775372\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7218 (step 7218): 1.583453\n",
      "Batch #10\tAverage Generator Loss: 1166.425702\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #7219 (step 7219): 1.389864\n",
      "Batch #10\tAverage Generator Loss: 1110.792651\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #7220 (step 7220): 1.611233\n",
      "Batch #10\tAverage Generator Loss: 1152.925842\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #7221 (step 7221): 1.278990\n",
      "Batch #10\tAverage Generator Loss: 1128.454633\tAverage Discriminator Loss: 0.000222\n",
      "\n",
      "Train time for epoch #7222 (step 7222): 1.537444\n",
      "Batch #10\tAverage Generator Loss: 1233.002490\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7223 (step 7223): 1.289592\n",
      "Batch #10\tAverage Generator Loss: 1079.920575\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7224 (step 7224): 1.532613\n",
      "Batch #10\tAverage Generator Loss: 1197.980890\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7225 (step 7225): 1.483198\n",
      "Batch #10\tAverage Generator Loss: 1237.917316\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #7226 (step 7226): 1.337556\n",
      "Batch #10\tAverage Generator Loss: 1264.769525\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7227 (step 7227): 1.625272\n",
      "Batch #10\tAverage Generator Loss: 1237.021350\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #7228 (step 7228): 1.236817\n",
      "Batch #10\tAverage Generator Loss: 932.896347\tAverage Discriminator Loss: 0.019697\n",
      "\n",
      "Train time for epoch #7229 (step 7229): 1.592663\n",
      "Batch #10\tAverage Generator Loss: 1247.419324\tAverage Discriminator Loss: 0.002242\n",
      "\n",
      "Train time for epoch #7230 (step 7230): 1.287012\n",
      "Batch #10\tAverage Generator Loss: 1192.427692\tAverage Discriminator Loss: 0.000137\n",
      "\n",
      "Train time for epoch #7231 (step 7231): 1.623267\n",
      "Batch #10\tAverage Generator Loss: 1177.292828\tAverage Discriminator Loss: 0.000032\n",
      "\n",
      "Train time for epoch #7232 (step 7232): 1.454186\n",
      "Batch #10\tAverage Generator Loss: 1296.178391\tAverage Discriminator Loss: 0.000023\n",
      "\n",
      "Train time for epoch #7233 (step 7233): 1.630239\n",
      "Batch #10\tAverage Generator Loss: 1248.636298\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #7234 (step 7234): 1.286654\n",
      "Batch #10\tAverage Generator Loss: 1117.518756\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7235 (step 7235): 1.563029\n",
      "Batch #10\tAverage Generator Loss: 1272.334131\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #7236 (step 7236): 1.339115\n",
      "Batch #10\tAverage Generator Loss: 1375.694971\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #7237 (step 7237): 1.677418\n",
      "Batch #10\tAverage Generator Loss: 1343.140881\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #7238 (step 7238): 1.417027\n",
      "Batch #10\tAverage Generator Loss: 1169.261102\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #7239 (step 7239): 1.503881\n",
      "Batch #10\tAverage Generator Loss: 1090.717334\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #7240 (step 7240): 1.285632\n",
      "Batch #10\tAverage Generator Loss: 1102.746820\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7241 (step 7241): 1.677914\n",
      "Batch #10\tAverage Generator Loss: 1349.098932\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #7242 (step 7242): 1.333011\n",
      "Batch #10\tAverage Generator Loss: 1274.523895\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #7243 (step 7243): 1.643739\n",
      "Batch #10\tAverage Generator Loss: 1089.984799\tAverage Discriminator Loss: 0.013081\n",
      "\n",
      "Train time for epoch #7244 (step 7244): 1.335188\n",
      "Batch #10\tAverage Generator Loss: 1169.842078\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #7245 (step 7245): 1.598038\n",
      "Batch #10\tAverage Generator Loss: 1046.595398\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7246 (step 7246): 1.313397\n",
      "Batch #10\tAverage Generator Loss: 1305.978601\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #7247 (step 7247): 1.498921\n",
      "Batch #10\tAverage Generator Loss: 1256.579700\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7248 (step 7248): 1.286820\n",
      "Batch #10\tAverage Generator Loss: 1041.532288\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7249 (step 7249): 1.545696\n",
      "Batch #10\tAverage Generator Loss: 1203.494824\tAverage Discriminator Loss: 0.005109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #7250 (step 7250): 1.389580\n",
      "Batch #10\tAverage Generator Loss: 1091.435977\tAverage Discriminator Loss: 0.000205\n",
      "\n",
      "Train time for epoch #7251 (step 7251): 1.551908\n",
      "Batch #10\tAverage Generator Loss: 1212.075256\tAverage Discriminator Loss: 0.000170\n",
      "\n",
      "Train time for epoch #7252 (step 7252): 1.354314\n",
      "Batch #10\tAverage Generator Loss: 1019.559244\tAverage Discriminator Loss: 0.000061\n",
      "\n",
      "Train time for epoch #7253 (step 7253): 1.647246\n",
      "Batch #10\tAverage Generator Loss: 1226.133282\tAverage Discriminator Loss: 0.000044\n",
      "\n",
      "Train time for epoch #7254 (step 7254): 1.261275\n",
      "Batch #10\tAverage Generator Loss: 1163.399023\tAverage Discriminator Loss: 0.000024\n",
      "\n",
      "Train time for epoch #7255 (step 7255): 1.593024\n",
      "Batch #10\tAverage Generator Loss: 1391.884851\tAverage Discriminator Loss: 0.000028\n",
      "\n",
      "Train time for epoch #7256 (step 7256): 1.325505\n",
      "Batch #10\tAverage Generator Loss: 974.920166\tAverage Discriminator Loss: 0.000020\n",
      "\n",
      "Train time for epoch #7257 (step 7257): 1.628585\n",
      "Batch #10\tAverage Generator Loss: 1391.448047\tAverage Discriminator Loss: 0.000019\n",
      "\n",
      "Train time for epoch #7258 (step 7258): 1.505063\n",
      "Batch #10\tAverage Generator Loss: 1093.791125\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #7259 (step 7259): 1.278461\n",
      "Batch #10\tAverage Generator Loss: 1262.967297\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #7260 (step 7260): 1.546689\n",
      "Batch #10\tAverage Generator Loss: 1203.411609\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #7261 (step 7261): 1.298860\n",
      "Batch #10\tAverage Generator Loss: 1224.398853\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #7262 (step 7262): 1.291442\n",
      "Batch #10\tAverage Generator Loss: 1228.767822\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #7263 (step 7263): 1.621814\n",
      "Batch #10\tAverage Generator Loss: 1370.445142\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #7264 (step 7264): 1.613410\n",
      "Batch #10\tAverage Generator Loss: 1084.555225\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #7265 (step 7265): 1.276728\n",
      "Batch #10\tAverage Generator Loss: 1219.882611\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #7266 (step 7266): 1.566855\n",
      "Batch #10\tAverage Generator Loss: 1170.069562\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #7267 (step 7267): 1.378267\n",
      "Batch #10\tAverage Generator Loss: 1166.804565\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #7268 (step 7268): 1.578242\n",
      "Batch #10\tAverage Generator Loss: 1298.711340\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #7269 (step 7269): 1.291428\n",
      "Batch #10\tAverage Generator Loss: 1213.117493\tAverage Discriminator Loss: 0.000037\n",
      "\n",
      "Train time for epoch #7270 (step 7270): 1.553282\n",
      "Batch #10\tAverage Generator Loss: 1232.045087\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #7271 (step 7271): 1.340570\n",
      "Batch #10\tAverage Generator Loss: 1369.653082\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #7272 (step 7272): 1.797592\n",
      "Batch #10\tAverage Generator Loss: 1152.704773\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #7273 (step 7273): 1.292483\n",
      "Batch #10\tAverage Generator Loss: 1083.151904\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #7274 (step 7274): 1.563159\n",
      "Batch #10\tAverage Generator Loss: 1210.500931\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #7275 (step 7275): 1.365192\n",
      "Batch #10\tAverage Generator Loss: 1520.703070\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #7276 (step 7276): 1.548683\n",
      "Batch #10\tAverage Generator Loss: 1231.346613\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #7277 (step 7277): 1.361948\n",
      "Batch #10\tAverage Generator Loss: 1328.888116\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #7278 (step 7278): 1.769449\n",
      "Batch #10\tAverage Generator Loss: 1288.194690\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #7279 (step 7279): 1.296644\n",
      "Batch #10\tAverage Generator Loss: 1382.112915\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #7280 (step 7280): 1.604468\n",
      "Batch #10\tAverage Generator Loss: 1278.422748\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #7281 (step 7281): 1.369102\n",
      "Batch #10\tAverage Generator Loss: 1270.381104\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #7282 (step 7282): 1.554643\n",
      "Batch #10\tAverage Generator Loss: 1168.763892\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #7283 (step 7283): 1.353409\n",
      "Batch #10\tAverage Generator Loss: 1241.164246\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #7284 (step 7284): 1.546929\n",
      "Batch #10\tAverage Generator Loss: 1329.636707\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #7285 (step 7285): 1.345265\n",
      "Batch #10\tAverage Generator Loss: 1352.785651\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #7286 (step 7286): 1.558645\n",
      "Batch #10\tAverage Generator Loss: 1322.401923\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #7287 (step 7287): 1.298628\n",
      "Batch #10\tAverage Generator Loss: 1471.542145\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #7288 (step 7288): 1.572599\n",
      "Batch #10\tAverage Generator Loss: 1365.826099\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #7289 (step 7289): 1.555215\n",
      "Batch #10\tAverage Generator Loss: 1479.212531\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7290 (step 7290): 1.338200\n",
      "Batch #10\tAverage Generator Loss: 1156.731580\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #7291 (step 7291): 1.559071\n",
      "Batch #10\tAverage Generator Loss: 1261.872879\tAverage Discriminator Loss: 0.000272\n",
      "\n",
      "Train time for epoch #7292 (step 7292): 1.396664\n",
      "Batch #10\tAverage Generator Loss: 1269.999176\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #7293 (step 7293): 1.590003\n",
      "Batch #10\tAverage Generator Loss: 1292.698749\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #7294 (step 7294): 1.347322\n",
      "Batch #10\tAverage Generator Loss: 1166.866199\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #7295 (step 7295): 1.664192\n",
      "Batch #10\tAverage Generator Loss: 1212.279248\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #7296 (step 7296): 1.297642\n",
      "Batch #10\tAverage Generator Loss: 1150.165680\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #7297 (step 7297): 1.576086\n",
      "Batch #10\tAverage Generator Loss: 1145.505899\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #7298 (step 7298): 1.283168\n",
      "Batch #10\tAverage Generator Loss: 1196.520294\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #7299 (step 7299): 1.543049\n",
      "Batch #10\tAverage Generator Loss: 1284.377362\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #7300 (step 7300): 1.345629\n",
      "Batch #10\tAverage Generator Loss: 1221.773810\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #7301 (step 7301): 1.554455\n",
      "Batch #10\tAverage Generator Loss: 1191.658667\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #7302 (step 7302): 1.328697\n",
      "Batch #10\tAverage Generator Loss: 1351.327515\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #7303 (step 7303): 1.650350\n",
      "Batch #10\tAverage Generator Loss: 1214.870294\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #7304 (step 7304): 1.285734\n",
      "Batch #10\tAverage Generator Loss: 1161.098636\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #7305 (step 7305): 1.539130\n",
      "Batch #10\tAverage Generator Loss: 1189.667682\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #7306 (step 7306): 1.348613\n",
      "Batch #10\tAverage Generator Loss: 1360.728894\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #7307 (step 7307): 1.546780\n",
      "Batch #10\tAverage Generator Loss: 1137.243274\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #7308 (step 7308): 1.481354\n",
      "Batch #10\tAverage Generator Loss: 1371.915430\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #7309 (step 7309): 1.649581\n",
      "Batch #10\tAverage Generator Loss: 1367.200067\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7310 (step 7310): 1.315879\n",
      "Batch #10\tAverage Generator Loss: 1142.710263\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #7311 (step 7311): 1.589252\n",
      "Batch #10\tAverage Generator Loss: 1291.853528\tAverage Discriminator Loss: 0.000005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #7312 (step 7312): 1.314844\n",
      "Batch #10\tAverage Generator Loss: 1119.503448\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #7313 (step 7313): 1.556439\n",
      "Batch #10\tAverage Generator Loss: 1129.241064\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #7314 (step 7314): 1.619812\n",
      "Batch #10\tAverage Generator Loss: 1120.463855\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #7315 (step 7315): 1.498624\n",
      "Batch #10\tAverage Generator Loss: 1259.765112\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7316 (step 7316): 1.634969\n",
      "Batch #10\tAverage Generator Loss: 1099.316864\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #7317 (step 7317): 1.429176\n",
      "Batch #10\tAverage Generator Loss: 1276.376135\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7318 (step 7318): 1.581838\n",
      "Batch #10\tAverage Generator Loss: 1295.387219\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #7319 (step 7319): 1.383824\n",
      "Batch #10\tAverage Generator Loss: 1169.677698\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7320 (step 7320): 1.389259\n",
      "Batch #10\tAverage Generator Loss: 1254.916907\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7321 (step 7321): 1.551577\n",
      "Batch #10\tAverage Generator Loss: 1175.919037\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #7322 (step 7322): 1.378218\n",
      "Batch #10\tAverage Generator Loss: 1271.596881\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7323 (step 7323): 1.604957\n",
      "Batch #10\tAverage Generator Loss: 1199.220044\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7324 (step 7324): 1.615892\n",
      "Batch #10\tAverage Generator Loss: 1160.374475\tAverage Discriminator Loss: 0.000321\n",
      "\n",
      "Train time for epoch #7325 (step 7325): 1.477622\n",
      "Batch #10\tAverage Generator Loss: 1194.828290\tAverage Discriminator Loss: 0.000025\n",
      "\n",
      "Train time for epoch #7326 (step 7326): 1.696384\n",
      "Batch #10\tAverage Generator Loss: 1263.761908\tAverage Discriminator Loss: 0.000028\n",
      "\n",
      "Train time for epoch #7327 (step 7327): 1.363257\n",
      "Batch #10\tAverage Generator Loss: 1162.716980\tAverage Discriminator Loss: 0.000035\n",
      "\n",
      "Train time for epoch #7328 (step 7328): 1.567457\n",
      "Batch #10\tAverage Generator Loss: 1186.270361\tAverage Discriminator Loss: 0.000024\n",
      "\n",
      "Train time for epoch #7329 (step 7329): 1.349475\n",
      "Batch #10\tAverage Generator Loss: 1149.032428\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #7330 (step 7330): 1.662767\n",
      "Batch #10\tAverage Generator Loss: 1151.405411\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #7331 (step 7331): 1.397795\n",
      "Batch #10\tAverage Generator Loss: 1232.258899\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #7332 (step 7332): 1.715290\n",
      "Batch #10\tAverage Generator Loss: 1278.823126\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #7333 (step 7333): 1.388740\n",
      "Batch #10\tAverage Generator Loss: 1159.028442\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #7334 (step 7334): 1.550471\n",
      "Batch #10\tAverage Generator Loss: 1210.291095\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #7335 (step 7335): 1.324903\n",
      "Batch #10\tAverage Generator Loss: 1121.957977\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #7336 (step 7336): 1.599441\n",
      "Batch #10\tAverage Generator Loss: 1291.522052\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #7337 (step 7337): 1.345484\n",
      "Batch #10\tAverage Generator Loss: 1198.098285\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #7338 (step 7338): 1.552087\n",
      "Batch #10\tAverage Generator Loss: 1238.662292\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #7339 (step 7339): 1.373875\n",
      "Batch #10\tAverage Generator Loss: 1256.683240\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #7340 (step 7340): 1.597659\n",
      "Batch #10\tAverage Generator Loss: 1330.926233\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #7341 (step 7341): 1.364591\n",
      "Batch #10\tAverage Generator Loss: 1310.364691\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #7342 (step 7342): 1.526895\n",
      "Batch #10\tAverage Generator Loss: 1249.428723\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #7343 (step 7343): 1.570206\n",
      "Batch #10\tAverage Generator Loss: 1267.146753\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #7344 (step 7344): 1.288900\n",
      "Batch #10\tAverage Generator Loss: 1416.514001\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #7345 (step 7345): 1.533766\n",
      "Batch #10\tAverage Generator Loss: 1313.267206\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #7346 (step 7346): 1.275670\n",
      "Batch #10\tAverage Generator Loss: 1289.641779\tAverage Discriminator Loss: 0.002186\n",
      "\n",
      "Train time for epoch #7347 (step 7347): 1.320638\n",
      "Batch #10\tAverage Generator Loss: 1216.705219\tAverage Discriminator Loss: 0.000058\n",
      "\n",
      "Train time for epoch #7348 (step 7348): 1.489193\n",
      "Batch #10\tAverage Generator Loss: 1264.277612\tAverage Discriminator Loss: 0.000131\n",
      "\n",
      "Train time for epoch #7349 (step 7349): 1.443426\n",
      "Batch #10\tAverage Generator Loss: 1137.116205\tAverage Discriminator Loss: 0.000031\n",
      "\n",
      "Train time for epoch #7350 (step 7350): 1.596305\n",
      "Batch #10\tAverage Generator Loss: 1234.695892\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #7351 (step 7351): 1.589211\n",
      "Batch #10\tAverage Generator Loss: 1197.962988\tAverage Discriminator Loss: 0.000208\n",
      "\n",
      "Train time for epoch #7352 (step 7352): 1.287912\n",
      "Batch #10\tAverage Generator Loss: 1071.363660\tAverage Discriminator Loss: 0.075338\n",
      "\n",
      "Train time for epoch #7353 (step 7353): 1.590853\n",
      "Batch #10\tAverage Generator Loss: 1321.962561\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7354 (step 7354): 1.321117\n",
      "Batch #10\tAverage Generator Loss: 1140.100290\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7355 (step 7355): 1.564416\n",
      "Batch #10\tAverage Generator Loss: 1215.297638\tAverage Discriminator Loss: 0.000931\n",
      "\n",
      "Train time for epoch #7356 (step 7356): 1.376977\n",
      "Batch #10\tAverage Generator Loss: 1259.528802\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #7357 (step 7357): 1.541207\n",
      "Batch #10\tAverage Generator Loss: 1249.278455\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7358 (step 7358): 1.293905\n",
      "Batch #10\tAverage Generator Loss: 1421.342657\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7359 (step 7359): 1.566363\n",
      "Batch #10\tAverage Generator Loss: 1252.839255\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7360 (step 7360): 1.291769\n",
      "Batch #10\tAverage Generator Loss: 1005.806189\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7361 (step 7361): 1.505080\n",
      "Batch #10\tAverage Generator Loss: 1227.619281\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7362 (step 7362): 1.327224\n",
      "Batch #10\tAverage Generator Loss: 1187.810623\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7363 (step 7363): 1.590143\n",
      "Batch #10\tAverage Generator Loss: 1207.579364\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7364 (step 7364): 1.391975\n",
      "Batch #10\tAverage Generator Loss: 1191.797430\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7365 (step 7365): 1.551115\n",
      "Batch #10\tAverage Generator Loss: 1370.884332\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7366 (step 7366): 1.288843\n",
      "Batch #10\tAverage Generator Loss: 1188.101074\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7367 (step 7367): 1.539080\n",
      "Batch #10\tAverage Generator Loss: 1302.192615\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7368 (step 7368): 1.385891\n",
      "Batch #10\tAverage Generator Loss: 1125.592642\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7369 (step 7369): 1.603847\n",
      "Batch #10\tAverage Generator Loss: 1429.165149\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7370 (step 7370): 1.337810\n",
      "Batch #10\tAverage Generator Loss: 1061.167542\tAverage Discriminator Loss: 0.029415\n",
      "\n",
      "Train time for epoch #7371 (step 7371): 1.614189\n",
      "Batch #10\tAverage Generator Loss: 1262.652307\tAverage Discriminator Loss: 0.000172\n",
      "\n",
      "Train time for epoch #7372 (step 7372): 1.286712\n",
      "Batch #10\tAverage Generator Loss: 1302.702576\tAverage Discriminator Loss: 0.000111\n",
      "\n",
      "Train time for epoch #7373 (step 7373): 1.636535\n",
      "Batch #10\tAverage Generator Loss: 1229.577246\tAverage Discriminator Loss: 0.000049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #7374 (step 7374): 1.361297\n",
      "Batch #10\tAverage Generator Loss: 1286.221362\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #7375 (step 7375): 1.631469\n",
      "Batch #10\tAverage Generator Loss: 1261.010251\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #7376 (step 7376): 1.349048\n",
      "Batch #10\tAverage Generator Loss: 1204.230719\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #7377 (step 7377): 1.648934\n",
      "Batch #10\tAverage Generator Loss: 1081.022769\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #7378 (step 7378): 1.433230\n",
      "Batch #10\tAverage Generator Loss: 1257.715262\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #7379 (step 7379): 1.580949\n",
      "Batch #10\tAverage Generator Loss: 1393.143494\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #7380 (step 7380): 1.289273\n",
      "Batch #10\tAverage Generator Loss: 1232.507202\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #7381 (step 7381): 1.582023\n",
      "Batch #10\tAverage Generator Loss: 1249.032245\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #7382 (step 7382): 1.301113\n",
      "Batch #10\tAverage Generator Loss: 1267.506491\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #7383 (step 7383): 1.613156\n",
      "Batch #10\tAverage Generator Loss: 1157.525079\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #7384 (step 7384): 1.591424\n",
      "Batch #10\tAverage Generator Loss: 1375.760468\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #7385 (step 7385): 1.286081\n",
      "Batch #10\tAverage Generator Loss: 1262.345111\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #7386 (step 7386): 1.555314\n",
      "Batch #10\tAverage Generator Loss: 1133.642139\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #7387 (step 7387): 1.371153\n",
      "Batch #10\tAverage Generator Loss: 1175.527472\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #7388 (step 7388): 1.601445\n",
      "Batch #10\tAverage Generator Loss: 1306.480402\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #7389 (step 7389): 1.356125\n",
      "Batch #10\tAverage Generator Loss: 1427.825885\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #7390 (step 7390): 1.622354\n",
      "Batch #10\tAverage Generator Loss: 1286.230536\tAverage Discriminator Loss: 0.102426\n",
      "\n",
      "Train time for epoch #7391 (step 7391): 1.384434\n",
      "Batch #10\tAverage Generator Loss: 1366.023505\tAverage Discriminator Loss: 0.031271\n",
      "\n",
      "Train time for epoch #7392 (step 7392): 1.622972\n",
      "Batch #10\tAverage Generator Loss: 1209.350366\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7393 (step 7393): 1.278754\n",
      "Batch #10\tAverage Generator Loss: 1366.604419\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7394 (step 7394): 1.631141\n",
      "Batch #10\tAverage Generator Loss: 1269.097260\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7395 (step 7395): 1.302148\n",
      "Batch #10\tAverage Generator Loss: 1246.572876\tAverage Discriminator Loss: 0.014137\n",
      "\n",
      "Train time for epoch #7396 (step 7396): 1.581213\n",
      "Batch #10\tAverage Generator Loss: 1131.445129\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7397 (step 7397): 1.433486\n",
      "Batch #10\tAverage Generator Loss: 1208.275104\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7398 (step 7398): 1.598566\n",
      "Batch #10\tAverage Generator Loss: 1287.114105\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7399 (step 7399): 1.399376\n",
      "Batch #10\tAverage Generator Loss: 1318.216803\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7400 (step 7400): 1.558336\n",
      "Batch #10\tAverage Generator Loss: 1360.345959\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7401 (step 7401): 1.325630\n",
      "Batch #10\tAverage Generator Loss: 1299.931067\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7402 (step 7402): 1.633070\n",
      "Batch #10\tAverage Generator Loss: 1471.706866\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7403 (step 7403): 1.287291\n",
      "Batch #10\tAverage Generator Loss: 1350.728534\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7404 (step 7404): 1.518739\n",
      "Batch #10\tAverage Generator Loss: 1416.327234\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7405 (step 7405): 1.283555\n",
      "Batch #10\tAverage Generator Loss: 1602.458942\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7406 (step 7406): 1.604445\n",
      "Batch #10\tAverage Generator Loss: 1664.510834\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7407 (step 7407): 1.413477\n",
      "Batch #10\tAverage Generator Loss: 1543.372192\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7408 (step 7408): 1.782888\n",
      "Batch #10\tAverage Generator Loss: 1412.592609\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7409 (step 7409): 1.568612\n",
      "Batch #10\tAverage Generator Loss: 1265.571066\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7410 (step 7410): 1.288098\n",
      "Batch #10\tAverage Generator Loss: 1352.410626\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7411 (step 7411): 1.521358\n",
      "Batch #10\tAverage Generator Loss: 1392.953656\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7412 (step 7412): 1.416741\n",
      "Batch #10\tAverage Generator Loss: 1404.934143\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7413 (step 7413): 1.595153\n",
      "Batch #10\tAverage Generator Loss: 1338.030743\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7414 (step 7414): 1.286330\n",
      "Batch #10\tAverage Generator Loss: 1486.457581\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7415 (step 7415): 1.585623\n",
      "Batch #10\tAverage Generator Loss: 1453.454779\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7416 (step 7416): 1.348579\n",
      "Batch #10\tAverage Generator Loss: 1421.337927\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7417 (step 7417): 1.539726\n",
      "Batch #10\tAverage Generator Loss: 1322.632886\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7418 (step 7418): 1.283954\n",
      "Batch #10\tAverage Generator Loss: 1246.861014\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7419 (step 7419): 1.545938\n",
      "Batch #10\tAverage Generator Loss: 1348.745789\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7420 (step 7420): 1.329352\n",
      "Batch #10\tAverage Generator Loss: 1419.298273\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7421 (step 7421): 1.551221\n",
      "Batch #10\tAverage Generator Loss: 1249.996686\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7422 (step 7422): 1.292243\n",
      "Batch #10\tAverage Generator Loss: 1217.173744\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7423 (step 7423): 1.509017\n",
      "Batch #10\tAverage Generator Loss: 1555.686298\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7424 (step 7424): 1.261729\n",
      "Batch #10\tAverage Generator Loss: 1437.286975\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7425 (step 7425): 1.530047\n",
      "Batch #10\tAverage Generator Loss: 1228.011469\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7426 (step 7426): 1.343077\n",
      "Batch #10\tAverage Generator Loss: 1355.141144\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7427 (step 7427): 1.576126\n",
      "Batch #10\tAverage Generator Loss: 1231.379169\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7428 (step 7428): 1.290541\n",
      "Batch #10\tAverage Generator Loss: 1446.255505\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7429 (step 7429): 1.555422\n",
      "Batch #10\tAverage Generator Loss: 1406.264160\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7430 (step 7430): 1.333769\n",
      "Batch #10\tAverage Generator Loss: 1409.354480\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7431 (step 7431): 1.588233\n",
      "Batch #10\tAverage Generator Loss: 1159.990076\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7432 (step 7432): 1.240517\n",
      "Batch #10\tAverage Generator Loss: 1333.701532\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7433 (step 7433): 1.652611\n",
      "Batch #10\tAverage Generator Loss: 1305.671164\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7434 (step 7434): 1.312770\n",
      "Batch #10\tAverage Generator Loss: 1497.043048\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7435 (step 7435): 1.604111\n",
      "Batch #10\tAverage Generator Loss: 1218.990442\tAverage Discriminator Loss: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #7436 (step 7436): 1.285814\n",
      "Batch #10\tAverage Generator Loss: 1371.672479\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7437 (step 7437): 1.553018\n",
      "Batch #10\tAverage Generator Loss: 1387.613519\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7438 (step 7438): 1.725969\n",
      "Batch #10\tAverage Generator Loss: 1479.571069\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7439 (step 7439): 1.417675\n",
      "Batch #10\tAverage Generator Loss: 1348.942432\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7440 (step 7440): 1.635161\n",
      "Batch #10\tAverage Generator Loss: 1390.460828\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7441 (step 7441): 1.345697\n",
      "Batch #10\tAverage Generator Loss: 1378.111322\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7442 (step 7442): 1.851051\n",
      "Batch #10\tAverage Generator Loss: 1238.789117\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7443 (step 7443): 1.370599\n",
      "Batch #10\tAverage Generator Loss: 1525.579059\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7444 (step 7444): 1.570294\n",
      "Batch #10\tAverage Generator Loss: 1335.923666\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7445 (step 7445): 1.295237\n",
      "Batch #10\tAverage Generator Loss: 1383.246271\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7446 (step 7446): 1.609418\n",
      "Batch #10\tAverage Generator Loss: 1337.604510\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7447 (step 7447): 1.313274\n",
      "Batch #10\tAverage Generator Loss: 1363.162628\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7448 (step 7448): 1.572437\n",
      "Batch #10\tAverage Generator Loss: 1411.232697\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7449 (step 7449): 1.331112\n",
      "Batch #10\tAverage Generator Loss: 1463.804932\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7450 (step 7450): 1.566573\n",
      "Batch #10\tAverage Generator Loss: 1227.032184\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7451 (step 7451): 1.299685\n",
      "Batch #10\tAverage Generator Loss: 1252.825671\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7452 (step 7452): 1.546999\n",
      "Batch #10\tAverage Generator Loss: 1166.299719\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7453 (step 7453): 1.290787\n",
      "Batch #10\tAverage Generator Loss: 1431.530731\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7454 (step 7454): 1.600270\n",
      "Batch #10\tAverage Generator Loss: 1386.280219\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7455 (step 7455): 1.324466\n",
      "Batch #10\tAverage Generator Loss: 1386.836316\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7456 (step 7456): 1.596367\n",
      "Batch #10\tAverage Generator Loss: 1391.860443\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7457 (step 7457): 1.342897\n",
      "Batch #10\tAverage Generator Loss: 1469.130164\tAverage Discriminator Loss: 0.011471\n",
      "\n",
      "Train time for epoch #7458 (step 7458): 1.547849\n",
      "Batch #10\tAverage Generator Loss: 1497.840991\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7459 (step 7459): 1.346313\n",
      "Batch #10\tAverage Generator Loss: 1108.990631\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7460 (step 7460): 1.685395\n",
      "Batch #10\tAverage Generator Loss: 1411.129407\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7461 (step 7461): 1.539629\n",
      "Batch #10\tAverage Generator Loss: 1198.099011\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7462 (step 7462): 1.334055\n",
      "Batch #10\tAverage Generator Loss: 1218.312115\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7463 (step 7463): 1.606024\n",
      "Batch #10\tAverage Generator Loss: 1325.013196\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7464 (step 7464): 1.397544\n",
      "Batch #10\tAverage Generator Loss: 1107.766766\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7465 (step 7465): 1.627224\n",
      "Batch #10\tAverage Generator Loss: 1411.204333\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7466 (step 7466): 1.301759\n",
      "Batch #10\tAverage Generator Loss: 1388.416663\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7467 (step 7467): 1.693471\n",
      "Batch #10\tAverage Generator Loss: 1252.579938\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7468 (step 7468): 1.346667\n",
      "Batch #10\tAverage Generator Loss: 1184.632947\tAverage Discriminator Loss: 0.000032\n",
      "\n",
      "Train time for epoch #7469 (step 7469): 1.669920\n",
      "Batch #10\tAverage Generator Loss: 1301.679791\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7470 (step 7470): 1.350833\n",
      "Batch #10\tAverage Generator Loss: 1357.864771\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7471 (step 7471): 1.552967\n",
      "Batch #10\tAverage Generator Loss: 1205.150873\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7472 (step 7472): 1.358510\n",
      "Batch #10\tAverage Generator Loss: 1272.984473\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7473 (step 7473): 1.570766\n",
      "Batch #10\tAverage Generator Loss: 1319.109723\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7474 (step 7474): 1.365613\n",
      "Batch #10\tAverage Generator Loss: 1209.394171\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7475 (step 7475): 1.689868\n",
      "Batch #10\tAverage Generator Loss: 1242.316138\tAverage Discriminator Loss: 0.041170\n",
      "\n",
      "Train time for epoch #7476 (step 7476): 1.422059\n",
      "Batch #10\tAverage Generator Loss: 1180.271954\tAverage Discriminator Loss: 0.064101\n",
      "\n",
      "Train time for epoch #7477 (step 7477): 1.554601\n",
      "Batch #10\tAverage Generator Loss: 1432.333411\tAverage Discriminator Loss: 0.037595\n",
      "\n",
      "Train time for epoch #7478 (step 7478): 1.324346\n",
      "Batch #10\tAverage Generator Loss: 1383.311060\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7479 (step 7479): 1.620568\n",
      "Batch #10\tAverage Generator Loss: 973.370006\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7480 (step 7480): 1.309051\n",
      "Batch #10\tAverage Generator Loss: 1269.276331\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7481 (step 7481): 1.561592\n",
      "Batch #10\tAverage Generator Loss: 1358.589172\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7482 (step 7482): 1.370714\n",
      "Batch #10\tAverage Generator Loss: 1385.439453\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7483 (step 7483): 1.525481\n",
      "Batch #10\tAverage Generator Loss: 1583.267407\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7484 (step 7484): 1.304302\n",
      "Batch #10\tAverage Generator Loss: 1301.588879\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #7485 (step 7485): 1.561963\n",
      "Batch #10\tAverage Generator Loss: 1171.145862\tAverage Discriminator Loss: 0.159496\n",
      "\n",
      "Train time for epoch #7486 (step 7486): 1.399367\n",
      "Batch #10\tAverage Generator Loss: 1028.138300\tAverage Discriminator Loss: 0.000029\n",
      "\n",
      "Train time for epoch #7487 (step 7487): 1.578165\n",
      "Batch #10\tAverage Generator Loss: 1030.831378\tAverage Discriminator Loss: 0.000669\n",
      "\n",
      "Train time for epoch #7488 (step 7488): 1.286482\n",
      "Batch #10\tAverage Generator Loss: 1184.308972\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #7489 (step 7489): 1.521930\n",
      "Batch #10\tAverage Generator Loss: 981.115594\tAverage Discriminator Loss: 0.001822\n",
      "\n",
      "Train time for epoch #7490 (step 7490): 1.352147\n",
      "Batch #10\tAverage Generator Loss: 1193.842572\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7491 (step 7491): 1.665043\n",
      "Batch #10\tAverage Generator Loss: 1190.705469\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7492 (step 7492): 1.573977\n",
      "Batch #10\tAverage Generator Loss: 1144.367859\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7493 (step 7493): 1.332168\n",
      "Batch #10\tAverage Generator Loss: 1382.072595\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7494 (step 7494): 1.751618\n",
      "Batch #10\tAverage Generator Loss: 1268.731708\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7495 (step 7495): 1.377664\n",
      "Batch #10\tAverage Generator Loss: 1246.360056\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7496 (step 7496): 1.553109\n",
      "Batch #10\tAverage Generator Loss: 1212.213049\tAverage Discriminator Loss: 0.000377\n",
      "\n",
      "Train time for epoch #7497 (step 7497): 1.293132\n",
      "Batch #10\tAverage Generator Loss: 1202.541089\tAverage Discriminator Loss: 0.000001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #7498 (step 7498): 1.707080\n",
      "Batch #10\tAverage Generator Loss: 1236.542303\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7499 (step 7499): 1.330283\n",
      "Batch #10\tAverage Generator Loss: 1345.574908\tAverage Discriminator Loss: 0.030897\n",
      "\n",
      "Train time for epoch #7500 (step 7500): 1.559203\n",
      "Batch #10\tAverage Generator Loss: 1148.680225\tAverage Discriminator Loss: 0.000183\n",
      "\n",
      "Train time for epoch #7501 (step 7501): 1.291359\n",
      "Batch #10\tAverage Generator Loss: 1367.858673\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #7502 (step 7502): 1.663404\n",
      "Batch #10\tAverage Generator Loss: 1255.152380\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7503 (step 7503): 1.286859\n",
      "Batch #10\tAverage Generator Loss: 1221.144739\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #7504 (step 7504): 1.381336\n",
      "Batch #10\tAverage Generator Loss: 1129.583673\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #7505 (step 7505): 1.533004\n",
      "Batch #10\tAverage Generator Loss: 1219.063104\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #7506 (step 7506): 1.357499\n",
      "Batch #10\tAverage Generator Loss: 1176.638629\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #7507 (step 7507): 1.554891\n",
      "Batch #10\tAverage Generator Loss: 1340.940350\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7508 (step 7508): 1.287594\n",
      "Batch #10\tAverage Generator Loss: 1235.281390\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #7509 (step 7509): 1.736882\n",
      "Batch #10\tAverage Generator Loss: 1367.817059\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7510 (step 7510): 1.622114\n",
      "Batch #10\tAverage Generator Loss: 1295.489105\tAverage Discriminator Loss: 0.011597\n",
      "\n",
      "Train time for epoch #7511 (step 7511): 1.298226\n",
      "Batch #10\tAverage Generator Loss: 1149.290387\tAverage Discriminator Loss: 0.000447\n",
      "\n",
      "Train time for epoch #7512 (step 7512): 1.617928\n",
      "Batch #10\tAverage Generator Loss: 1398.574860\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #7513 (step 7513): 1.359668\n",
      "Batch #10\tAverage Generator Loss: 1364.657648\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #7514 (step 7514): 1.524454\n",
      "Batch #10\tAverage Generator Loss: 1361.220276\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7515 (step 7515): 1.336250\n",
      "Batch #10\tAverage Generator Loss: 1469.428333\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #7516 (step 7516): 1.567188\n",
      "Batch #10\tAverage Generator Loss: 1322.771564\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #7517 (step 7517): 1.349498\n",
      "Batch #10\tAverage Generator Loss: 1133.912952\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #7518 (step 7518): 1.600712\n",
      "Batch #10\tAverage Generator Loss: 1323.718555\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #7519 (step 7519): 1.591015\n",
      "Batch #10\tAverage Generator Loss: 1228.531049\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #7520 (step 7520): 1.563264\n",
      "Batch #10\tAverage Generator Loss: 1438.229260\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #7521 (step 7521): 1.337114\n",
      "Batch #10\tAverage Generator Loss: 1143.693762\tAverage Discriminator Loss: 0.004093\n",
      "\n",
      "Train time for epoch #7522 (step 7522): 1.616305\n",
      "Batch #10\tAverage Generator Loss: 1421.010663\tAverage Discriminator Loss: 0.000021\n",
      "\n",
      "Train time for epoch #7523 (step 7523): 1.314616\n",
      "Batch #10\tAverage Generator Loss: 1229.852484\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #7524 (step 7524): 1.648719\n",
      "Batch #10\tAverage Generator Loss: 1316.983160\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #7525 (step 7525): 1.428336\n",
      "Batch #10\tAverage Generator Loss: 1226.091339\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #7526 (step 7526): 1.672669\n",
      "Batch #10\tAverage Generator Loss: 1198.317450\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #7527 (step 7527): 1.397259\n",
      "Batch #10\tAverage Generator Loss: 1384.291229\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #7528 (step 7528): 1.710299\n",
      "Batch #10\tAverage Generator Loss: 1462.708832\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #7529 (step 7529): 1.280562\n",
      "Batch #10\tAverage Generator Loss: 1414.083679\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #7530 (step 7530): 1.701420\n",
      "Batch #10\tAverage Generator Loss: 1295.964938\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #7531 (step 7531): 1.327604\n",
      "Batch #10\tAverage Generator Loss: 1150.105106\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #7532 (step 7532): 1.554078\n",
      "Batch #10\tAverage Generator Loss: 1231.811060\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #7533 (step 7533): 1.289665\n",
      "Batch #10\tAverage Generator Loss: 1336.977429\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #7534 (step 7534): 1.545094\n",
      "Batch #10\tAverage Generator Loss: 1443.267096\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #7535 (step 7535): 1.325699\n",
      "Batch #10\tAverage Generator Loss: 1386.324072\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7536 (step 7536): 1.642264\n",
      "Batch #10\tAverage Generator Loss: 1491.588312\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7537 (step 7537): 1.588904\n",
      "Batch #10\tAverage Generator Loss: 1319.300159\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #7538 (step 7538): 1.273266\n",
      "Batch #10\tAverage Generator Loss: 1132.640875\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7539 (step 7539): 1.233952\n",
      "Batch #10\tAverage Generator Loss: 1296.382642\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #7540 (step 7540): 1.605096\n",
      "Batch #10\tAverage Generator Loss: 1381.169220\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #7541 (step 7541): 1.660342\n",
      "Batch #10\tAverage Generator Loss: 1395.614136\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #7542 (step 7542): 1.360994\n",
      "Batch #10\tAverage Generator Loss: 1195.077643\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7543 (step 7543): 1.349318\n",
      "Batch #10\tAverage Generator Loss: 1310.422845\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7544 (step 7544): 1.630728\n",
      "Batch #10\tAverage Generator Loss: 1244.694135\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #7545 (step 7545): 1.550176\n",
      "Batch #10\tAverage Generator Loss: 1332.977625\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #7546 (step 7546): 1.314116\n",
      "Batch #10\tAverage Generator Loss: 1342.484277\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7547 (step 7547): 1.545341\n",
      "Batch #10\tAverage Generator Loss: 1356.651318\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #7548 (step 7548): 1.358069\n",
      "Batch #10\tAverage Generator Loss: 1000.613226\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7549 (step 7549): 1.748879\n",
      "Batch #10\tAverage Generator Loss: 1287.763196\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7550 (step 7550): 1.277432\n",
      "Batch #10\tAverage Generator Loss: 1443.653705\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7551 (step 7551): 1.700221\n",
      "Batch #10\tAverage Generator Loss: 1432.498456\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7552 (step 7552): 1.303185\n",
      "Batch #10\tAverage Generator Loss: 1349.753748\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #7553 (step 7553): 1.706681\n",
      "Batch #10\tAverage Generator Loss: 1293.453796\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7554 (step 7554): 1.466883\n",
      "Batch #10\tAverage Generator Loss: 1257.426178\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #7555 (step 7555): 1.550672\n",
      "Batch #10\tAverage Generator Loss: 1290.174500\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #7556 (step 7556): 1.386995\n",
      "Batch #10\tAverage Generator Loss: 1278.702295\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7557 (step 7557): 1.615891\n",
      "Batch #10\tAverage Generator Loss: 1228.918082\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #7558 (step 7558): 1.288553\n",
      "Batch #10\tAverage Generator Loss: 1145.796222\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #7559 (step 7559): 1.602119\n",
      "Batch #10\tAverage Generator Loss: 964.494492\tAverage Discriminator Loss: 0.000002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #7560 (step 7560): 1.387544\n",
      "Batch #10\tAverage Generator Loss: 1273.675256\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7561 (step 7561): 1.572208\n",
      "Batch #10\tAverage Generator Loss: 1266.695471\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #7562 (step 7562): 1.299100\n",
      "Batch #10\tAverage Generator Loss: 1129.133376\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #7563 (step 7563): 1.608933\n",
      "Batch #10\tAverage Generator Loss: 1242.958856\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #7564 (step 7564): 1.390941\n",
      "Batch #10\tAverage Generator Loss: 1103.895337\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #7565 (step 7565): 1.606070\n",
      "Batch #10\tAverage Generator Loss: 1292.774573\tAverage Discriminator Loss: 0.125703\n",
      "\n",
      "Train time for epoch #7566 (step 7566): 1.326046\n",
      "Batch #10\tAverage Generator Loss: 1073.046138\tAverage Discriminator Loss: 0.078048\n",
      "\n",
      "Train time for epoch #7567 (step 7567): 1.649422\n",
      "Batch #10\tAverage Generator Loss: 1223.688074\tAverage Discriminator Loss: 0.059136\n",
      "\n",
      "Train time for epoch #7568 (step 7568): 1.339740\n",
      "Batch #10\tAverage Generator Loss: 981.213214\tAverage Discriminator Loss: 0.000065\n",
      "\n",
      "Train time for epoch #7569 (step 7569): 1.556207\n",
      "Batch #10\tAverage Generator Loss: 1207.073688\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7570 (step 7570): 1.336289\n",
      "Batch #10\tAverage Generator Loss: 1059.829230\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7571 (step 7571): 1.722879\n",
      "Batch #10\tAverage Generator Loss: 918.338794\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7572 (step 7572): 1.401975\n",
      "Batch #10\tAverage Generator Loss: 1054.383020\tAverage Discriminator Loss: 0.007564\n",
      "\n",
      "Train time for epoch #7573 (step 7573): 1.539168\n",
      "Batch #10\tAverage Generator Loss: 1185.454965\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7574 (step 7574): 1.451962\n",
      "Batch #10\tAverage Generator Loss: 1656.075836\tAverage Discriminator Loss: 0.010885\n",
      "\n",
      "Train time for epoch #7575 (step 7575): 1.553522\n",
      "Batch #10\tAverage Generator Loss: 1481.893848\tAverage Discriminator Loss: 0.000134\n",
      "\n",
      "Train time for epoch #7576 (step 7576): 1.455597\n",
      "Batch #10\tAverage Generator Loss: 1656.522998\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7577 (step 7577): 1.789721\n",
      "Batch #10\tAverage Generator Loss: 1347.578357\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7578 (step 7578): 1.339711\n",
      "Batch #10\tAverage Generator Loss: 1636.492725\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7579 (step 7579): 1.542222\n",
      "Batch #10\tAverage Generator Loss: 1313.797070\tAverage Discriminator Loss: 0.105694\n",
      "\n",
      "Train time for epoch #7580 (step 7580): 1.686302\n",
      "Batch #10\tAverage Generator Loss: 1470.253558\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7581 (step 7581): 1.351484\n",
      "Batch #10\tAverage Generator Loss: 1158.801886\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7582 (step 7582): 1.331266\n",
      "Batch #10\tAverage Generator Loss: 1144.782840\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7583 (step 7583): 1.644883\n",
      "Batch #10\tAverage Generator Loss: 1203.527405\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7584 (step 7584): 1.290600\n",
      "Batch #10\tAverage Generator Loss: 1243.481805\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7585 (step 7585): 1.592814\n",
      "Batch #10\tAverage Generator Loss: 1352.948578\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7586 (step 7586): 1.664150\n",
      "Batch #10\tAverage Generator Loss: 1272.389435\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7587 (step 7587): 1.336258\n",
      "Batch #10\tAverage Generator Loss: 1332.496063\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7588 (step 7588): 1.629111\n",
      "Batch #10\tAverage Generator Loss: 1280.101331\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7589 (step 7589): 1.352234\n",
      "Batch #10\tAverage Generator Loss: 1306.391968\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7590 (step 7590): 1.403996\n",
      "Batch #10\tAverage Generator Loss: 1233.979620\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7591 (step 7591): 1.557227\n",
      "Batch #10\tAverage Generator Loss: 1118.764996\tAverage Discriminator Loss: 0.044047\n",
      "\n",
      "Train time for epoch #7592 (step 7592): 1.565181\n",
      "Batch #10\tAverage Generator Loss: 1146.242609\tAverage Discriminator Loss: 0.000079\n",
      "\n",
      "Train time for epoch #7593 (step 7593): 1.292931\n",
      "Batch #10\tAverage Generator Loss: 1178.663766\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #7594 (step 7594): 1.352498\n",
      "Batch #10\tAverage Generator Loss: 1023.166681\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #7595 (step 7595): 1.615436\n",
      "Batch #10\tAverage Generator Loss: 1166.003140\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #7596 (step 7596): 1.558129\n",
      "Batch #10\tAverage Generator Loss: 995.796524\tAverage Discriminator Loss: 0.093668\n",
      "\n",
      "Train time for epoch #7597 (step 7597): 1.325818\n",
      "Batch #10\tAverage Generator Loss: 1036.404620\tAverage Discriminator Loss: 0.019793\n",
      "\n",
      "Train time for epoch #7598 (step 7598): 1.606365\n",
      "Batch #10\tAverage Generator Loss: 1116.210583\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7599 (step 7599): 1.269125\n",
      "Batch #10\tAverage Generator Loss: 1039.770642\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7600 (step 7600): 1.548725\n",
      "Batch #10\tAverage Generator Loss: 1061.936475\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7601 (step 7601): 1.387925\n",
      "Batch #10\tAverage Generator Loss: 1081.759729\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7602 (step 7602): 1.635710\n",
      "Batch #10\tAverage Generator Loss: 1040.541779\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7603 (step 7603): 1.349216\n",
      "Batch #10\tAverage Generator Loss: 1038.834851\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7604 (step 7604): 1.567358\n",
      "Batch #10\tAverage Generator Loss: 967.452008\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7605 (step 7605): 1.328006\n",
      "Batch #10\tAverage Generator Loss: 999.437848\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7606 (step 7606): 1.553274\n",
      "Batch #10\tAverage Generator Loss: 963.949658\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7607 (step 7607): 1.293704\n",
      "Batch #10\tAverage Generator Loss: 962.731665\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7608 (step 7608): 1.752988\n",
      "Batch #10\tAverage Generator Loss: 964.997241\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7609 (step 7609): 1.290284\n",
      "Batch #10\tAverage Generator Loss: 991.247223\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7610 (step 7610): 1.634394\n",
      "Batch #10\tAverage Generator Loss: 888.130496\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7611 (step 7611): 1.427746\n",
      "Batch #10\tAverage Generator Loss: 1006.541705\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7612 (step 7612): 1.604618\n",
      "Batch #10\tAverage Generator Loss: 993.634302\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7613 (step 7613): 1.356040\n",
      "Batch #10\tAverage Generator Loss: 899.171088\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7614 (step 7614): 1.560239\n",
      "Batch #10\tAverage Generator Loss: 878.488577\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7615 (step 7615): 1.296474\n",
      "Batch #10\tAverage Generator Loss: 974.330975\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7616 (step 7616): 1.574949\n",
      "Batch #10\tAverage Generator Loss: 962.686572\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7617 (step 7617): 1.477056\n",
      "Batch #10\tAverage Generator Loss: 986.970026\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7618 (step 7618): 1.558360\n",
      "Batch #10\tAverage Generator Loss: 811.127087\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7619 (step 7619): 1.362467\n",
      "Batch #10\tAverage Generator Loss: 990.493860\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7620 (step 7620): 1.703486\n",
      "Batch #10\tAverage Generator Loss: 839.795370\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7621 (step 7621): 1.342452\n",
      "Batch #10\tAverage Generator Loss: 960.581866\tAverage Discriminator Loss: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #7622 (step 7622): 1.573868\n",
      "Batch #10\tAverage Generator Loss: 895.538751\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7623 (step 7623): 1.409473\n",
      "Batch #10\tAverage Generator Loss: 968.216052\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7624 (step 7624): 1.538890\n",
      "Batch #10\tAverage Generator Loss: 905.856128\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7625 (step 7625): 1.328811\n",
      "Batch #10\tAverage Generator Loss: 867.287451\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7626 (step 7626): 1.609554\n",
      "Batch #10\tAverage Generator Loss: 1017.204816\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7627 (step 7627): 1.417473\n",
      "Batch #10\tAverage Generator Loss: 1063.744440\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #7628 (step 7628): 1.659461\n",
      "Batch #10\tAverage Generator Loss: 863.841852\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7629 (step 7629): 1.517546\n",
      "Batch #10\tAverage Generator Loss: 1066.276144\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7630 (step 7630): 1.401823\n",
      "Batch #10\tAverage Generator Loss: 959.237860\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7631 (step 7631): 1.607257\n",
      "Batch #10\tAverage Generator Loss: 878.825745\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7632 (step 7632): 1.285636\n",
      "Batch #10\tAverage Generator Loss: 913.501825\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7633 (step 7633): 1.652109\n",
      "Batch #10\tAverage Generator Loss: 955.979944\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7634 (step 7634): 1.350340\n",
      "Batch #10\tAverage Generator Loss: 787.587292\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7635 (step 7635): 1.581720\n",
      "Batch #10\tAverage Generator Loss: 906.390619\tAverage Discriminator Loss: 0.005829\n",
      "\n",
      "Train time for epoch #7636 (step 7636): 1.291098\n",
      "Batch #10\tAverage Generator Loss: 1072.235345\tAverage Discriminator Loss: 0.000677\n",
      "\n",
      "Train time for epoch #7637 (step 7637): 1.563947\n",
      "Batch #10\tAverage Generator Loss: 1095.637000\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7638 (step 7638): 1.300950\n",
      "Batch #10\tAverage Generator Loss: 976.721863\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7639 (step 7639): 1.614532\n",
      "Batch #10\tAverage Generator Loss: 884.928088\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7640 (step 7640): 1.294501\n",
      "Batch #10\tAverage Generator Loss: 875.417691\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7641 (step 7641): 1.570125\n",
      "Batch #10\tAverage Generator Loss: 1118.849591\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7642 (step 7642): 1.360335\n",
      "Batch #10\tAverage Generator Loss: 991.455792\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7643 (step 7643): 1.656027\n",
      "Batch #10\tAverage Generator Loss: 881.038904\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7644 (step 7644): 1.288585\n",
      "Batch #10\tAverage Generator Loss: 901.650513\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7645 (step 7645): 1.552762\n",
      "Batch #10\tAverage Generator Loss: 917.687280\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7646 (step 7646): 1.343152\n",
      "Batch #10\tAverage Generator Loss: 955.814627\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7647 (step 7647): 1.512571\n",
      "Batch #10\tAverage Generator Loss: 1054.505725\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7648 (step 7648): 1.420026\n",
      "Batch #10\tAverage Generator Loss: 929.908813\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7649 (step 7649): 1.597659\n",
      "Batch #10\tAverage Generator Loss: 987.277625\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7650 (step 7650): 1.407696\n",
      "Batch #10\tAverage Generator Loss: 1037.787115\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #7651 (step 7651): 1.643813\n",
      "Batch #10\tAverage Generator Loss: 881.633038\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7652 (step 7652): 1.506435\n",
      "Batch #10\tAverage Generator Loss: 928.431088\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7653 (step 7653): 1.659293\n",
      "Batch #10\tAverage Generator Loss: 907.545593\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7654 (step 7654): 1.289837\n",
      "Batch #10\tAverage Generator Loss: 928.228052\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7655 (step 7655): 1.605460\n",
      "Batch #10\tAverage Generator Loss: 863.663318\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7656 (step 7656): 1.292433\n",
      "Batch #10\tAverage Generator Loss: 937.687775\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7657 (step 7657): 1.595252\n",
      "Batch #10\tAverage Generator Loss: 916.133411\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7658 (step 7658): 1.392648\n",
      "Batch #10\tAverage Generator Loss: 782.884253\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7659 (step 7659): 1.588683\n",
      "Batch #10\tAverage Generator Loss: 851.791031\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7660 (step 7660): 1.272539\n",
      "Batch #10\tAverage Generator Loss: 974.767407\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7661 (step 7661): 1.553091\n",
      "Batch #10\tAverage Generator Loss: 924.886115\tAverage Discriminator Loss: 0.000683\n",
      "\n",
      "Train time for epoch #7662 (step 7662): 1.324742\n",
      "Batch #10\tAverage Generator Loss: 1030.695715\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #7663 (step 7663): 1.656326\n",
      "Batch #10\tAverage Generator Loss: 1067.476898\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #7664 (step 7664): 1.302579\n",
      "Batch #10\tAverage Generator Loss: 929.021628\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #7665 (step 7665): 1.557758\n",
      "Batch #10\tAverage Generator Loss: 960.612213\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #7666 (step 7666): 1.288730\n",
      "Batch #10\tAverage Generator Loss: 1002.705450\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #7667 (step 7667): 1.633759\n",
      "Batch #10\tAverage Generator Loss: 888.897198\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #7668 (step 7668): 1.349934\n",
      "Batch #10\tAverage Generator Loss: 905.109772\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #7669 (step 7669): 1.634590\n",
      "Batch #10\tAverage Generator Loss: 872.496906\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #7670 (step 7670): 1.292188\n",
      "Batch #10\tAverage Generator Loss: 1061.777411\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #7671 (step 7671): 1.512126\n",
      "Batch #10\tAverage Generator Loss: 986.464740\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #7672 (step 7672): 1.430819\n",
      "Batch #10\tAverage Generator Loss: 993.494397\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #7673 (step 7673): 1.571383\n",
      "Batch #10\tAverage Generator Loss: 1036.978009\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #7674 (step 7674): 1.478492\n",
      "Batch #10\tAverage Generator Loss: 1084.880084\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #7675 (step 7675): 1.666820\n",
      "Batch #10\tAverage Generator Loss: 1082.639203\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #7676 (step 7676): 1.425575\n",
      "Batch #10\tAverage Generator Loss: 941.144116\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #7677 (step 7677): 1.512083\n",
      "Batch #10\tAverage Generator Loss: 1018.796283\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #7678 (step 7678): 1.351305\n",
      "Batch #10\tAverage Generator Loss: 932.588425\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #7679 (step 7679): 1.562799\n",
      "Batch #10\tAverage Generator Loss: 1073.100867\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #7680 (step 7680): 1.391228\n",
      "Batch #10\tAverage Generator Loss: 907.550311\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #7681 (step 7681): 1.599710\n",
      "Batch #10\tAverage Generator Loss: 882.394617\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #7682 (step 7682): 1.387090\n",
      "Batch #10\tAverage Generator Loss: 934.789148\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #7683 (step 7683): 1.681531\n",
      "Batch #10\tAverage Generator Loss: 950.706030\tAverage Discriminator Loss: 0.000004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #7684 (step 7684): 1.288511\n",
      "Batch #10\tAverage Generator Loss: 885.707028\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #7685 (step 7685): 1.571328\n",
      "Batch #10\tAverage Generator Loss: 967.895648\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7686 (step 7686): 1.347015\n",
      "Batch #10\tAverage Generator Loss: 1026.285620\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #7687 (step 7687): 1.559274\n",
      "Batch #10\tAverage Generator Loss: 895.785516\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #7688 (step 7688): 1.311999\n",
      "Batch #10\tAverage Generator Loss: 981.965753\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #7689 (step 7689): 1.604388\n",
      "Batch #10\tAverage Generator Loss: 919.343549\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #7690 (step 7690): 1.281692\n",
      "Batch #10\tAverage Generator Loss: 1046.225381\tAverage Discriminator Loss: 0.000169\n",
      "\n",
      "Train time for epoch #7691 (step 7691): 1.509196\n",
      "Batch #10\tAverage Generator Loss: 997.686658\tAverage Discriminator Loss: 0.000031\n",
      "\n",
      "Train time for epoch #7692 (step 7692): 1.345251\n",
      "Batch #10\tAverage Generator Loss: 1022.698404\tAverage Discriminator Loss: 0.068704\n",
      "\n",
      "Train time for epoch #7693 (step 7693): 1.551600\n",
      "Batch #10\tAverage Generator Loss: 1013.745117\tAverage Discriminator Loss: 0.006243\n",
      "\n",
      "Train time for epoch #7694 (step 7694): 1.302549\n",
      "Batch #10\tAverage Generator Loss: 1027.321179\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #7695 (step 7695): 1.621827\n",
      "Batch #10\tAverage Generator Loss: 957.217657\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #7696 (step 7696): 1.327142\n",
      "Batch #10\tAverage Generator Loss: 945.208340\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #7697 (step 7697): 1.614064\n",
      "Batch #10\tAverage Generator Loss: 856.387817\tAverage Discriminator Loss: 0.103386\n",
      "\n",
      "Train time for epoch #7698 (step 7698): 1.331753\n",
      "Batch #10\tAverage Generator Loss: 784.290622\tAverage Discriminator Loss: 0.016290\n",
      "\n",
      "Train time for epoch #7699 (step 7699): 1.633668\n",
      "Batch #10\tAverage Generator Loss: 759.490057\tAverage Discriminator Loss: 0.001993\n",
      "\n",
      "Train time for epoch #7700 (step 7700): 1.381424\n",
      "Batch #10\tAverage Generator Loss: 839.787537\tAverage Discriminator Loss: 0.000481\n",
      "\n",
      "Train time for epoch #7701 (step 7701): 1.612397\n",
      "Batch #10\tAverage Generator Loss: 846.380237\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #7702 (step 7702): 1.393263\n",
      "Batch #10\tAverage Generator Loss: 720.172464\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #7703 (step 7703): 1.608186\n",
      "Batch #10\tAverage Generator Loss: 760.316528\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7704 (step 7704): 1.384161\n",
      "Batch #10\tAverage Generator Loss: 685.519235\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7705 (step 7705): 1.672813\n",
      "Batch #10\tAverage Generator Loss: 761.833856\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7706 (step 7706): 1.239536\n",
      "Batch #10\tAverage Generator Loss: 888.953461\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7707 (step 7707): 1.558262\n",
      "Batch #10\tAverage Generator Loss: 753.171793\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7708 (step 7708): 1.444919\n",
      "Batch #10\tAverage Generator Loss: 804.113037\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7709 (step 7709): 1.635920\n",
      "Batch #10\tAverage Generator Loss: 756.775650\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7710 (step 7710): 1.493865\n",
      "Batch #10\tAverage Generator Loss: 781.954663\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7711 (step 7711): 1.662484\n",
      "Batch #10\tAverage Generator Loss: 833.537439\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7712 (step 7712): 1.468123\n",
      "Batch #10\tAverage Generator Loss: 789.318890\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7713 (step 7713): 1.732436\n",
      "Batch #10\tAverage Generator Loss: 802.647253\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7714 (step 7714): 1.666920\n",
      "Batch #10\tAverage Generator Loss: 799.616107\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7715 (step 7715): 1.329253\n",
      "Batch #10\tAverage Generator Loss: 674.153156\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7716 (step 7716): 1.702570\n",
      "Batch #10\tAverage Generator Loss: 721.134941\tAverage Discriminator Loss: 0.006095\n",
      "\n",
      "Train time for epoch #7717 (step 7717): 1.478964\n",
      "Batch #10\tAverage Generator Loss: 1106.793118\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7718 (step 7718): 1.666703\n",
      "Batch #10\tAverage Generator Loss: 1148.988654\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7719 (step 7719): 1.254114\n",
      "Batch #10\tAverage Generator Loss: 1231.753485\tAverage Discriminator Loss: 0.000380\n",
      "\n",
      "Train time for epoch #7720 (step 7720): 1.565917\n",
      "Batch #10\tAverage Generator Loss: 1069.292511\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7721 (step 7721): 1.398643\n",
      "Batch #10\tAverage Generator Loss: 1212.979987\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7722 (step 7722): 1.596346\n",
      "Batch #10\tAverage Generator Loss: 1115.129608\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7723 (step 7723): 1.284832\n",
      "Batch #10\tAverage Generator Loss: 984.799454\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7724 (step 7724): 1.561085\n",
      "Batch #10\tAverage Generator Loss: 1216.899921\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7725 (step 7725): 1.334406\n",
      "Batch #10\tAverage Generator Loss: 1071.226468\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7726 (step 7726): 1.664582\n",
      "Batch #10\tAverage Generator Loss: 1218.687738\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7727 (step 7727): 1.300143\n",
      "Batch #10\tAverage Generator Loss: 1303.599994\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7728 (step 7728): 1.698883\n",
      "Batch #10\tAverage Generator Loss: 1034.715857\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7729 (step 7729): 1.340353\n",
      "Batch #10\tAverage Generator Loss: 1432.477411\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7730 (step 7730): 1.766903\n",
      "Batch #10\tAverage Generator Loss: 1240.742566\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7731 (step 7731): 1.428371\n",
      "Batch #10\tAverage Generator Loss: 1299.315094\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7732 (step 7732): 1.539773\n",
      "Batch #10\tAverage Generator Loss: 1255.218524\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7733 (step 7733): 1.329687\n",
      "Batch #10\tAverage Generator Loss: 1344.017133\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7734 (step 7734): 1.624136\n",
      "Batch #10\tAverage Generator Loss: 1279.561047\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7735 (step 7735): 1.398739\n",
      "Batch #10\tAverage Generator Loss: 1147.179016\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7736 (step 7736): 1.585822\n",
      "Batch #10\tAverage Generator Loss: 1250.839508\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7737 (step 7737): 1.289994\n",
      "Batch #10\tAverage Generator Loss: 1160.927536\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7738 (step 7738): 1.603128\n",
      "Batch #10\tAverage Generator Loss: 1146.126501\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7739 (step 7739): 1.351599\n",
      "Batch #10\tAverage Generator Loss: 1141.869452\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7740 (step 7740): 1.628255\n",
      "Batch #10\tAverage Generator Loss: 1176.740887\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7741 (step 7741): 1.317436\n",
      "Batch #10\tAverage Generator Loss: 1304.927802\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7742 (step 7742): 1.687782\n",
      "Batch #10\tAverage Generator Loss: 946.715436\tAverage Discriminator Loss: 0.146453\n",
      "\n",
      "Train time for epoch #7743 (step 7743): 1.395429\n",
      "Batch #10\tAverage Generator Loss: 938.178394\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7744 (step 7744): 1.557611\n",
      "Batch #10\tAverage Generator Loss: 818.437717\tAverage Discriminator Loss: 0.019948\n",
      "\n",
      "Train time for epoch #7745 (step 7745): 1.323382\n",
      "Batch #10\tAverage Generator Loss: 734.332440\tAverage Discriminator Loss: 0.000002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #7746 (step 7746): 1.675240\n",
      "Batch #10\tAverage Generator Loss: 778.735941\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7747 (step 7747): 1.438538\n",
      "Batch #10\tAverage Generator Loss: 660.105132\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7748 (step 7748): 1.628379\n",
      "Batch #10\tAverage Generator Loss: 934.035858\tAverage Discriminator Loss: 0.022602\n",
      "\n",
      "Train time for epoch #7749 (step 7749): 1.426574\n",
      "Batch #10\tAverage Generator Loss: 1064.021985\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #7750 (step 7750): 1.581956\n",
      "Batch #10\tAverage Generator Loss: 1079.728589\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7751 (step 7751): 1.475585\n",
      "Batch #10\tAverage Generator Loss: 1068.380347\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7752 (step 7752): 1.567297\n",
      "Batch #10\tAverage Generator Loss: 970.622998\tAverage Discriminator Loss: 0.004908\n",
      "\n",
      "Train time for epoch #7753 (step 7753): 1.344980\n",
      "Batch #10\tAverage Generator Loss: 1159.678445\tAverage Discriminator Loss: 0.003220\n",
      "\n",
      "Train time for epoch #7754 (step 7754): 1.583278\n",
      "Batch #10\tAverage Generator Loss: 1006.403757\tAverage Discriminator Loss: 0.105469\n",
      "\n",
      "Train time for epoch #7755 (step 7755): 1.293636\n",
      "Batch #10\tAverage Generator Loss: 1225.129071\tAverage Discriminator Loss: 0.002895\n",
      "\n",
      "Train time for epoch #7756 (step 7756): 1.629007\n",
      "Batch #10\tAverage Generator Loss: 1020.722986\tAverage Discriminator Loss: 0.000035\n",
      "\n",
      "Train time for epoch #7757 (step 7757): 1.436903\n",
      "Batch #10\tAverage Generator Loss: 1211.046582\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #7758 (step 7758): 1.731404\n",
      "Batch #10\tAverage Generator Loss: 1209.693604\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #7759 (step 7759): 1.395869\n",
      "Batch #10\tAverage Generator Loss: 1126.038565\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #7760 (step 7760): 1.561902\n",
      "Batch #10\tAverage Generator Loss: 1158.214539\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #7761 (step 7761): 1.325384\n",
      "Batch #10\tAverage Generator Loss: 1211.198657\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #7762 (step 7762): 1.633849\n",
      "Batch #10\tAverage Generator Loss: 1229.014331\tAverage Discriminator Loss: 0.080451\n",
      "\n",
      "Train time for epoch #7763 (step 7763): 1.349966\n",
      "Batch #10\tAverage Generator Loss: 1180.503772\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7764 (step 7764): 1.569588\n",
      "Batch #10\tAverage Generator Loss: 1025.313290\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7765 (step 7765): 1.288511\n",
      "Batch #10\tAverage Generator Loss: 1199.591083\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7766 (step 7766): 1.718871\n",
      "Batch #10\tAverage Generator Loss: 991.792163\tAverage Discriminator Loss: 0.066263\n",
      "\n",
      "Train time for epoch #7767 (step 7767): 1.377945\n",
      "Batch #10\tAverage Generator Loss: 1247.053235\tAverage Discriminator Loss: 0.000270\n",
      "\n",
      "Train time for epoch #7768 (step 7768): 1.506949\n",
      "Batch #10\tAverage Generator Loss: 1132.147736\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #7769 (step 7769): 1.344124\n",
      "Batch #10\tAverage Generator Loss: 1153.106934\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7770 (step 7770): 1.627738\n",
      "Batch #10\tAverage Generator Loss: 1148.454639\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7771 (step 7771): 1.389866\n",
      "Batch #10\tAverage Generator Loss: 1027.120819\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7772 (step 7772): 1.664645\n",
      "Batch #10\tAverage Generator Loss: 994.530688\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7773 (step 7773): 1.342116\n",
      "Batch #10\tAverage Generator Loss: 1120.085010\tAverage Discriminator Loss: 0.006358\n",
      "\n",
      "Train time for epoch #7774 (step 7774): 1.571569\n",
      "Batch #10\tAverage Generator Loss: 1211.985278\tAverage Discriminator Loss: 0.001460\n",
      "\n",
      "Train time for epoch #7775 (step 7775): 1.449721\n",
      "Batch #10\tAverage Generator Loss: 1228.803888\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #7776 (step 7776): 1.562813\n",
      "Batch #10\tAverage Generator Loss: 1143.018036\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7777 (step 7777): 1.603863\n",
      "Batch #10\tAverage Generator Loss: 1229.194531\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7778 (step 7778): 1.257217\n",
      "Batch #10\tAverage Generator Loss: 1320.599786\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7779 (step 7779): 1.618926\n",
      "Batch #10\tAverage Generator Loss: 1174.388065\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7780 (step 7780): 1.346267\n",
      "Batch #10\tAverage Generator Loss: 1276.476868\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7781 (step 7781): 1.648556\n",
      "Batch #10\tAverage Generator Loss: 1227.828278\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7782 (step 7782): 1.300240\n",
      "Batch #10\tAverage Generator Loss: 1119.341391\tAverage Discriminator Loss: 0.013555\n",
      "\n",
      "Train time for epoch #7783 (step 7783): 1.655214\n",
      "Batch #10\tAverage Generator Loss: 1389.304871\tAverage Discriminator Loss: 0.005833\n",
      "\n",
      "Train time for epoch #7784 (step 7784): 1.292889\n",
      "Batch #10\tAverage Generator Loss: 1196.758246\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #7785 (step 7785): 1.564506\n",
      "Batch #10\tAverage Generator Loss: 1163.523254\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7786 (step 7786): 1.440748\n",
      "Batch #10\tAverage Generator Loss: 1193.470355\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7787 (step 7787): 1.633079\n",
      "Batch #10\tAverage Generator Loss: 1147.198846\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7788 (step 7788): 1.350382\n",
      "Batch #10\tAverage Generator Loss: 1174.028162\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #7789 (step 7789): 1.633762\n",
      "Batch #10\tAverage Generator Loss: 1137.306464\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7790 (step 7790): 1.338334\n",
      "Batch #10\tAverage Generator Loss: 1130.391150\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7791 (step 7791): 1.619024\n",
      "Batch #10\tAverage Generator Loss: 1137.221912\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7792 (step 7792): 1.332206\n",
      "Batch #10\tAverage Generator Loss: 1150.072855\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7793 (step 7793): 1.541931\n",
      "Batch #10\tAverage Generator Loss: 1247.622296\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7794 (step 7794): 1.292579\n",
      "Batch #10\tAverage Generator Loss: 1091.499652\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7795 (step 7795): 1.698287\n",
      "Batch #10\tAverage Generator Loss: 1054.812122\tAverage Discriminator Loss: 0.000045\n",
      "\n",
      "Train time for epoch #7796 (step 7796): 1.253410\n",
      "Batch #10\tAverage Generator Loss: 1143.795343\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7797 (step 7797): 1.651834\n",
      "Batch #10\tAverage Generator Loss: 1193.487549\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7798 (step 7798): 1.298372\n",
      "Batch #10\tAverage Generator Loss: 1138.877881\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7799 (step 7799): 1.574638\n",
      "Batch #10\tAverage Generator Loss: 1171.520172\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7800 (step 7800): 1.389047\n",
      "Batch #10\tAverage Generator Loss: 1083.279391\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7801 (step 7801): 1.716033\n",
      "Batch #10\tAverage Generator Loss: 1148.844946\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7802 (step 7802): 1.389686\n",
      "Batch #10\tAverage Generator Loss: 1234.679755\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7803 (step 7803): 1.643903\n",
      "Batch #10\tAverage Generator Loss: 1201.659985\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7804 (step 7804): 1.340170\n",
      "Batch #10\tAverage Generator Loss: 1080.330817\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7805 (step 7805): 1.608324\n",
      "Batch #10\tAverage Generator Loss: 1119.819263\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7806 (step 7806): 1.333474\n",
      "Batch #10\tAverage Generator Loss: 1035.125885\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7807 (step 7807): 1.733548\n",
      "Batch #10\tAverage Generator Loss: 1188.006403\tAverage Discriminator Loss: 0.000001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #7808 (step 7808): 1.291141\n",
      "Batch #10\tAverage Generator Loss: 1158.692255\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7809 (step 7809): 1.686182\n",
      "Batch #10\tAverage Generator Loss: 1296.439319\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7810 (step 7810): 1.335039\n",
      "Batch #10\tAverage Generator Loss: 1248.824847\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7811 (step 7811): 1.747702\n",
      "Batch #10\tAverage Generator Loss: 1085.399384\tAverage Discriminator Loss: 0.016651\n",
      "\n",
      "Train time for epoch #7812 (step 7812): 1.297684\n",
      "Batch #10\tAverage Generator Loss: 1162.367523\tAverage Discriminator Loss: 0.001023\n",
      "\n",
      "Train time for epoch #7813 (step 7813): 1.597066\n",
      "Batch #10\tAverage Generator Loss: 1078.020728\tAverage Discriminator Loss: 0.017021\n",
      "\n",
      "Train time for epoch #7814 (step 7814): 1.293850\n",
      "Batch #10\tAverage Generator Loss: 1253.745032\tAverage Discriminator Loss: 0.000303\n",
      "\n",
      "Train time for epoch #7815 (step 7815): 1.600132\n",
      "Batch #10\tAverage Generator Loss: 1117.332483\tAverage Discriminator Loss: 0.000102\n",
      "\n",
      "Train time for epoch #7816 (step 7816): 1.382173\n",
      "Batch #10\tAverage Generator Loss: 1222.747174\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #7817 (step 7817): 1.559673\n",
      "Batch #10\tAverage Generator Loss: 1275.968512\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #7818 (step 7818): 1.298450\n",
      "Batch #10\tAverage Generator Loss: 1085.015088\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #7819 (step 7819): 1.512516\n",
      "Batch #10\tAverage Generator Loss: 1145.865198\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #7820 (step 7820): 1.335732\n",
      "Batch #10\tAverage Generator Loss: 1095.749405\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #7821 (step 7821): 1.701618\n",
      "Batch #10\tAverage Generator Loss: 1216.432880\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #7822 (step 7822): 1.347313\n",
      "Batch #10\tAverage Generator Loss: 1146.474124\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #7823 (step 7823): 1.617851\n",
      "Batch #10\tAverage Generator Loss: 1327.534668\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #7824 (step 7824): 1.364336\n",
      "Batch #10\tAverage Generator Loss: 1210.014716\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #7825 (step 7825): 1.267788\n",
      "Batch #10\tAverage Generator Loss: 1197.454529\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #7826 (step 7826): 1.572639\n",
      "Batch #10\tAverage Generator Loss: 1168.752960\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #7827 (step 7827): 1.455650\n",
      "Batch #10\tAverage Generator Loss: 1252.399817\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7828 (step 7828): 1.630247\n",
      "Batch #10\tAverage Generator Loss: 1175.945837\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #7829 (step 7829): 1.336185\n",
      "Batch #10\tAverage Generator Loss: 1060.836876\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #7830 (step 7830): 1.630385\n",
      "Batch #10\tAverage Generator Loss: 1086.670459\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7831 (step 7831): 1.379283\n",
      "Batch #10\tAverage Generator Loss: 1035.626917\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7832 (step 7832): 1.576387\n",
      "Batch #10\tAverage Generator Loss: 1175.964307\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7833 (step 7833): 1.297231\n",
      "Batch #10\tAverage Generator Loss: 1196.444952\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7834 (step 7834): 1.629735\n",
      "Batch #10\tAverage Generator Loss: 1184.357513\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7835 (step 7835): 1.290380\n",
      "Batch #10\tAverage Generator Loss: 1231.785126\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #7836 (step 7836): 1.690860\n",
      "Batch #10\tAverage Generator Loss: 1214.469965\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7837 (step 7837): 1.429441\n",
      "Batch #10\tAverage Generator Loss: 1151.687189\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #7838 (step 7838): 1.663414\n",
      "Batch #10\tAverage Generator Loss: 1192.886365\tAverage Discriminator Loss: 0.000733\n",
      "\n",
      "Train time for epoch #7839 (step 7839): 1.288600\n",
      "Batch #10\tAverage Generator Loss: 1102.366379\tAverage Discriminator Loss: 0.000047\n",
      "\n",
      "Train time for epoch #7840 (step 7840): 1.587164\n",
      "Batch #10\tAverage Generator Loss: 1060.835199\tAverage Discriminator Loss: 0.000038\n",
      "\n",
      "Train time for epoch #7841 (step 7841): 1.303381\n",
      "Batch #10\tAverage Generator Loss: 1132.631671\tAverage Discriminator Loss: 0.000019\n",
      "\n",
      "Train time for epoch #7842 (step 7842): 1.571422\n",
      "Batch #10\tAverage Generator Loss: 1168.489423\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #7843 (step 7843): 1.386884\n",
      "Batch #10\tAverage Generator Loss: 1180.999805\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #7844 (step 7844): 1.576437\n",
      "Batch #10\tAverage Generator Loss: 1229.621930\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #7845 (step 7845): 1.295412\n",
      "Batch #10\tAverage Generator Loss: 1176.123132\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #7846 (step 7846): 1.615916\n",
      "Batch #10\tAverage Generator Loss: 1084.873657\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #7847 (step 7847): 1.288522\n",
      "Batch #10\tAverage Generator Loss: 1257.045593\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #7848 (step 7848): 1.568906\n",
      "Batch #10\tAverage Generator Loss: 1057.453577\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #7849 (step 7849): 1.394039\n",
      "Batch #10\tAverage Generator Loss: 1109.952417\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #7850 (step 7850): 1.558288\n",
      "Batch #10\tAverage Generator Loss: 1050.480780\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #7851 (step 7851): 1.295270\n",
      "Batch #10\tAverage Generator Loss: 1093.094934\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #7852 (step 7852): 1.513020\n",
      "Batch #10\tAverage Generator Loss: 1101.605719\tAverage Discriminator Loss: 0.015381\n",
      "\n",
      "Train time for epoch #7853 (step 7853): 1.335347\n",
      "Batch #10\tAverage Generator Loss: 1084.481509\tAverage Discriminator Loss: 0.000620\n",
      "\n",
      "Train time for epoch #7854 (step 7854): 1.753629\n",
      "Batch #10\tAverage Generator Loss: 1131.705548\tAverage Discriminator Loss: 0.000021\n",
      "\n",
      "Train time for epoch #7855 (step 7855): 1.291741\n",
      "Batch #10\tAverage Generator Loss: 1060.085266\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #7856 (step 7856): 1.574936\n",
      "Batch #10\tAverage Generator Loss: 1186.619727\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #7857 (step 7857): 1.343688\n",
      "Batch #10\tAverage Generator Loss: 978.694989\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #7858 (step 7858): 1.594296\n",
      "Batch #10\tAverage Generator Loss: 1091.174597\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #7859 (step 7859): 1.283488\n",
      "Batch #10\tAverage Generator Loss: 1201.910956\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #7860 (step 7860): 1.607105\n",
      "Batch #10\tAverage Generator Loss: 1082.042285\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #7861 (step 7861): 1.409142\n",
      "Batch #10\tAverage Generator Loss: 1138.337671\tAverage Discriminator Loss: 0.005097\n",
      "\n",
      "Train time for epoch #7862 (step 7862): 1.609181\n",
      "Batch #10\tAverage Generator Loss: 1105.369257\tAverage Discriminator Loss: 0.000539\n",
      "\n",
      "Train time for epoch #7863 (step 7863): 1.303351\n",
      "Batch #10\tAverage Generator Loss: 1128.710092\tAverage Discriminator Loss: 0.000061\n",
      "\n",
      "Train time for epoch #7864 (step 7864): 1.610251\n",
      "Batch #10\tAverage Generator Loss: 1206.440375\tAverage Discriminator Loss: 0.000023\n",
      "\n",
      "Train time for epoch #7865 (step 7865): 1.291574\n",
      "Batch #10\tAverage Generator Loss: 1111.525940\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #7866 (step 7866): 1.789269\n",
      "Batch #10\tAverage Generator Loss: 1118.388452\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #7867 (step 7867): 1.300565\n",
      "Batch #10\tAverage Generator Loss: 1113.158099\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #7868 (step 7868): 1.573007\n",
      "Batch #10\tAverage Generator Loss: 1210.444568\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #7869 (step 7869): 1.318897\n",
      "Batch #10\tAverage Generator Loss: 1142.961267\tAverage Discriminator Loss: 0.000007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #7870 (step 7870): 1.629667\n",
      "Batch #10\tAverage Generator Loss: 1274.651410\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #7871 (step 7871): 1.354799\n",
      "Batch #10\tAverage Generator Loss: 1106.758398\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #7872 (step 7872): 1.609881\n",
      "Batch #10\tAverage Generator Loss: 1202.084125\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #7873 (step 7873): 1.397729\n",
      "Batch #10\tAverage Generator Loss: 1165.594800\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #7874 (step 7874): 1.638043\n",
      "Batch #10\tAverage Generator Loss: 1160.772385\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #7875 (step 7875): 1.296968\n",
      "Batch #10\tAverage Generator Loss: 1245.212555\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #7876 (step 7876): 1.649114\n",
      "Batch #10\tAverage Generator Loss: 1189.094745\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #7877 (step 7877): 1.336240\n",
      "Batch #10\tAverage Generator Loss: 1352.058459\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #7878 (step 7878): 1.612127\n",
      "Batch #10\tAverage Generator Loss: 1230.705457\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #7879 (step 7879): 1.295863\n",
      "Batch #10\tAverage Generator Loss: 1261.890314\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #7880 (step 7880): 1.569117\n",
      "Batch #10\tAverage Generator Loss: 1182.682800\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #7881 (step 7881): 1.288343\n",
      "Batch #10\tAverage Generator Loss: 1222.055725\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #7882 (step 7882): 1.533494\n",
      "Batch #10\tAverage Generator Loss: 1178.657654\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7883 (step 7883): 1.281516\n",
      "Batch #10\tAverage Generator Loss: 1193.492896\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #7884 (step 7884): 1.629296\n",
      "Batch #10\tAverage Generator Loss: 1165.085004\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #7885 (step 7885): 1.345432\n",
      "Batch #10\tAverage Generator Loss: 1156.058667\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7886 (step 7886): 1.556167\n",
      "Batch #10\tAverage Generator Loss: 1186.119217\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #7887 (step 7887): 1.384651\n",
      "Batch #10\tAverage Generator Loss: 960.129510\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7888 (step 7888): 1.513147\n",
      "Batch #10\tAverage Generator Loss: 1117.052686\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #7889 (step 7889): 1.294585\n",
      "Batch #10\tAverage Generator Loss: 1125.874896\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7890 (step 7890): 1.561610\n",
      "Batch #10\tAverage Generator Loss: 1172.054956\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #7891 (step 7891): 1.422151\n",
      "Batch #10\tAverage Generator Loss: 1263.737524\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7892 (step 7892): 1.566399\n",
      "Batch #10\tAverage Generator Loss: 1326.230548\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7893 (step 7893): 1.369551\n",
      "Batch #10\tAverage Generator Loss: 1173.767291\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #7894 (step 7894): 1.567612\n",
      "Batch #10\tAverage Generator Loss: 1107.727301\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7895 (step 7895): 1.309641\n",
      "Batch #10\tAverage Generator Loss: 1184.802103\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7896 (step 7896): 1.800806\n",
      "Batch #10\tAverage Generator Loss: 1174.568079\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7897 (step 7897): 1.339461\n",
      "Batch #10\tAverage Generator Loss: 1139.729346\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7898 (step 7898): 1.822486\n",
      "Batch #10\tAverage Generator Loss: 1207.401801\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7899 (step 7899): 1.822174\n",
      "Batch #10\tAverage Generator Loss: 1193.124982\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7900 (step 7900): 1.779151\n",
      "Batch #10\tAverage Generator Loss: 1184.945258\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7901 (step 7901): 1.367249\n",
      "Batch #10\tAverage Generator Loss: 1160.713452\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7902 (step 7902): 1.750288\n",
      "Batch #10\tAverage Generator Loss: 1050.579462\tAverage Discriminator Loss: 0.011088\n",
      "\n",
      "Train time for epoch #7903 (step 7903): 2.243885\n",
      "Batch #10\tAverage Generator Loss: 1178.450311\tAverage Discriminator Loss: 0.006327\n",
      "\n",
      "Train time for epoch #7904 (step 7904): 1.865081\n",
      "Batch #10\tAverage Generator Loss: 1298.464215\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7905 (step 7905): 1.350374\n",
      "Batch #10\tAverage Generator Loss: 1211.415918\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7906 (step 7906): 2.044672\n",
      "Batch #10\tAverage Generator Loss: 1333.833124\tAverage Discriminator Loss: 0.002459\n",
      "\n",
      "Train time for epoch #7907 (step 7907): 1.391168\n",
      "Batch #10\tAverage Generator Loss: 1320.701178\tAverage Discriminator Loss: 0.001908\n",
      "\n",
      "Train time for epoch #7908 (step 7908): 1.761322\n",
      "Batch #10\tAverage Generator Loss: 1244.899500\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #7909 (step 7909): 1.289877\n",
      "Batch #10\tAverage Generator Loss: 1119.913022\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7910 (step 7910): 2.169410\n",
      "Batch #10\tAverage Generator Loss: 1362.291333\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7911 (step 7911): 1.318110\n",
      "Batch #10\tAverage Generator Loss: 1063.855890\tAverage Discriminator Loss: 0.002656\n",
      "\n",
      "Train time for epoch #7912 (step 7912): 1.764146\n",
      "Batch #10\tAverage Generator Loss: 1094.857635\tAverage Discriminator Loss: 0.000042\n",
      "\n",
      "Train time for epoch #7913 (step 7913): 1.336256\n",
      "Batch #10\tAverage Generator Loss: 1396.954028\tAverage Discriminator Loss: 0.033352\n",
      "\n",
      "Train time for epoch #7914 (step 7914): 1.739436\n",
      "Batch #10\tAverage Generator Loss: 1487.839087\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7915 (step 7915): 1.282764\n",
      "Batch #10\tAverage Generator Loss: 1436.927972\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7916 (step 7916): 1.569664\n",
      "Batch #10\tAverage Generator Loss: 1451.991089\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7917 (step 7917): 1.417668\n",
      "Batch #10\tAverage Generator Loss: 1523.386993\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7918 (step 7918): 1.578348\n",
      "Batch #10\tAverage Generator Loss: 1542.688837\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7919 (step 7919): 1.292973\n",
      "Batch #10\tAverage Generator Loss: 1536.588428\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7920 (step 7920): 1.574333\n",
      "Batch #10\tAverage Generator Loss: 1356.099640\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7921 (step 7921): 1.370605\n",
      "Batch #10\tAverage Generator Loss: 1427.974408\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7922 (step 7922): 1.650434\n",
      "Batch #10\tAverage Generator Loss: 1413.356946\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7923 (step 7923): 1.345949\n",
      "Batch #10\tAverage Generator Loss: 1402.023743\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7924 (step 7924): 1.578646\n",
      "Batch #10\tAverage Generator Loss: 1365.605835\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7925 (step 7925): 1.346085\n",
      "Batch #10\tAverage Generator Loss: 1495.946118\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7926 (step 7926): 1.667840\n",
      "Batch #10\tAverage Generator Loss: 1435.470984\tAverage Discriminator Loss: 0.074397\n",
      "\n",
      "Train time for epoch #7927 (step 7927): 1.418421\n",
      "Batch #10\tAverage Generator Loss: 1534.510602\tAverage Discriminator Loss: 0.029010\n",
      "\n",
      "Train time for epoch #7928 (step 7928): 1.598791\n",
      "Batch #10\tAverage Generator Loss: 1360.333429\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7929 (step 7929): 1.404109\n",
      "Batch #10\tAverage Generator Loss: 1211.000531\tAverage Discriminator Loss: 0.108629\n",
      "\n",
      "Train time for epoch #7930 (step 7930): 1.622633\n",
      "Batch #10\tAverage Generator Loss: 1225.309332\tAverage Discriminator Loss: 0.009089\n",
      "\n",
      "Train time for epoch #7931 (step 7931): 1.286531\n",
      "Batch #10\tAverage Generator Loss: 1175.323621\tAverage Discriminator Loss: 0.000001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #7932 (step 7932): 1.605477\n",
      "Batch #10\tAverage Generator Loss: 1131.654709\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #7933 (step 7933): 1.366625\n",
      "Batch #10\tAverage Generator Loss: 1125.063614\tAverage Discriminator Loss: 0.468321\n",
      "\n",
      "Train time for epoch #7934 (step 7934): 1.611354\n",
      "Batch #10\tAverage Generator Loss: 753.971347\tAverage Discriminator Loss: 0.049632\n",
      "\n",
      "Train time for epoch #7935 (step 7935): 1.290442\n",
      "Batch #10\tAverage Generator Loss: 735.957581\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7936 (step 7936): 1.636378\n",
      "Batch #10\tAverage Generator Loss: 726.911618\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7937 (step 7937): 1.380505\n",
      "Batch #10\tAverage Generator Loss: 605.522125\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7938 (step 7938): 1.666237\n",
      "Batch #10\tAverage Generator Loss: 688.355431\tAverage Discriminator Loss: 0.000864\n",
      "\n",
      "Train time for epoch #7939 (step 7939): 1.243817\n",
      "Batch #10\tAverage Generator Loss: 759.668762\tAverage Discriminator Loss: 0.050233\n",
      "\n",
      "Train time for epoch #7940 (step 7940): 1.758432\n",
      "Batch #10\tAverage Generator Loss: 1058.004132\tAverage Discriminator Loss: 0.002788\n",
      "\n",
      "Train time for epoch #7941 (step 7941): 1.323136\n",
      "Batch #10\tAverage Generator Loss: 1055.323059\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7942 (step 7942): 1.587188\n",
      "Batch #10\tAverage Generator Loss: 1044.802869\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7943 (step 7943): 1.467112\n",
      "Batch #10\tAverage Generator Loss: 1057.695566\tAverage Discriminator Loss: 0.096472\n",
      "\n",
      "Train time for epoch #7944 (step 7944): 1.617527\n",
      "Batch #10\tAverage Generator Loss: 1195.404395\tAverage Discriminator Loss: 0.125611\n",
      "\n",
      "Train time for epoch #7945 (step 7945): 1.344186\n",
      "Batch #10\tAverage Generator Loss: 1275.645245\tAverage Discriminator Loss: 0.007260\n",
      "\n",
      "Train time for epoch #7946 (step 7946): 1.675572\n",
      "Batch #10\tAverage Generator Loss: 1108.196429\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #7947 (step 7947): 1.291200\n",
      "Batch #10\tAverage Generator Loss: 1236.727716\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7948 (step 7948): 1.539432\n",
      "Batch #10\tAverage Generator Loss: 1227.131110\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7949 (step 7949): 1.300333\n",
      "Batch #10\tAverage Generator Loss: 1085.010236\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7950 (step 7950): 1.620718\n",
      "Batch #10\tAverage Generator Loss: 1193.050513\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7951 (step 7951): 1.440776\n",
      "Batch #10\tAverage Generator Loss: 1141.476855\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7952 (step 7952): 1.637657\n",
      "Batch #10\tAverage Generator Loss: 1392.536609\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7953 (step 7953): 1.282658\n",
      "Batch #10\tAverage Generator Loss: 1152.376974\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7954 (step 7954): 1.584606\n",
      "Batch #10\tAverage Generator Loss: 1219.993011\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7955 (step 7955): 1.283177\n",
      "Batch #10\tAverage Generator Loss: 1128.752972\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7956 (step 7956): 1.534469\n",
      "Batch #10\tAverage Generator Loss: 1238.173822\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7957 (step 7957): 1.289177\n",
      "Batch #10\tAverage Generator Loss: 1129.948376\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7958 (step 7958): 1.588298\n",
      "Batch #10\tAverage Generator Loss: 1151.895764\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7959 (step 7959): 1.290877\n",
      "Batch #10\tAverage Generator Loss: 1322.578448\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7960 (step 7960): 1.620553\n",
      "Batch #10\tAverage Generator Loss: 1234.935120\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7961 (step 7961): 1.305943\n",
      "Batch #10\tAverage Generator Loss: 1212.331549\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7962 (step 7962): 1.609778\n",
      "Batch #10\tAverage Generator Loss: 1315.908484\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7963 (step 7963): 1.406220\n",
      "Batch #10\tAverage Generator Loss: 1264.211072\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7964 (step 7964): 1.556609\n",
      "Batch #10\tAverage Generator Loss: 1308.635242\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7965 (step 7965): 1.270601\n",
      "Batch #10\tAverage Generator Loss: 1247.780701\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7966 (step 7966): 1.614384\n",
      "Batch #10\tAverage Generator Loss: 1248.730377\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7967 (step 7967): 1.378451\n",
      "Batch #10\tAverage Generator Loss: 1367.398169\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7968 (step 7968): 1.611683\n",
      "Batch #10\tAverage Generator Loss: 1229.526434\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7969 (step 7969): 1.284032\n",
      "Batch #10\tAverage Generator Loss: 1194.030353\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7970 (step 7970): 1.630460\n",
      "Batch #10\tAverage Generator Loss: 1268.640033\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7971 (step 7971): 1.352395\n",
      "Batch #10\tAverage Generator Loss: 1142.503577\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7972 (step 7972): 1.615312\n",
      "Batch #10\tAverage Generator Loss: 1187.236920\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7973 (step 7973): 1.410289\n",
      "Batch #10\tAverage Generator Loss: 1133.174500\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7974 (step 7974): 1.601970\n",
      "Batch #10\tAverage Generator Loss: 1167.449951\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7975 (step 7975): 1.421245\n",
      "Batch #10\tAverage Generator Loss: 1097.916486\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7976 (step 7976): 1.561287\n",
      "Batch #10\tAverage Generator Loss: 1270.818060\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #7977 (step 7977): 1.346027\n",
      "Batch #10\tAverage Generator Loss: 1342.519983\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #7978 (step 7978): 1.694750\n",
      "Batch #10\tAverage Generator Loss: 1303.673572\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7979 (step 7979): 1.302120\n",
      "Batch #10\tAverage Generator Loss: 1154.331659\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7980 (step 7980): 1.604050\n",
      "Batch #10\tAverage Generator Loss: 1181.307007\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7981 (step 7981): 1.387864\n",
      "Batch #10\tAverage Generator Loss: 1039.801105\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7982 (step 7982): 1.559882\n",
      "Batch #10\tAverage Generator Loss: 1235.431058\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7983 (step 7983): 1.390673\n",
      "Batch #10\tAverage Generator Loss: 1262.305670\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7984 (step 7984): 1.685640\n",
      "Batch #10\tAverage Generator Loss: 1257.794232\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7985 (step 7985): 1.249321\n",
      "Batch #10\tAverage Generator Loss: 1354.461011\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7986 (step 7986): 1.580369\n",
      "Batch #10\tAverage Generator Loss: 1246.101892\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7987 (step 7987): 1.282702\n",
      "Batch #10\tAverage Generator Loss: 1309.227576\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7988 (step 7988): 1.630382\n",
      "Batch #10\tAverage Generator Loss: 1231.338171\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7989 (step 7989): 1.297273\n",
      "Batch #10\tAverage Generator Loss: 1245.867175\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7990 (step 7990): 1.566345\n",
      "Batch #10\tAverage Generator Loss: 1281.163892\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7991 (step 7991): 1.313975\n",
      "Batch #10\tAverage Generator Loss: 1165.642438\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7992 (step 7992): 1.686681\n",
      "Batch #10\tAverage Generator Loss: 1192.998059\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #7993 (step 7993): 1.443662\n",
      "Batch #10\tAverage Generator Loss: 1214.156689\tAverage Discriminator Loss: 0.002095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #7994 (step 7994): 1.665368\n",
      "Batch #10\tAverage Generator Loss: 1199.300403\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #7995 (step 7995): 1.296679\n",
      "Batch #10\tAverage Generator Loss: 1344.963019\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #7996 (step 7996): 1.587969\n",
      "Batch #10\tAverage Generator Loss: 1279.206805\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #7997 (step 7997): 1.247015\n",
      "Batch #10\tAverage Generator Loss: 1192.611188\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7998 (step 7998): 1.571356\n",
      "Batch #10\tAverage Generator Loss: 1378.740491\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #7999 (step 7999): 1.290147\n",
      "Batch #10\tAverage Generator Loss: 1109.400690\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #8000 (step 8000): 1.336014\n",
      "Batch #10\tAverage Generator Loss: 1192.529620\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8001 (step 8001): 1.653015\n",
      "Batch #10\tAverage Generator Loss: 1197.180493\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8002 (step 8002): 1.670509\n",
      "Batch #10\tAverage Generator Loss: 1126.902521\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8003 (step 8003): 1.371921\n",
      "Batch #10\tAverage Generator Loss: 1327.587866\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8004 (step 8004): 1.690428\n",
      "Batch #10\tAverage Generator Loss: 1168.603564\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8005 (step 8005): 1.388734\n",
      "Batch #10\tAverage Generator Loss: 1221.213159\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8006 (step 8006): 1.581879\n",
      "Batch #10\tAverage Generator Loss: 1270.352893\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8007 (step 8007): 1.355435\n",
      "Batch #10\tAverage Generator Loss: 1223.307764\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8008 (step 8008): 1.684447\n",
      "Batch #10\tAverage Generator Loss: 1228.621234\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8009 (step 8009): 1.322742\n",
      "Batch #10\tAverage Generator Loss: 1193.017084\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8010 (step 8010): 1.662800\n",
      "Batch #10\tAverage Generator Loss: 1218.767212\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8011 (step 8011): 1.355922\n",
      "Batch #10\tAverage Generator Loss: 1120.639398\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8012 (step 8012): 1.808037\n",
      "Batch #10\tAverage Generator Loss: 1227.609406\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8013 (step 8013): 1.346058\n",
      "Batch #10\tAverage Generator Loss: 1303.981396\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8014 (step 8014): 1.559343\n",
      "Batch #10\tAverage Generator Loss: 1340.332550\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8015 (step 8015): 1.287785\n",
      "Batch #10\tAverage Generator Loss: 1325.248303\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8016 (step 8016): 1.570009\n",
      "Batch #10\tAverage Generator Loss: 1314.016870\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8017 (step 8017): 1.346863\n",
      "Batch #10\tAverage Generator Loss: 1178.314557\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8018 (step 8018): 1.673128\n",
      "Batch #10\tAverage Generator Loss: 1227.446106\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8019 (step 8019): 1.341152\n",
      "Batch #10\tAverage Generator Loss: 1242.050696\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8020 (step 8020): 1.581412\n",
      "Batch #10\tAverage Generator Loss: 1286.194141\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8021 (step 8021): 1.365891\n",
      "Batch #10\tAverage Generator Loss: 1196.616754\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8022 (step 8022): 1.683856\n",
      "Batch #10\tAverage Generator Loss: 1230.557837\tAverage Discriminator Loss: 0.005832\n",
      "\n",
      "Train time for epoch #8023 (step 8023): 1.311708\n",
      "Batch #10\tAverage Generator Loss: 1132.110779\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #8024 (step 8024): 1.686406\n",
      "Batch #10\tAverage Generator Loss: 1331.755273\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #8025 (step 8025): 1.292335\n",
      "Batch #10\tAverage Generator Loss: 1277.571552\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #8026 (step 8026): 1.364174\n",
      "Batch #10\tAverage Generator Loss: 1072.076965\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #8027 (step 8027): 1.631891\n",
      "Batch #10\tAverage Generator Loss: 1272.330835\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8028 (step 8028): 1.566097\n",
      "Batch #10\tAverage Generator Loss: 1204.306848\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #8029 (step 8029): 1.393401\n",
      "Batch #10\tAverage Generator Loss: 1167.149530\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #8030 (step 8030): 1.625639\n",
      "Batch #10\tAverage Generator Loss: 1211.624615\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #8031 (step 8031): 1.295770\n",
      "Batch #10\tAverage Generator Loss: 1321.781958\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8032 (step 8032): 1.623260\n",
      "Batch #10\tAverage Generator Loss: 1290.262091\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8033 (step 8033): 1.356894\n",
      "Batch #10\tAverage Generator Loss: 1400.466687\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8034 (step 8034): 1.722601\n",
      "Batch #10\tAverage Generator Loss: 1315.443750\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8035 (step 8035): 1.269094\n",
      "Batch #10\tAverage Generator Loss: 1320.766943\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8036 (step 8036): 1.635803\n",
      "Batch #10\tAverage Generator Loss: 1293.960370\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8037 (step 8037): 1.468688\n",
      "Batch #10\tAverage Generator Loss: 1258.171631\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8038 (step 8038): 1.634952\n",
      "Batch #10\tAverage Generator Loss: 1105.618213\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8039 (step 8039): 1.284608\n",
      "Batch #10\tAverage Generator Loss: 1205.650055\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8040 (step 8040): 1.563057\n",
      "Batch #10\tAverage Generator Loss: 1210.700787\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8041 (step 8041): 1.332907\n",
      "Batch #10\tAverage Generator Loss: 1296.464697\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8042 (step 8042): 1.657361\n",
      "Batch #10\tAverage Generator Loss: 1294.556036\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8043 (step 8043): 1.295635\n",
      "Batch #10\tAverage Generator Loss: 1394.596613\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8044 (step 8044): 1.811673\n",
      "Batch #10\tAverage Generator Loss: 1245.286719\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8045 (step 8045): 1.288754\n",
      "Batch #10\tAverage Generator Loss: 1385.271802\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8046 (step 8046): 1.613855\n",
      "Batch #10\tAverage Generator Loss: 1380.452649\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8047 (step 8047): 1.561508\n",
      "Batch #10\tAverage Generator Loss: 1235.944391\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #8048 (step 8048): 1.753014\n",
      "Batch #10\tAverage Generator Loss: 1397.076099\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8049 (step 8049): 1.289311\n",
      "Batch #10\tAverage Generator Loss: 1298.603394\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8050 (step 8050): 1.561337\n",
      "Batch #10\tAverage Generator Loss: 1206.815564\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8051 (step 8051): 1.326649\n",
      "Batch #10\tAverage Generator Loss: 1298.945337\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8052 (step 8052): 1.724497\n",
      "Batch #10\tAverage Generator Loss: 1268.071613\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8053 (step 8053): 1.405061\n",
      "Batch #10\tAverage Generator Loss: 1263.047668\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8054 (step 8054): 1.671844\n",
      "Batch #10\tAverage Generator Loss: 1165.601312\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8055 (step 8055): 1.332196\n",
      "Batch #10\tAverage Generator Loss: 1195.471210\tAverage Discriminator Loss: 0.000001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #8056 (step 8056): 1.334970\n",
      "Batch #10\tAverage Generator Loss: 1163.168042\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8057 (step 8057): 1.583401\n",
      "Batch #10\tAverage Generator Loss: 1154.509296\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8058 (step 8058): 1.334156\n",
      "Batch #10\tAverage Generator Loss: 1266.815784\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8059 (step 8059): 1.558273\n",
      "Batch #10\tAverage Generator Loss: 1160.637415\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8060 (step 8060): 1.351130\n",
      "Batch #10\tAverage Generator Loss: 1185.352594\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8061 (step 8061): 1.694263\n",
      "Batch #10\tAverage Generator Loss: 1323.723102\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8062 (step 8062): 1.379877\n",
      "Batch #10\tAverage Generator Loss: 1293.925433\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8063 (step 8063): 1.572275\n",
      "Batch #10\tAverage Generator Loss: 1208.229434\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8064 (step 8064): 1.279548\n",
      "Batch #10\tAverage Generator Loss: 1227.986420\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8065 (step 8065): 1.601412\n",
      "Batch #10\tAverage Generator Loss: 1116.458063\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8066 (step 8066): 1.357075\n",
      "Batch #10\tAverage Generator Loss: 1290.956305\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8067 (step 8067): 1.587418\n",
      "Batch #10\tAverage Generator Loss: 1281.731702\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8068 (step 8068): 1.305537\n",
      "Batch #10\tAverage Generator Loss: 1187.634528\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8069 (step 8069): 1.688333\n",
      "Batch #10\tAverage Generator Loss: 1200.355698\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8070 (step 8070): 1.282438\n",
      "Batch #10\tAverage Generator Loss: 1293.356934\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8071 (step 8071): 1.638806\n",
      "Batch #10\tAverage Generator Loss: 1131.491318\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8072 (step 8072): 1.390575\n",
      "Batch #10\tAverage Generator Loss: 1122.356635\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8073 (step 8073): 1.575856\n",
      "Batch #10\tAverage Generator Loss: 1340.934180\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8074 (step 8074): 1.348042\n",
      "Batch #10\tAverage Generator Loss: 1268.030438\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8075 (step 8075): 1.706419\n",
      "Batch #10\tAverage Generator Loss: 1248.924078\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8076 (step 8076): 1.277933\n",
      "Batch #10\tAverage Generator Loss: 1267.860565\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8077 (step 8077): 1.624996\n",
      "Batch #10\tAverage Generator Loss: 1305.828253\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8078 (step 8078): 1.290187\n",
      "Batch #10\tAverage Generator Loss: 1206.977615\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8079 (step 8079): 1.639108\n",
      "Batch #10\tAverage Generator Loss: 1141.407904\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8080 (step 8080): 1.375363\n",
      "Batch #10\tAverage Generator Loss: 1284.227020\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8081 (step 8081): 1.591343\n",
      "Batch #10\tAverage Generator Loss: 1317.476276\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8082 (step 8082): 1.444920\n",
      "Batch #10\tAverage Generator Loss: 1257.998700\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8083 (step 8083): 1.675575\n",
      "Batch #10\tAverage Generator Loss: 1404.439307\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8084 (step 8084): 1.341900\n",
      "Batch #10\tAverage Generator Loss: 1240.929272\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8085 (step 8085): 1.731984\n",
      "Batch #10\tAverage Generator Loss: 1407.854681\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8086 (step 8086): 1.283107\n",
      "Batch #10\tAverage Generator Loss: 1367.540155\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8087 (step 8087): 1.612161\n",
      "Batch #10\tAverage Generator Loss: 1236.321332\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8088 (step 8088): 1.393354\n",
      "Batch #10\tAverage Generator Loss: 1096.343140\tAverage Discriminator Loss: 0.013381\n",
      "\n",
      "Train time for epoch #8089 (step 8089): 1.659605\n",
      "Batch #10\tAverage Generator Loss: 1513.325092\tAverage Discriminator Loss: 0.007297\n",
      "\n",
      "Train time for epoch #8090 (step 8090): 1.328719\n",
      "Batch #10\tAverage Generator Loss: 1526.086133\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8091 (step 8091): 1.569094\n",
      "Batch #10\tAverage Generator Loss: 1300.317487\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8092 (step 8092): 1.396381\n",
      "Batch #10\tAverage Generator Loss: 1421.192480\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8093 (step 8093): 1.657203\n",
      "Batch #10\tAverage Generator Loss: 1350.901746\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8094 (step 8094): 1.348304\n",
      "Batch #10\tAverage Generator Loss: 1454.695654\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8095 (step 8095): 1.566000\n",
      "Batch #10\tAverage Generator Loss: 1197.731223\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8096 (step 8096): 1.288544\n",
      "Batch #10\tAverage Generator Loss: 1461.014581\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8097 (step 8097): 1.560805\n",
      "Batch #10\tAverage Generator Loss: 1321.953015\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8098 (step 8098): 1.428536\n",
      "Batch #10\tAverage Generator Loss: 1504.140796\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8099 (step 8099): 1.661030\n",
      "Batch #10\tAverage Generator Loss: 1437.029907\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8100 (step 8100): 1.291788\n",
      "Batch #10\tAverage Generator Loss: 1408.831519\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8101 (step 8101): 1.750681\n",
      "Batch #10\tAverage Generator Loss: 1286.236456\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8102 (step 8102): 1.300167\n",
      "Batch #10\tAverage Generator Loss: 1350.529315\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8103 (step 8103): 1.748481\n",
      "Batch #10\tAverage Generator Loss: 1324.531628\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8104 (step 8104): 1.305313\n",
      "Batch #10\tAverage Generator Loss: 1517.176117\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8105 (step 8105): 1.673697\n",
      "Batch #10\tAverage Generator Loss: 1455.413269\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #8106 (step 8106): 1.384940\n",
      "Batch #10\tAverage Generator Loss: 1455.808411\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8107 (step 8107): 1.594089\n",
      "Batch #10\tAverage Generator Loss: 1355.135748\tAverage Discriminator Loss: 0.088892\n",
      "\n",
      "Train time for epoch #8108 (step 8108): 1.395714\n",
      "Batch #10\tAverage Generator Loss: 1245.662994\tAverage Discriminator Loss: 0.008783\n",
      "\n",
      "Train time for epoch #8109 (step 8109): 1.709084\n",
      "Batch #10\tAverage Generator Loss: 1572.952924\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8110 (step 8110): 1.390771\n",
      "Batch #10\tAverage Generator Loss: 1428.268268\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8111 (step 8111): 1.667714\n",
      "Batch #10\tAverage Generator Loss: 1243.447171\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8112 (step 8112): 1.344877\n",
      "Batch #10\tAverage Generator Loss: 1322.029913\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8113 (step 8113): 1.631091\n",
      "Batch #10\tAverage Generator Loss: 1161.294699\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8114 (step 8114): 1.372134\n",
      "Batch #10\tAverage Generator Loss: 1299.012241\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8115 (step 8115): 1.645116\n",
      "Batch #10\tAverage Generator Loss: 1448.021564\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8116 (step 8116): 1.391922\n",
      "Batch #10\tAverage Generator Loss: 1388.544867\tAverage Discriminator Loss: 0.339322\n",
      "\n",
      "Train time for epoch #8117 (step 8117): 1.528494\n",
      "Batch #10\tAverage Generator Loss: 1530.176892\tAverage Discriminator Loss: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #8118 (step 8118): 1.279520\n",
      "Batch #10\tAverage Generator Loss: 1825.686261\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8119 (step 8119): 1.807879\n",
      "Batch #10\tAverage Generator Loss: 1819.305109\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8120 (step 8120): 1.400513\n",
      "Batch #10\tAverage Generator Loss: 1717.770862\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8121 (step 8121): 1.576666\n",
      "Batch #10\tAverage Generator Loss: 1710.674078\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8122 (step 8122): 1.472912\n",
      "Batch #10\tAverage Generator Loss: 1884.252954\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8123 (step 8123): 1.668028\n",
      "Batch #10\tAverage Generator Loss: 1639.616180\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8124 (step 8124): 1.409557\n",
      "Batch #10\tAverage Generator Loss: 1901.778961\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8125 (step 8125): 1.608197\n",
      "Batch #10\tAverage Generator Loss: 2010.112183\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8126 (step 8126): 1.451325\n",
      "Batch #10\tAverage Generator Loss: 1961.311780\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8127 (step 8127): 1.607955\n",
      "Batch #10\tAverage Generator Loss: 1703.304205\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8128 (step 8128): 1.297304\n",
      "Batch #10\tAverage Generator Loss: 1863.602393\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8129 (step 8129): 1.368249\n",
      "Batch #10\tAverage Generator Loss: 1761.698053\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8130 (step 8130): 1.520458\n",
      "Batch #10\tAverage Generator Loss: 1744.977368\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8131 (step 8131): 1.689543\n",
      "Batch #10\tAverage Generator Loss: 1721.475958\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8132 (step 8132): 1.322758\n",
      "Batch #10\tAverage Generator Loss: 2132.054980\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8133 (step 8133): 1.700795\n",
      "Batch #10\tAverage Generator Loss: 1811.271173\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8134 (step 8134): 1.339359\n",
      "Batch #10\tAverage Generator Loss: 2058.734192\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8135 (step 8135): 1.563906\n",
      "Batch #10\tAverage Generator Loss: 2222.416736\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8136 (step 8136): 1.348004\n",
      "Batch #10\tAverage Generator Loss: 1957.929358\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8137 (step 8137): 1.585467\n",
      "Batch #10\tAverage Generator Loss: 1925.689551\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8138 (step 8138): 1.302534\n",
      "Batch #10\tAverage Generator Loss: 1642.219275\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8139 (step 8139): 1.374465\n",
      "Batch #10\tAverage Generator Loss: 2089.258081\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8140 (step 8140): 1.602528\n",
      "Batch #10\tAverage Generator Loss: 1786.767035\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8141 (step 8141): 1.419029\n",
      "Batch #10\tAverage Generator Loss: 1818.129150\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8142 (step 8142): 1.615522\n",
      "Batch #10\tAverage Generator Loss: 2014.731805\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8143 (step 8143): 1.304976\n",
      "Batch #10\tAverage Generator Loss: 1905.761768\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8144 (step 8144): 1.643069\n",
      "Batch #10\tAverage Generator Loss: 1925.596985\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8145 (step 8145): 1.441214\n",
      "Batch #10\tAverage Generator Loss: 2130.518335\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8146 (step 8146): 1.629296\n",
      "Batch #10\tAverage Generator Loss: 1701.355365\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8147 (step 8147): 1.441405\n",
      "Batch #10\tAverage Generator Loss: 1774.823242\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8148 (step 8148): 1.598774\n",
      "Batch #10\tAverage Generator Loss: 1771.854834\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8149 (step 8149): 1.397676\n",
      "Batch #10\tAverage Generator Loss: 1590.723590\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8150 (step 8150): 1.751790\n",
      "Batch #10\tAverage Generator Loss: 1730.728979\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8151 (step 8151): 1.340823\n",
      "Batch #10\tAverage Generator Loss: 1901.791199\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8152 (step 8152): 1.582391\n",
      "Batch #10\tAverage Generator Loss: 1892.799060\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8153 (step 8153): 1.294925\n",
      "Batch #10\tAverage Generator Loss: 1965.689038\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8154 (step 8154): 1.571774\n",
      "Batch #10\tAverage Generator Loss: 1619.822565\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8155 (step 8155): 1.286406\n",
      "Batch #10\tAverage Generator Loss: 1875.506128\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8156 (step 8156): 1.586806\n",
      "Batch #10\tAverage Generator Loss: 1473.329291\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8157 (step 8157): 1.251073\n",
      "Batch #10\tAverage Generator Loss: 1744.867828\tAverage Discriminator Loss: 0.010737\n",
      "\n",
      "Train time for epoch #8158 (step 8158): 1.568715\n",
      "Batch #10\tAverage Generator Loss: 1506.577600\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8159 (step 8159): 1.332081\n",
      "Batch #10\tAverage Generator Loss: 1613.405731\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8160 (step 8160): 1.652374\n",
      "Batch #10\tAverage Generator Loss: 1742.876874\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8161 (step 8161): 1.296959\n",
      "Batch #10\tAverage Generator Loss: 1928.045532\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8162 (step 8162): 1.591587\n",
      "Batch #10\tAverage Generator Loss: 1347.860681\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8163 (step 8163): 1.333864\n",
      "Batch #10\tAverage Generator Loss: 1725.789746\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8164 (step 8164): 1.570254\n",
      "Batch #10\tAverage Generator Loss: 1514.943237\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8165 (step 8165): 1.281496\n",
      "Batch #10\tAverage Generator Loss: 1601.000183\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8166 (step 8166): 1.658993\n",
      "Batch #10\tAverage Generator Loss: 1555.721436\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8167 (step 8167): 1.337907\n",
      "Batch #10\tAverage Generator Loss: 1759.804028\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8168 (step 8168): 1.611107\n",
      "Batch #10\tAverage Generator Loss: 1477.883649\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8169 (step 8169): 1.459774\n",
      "Batch #10\tAverage Generator Loss: 1481.689496\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8170 (step 8170): 1.642964\n",
      "Batch #10\tAverage Generator Loss: 1822.489307\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8171 (step 8171): 1.350147\n",
      "Batch #10\tAverage Generator Loss: 1811.413647\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8172 (step 8172): 1.292416\n",
      "Batch #10\tAverage Generator Loss: 1638.117413\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8173 (step 8173): 1.517849\n",
      "Batch #10\tAverage Generator Loss: 1558.786981\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8174 (step 8174): 1.488524\n",
      "Batch #10\tAverage Generator Loss: 1558.836700\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8175 (step 8175): 1.609197\n",
      "Batch #10\tAverage Generator Loss: 1650.684277\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8176 (step 8176): 1.398557\n",
      "Batch #10\tAverage Generator Loss: 1700.915698\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8177 (step 8177): 1.529989\n",
      "Batch #10\tAverage Generator Loss: 1411.687787\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8178 (step 8178): 1.402296\n",
      "Batch #10\tAverage Generator Loss: 1555.451318\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8179 (step 8179): 1.624131\n",
      "Batch #10\tAverage Generator Loss: 1506.257770\tAverage Discriminator Loss: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #8180 (step 8180): 1.363768\n",
      "Batch #10\tAverage Generator Loss: 1735.970178\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8181 (step 8181): 1.624588\n",
      "Batch #10\tAverage Generator Loss: 1863.113196\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8182 (step 8182): 1.341009\n",
      "Batch #10\tAverage Generator Loss: 1665.141669\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8183 (step 8183): 1.655424\n",
      "Batch #10\tAverage Generator Loss: 1389.994299\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #8184 (step 8184): 1.291972\n",
      "Batch #10\tAverage Generator Loss: 1574.061548\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8185 (step 8185): 1.588024\n",
      "Batch #10\tAverage Generator Loss: 1515.445483\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8186 (step 8186): 1.376887\n",
      "Batch #10\tAverage Generator Loss: 1513.912729\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8187 (step 8187): 1.628247\n",
      "Batch #10\tAverage Generator Loss: 1657.501703\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8188 (step 8188): 1.339146\n",
      "Batch #10\tAverage Generator Loss: 1568.698499\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8189 (step 8189): 1.625713\n",
      "Batch #10\tAverage Generator Loss: 1779.678857\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8190 (step 8190): 1.342302\n",
      "Batch #10\tAverage Generator Loss: 1644.941791\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8191 (step 8191): 1.839847\n",
      "Batch #10\tAverage Generator Loss: 1844.362659\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8192 (step 8192): 1.282039\n",
      "Batch #10\tAverage Generator Loss: 1648.119739\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8193 (step 8193): 1.578557\n",
      "Batch #10\tAverage Generator Loss: 1746.977515\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8194 (step 8194): 1.398719\n",
      "Batch #10\tAverage Generator Loss: 1734.095215\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8195 (step 8195): 1.578004\n",
      "Batch #10\tAverage Generator Loss: 1660.673016\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8196 (step 8196): 1.392686\n",
      "Batch #10\tAverage Generator Loss: 1868.255408\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8197 (step 8197): 1.594531\n",
      "Batch #10\tAverage Generator Loss: 1854.088226\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8198 (step 8198): 1.430768\n",
      "Batch #10\tAverage Generator Loss: 1639.413153\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8199 (step 8199): 1.610174\n",
      "Batch #10\tAverage Generator Loss: 1515.721509\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8200 (step 8200): 1.297570\n",
      "Batch #10\tAverage Generator Loss: 1782.984705\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8201 (step 8201): 1.636071\n",
      "Batch #10\tAverage Generator Loss: 1615.286203\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8202 (step 8202): 1.344713\n",
      "Batch #10\tAverage Generator Loss: 1570.320929\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8203 (step 8203): 1.600458\n",
      "Batch #10\tAverage Generator Loss: 1605.184668\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8204 (step 8204): 1.408946\n",
      "Batch #10\tAverage Generator Loss: 1600.243591\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8205 (step 8205): 1.634220\n",
      "Batch #10\tAverage Generator Loss: 1498.114368\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8206 (step 8206): 1.500289\n",
      "Batch #10\tAverage Generator Loss: 1517.339142\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8207 (step 8207): 1.565871\n",
      "Batch #10\tAverage Generator Loss: 1802.020850\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8208 (step 8208): 1.285003\n",
      "Batch #10\tAverage Generator Loss: 1492.927991\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8209 (step 8209): 1.707345\n",
      "Batch #10\tAverage Generator Loss: 1726.305939\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8210 (step 8210): 1.373854\n",
      "Batch #10\tAverage Generator Loss: 1586.080603\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8211 (step 8211): 1.562176\n",
      "Batch #10\tAverage Generator Loss: 1705.649951\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8212 (step 8212): 1.433028\n",
      "Batch #10\tAverage Generator Loss: 1484.057959\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8213 (step 8213): 1.517804\n",
      "Batch #10\tAverage Generator Loss: 1582.571375\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8214 (step 8214): 1.287901\n",
      "Batch #10\tAverage Generator Loss: 1677.954950\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8215 (step 8215): 1.620038\n",
      "Batch #10\tAverage Generator Loss: 1727.892322\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8216 (step 8216): 1.390453\n",
      "Batch #10\tAverage Generator Loss: 1784.582556\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8217 (step 8217): 1.571084\n",
      "Batch #10\tAverage Generator Loss: 1775.233710\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8218 (step 8218): 1.391958\n",
      "Batch #10\tAverage Generator Loss: 1822.925464\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8219 (step 8219): 1.666520\n",
      "Batch #10\tAverage Generator Loss: 1771.234137\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8220 (step 8220): 1.407662\n",
      "Batch #10\tAverage Generator Loss: 1377.423816\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8221 (step 8221): 1.650322\n",
      "Batch #10\tAverage Generator Loss: 1510.216321\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8222 (step 8222): 1.252263\n",
      "Batch #10\tAverage Generator Loss: 1867.459937\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8223 (step 8223): 1.577209\n",
      "Batch #10\tAverage Generator Loss: 1742.491266\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8224 (step 8224): 1.284505\n",
      "Batch #10\tAverage Generator Loss: 1658.040942\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8225 (step 8225): 1.628131\n",
      "Batch #10\tAverage Generator Loss: 1767.787262\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8226 (step 8226): 1.287826\n",
      "Batch #10\tAverage Generator Loss: 1661.706714\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8227 (step 8227): 1.718203\n",
      "Batch #10\tAverage Generator Loss: 1396.596069\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8228 (step 8228): 1.287294\n",
      "Batch #10\tAverage Generator Loss: 1666.242499\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8229 (step 8229): 1.346826\n",
      "Batch #10\tAverage Generator Loss: 1735.971082\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8230 (step 8230): 1.575487\n",
      "Batch #10\tAverage Generator Loss: 1571.477441\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8231 (step 8231): 1.281540\n",
      "Batch #10\tAverage Generator Loss: 1511.398199\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8232 (step 8232): 1.608170\n",
      "Batch #10\tAverage Generator Loss: 1431.539856\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8233 (step 8233): 1.310027\n",
      "Batch #10\tAverage Generator Loss: 1725.472430\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8234 (step 8234): 1.686695\n",
      "Batch #10\tAverage Generator Loss: 1375.105679\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8235 (step 8235): 1.465762\n",
      "Batch #10\tAverage Generator Loss: 1642.358395\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8236 (step 8236): 1.589807\n",
      "Batch #10\tAverage Generator Loss: 1943.318262\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8237 (step 8237): 1.399720\n",
      "Batch #10\tAverage Generator Loss: 1686.513831\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8238 (step 8238): 1.682348\n",
      "Batch #10\tAverage Generator Loss: 1616.807990\tAverage Discriminator Loss: 0.012333\n",
      "\n",
      "Train time for epoch #8239 (step 8239): 1.388699\n",
      "Batch #10\tAverage Generator Loss: 1526.851984\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8240 (step 8240): 1.575807\n",
      "Batch #10\tAverage Generator Loss: 1471.449908\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8241 (step 8241): 1.442545\n",
      "Batch #10\tAverage Generator Loss: 1635.442303\tAverage Discriminator Loss: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #8242 (step 8242): 1.616490\n",
      "Batch #10\tAverage Generator Loss: 1484.644269\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8243 (step 8243): 1.288129\n",
      "Batch #10\tAverage Generator Loss: 1513.433228\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8244 (step 8244): 1.722161\n",
      "Batch #10\tAverage Generator Loss: 1808.536829\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8245 (step 8245): 1.290075\n",
      "Batch #10\tAverage Generator Loss: 1514.202905\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8246 (step 8246): 1.559352\n",
      "Batch #10\tAverage Generator Loss: 1621.450696\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8247 (step 8247): 1.331953\n",
      "Batch #10\tAverage Generator Loss: 1552.439935\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8248 (step 8248): 1.581199\n",
      "Batch #10\tAverage Generator Loss: 1652.157642\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8249 (step 8249): 1.293135\n",
      "Batch #10\tAverage Generator Loss: 1436.601593\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8250 (step 8250): 1.352257\n",
      "Batch #10\tAverage Generator Loss: 1484.535046\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8251 (step 8251): 1.615443\n",
      "Batch #10\tAverage Generator Loss: 1749.425977\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8252 (step 8252): 1.246797\n",
      "Batch #10\tAverage Generator Loss: 1616.642700\tAverage Discriminator Loss: 0.003159\n",
      "\n",
      "Train time for epoch #8253 (step 8253): 1.718546\n",
      "Batch #10\tAverage Generator Loss: 1648.042963\tAverage Discriminator Loss: 0.004794\n",
      "\n",
      "Train time for epoch #8254 (step 8254): 1.298589\n",
      "Batch #10\tAverage Generator Loss: 1566.271820\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8255 (step 8255): 1.599789\n",
      "Batch #10\tAverage Generator Loss: 1500.557776\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8256 (step 8256): 1.418771\n",
      "Batch #10\tAverage Generator Loss: 1657.664062\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8257 (step 8257): 1.583324\n",
      "Batch #10\tAverage Generator Loss: 1432.488757\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8258 (step 8258): 1.292149\n",
      "Batch #10\tAverage Generator Loss: 1500.694873\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8259 (step 8259): 1.683847\n",
      "Batch #10\tAverage Generator Loss: 1496.611078\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8260 (step 8260): 1.348235\n",
      "Batch #10\tAverage Generator Loss: 1773.749561\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8261 (step 8261): 1.744695\n",
      "Batch #10\tAverage Generator Loss: 1497.852405\tAverage Discriminator Loss: 0.022430\n",
      "\n",
      "Train time for epoch #8262 (step 8262): 1.321653\n",
      "Batch #10\tAverage Generator Loss: 1424.390240\tAverage Discriminator Loss: 0.004626\n",
      "\n",
      "Train time for epoch #8263 (step 8263): 1.689369\n",
      "Batch #10\tAverage Generator Loss: 1516.277802\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8264 (step 8264): 1.346821\n",
      "Batch #10\tAverage Generator Loss: 1590.119550\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8265 (step 8265): 1.652412\n",
      "Batch #10\tAverage Generator Loss: 1260.074872\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8266 (step 8266): 1.335431\n",
      "Batch #10\tAverage Generator Loss: 1492.246851\tAverage Discriminator Loss: 0.015741\n",
      "\n",
      "Train time for epoch #8267 (step 8267): 1.654748\n",
      "Batch #10\tAverage Generator Loss: 1265.010304\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8268 (step 8268): 1.413863\n",
      "Batch #10\tAverage Generator Loss: 1268.402472\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8269 (step 8269): 1.612183\n",
      "Batch #10\tAverage Generator Loss: 1332.593350\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #8270 (step 8270): 1.287197\n",
      "Batch #10\tAverage Generator Loss: 1338.749689\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8271 (step 8271): 1.552830\n",
      "Batch #10\tAverage Generator Loss: 1320.803369\tAverage Discriminator Loss: 0.000057\n",
      "\n",
      "Train time for epoch #8272 (step 8272): 1.308378\n",
      "Batch #10\tAverage Generator Loss: 1444.542487\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8273 (step 8273): 1.433870\n",
      "Batch #10\tAverage Generator Loss: 1234.337698\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8274 (step 8274): 1.603020\n",
      "Batch #10\tAverage Generator Loss: 1233.381049\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8275 (step 8275): 1.442144\n",
      "Batch #10\tAverage Generator Loss: 1323.086044\tAverage Discriminator Loss: 0.008194\n",
      "\n",
      "Train time for epoch #8276 (step 8276): 1.512186\n",
      "Batch #10\tAverage Generator Loss: 1374.496460\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #8277 (step 8277): 1.644452\n",
      "Batch #10\tAverage Generator Loss: 1394.482941\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8278 (step 8278): 1.338136\n",
      "Batch #10\tAverage Generator Loss: 1309.135590\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8279 (step 8279): 1.389951\n",
      "Batch #10\tAverage Generator Loss: 1309.645337\tAverage Discriminator Loss: 0.000027\n",
      "\n",
      "Train time for epoch #8280 (step 8280): 1.551376\n",
      "Batch #10\tAverage Generator Loss: 1382.342126\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8281 (step 8281): 1.290677\n",
      "Batch #10\tAverage Generator Loss: 1478.739996\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8282 (step 8282): 1.667645\n",
      "Batch #10\tAverage Generator Loss: 1462.970209\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8283 (step 8283): 1.490351\n",
      "Batch #10\tAverage Generator Loss: 1297.362366\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8284 (step 8284): 1.580275\n",
      "Batch #10\tAverage Generator Loss: 1421.880762\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8285 (step 8285): 1.239919\n",
      "Batch #10\tAverage Generator Loss: 1356.145490\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8286 (step 8286): 1.687181\n",
      "Batch #10\tAverage Generator Loss: 1262.048206\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8287 (step 8287): 1.351771\n",
      "Batch #10\tAverage Generator Loss: 1373.864142\tAverage Discriminator Loss: 0.007367\n",
      "\n",
      "Train time for epoch #8288 (step 8288): 1.616938\n",
      "Batch #10\tAverage Generator Loss: 1172.704199\tAverage Discriminator Loss: 0.006377\n",
      "\n",
      "Train time for epoch #8289 (step 8289): 1.355188\n",
      "Batch #10\tAverage Generator Loss: 1196.479437\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #8290 (step 8290): 1.665732\n",
      "Batch #10\tAverage Generator Loss: 1209.253784\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8291 (step 8291): 1.397664\n",
      "Batch #10\tAverage Generator Loss: 1371.795447\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8292 (step 8292): 1.605480\n",
      "Batch #10\tAverage Generator Loss: 1440.186536\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8293 (step 8293): 1.308430\n",
      "Batch #10\tAverage Generator Loss: 1104.405750\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8294 (step 8294): 1.628046\n",
      "Batch #10\tAverage Generator Loss: 1386.176831\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8295 (step 8295): 1.245413\n",
      "Batch #10\tAverage Generator Loss: 1283.492749\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8296 (step 8296): 1.728935\n",
      "Batch #10\tAverage Generator Loss: 1344.668973\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8297 (step 8297): 1.348143\n",
      "Batch #10\tAverage Generator Loss: 1370.002319\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8298 (step 8298): 1.630765\n",
      "Batch #10\tAverage Generator Loss: 1372.843286\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #8299 (step 8299): 1.315973\n",
      "Batch #10\tAverage Generator Loss: 1487.885559\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8300 (step 8300): 1.583378\n",
      "Batch #10\tAverage Generator Loss: 1324.285541\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8301 (step 8301): 1.425591\n",
      "Batch #10\tAverage Generator Loss: 1429.339581\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8302 (step 8302): 1.615203\n",
      "Batch #10\tAverage Generator Loss: 1238.274261\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8303 (step 8303): 1.349655\n",
      "Batch #10\tAverage Generator Loss: 1508.487292\tAverage Discriminator Loss: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #8304 (step 8304): 1.597436\n",
      "Batch #10\tAverage Generator Loss: 1339.882257\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8305 (step 8305): 1.343419\n",
      "Batch #10\tAverage Generator Loss: 1385.770959\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8306 (step 8306): 1.347489\n",
      "Batch #10\tAverage Generator Loss: 1460.033704\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8307 (step 8307): 1.678344\n",
      "Batch #10\tAverage Generator Loss: 1407.722070\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8308 (step 8308): 1.359418\n",
      "Batch #10\tAverage Generator Loss: 1382.368494\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8309 (step 8309): 1.729812\n",
      "Batch #10\tAverage Generator Loss: 1418.360010\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8310 (step 8310): 1.303176\n",
      "Batch #10\tAverage Generator Loss: 1326.742166\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8311 (step 8311): 1.651605\n",
      "Batch #10\tAverage Generator Loss: 1367.882288\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8312 (step 8312): 1.281874\n",
      "Batch #10\tAverage Generator Loss: 1413.836090\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8313 (step 8313): 1.687377\n",
      "Batch #10\tAverage Generator Loss: 1261.075122\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8314 (step 8314): 1.446295\n",
      "Batch #10\tAverage Generator Loss: 1450.822058\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8315 (step 8315): 1.678937\n",
      "Batch #10\tAverage Generator Loss: 1452.845947\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8316 (step 8316): 1.283704\n",
      "Batch #10\tAverage Generator Loss: 1183.833478\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8317 (step 8317): 1.564567\n",
      "Batch #10\tAverage Generator Loss: 1364.039575\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8318 (step 8318): 1.293478\n",
      "Batch #10\tAverage Generator Loss: 1454.454858\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8319 (step 8319): 1.745865\n",
      "Batch #10\tAverage Generator Loss: 1316.523608\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8320 (step 8320): 1.294542\n",
      "Batch #10\tAverage Generator Loss: 1303.691724\tAverage Discriminator Loss: 0.005734\n",
      "\n",
      "Train time for epoch #8321 (step 8321): 1.577844\n",
      "Batch #10\tAverage Generator Loss: 1475.900073\tAverage Discriminator Loss: 0.000118\n",
      "\n",
      "Train time for epoch #8322 (step 8322): 1.373648\n",
      "Batch #10\tAverage Generator Loss: 1618.567334\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8323 (step 8323): 1.524377\n",
      "Batch #10\tAverage Generator Loss: 1557.069501\tAverage Discriminator Loss: 0.000787\n",
      "\n",
      "Train time for epoch #8324 (step 8324): 1.425004\n",
      "Batch #10\tAverage Generator Loss: 1500.186395\tAverage Discriminator Loss: 0.001552\n",
      "\n",
      "Train time for epoch #8325 (step 8325): 1.676949\n",
      "Batch #10\tAverage Generator Loss: 1599.982642\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8326 (step 8326): 1.397645\n",
      "Batch #10\tAverage Generator Loss: 1704.039771\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8327 (step 8327): 1.576102\n",
      "Batch #10\tAverage Generator Loss: 1469.277679\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8328 (step 8328): 1.302828\n",
      "Batch #10\tAverage Generator Loss: 1552.424493\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8329 (step 8329): 1.558399\n",
      "Batch #10\tAverage Generator Loss: 1682.819580\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8330 (step 8330): 1.298575\n",
      "Batch #10\tAverage Generator Loss: 1407.543237\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8331 (step 8331): 1.621484\n",
      "Batch #10\tAverage Generator Loss: 1815.444690\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8332 (step 8332): 1.296943\n",
      "Batch #10\tAverage Generator Loss: 1359.456049\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8333 (step 8333): 1.663291\n",
      "Batch #10\tAverage Generator Loss: 1636.995306\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8334 (step 8334): 1.351901\n",
      "Batch #10\tAverage Generator Loss: 1594.050769\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8335 (step 8335): 1.677958\n",
      "Batch #10\tAverage Generator Loss: 1711.779639\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8336 (step 8336): 1.407692\n",
      "Batch #10\tAverage Generator Loss: 1928.054663\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8337 (step 8337): 1.586336\n",
      "Batch #10\tAverage Generator Loss: 1601.928735\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8338 (step 8338): 1.368713\n",
      "Batch #10\tAverage Generator Loss: 1446.451169\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8339 (step 8339): 1.639758\n",
      "Batch #10\tAverage Generator Loss: 1689.973962\tAverage Discriminator Loss: 0.007445\n",
      "\n",
      "Train time for epoch #8340 (step 8340): 1.323577\n",
      "Batch #10\tAverage Generator Loss: 1640.257495\tAverage Discriminator Loss: 0.000361\n",
      "\n",
      "Train time for epoch #8341 (step 8341): 1.602429\n",
      "Batch #10\tAverage Generator Loss: 1698.459888\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8342 (step 8342): 1.351887\n",
      "Batch #10\tAverage Generator Loss: 1844.835254\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8343 (step 8343): 1.685611\n",
      "Batch #10\tAverage Generator Loss: 1722.836292\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8344 (step 8344): 1.346162\n",
      "Batch #10\tAverage Generator Loss: 1371.295297\tAverage Discriminator Loss: 0.026800\n",
      "\n",
      "Train time for epoch #8345 (step 8345): 1.645807\n",
      "Batch #10\tAverage Generator Loss: 1557.311584\tAverage Discriminator Loss: 0.078118\n",
      "\n",
      "Train time for epoch #8346 (step 8346): 1.334648\n",
      "Batch #10\tAverage Generator Loss: 1134.832333\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8347 (step 8347): 1.781439\n",
      "Batch #10\tAverage Generator Loss: 1245.448059\tAverage Discriminator Loss: 0.004024\n",
      "\n",
      "Train time for epoch #8348 (step 8348): 1.290896\n",
      "Batch #10\tAverage Generator Loss: 1385.500119\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8349 (step 8349): 1.594114\n",
      "Batch #10\tAverage Generator Loss: 1385.420135\tAverage Discriminator Loss: 0.001896\n",
      "\n",
      "Train time for epoch #8350 (step 8350): 1.343922\n",
      "Batch #10\tAverage Generator Loss: 1602.015674\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8351 (step 8351): 1.718135\n",
      "Batch #10\tAverage Generator Loss: 1795.053021\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8352 (step 8352): 1.354738\n",
      "Batch #10\tAverage Generator Loss: 1521.613953\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8353 (step 8353): 1.389202\n",
      "Batch #10\tAverage Generator Loss: 1486.673056\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8354 (step 8354): 1.649049\n",
      "Batch #10\tAverage Generator Loss: 1927.725879\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8355 (step 8355): 1.288887\n",
      "Batch #10\tAverage Generator Loss: 1539.510919\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8356 (step 8356): 1.551348\n",
      "Batch #10\tAverage Generator Loss: 1478.113953\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8357 (step 8357): 1.378190\n",
      "Batch #10\tAverage Generator Loss: 1624.341223\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8358 (step 8358): 1.652464\n",
      "Batch #10\tAverage Generator Loss: 1729.154175\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8359 (step 8359): 1.621880\n",
      "Batch #10\tAverage Generator Loss: 1706.030573\tAverage Discriminator Loss: 0.001373\n",
      "\n",
      "Train time for epoch #8360 (step 8360): 1.343582\n",
      "Batch #10\tAverage Generator Loss: 1870.139453\tAverage Discriminator Loss: 0.000702\n",
      "\n",
      "Train time for epoch #8361 (step 8361): 1.426113\n",
      "Batch #10\tAverage Generator Loss: 1585.347491\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8362 (step 8362): 1.566921\n",
      "Batch #10\tAverage Generator Loss: 1536.747906\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8363 (step 8363): 1.363000\n",
      "Batch #10\tAverage Generator Loss: 1954.574957\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8364 (step 8364): 1.660544\n",
      "Batch #10\tAverage Generator Loss: 1712.346924\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8365 (step 8365): 1.671166\n",
      "Batch #10\tAverage Generator Loss: 1769.141309\tAverage Discriminator Loss: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #8366 (step 8366): 1.301793\n",
      "Batch #10\tAverage Generator Loss: 1572.661911\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8367 (step 8367): 1.331996\n",
      "Batch #10\tAverage Generator Loss: 1589.419958\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8368 (step 8368): 1.580584\n",
      "Batch #10\tAverage Generator Loss: 1765.026184\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8369 (step 8369): 1.291905\n",
      "Batch #10\tAverage Generator Loss: 1377.771881\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8370 (step 8370): 1.646961\n",
      "Batch #10\tAverage Generator Loss: 1923.799377\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8371 (step 8371): 1.376597\n",
      "Batch #10\tAverage Generator Loss: 1519.467120\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8372 (step 8372): 1.572068\n",
      "Batch #10\tAverage Generator Loss: 1447.142035\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8373 (step 8373): 1.333587\n",
      "Batch #10\tAverage Generator Loss: 1713.003589\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8374 (step 8374): 1.749221\n",
      "Batch #10\tAverage Generator Loss: 1605.228864\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8375 (step 8375): 1.352791\n",
      "Batch #10\tAverage Generator Loss: 1667.821008\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8376 (step 8376): 1.616970\n",
      "Batch #10\tAverage Generator Loss: 1732.973022\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8377 (step 8377): 1.331711\n",
      "Batch #10\tAverage Generator Loss: 1664.480383\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8378 (step 8378): 1.587103\n",
      "Batch #10\tAverage Generator Loss: 1626.687119\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8379 (step 8379): 1.290564\n",
      "Batch #10\tAverage Generator Loss: 1685.779175\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8380 (step 8380): 1.580691\n",
      "Batch #10\tAverage Generator Loss: 1656.500549\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8381 (step 8381): 1.303190\n",
      "Batch #10\tAverage Generator Loss: 1748.373627\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8382 (step 8382): 1.657713\n",
      "Batch #10\tAverage Generator Loss: 1669.704706\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8383 (step 8383): 1.339417\n",
      "Batch #10\tAverage Generator Loss: 1771.486206\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8384 (step 8384): 1.651847\n",
      "Batch #10\tAverage Generator Loss: 1741.836426\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8385 (step 8385): 1.448550\n",
      "Batch #10\tAverage Generator Loss: 1701.823901\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8386 (step 8386): 1.559408\n",
      "Batch #10\tAverage Generator Loss: 1643.533591\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8387 (step 8387): 1.440207\n",
      "Batch #10\tAverage Generator Loss: 1688.153088\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8388 (step 8388): 1.672415\n",
      "Batch #10\tAverage Generator Loss: 1422.806189\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8389 (step 8389): 1.334604\n",
      "Batch #10\tAverage Generator Loss: 1361.845844\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8390 (step 8390): 1.687145\n",
      "Batch #10\tAverage Generator Loss: 1786.348560\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8391 (step 8391): 1.300794\n",
      "Batch #10\tAverage Generator Loss: 1766.033838\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8392 (step 8392): 1.581086\n",
      "Batch #10\tAverage Generator Loss: 1746.459747\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8393 (step 8393): 1.328332\n",
      "Batch #10\tAverage Generator Loss: 1675.431421\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8394 (step 8394): 1.642342\n",
      "Batch #10\tAverage Generator Loss: 1458.116003\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8395 (step 8395): 1.373685\n",
      "Batch #10\tAverage Generator Loss: 1795.485260\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8396 (step 8396): 1.632108\n",
      "Batch #10\tAverage Generator Loss: 1483.779865\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8397 (step 8397): 1.384241\n",
      "Batch #10\tAverage Generator Loss: 1579.796143\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8398 (step 8398): 1.287021\n",
      "Batch #10\tAverage Generator Loss: 1453.878003\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8399 (step 8399): 1.529232\n",
      "Batch #10\tAverage Generator Loss: 1797.442749\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8400 (step 8400): 1.329286\n",
      "Batch #10\tAverage Generator Loss: 1887.471405\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8401 (step 8401): 1.728229\n",
      "Batch #10\tAverage Generator Loss: 1334.826624\tAverage Discriminator Loss: 0.065474\n",
      "\n",
      "Train time for epoch #8402 (step 8402): 1.287012\n",
      "Batch #10\tAverage Generator Loss: 1335.489899\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #8403 (step 8403): 1.626975\n",
      "Batch #10\tAverage Generator Loss: 1397.282776\tAverage Discriminator Loss: 0.000101\n",
      "\n",
      "Train time for epoch #8404 (step 8404): 1.287983\n",
      "Batch #10\tAverage Generator Loss: 1141.731470\tAverage Discriminator Loss: 0.026867\n",
      "\n",
      "Train time for epoch #8405 (step 8405): 1.569813\n",
      "Batch #10\tAverage Generator Loss: 1197.064763\tAverage Discriminator Loss: 0.009757\n",
      "\n",
      "Train time for epoch #8406 (step 8406): 1.276801\n",
      "Batch #10\tAverage Generator Loss: 1216.270001\tAverage Discriminator Loss: 0.000037\n",
      "\n",
      "Train time for epoch #8407 (step 8407): 1.605789\n",
      "Batch #10\tAverage Generator Loss: 1163.928381\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8408 (step 8408): 1.376385\n",
      "Batch #10\tAverage Generator Loss: 1174.348907\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #8409 (step 8409): 1.663293\n",
      "Batch #10\tAverage Generator Loss: 1267.253644\tAverage Discriminator Loss: 0.182202\n",
      "\n",
      "Train time for epoch #8410 (step 8410): 1.409735\n",
      "Batch #10\tAverage Generator Loss: 1020.955028\tAverage Discriminator Loss: 0.033432\n",
      "\n",
      "Train time for epoch #8411 (step 8411): 1.628513\n",
      "Batch #10\tAverage Generator Loss: 1143.708719\tAverage Discriminator Loss: 0.071662\n",
      "\n",
      "Train time for epoch #8412 (step 8412): 1.338490\n",
      "Batch #10\tAverage Generator Loss: 1552.324561\tAverage Discriminator Loss: 0.000663\n",
      "\n",
      "Train time for epoch #8413 (step 8413): 1.597685\n",
      "Batch #10\tAverage Generator Loss: 1788.650574\tAverage Discriminator Loss: 0.087633\n",
      "\n",
      "Train time for epoch #8414 (step 8414): 1.302130\n",
      "Batch #10\tAverage Generator Loss: 1627.428558\tAverage Discriminator Loss: 0.034589\n",
      "\n",
      "Train time for epoch #8415 (step 8415): 1.686718\n",
      "Batch #10\tAverage Generator Loss: 1778.502966\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8416 (step 8416): 1.412107\n",
      "Batch #10\tAverage Generator Loss: 1602.445227\tAverage Discriminator Loss: 0.000051\n",
      "\n",
      "Train time for epoch #8417 (step 8417): 1.761920\n",
      "Batch #10\tAverage Generator Loss: 1730.769415\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8418 (step 8418): 1.350159\n",
      "Batch #10\tAverage Generator Loss: 1897.135217\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8419 (step 8419): 1.585495\n",
      "Batch #10\tAverage Generator Loss: 1714.254865\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8420 (step 8420): 1.342638\n",
      "Batch #10\tAverage Generator Loss: 1670.160913\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8421 (step 8421): 1.731447\n",
      "Batch #10\tAverage Generator Loss: 1612.082092\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8422 (step 8422): 1.321897\n",
      "Batch #10\tAverage Generator Loss: 1741.526111\tAverage Discriminator Loss: 0.037143\n",
      "\n",
      "Train time for epoch #8423 (step 8423): 1.597324\n",
      "Batch #10\tAverage Generator Loss: 1666.547693\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8424 (step 8424): 1.406671\n",
      "Batch #10\tAverage Generator Loss: 1396.158423\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #8425 (step 8425): 1.381689\n",
      "Batch #10\tAverage Generator Loss: 1672.986630\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #8426 (step 8426): 1.589697\n",
      "Batch #10\tAverage Generator Loss: 1641.524719\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #8427 (step 8427): 1.601748\n",
      "Batch #10\tAverage Generator Loss: 1490.414362\tAverage Discriminator Loss: 0.000006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #8428 (step 8428): 1.293819\n",
      "Batch #10\tAverage Generator Loss: 1577.987177\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #8429 (step 8429): 1.572584\n",
      "Batch #10\tAverage Generator Loss: 1803.423206\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #8430 (step 8430): 1.344848\n",
      "Batch #10\tAverage Generator Loss: 1538.548383\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8431 (step 8431): 1.355830\n",
      "Batch #10\tAverage Generator Loss: 1570.522217\tAverage Discriminator Loss: 0.331577\n",
      "\n",
      "Train time for epoch #8432 (step 8432): 1.693971\n",
      "Batch #10\tAverage Generator Loss: 1367.309192\tAverage Discriminator Loss: 0.000057\n",
      "\n",
      "Train time for epoch #8433 (step 8433): 1.290427\n",
      "Batch #10\tAverage Generator Loss: 1640.498621\tAverage Discriminator Loss: 0.000580\n",
      "\n",
      "Train time for epoch #8434 (step 8434): 1.635654\n",
      "Batch #10\tAverage Generator Loss: 1499.030878\tAverage Discriminator Loss: 0.000024\n",
      "\n",
      "Train time for epoch #8435 (step 8435): 1.292947\n",
      "Batch #10\tAverage Generator Loss: 1415.865137\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #8436 (step 8436): 1.577459\n",
      "Batch #10\tAverage Generator Loss: 1449.954626\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8437 (step 8437): 1.398440\n",
      "Batch #10\tAverage Generator Loss: 1318.501935\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #8438 (step 8438): 1.686546\n",
      "Batch #10\tAverage Generator Loss: 1547.860010\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #8439 (step 8439): 1.361972\n",
      "Batch #10\tAverage Generator Loss: 1618.218713\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8440 (step 8440): 1.708312\n",
      "Batch #10\tAverage Generator Loss: 1381.965393\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #8441 (step 8441): 1.344360\n",
      "Batch #10\tAverage Generator Loss: 1541.322583\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #8442 (step 8442): 1.627688\n",
      "Batch #10\tAverage Generator Loss: 1308.198755\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #8443 (step 8443): 1.300724\n",
      "Batch #10\tAverage Generator Loss: 1452.407080\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #8444 (step 8444): 1.785988\n",
      "Batch #10\tAverage Generator Loss: 1550.602698\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #8445 (step 8445): 1.329151\n",
      "Batch #10\tAverage Generator Loss: 1634.643262\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8446 (step 8446): 1.609004\n",
      "Batch #10\tAverage Generator Loss: 1395.640247\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #8447 (step 8447): 1.295376\n",
      "Batch #10\tAverage Generator Loss: 1537.763538\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8448 (step 8448): 1.617861\n",
      "Batch #10\tAverage Generator Loss: 1603.523645\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8449 (step 8449): 1.339153\n",
      "Batch #10\tAverage Generator Loss: 1395.558704\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #8450 (step 8450): 1.562325\n",
      "Batch #10\tAverage Generator Loss: 1627.447131\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8451 (step 8451): 1.280024\n",
      "Batch #10\tAverage Generator Loss: 1351.497430\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8452 (step 8452): 1.636839\n",
      "Batch #10\tAverage Generator Loss: 1389.969391\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8453 (step 8453): 1.392372\n",
      "Batch #10\tAverage Generator Loss: 1551.704456\tAverage Discriminator Loss: 0.004130\n",
      "\n",
      "Train time for epoch #8454 (step 8454): 1.285156\n",
      "Batch #10\tAverage Generator Loss: 1459.743524\tAverage Discriminator Loss: 0.000111\n",
      "\n",
      "Train time for epoch #8455 (step 8455): 1.639790\n",
      "Batch #10\tAverage Generator Loss: 1618.935437\tAverage Discriminator Loss: 0.000256\n",
      "\n",
      "Train time for epoch #8456 (step 8456): 1.285078\n",
      "Batch #10\tAverage Generator Loss: 1664.698425\tAverage Discriminator Loss: 0.000019\n",
      "\n",
      "Train time for epoch #8457 (step 8457): 1.749943\n",
      "Batch #10\tAverage Generator Loss: 1611.839130\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #8458 (step 8458): 1.291972\n",
      "Batch #10\tAverage Generator Loss: 1545.764453\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #8459 (step 8459): 1.696210\n",
      "Batch #10\tAverage Generator Loss: 1480.295868\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #8460 (step 8460): 1.432124\n",
      "Batch #10\tAverage Generator Loss: 1605.320996\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #8461 (step 8461): 1.590297\n",
      "Batch #10\tAverage Generator Loss: 1502.883441\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #8462 (step 8462): 1.291418\n",
      "Batch #10\tAverage Generator Loss: 1474.489880\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #8463 (step 8463): 1.664319\n",
      "Batch #10\tAverage Generator Loss: 1487.031561\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #8464 (step 8464): 1.354371\n",
      "Batch #10\tAverage Generator Loss: 1501.244513\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #8465 (step 8465): 1.587696\n",
      "Batch #10\tAverage Generator Loss: 1531.193726\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #8466 (step 8466): 1.375084\n",
      "Batch #10\tAverage Generator Loss: 1523.750629\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #8467 (step 8467): 1.743578\n",
      "Batch #10\tAverage Generator Loss: 1633.535602\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #8468 (step 8468): 1.341820\n",
      "Batch #10\tAverage Generator Loss: 1655.403882\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #8469 (step 8469): 1.641328\n",
      "Batch #10\tAverage Generator Loss: 1589.997974\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #8470 (step 8470): 1.530134\n",
      "Batch #10\tAverage Generator Loss: 1660.376697\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #8471 (step 8471): 1.694662\n",
      "Batch #10\tAverage Generator Loss: 1446.714966\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #8472 (step 8472): 1.326207\n",
      "Batch #10\tAverage Generator Loss: 1696.319067\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8473 (step 8473): 1.305423\n",
      "Batch #10\tAverage Generator Loss: 1743.015906\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #8474 (step 8474): 1.589483\n",
      "Batch #10\tAverage Generator Loss: 1627.673285\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8475 (step 8475): 1.318579\n",
      "Batch #10\tAverage Generator Loss: 1650.990460\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #8476 (step 8476): 1.634332\n",
      "Batch #10\tAverage Generator Loss: 1709.508057\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #8477 (step 8477): 1.299353\n",
      "Batch #10\tAverage Generator Loss: 1764.747339\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #8478 (step 8478): 1.623701\n",
      "Batch #10\tAverage Generator Loss: 1399.882971\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8479 (step 8479): 1.330777\n",
      "Batch #10\tAverage Generator Loss: 1388.891565\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8480 (step 8480): 1.648770\n",
      "Batch #10\tAverage Generator Loss: 1525.934375\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8481 (step 8481): 1.414941\n",
      "Batch #10\tAverage Generator Loss: 1627.715063\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8482 (step 8482): 1.616048\n",
      "Batch #10\tAverage Generator Loss: 1927.137305\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8483 (step 8483): 1.389795\n",
      "Batch #10\tAverage Generator Loss: 1494.062036\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8484 (step 8484): 1.622081\n",
      "Batch #10\tAverage Generator Loss: 1670.051959\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8485 (step 8485): 1.377170\n",
      "Batch #10\tAverage Generator Loss: 1737.302338\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8486 (step 8486): 1.572752\n",
      "Batch #10\tAverage Generator Loss: 1636.399640\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8487 (step 8487): 1.319880\n",
      "Batch #10\tAverage Generator Loss: 1633.821979\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #8488 (step 8488): 1.572432\n",
      "Batch #10\tAverage Generator Loss: 1745.345093\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #8489 (step 8489): 1.394362\n",
      "Batch #10\tAverage Generator Loss: 1857.957288\tAverage Discriminator Loss: 0.000002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #8490 (step 8490): 1.675744\n",
      "Batch #10\tAverage Generator Loss: 1540.639984\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8491 (step 8491): 1.326378\n",
      "Batch #10\tAverage Generator Loss: 1538.966785\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8492 (step 8492): 1.575234\n",
      "Batch #10\tAverage Generator Loss: 1699.619092\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8493 (step 8493): 1.284893\n",
      "Batch #10\tAverage Generator Loss: 1447.239435\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8494 (step 8494): 1.584610\n",
      "Batch #10\tAverage Generator Loss: 1520.816742\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8495 (step 8495): 1.334322\n",
      "Batch #10\tAverage Generator Loss: 1610.123993\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8496 (step 8496): 1.673450\n",
      "Batch #10\tAverage Generator Loss: 1562.801678\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8497 (step 8497): 1.331424\n",
      "Batch #10\tAverage Generator Loss: 1672.776953\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8498 (step 8498): 1.360176\n",
      "Batch #10\tAverage Generator Loss: 1710.196155\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8499 (step 8499): 1.612090\n",
      "Batch #10\tAverage Generator Loss: 1581.943701\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8500 (step 8500): 1.354036\n",
      "Batch #10\tAverage Generator Loss: 1570.380829\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8501 (step 8501): 1.628267\n",
      "Batch #10\tAverage Generator Loss: 1372.971808\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8502 (step 8502): 1.430035\n",
      "Batch #10\tAverage Generator Loss: 1525.277283\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8503 (step 8503): 1.643470\n",
      "Batch #10\tAverage Generator Loss: 1457.018628\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8504 (step 8504): 1.334534\n",
      "Batch #10\tAverage Generator Loss: 1774.668079\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8505 (step 8505): 1.643371\n",
      "Batch #10\tAverage Generator Loss: 1524.660687\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8506 (step 8506): 1.286683\n",
      "Batch #10\tAverage Generator Loss: 1576.091229\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8507 (step 8507): 1.541407\n",
      "Batch #10\tAverage Generator Loss: 1529.934961\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8508 (step 8508): 1.391288\n",
      "Batch #10\tAverage Generator Loss: 1574.606500\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8509 (step 8509): 1.650410\n",
      "Batch #10\tAverage Generator Loss: 1643.336407\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8510 (step 8510): 1.335183\n",
      "Batch #10\tAverage Generator Loss: 1418.457318\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8511 (step 8511): 1.594921\n",
      "Batch #10\tAverage Generator Loss: 1527.638507\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8512 (step 8512): 1.330535\n",
      "Batch #10\tAverage Generator Loss: 1580.931213\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8513 (step 8513): 1.695780\n",
      "Batch #10\tAverage Generator Loss: 1481.726758\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8514 (step 8514): 1.336942\n",
      "Batch #10\tAverage Generator Loss: 1537.917609\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8515 (step 8515): 1.247659\n",
      "Batch #10\tAverage Generator Loss: 1289.614056\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8516 (step 8516): 1.625106\n",
      "Batch #10\tAverage Generator Loss: 1764.571686\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8517 (step 8517): 1.342361\n",
      "Batch #10\tAverage Generator Loss: 1668.577563\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8518 (step 8518): 1.752177\n",
      "Batch #10\tAverage Generator Loss: 1518.660223\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8519 (step 8519): 1.503987\n",
      "Batch #10\tAverage Generator Loss: 1536.423792\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8520 (step 8520): 1.651427\n",
      "Batch #10\tAverage Generator Loss: 1689.263672\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8521 (step 8521): 1.266369\n",
      "Batch #10\tAverage Generator Loss: 1572.638501\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8522 (step 8522): 1.586288\n",
      "Batch #10\tAverage Generator Loss: 1454.711401\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8523 (step 8523): 1.385289\n",
      "Batch #10\tAverage Generator Loss: 1437.053180\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8524 (step 8524): 1.767214\n",
      "Batch #10\tAverage Generator Loss: 1555.155731\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8525 (step 8525): 1.374887\n",
      "Batch #10\tAverage Generator Loss: 1422.573108\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8526 (step 8526): 1.581670\n",
      "Batch #10\tAverage Generator Loss: 1539.435553\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8527 (step 8527): 1.298120\n",
      "Batch #10\tAverage Generator Loss: 1791.776001\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8528 (step 8528): 1.662982\n",
      "Batch #10\tAverage Generator Loss: 1606.843628\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8529 (step 8529): 1.333146\n",
      "Batch #10\tAverage Generator Loss: 1467.109302\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8530 (step 8530): 1.726593\n",
      "Batch #10\tAverage Generator Loss: 1492.833990\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8531 (step 8531): 1.334978\n",
      "Batch #10\tAverage Generator Loss: 1816.485229\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8532 (step 8532): 1.711138\n",
      "Batch #10\tAverage Generator Loss: 1564.089246\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8533 (step 8533): 1.289234\n",
      "Batch #10\tAverage Generator Loss: 1500.073328\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8534 (step 8534): 1.342242\n",
      "Batch #10\tAverage Generator Loss: 1678.253979\tAverage Discriminator Loss: 0.000260\n",
      "\n",
      "Train time for epoch #8535 (step 8535): 1.667187\n",
      "Batch #10\tAverage Generator Loss: 1631.410291\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #8536 (step 8536): 1.282201\n",
      "Batch #10\tAverage Generator Loss: 1442.651257\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #8537 (step 8537): 1.670998\n",
      "Batch #10\tAverage Generator Loss: 1695.579291\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #8538 (step 8538): 1.363107\n",
      "Batch #10\tAverage Generator Loss: 1514.464404\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #8539 (step 8539): 1.654478\n",
      "Batch #10\tAverage Generator Loss: 1656.963947\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #8540 (step 8540): 1.282619\n",
      "Batch #10\tAverage Generator Loss: 1375.921631\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #8541 (step 8541): 1.644727\n",
      "Batch #10\tAverage Generator Loss: 1626.517773\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #8542 (step 8542): 1.290668\n",
      "Batch #10\tAverage Generator Loss: 1639.734259\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #8543 (step 8543): 1.628013\n",
      "Batch #10\tAverage Generator Loss: 1558.160388\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #8544 (step 8544): 1.332177\n",
      "Batch #10\tAverage Generator Loss: 1414.270349\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #8545 (step 8545): 1.605419\n",
      "Batch #10\tAverage Generator Loss: 1611.303064\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8546 (step 8546): 1.286707\n",
      "Batch #10\tAverage Generator Loss: 1659.306799\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8547 (step 8547): 1.601593\n",
      "Batch #10\tAverage Generator Loss: 1615.068604\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8548 (step 8548): 1.280238\n",
      "Batch #10\tAverage Generator Loss: 1452.816852\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8549 (step 8549): 1.692866\n",
      "Batch #10\tAverage Generator Loss: 1494.961475\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8550 (step 8550): 1.243904\n",
      "Batch #10\tAverage Generator Loss: 1537.108752\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8551 (step 8551): 1.580351\n",
      "Batch #10\tAverage Generator Loss: 1572.693787\tAverage Discriminator Loss: 0.000002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #8552 (step 8552): 1.293444\n",
      "Batch #10\tAverage Generator Loss: 1418.425238\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8553 (step 8553): 1.697581\n",
      "Batch #10\tAverage Generator Loss: 1411.605057\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8554 (step 8554): 1.388582\n",
      "Batch #10\tAverage Generator Loss: 1600.033655\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8555 (step 8555): 1.724715\n",
      "Batch #10\tAverage Generator Loss: 1515.295599\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8556 (step 8556): 1.380507\n",
      "Batch #10\tAverage Generator Loss: 1425.057056\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8557 (step 8557): 1.648661\n",
      "Batch #10\tAverage Generator Loss: 1634.835693\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8558 (step 8558): 1.414422\n",
      "Batch #10\tAverage Generator Loss: 1660.435168\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8559 (step 8559): 1.648362\n",
      "Batch #10\tAverage Generator Loss: 1503.838318\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8560 (step 8560): 1.319791\n",
      "Batch #10\tAverage Generator Loss: 1716.698755\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8561 (step 8561): 1.648478\n",
      "Batch #10\tAverage Generator Loss: 1624.731177\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8562 (step 8562): 1.385066\n",
      "Batch #10\tAverage Generator Loss: 1553.387653\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8563 (step 8563): 1.563699\n",
      "Batch #10\tAverage Generator Loss: 1372.914722\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8564 (step 8564): 1.442015\n",
      "Batch #10\tAverage Generator Loss: 1485.674475\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8565 (step 8565): 1.292062\n",
      "Batch #10\tAverage Generator Loss: 1687.410645\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8566 (step 8566): 1.673867\n",
      "Batch #10\tAverage Generator Loss: 1532.674979\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8567 (step 8567): 1.363224\n",
      "Batch #10\tAverage Generator Loss: 1620.391809\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8568 (step 8568): 1.594447\n",
      "Batch #10\tAverage Generator Loss: 1610.974756\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8569 (step 8569): 1.477590\n",
      "Batch #10\tAverage Generator Loss: 1547.376624\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8570 (step 8570): 1.609171\n",
      "Batch #10\tAverage Generator Loss: 1536.052509\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8571 (step 8571): 1.460227\n",
      "Batch #10\tAverage Generator Loss: 1371.021094\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8572 (step 8572): 1.668383\n",
      "Batch #10\tAverage Generator Loss: 1681.046582\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8573 (step 8573): 1.292449\n",
      "Batch #10\tAverage Generator Loss: 1634.226807\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8574 (step 8574): 1.533995\n",
      "Batch #10\tAverage Generator Loss: 1561.778888\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8575 (step 8575): 1.318065\n",
      "Batch #10\tAverage Generator Loss: 1537.334058\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8576 (step 8576): 1.635728\n",
      "Batch #10\tAverage Generator Loss: 1504.886896\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8577 (step 8577): 1.287931\n",
      "Batch #10\tAverage Generator Loss: 1657.910596\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8578 (step 8578): 1.475747\n",
      "Batch #10\tAverage Generator Loss: 1480.562604\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8579 (step 8579): 1.684278\n",
      "Batch #10\tAverage Generator Loss: 1506.933881\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8580 (step 8580): 1.684420\n",
      "Batch #10\tAverage Generator Loss: 1628.030017\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8581 (step 8581): 1.284868\n",
      "Batch #10\tAverage Generator Loss: 1551.427515\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8582 (step 8582): 1.291762\n",
      "Batch #10\tAverage Generator Loss: 1477.268768\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8583 (step 8583): 1.626031\n",
      "Batch #10\tAverage Generator Loss: 1569.085663\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8584 (step 8584): 1.322926\n",
      "Batch #10\tAverage Generator Loss: 1551.817969\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8585 (step 8585): 1.604940\n",
      "Batch #10\tAverage Generator Loss: 1509.214764\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #8586 (step 8586): 1.338936\n",
      "Batch #10\tAverage Generator Loss: 1595.878180\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8587 (step 8587): 1.672336\n",
      "Batch #10\tAverage Generator Loss: 1513.622601\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8588 (step 8588): 1.331666\n",
      "Batch #10\tAverage Generator Loss: 1697.684601\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8589 (step 8589): 1.632065\n",
      "Batch #10\tAverage Generator Loss: 1448.645911\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8590 (step 8590): 1.328217\n",
      "Batch #10\tAverage Generator Loss: 1594.864490\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8591 (step 8591): 1.617147\n",
      "Batch #10\tAverage Generator Loss: 1486.910596\tAverage Discriminator Loss: 0.013573\n",
      "\n",
      "Train time for epoch #8592 (step 8592): 1.317428\n",
      "Batch #10\tAverage Generator Loss: 1497.819443\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #8593 (step 8593): 1.584359\n",
      "Batch #10\tAverage Generator Loss: 1285.970526\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8594 (step 8594): 1.278957\n",
      "Batch #10\tAverage Generator Loss: 1741.026892\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #8595 (step 8595): 1.694978\n",
      "Batch #10\tAverage Generator Loss: 1259.300159\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8596 (step 8596): 1.337938\n",
      "Batch #10\tAverage Generator Loss: 1576.296472\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8597 (step 8597): 1.607963\n",
      "Batch #10\tAverage Generator Loss: 1567.262280\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8598 (step 8598): 1.324781\n",
      "Batch #10\tAverage Generator Loss: 1829.455725\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8599 (step 8599): 1.640379\n",
      "Batch #10\tAverage Generator Loss: 1724.491736\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8600 (step 8600): 1.429737\n",
      "Batch #10\tAverage Generator Loss: 1585.921777\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8601 (step 8601): 1.727347\n",
      "Batch #10\tAverage Generator Loss: 1233.546173\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8602 (step 8602): 1.288634\n",
      "Batch #10\tAverage Generator Loss: 1684.017896\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8603 (step 8603): 1.334987\n",
      "Batch #10\tAverage Generator Loss: 1701.404712\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8604 (step 8604): 1.602019\n",
      "Batch #10\tAverage Generator Loss: 1524.876624\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8605 (step 8605): 1.292029\n",
      "Batch #10\tAverage Generator Loss: 1385.249902\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8606 (step 8606): 1.688230\n",
      "Batch #10\tAverage Generator Loss: 1528.406833\tAverage Discriminator Loss: 0.002688\n",
      "\n",
      "Train time for epoch #8607 (step 8607): 1.382333\n",
      "Batch #10\tAverage Generator Loss: 1651.679053\tAverage Discriminator Loss: 0.007415\n",
      "\n",
      "Train time for epoch #8608 (step 8608): 1.575760\n",
      "Batch #10\tAverage Generator Loss: 1493.742578\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8609 (step 8609): 1.472174\n",
      "Batch #10\tAverage Generator Loss: 1515.376270\tAverage Discriminator Loss: 0.002238\n",
      "\n",
      "Train time for epoch #8610 (step 8610): 1.683280\n",
      "Batch #10\tAverage Generator Loss: 1555.394116\tAverage Discriminator Loss: 0.000102\n",
      "\n",
      "Train time for epoch #8611 (step 8611): 1.282552\n",
      "Batch #10\tAverage Generator Loss: 1909.019031\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #8612 (step 8612): 1.600447\n",
      "Batch #10\tAverage Generator Loss: 1709.250659\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #8613 (step 8613): 1.297785\n",
      "Batch #10\tAverage Generator Loss: 1741.599847\tAverage Discriminator Loss: 0.000005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #8614 (step 8614): 1.283879\n",
      "Batch #10\tAverage Generator Loss: 1612.345911\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #8615 (step 8615): 1.601715\n",
      "Batch #10\tAverage Generator Loss: 1720.516431\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #8616 (step 8616): 1.328160\n",
      "Batch #10\tAverage Generator Loss: 1725.934045\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #8617 (step 8617): 1.577478\n",
      "Batch #10\tAverage Generator Loss: 1667.319641\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #8618 (step 8618): 1.286611\n",
      "Batch #10\tAverage Generator Loss: 1844.432025\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #8619 (step 8619): 1.694307\n",
      "Batch #10\tAverage Generator Loss: 1513.161365\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8620 (step 8620): 1.241804\n",
      "Batch #10\tAverage Generator Loss: 1819.145465\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8621 (step 8621): 1.638499\n",
      "Batch #10\tAverage Generator Loss: 1587.525232\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8622 (step 8622): 1.384272\n",
      "Batch #10\tAverage Generator Loss: 1569.737561\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8623 (step 8623): 1.679586\n",
      "Batch #10\tAverage Generator Loss: 1648.434033\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8624 (step 8624): 1.391599\n",
      "Batch #10\tAverage Generator Loss: 1761.937964\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8625 (step 8625): 1.604541\n",
      "Batch #10\tAverage Generator Loss: 1866.327539\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8626 (step 8626): 1.295069\n",
      "Batch #10\tAverage Generator Loss: 1578.418250\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8627 (step 8627): 1.696450\n",
      "Batch #10\tAverage Generator Loss: 1495.876251\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8628 (step 8628): 1.393291\n",
      "Batch #10\tAverage Generator Loss: 1870.761871\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8629 (step 8629): 1.601756\n",
      "Batch #10\tAverage Generator Loss: 1829.980939\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8630 (step 8630): 1.340698\n",
      "Batch #10\tAverage Generator Loss: 1748.914319\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8631 (step 8631): 1.716952\n",
      "Batch #10\tAverage Generator Loss: 1835.645471\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8632 (step 8632): 1.429492\n",
      "Batch #10\tAverage Generator Loss: 1615.907629\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8633 (step 8633): 1.646636\n",
      "Batch #10\tAverage Generator Loss: 1664.659900\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8634 (step 8634): 1.341417\n",
      "Batch #10\tAverage Generator Loss: 1638.148645\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8635 (step 8635): 1.642694\n",
      "Batch #10\tAverage Generator Loss: 1551.080127\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8636 (step 8636): 1.325258\n",
      "Batch #10\tAverage Generator Loss: 1867.538586\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8637 (step 8637): 1.391001\n",
      "Batch #10\tAverage Generator Loss: 1884.799438\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8638 (step 8638): 1.651236\n",
      "Batch #10\tAverage Generator Loss: 1687.399530\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8639 (step 8639): 1.402269\n",
      "Batch #10\tAverage Generator Loss: 1567.612152\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8640 (step 8640): 1.635026\n",
      "Batch #10\tAverage Generator Loss: 1784.904602\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8641 (step 8641): 1.331440\n",
      "Batch #10\tAverage Generator Loss: 1677.842175\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8642 (step 8642): 1.626149\n",
      "Batch #10\tAverage Generator Loss: 1621.515564\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8643 (step 8643): 1.373557\n",
      "Batch #10\tAverage Generator Loss: 1556.346545\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8644 (step 8644): 1.580989\n",
      "Batch #10\tAverage Generator Loss: 1580.288989\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8645 (step 8645): 1.350556\n",
      "Batch #10\tAverage Generator Loss: 1805.939819\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8646 (step 8646): 1.617795\n",
      "Batch #10\tAverage Generator Loss: 1551.220923\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8647 (step 8647): 1.486529\n",
      "Batch #10\tAverage Generator Loss: 1755.475165\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8648 (step 8648): 1.570837\n",
      "Batch #10\tAverage Generator Loss: 1634.136987\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8649 (step 8649): 1.333824\n",
      "Batch #10\tAverage Generator Loss: 1808.578552\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8650 (step 8650): 1.593266\n",
      "Batch #10\tAverage Generator Loss: 1870.678656\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8651 (step 8651): 1.338788\n",
      "Batch #10\tAverage Generator Loss: 1756.055334\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8652 (step 8652): 1.287646\n",
      "Batch #10\tAverage Generator Loss: 1825.348401\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8653 (step 8653): 1.632328\n",
      "Batch #10\tAverage Generator Loss: 1692.263348\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8654 (step 8654): 1.389079\n",
      "Batch #10\tAverage Generator Loss: 1497.013477\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8655 (step 8655): 1.594836\n",
      "Batch #10\tAverage Generator Loss: 1849.767444\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8656 (step 8656): 1.331669\n",
      "Batch #10\tAverage Generator Loss: 1792.381384\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8657 (step 8657): 1.616123\n",
      "Batch #10\tAverage Generator Loss: 1741.658655\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8658 (step 8658): 1.313999\n",
      "Batch #10\tAverage Generator Loss: 1754.523206\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8659 (step 8659): 1.685809\n",
      "Batch #10\tAverage Generator Loss: 1662.075433\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8660 (step 8660): 1.318364\n",
      "Batch #10\tAverage Generator Loss: 1903.874432\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8661 (step 8661): 1.698221\n",
      "Batch #10\tAverage Generator Loss: 1743.798776\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8662 (step 8662): 1.426979\n",
      "Batch #10\tAverage Generator Loss: 1681.142255\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8663 (step 8663): 1.610397\n",
      "Batch #10\tAverage Generator Loss: 1619.356427\tAverage Discriminator Loss: 0.000347\n",
      "\n",
      "Train time for epoch #8664 (step 8664): 1.305921\n",
      "Batch #10\tAverage Generator Loss: 1733.231500\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #8665 (step 8665): 1.613339\n",
      "Batch #10\tAverage Generator Loss: 1812.832214\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #8666 (step 8666): 1.350500\n",
      "Batch #10\tAverage Generator Loss: 1801.483594\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #8667 (step 8667): 1.346121\n",
      "Batch #10\tAverage Generator Loss: 1690.863196\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8668 (step 8668): 1.677175\n",
      "Batch #10\tAverage Generator Loss: 1598.605524\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8669 (step 8669): 1.406478\n",
      "Batch #10\tAverage Generator Loss: 1591.442328\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8670 (step 8670): 1.744591\n",
      "Batch #10\tAverage Generator Loss: 1617.605334\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8671 (step 8671): 1.392562\n",
      "Batch #10\tAverage Generator Loss: 1567.707849\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8672 (step 8672): 1.606061\n",
      "Batch #10\tAverage Generator Loss: 1592.847687\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8673 (step 8673): 1.502003\n",
      "Batch #10\tAverage Generator Loss: 1733.213391\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8674 (step 8674): 1.561808\n",
      "Batch #10\tAverage Generator Loss: 1607.567499\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8675 (step 8675): 1.291943\n",
      "Batch #10\tAverage Generator Loss: 1523.410468\tAverage Discriminator Loss: 0.117850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #8676 (step 8676): 1.649117\n",
      "Batch #10\tAverage Generator Loss: 1318.550809\tAverage Discriminator Loss: 0.000937\n",
      "\n",
      "Train time for epoch #8677 (step 8677): 1.354358\n",
      "Batch #10\tAverage Generator Loss: 1162.527496\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #8678 (step 8678): 1.718226\n",
      "Batch #10\tAverage Generator Loss: 1245.674902\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8679 (step 8679): 1.444953\n",
      "Batch #10\tAverage Generator Loss: 1154.673260\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8680 (step 8680): 1.735777\n",
      "Batch #10\tAverage Generator Loss: 1155.162643\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8681 (step 8681): 1.317562\n",
      "Batch #10\tAverage Generator Loss: 1183.994275\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8682 (step 8682): 1.635090\n",
      "Batch #10\tAverage Generator Loss: 1111.528290\tAverage Discriminator Loss: 0.069710\n",
      "\n",
      "Train time for epoch #8683 (step 8683): 1.409503\n",
      "Batch #10\tAverage Generator Loss: 1358.307074\tAverage Discriminator Loss: 0.000515\n",
      "\n",
      "Train time for epoch #8684 (step 8684): 1.659345\n",
      "Batch #10\tAverage Generator Loss: 1422.238336\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8685 (step 8685): 1.292564\n",
      "Batch #10\tAverage Generator Loss: 1398.534271\tAverage Discriminator Loss: 0.000024\n",
      "\n",
      "Train time for epoch #8686 (step 8686): 1.642333\n",
      "Batch #10\tAverage Generator Loss: 1293.742816\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8687 (step 8687): 1.340275\n",
      "Batch #10\tAverage Generator Loss: 1364.849548\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8688 (step 8688): 1.289629\n",
      "Batch #10\tAverage Generator Loss: 1430.532166\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8689 (step 8689): 1.536506\n",
      "Batch #10\tAverage Generator Loss: 1265.245837\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8690 (step 8690): 1.389244\n",
      "Batch #10\tAverage Generator Loss: 1391.526349\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8691 (step 8691): 1.588919\n",
      "Batch #10\tAverage Generator Loss: 1450.528491\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8692 (step 8692): 1.300894\n",
      "Batch #10\tAverage Generator Loss: 1478.658051\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8693 (step 8693): 1.588360\n",
      "Batch #10\tAverage Generator Loss: 1136.231036\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8694 (step 8694): 1.321300\n",
      "Batch #10\tAverage Generator Loss: 1517.253967\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8695 (step 8695): 1.617495\n",
      "Batch #10\tAverage Generator Loss: 1441.424738\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8696 (step 8696): 1.365680\n",
      "Batch #10\tAverage Generator Loss: 1348.353113\tAverage Discriminator Loss: 0.007888\n",
      "\n",
      "Train time for epoch #8697 (step 8697): 1.654728\n",
      "Batch #10\tAverage Generator Loss: 1372.516962\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8698 (step 8698): 1.275135\n",
      "Batch #10\tAverage Generator Loss: 1384.839960\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8699 (step 8699): 1.808920\n",
      "Batch #10\tAverage Generator Loss: 1501.098102\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8700 (step 8700): 1.302436\n",
      "Batch #10\tAverage Generator Loss: 1391.200519\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8701 (step 8701): 1.303351\n",
      "Batch #10\tAverage Generator Loss: 1494.531604\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8702 (step 8702): 1.681845\n",
      "Batch #10\tAverage Generator Loss: 1313.631561\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8703 (step 8703): 1.290437\n",
      "Batch #10\tAverage Generator Loss: 1244.387958\tAverage Discriminator Loss: 0.001651\n",
      "\n",
      "Train time for epoch #8704 (step 8704): 1.663157\n",
      "Batch #10\tAverage Generator Loss: 1519.694775\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8705 (step 8705): 1.284549\n",
      "Batch #10\tAverage Generator Loss: 1198.975446\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8706 (step 8706): 1.603861\n",
      "Batch #10\tAverage Generator Loss: 1437.493616\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8707 (step 8707): 1.443421\n",
      "Batch #10\tAverage Generator Loss: 1198.701587\tAverage Discriminator Loss: 0.013680\n",
      "\n",
      "Train time for epoch #8708 (step 8708): 1.656158\n",
      "Batch #10\tAverage Generator Loss: 1494.180029\tAverage Discriminator Loss: 0.000130\n",
      "\n",
      "Train time for epoch #8709 (step 8709): 1.299642\n",
      "Batch #10\tAverage Generator Loss: 1496.671790\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #8710 (step 8710): 1.655370\n",
      "Batch #10\tAverage Generator Loss: 1333.674982\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8711 (step 8711): 1.301281\n",
      "Batch #10\tAverage Generator Loss: 1217.133624\tAverage Discriminator Loss: 0.049637\n",
      "\n",
      "Train time for epoch #8712 (step 8712): 1.638079\n",
      "Batch #10\tAverage Generator Loss: 1152.054608\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #8713 (step 8713): 1.390276\n",
      "Batch #10\tAverage Generator Loss: 1381.090186\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8714 (step 8714): 1.641667\n",
      "Batch #10\tAverage Generator Loss: 1349.956647\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8715 (step 8715): 1.346445\n",
      "Batch #10\tAverage Generator Loss: 1523.585474\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8716 (step 8716): 1.645218\n",
      "Batch #10\tAverage Generator Loss: 1480.753259\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8717 (step 8717): 1.426136\n",
      "Batch #10\tAverage Generator Loss: 1357.592126\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8718 (step 8718): 1.638422\n",
      "Batch #10\tAverage Generator Loss: 1330.445215\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8719 (step 8719): 1.283308\n",
      "Batch #10\tAverage Generator Loss: 1450.673242\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8720 (step 8720): 1.616353\n",
      "Batch #10\tAverage Generator Loss: 1237.591364\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8721 (step 8721): 1.343060\n",
      "Batch #10\tAverage Generator Loss: 1425.119360\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8722 (step 8722): 1.338104\n",
      "Batch #10\tAverage Generator Loss: 1408.094586\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8723 (step 8723): 1.580946\n",
      "Batch #10\tAverage Generator Loss: 1088.172363\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8724 (step 8724): 1.289443\n",
      "Batch #10\tAverage Generator Loss: 1333.384430\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8725 (step 8725): 1.645812\n",
      "Batch #10\tAverage Generator Loss: 1395.336182\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8726 (step 8726): 1.390631\n",
      "Batch #10\tAverage Generator Loss: 1287.703754\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8727 (step 8727): 1.734960\n",
      "Batch #10\tAverage Generator Loss: 1553.001080\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8728 (step 8728): 1.399814\n",
      "Batch #10\tAverage Generator Loss: 1305.575671\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8729 (step 8729): 1.642114\n",
      "Batch #10\tAverage Generator Loss: 1566.429193\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8730 (step 8730): 1.289904\n",
      "Batch #10\tAverage Generator Loss: 1250.404248\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8731 (step 8731): 1.537873\n",
      "Batch #10\tAverage Generator Loss: 1439.109418\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8732 (step 8732): 1.292533\n",
      "Batch #10\tAverage Generator Loss: 1322.108057\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8733 (step 8733): 1.542688\n",
      "Batch #10\tAverage Generator Loss: 1392.116302\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8734 (step 8734): 1.298833\n",
      "Batch #10\tAverage Generator Loss: 1454.493195\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8735 (step 8735): 1.598933\n",
      "Batch #10\tAverage Generator Loss: 1442.737659\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8736 (step 8736): 1.335708\n",
      "Batch #10\tAverage Generator Loss: 1354.210425\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8737 (step 8737): 1.646020\n",
      "Batch #10\tAverage Generator Loss: 1479.890216\tAverage Discriminator Loss: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #8738 (step 8738): 1.452141\n",
      "Batch #10\tAverage Generator Loss: 1507.150842\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8739 (step 8739): 1.648728\n",
      "Batch #10\tAverage Generator Loss: 1296.407495\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8740 (step 8740): 1.293822\n",
      "Batch #10\tAverage Generator Loss: 1427.484570\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8741 (step 8741): 1.723519\n",
      "Batch #10\tAverage Generator Loss: 1290.114020\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8742 (step 8742): 1.287535\n",
      "Batch #10\tAverage Generator Loss: 1371.166699\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8743 (step 8743): 1.333777\n",
      "Batch #10\tAverage Generator Loss: 1460.230237\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8744 (step 8744): 1.598910\n",
      "Batch #10\tAverage Generator Loss: 1411.231335\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8745 (step 8745): 1.403235\n",
      "Batch #10\tAverage Generator Loss: 1464.119330\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8746 (step 8746): 1.698598\n",
      "Batch #10\tAverage Generator Loss: 1409.575378\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8747 (step 8747): 1.432838\n",
      "Batch #10\tAverage Generator Loss: 1451.274646\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8748 (step 8748): 1.617373\n",
      "Batch #10\tAverage Generator Loss: 1359.402710\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8749 (step 8749): 1.316046\n",
      "Batch #10\tAverage Generator Loss: 1397.848517\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8750 (step 8750): 1.623850\n",
      "Batch #10\tAverage Generator Loss: 1412.224802\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8751 (step 8751): 1.301773\n",
      "Batch #10\tAverage Generator Loss: 1442.179514\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8752 (step 8752): 1.592605\n",
      "Batch #10\tAverage Generator Loss: 1445.485461\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8753 (step 8753): 1.292443\n",
      "Batch #10\tAverage Generator Loss: 1074.807666\tAverage Discriminator Loss: 0.013624\n",
      "\n",
      "Train time for epoch #8754 (step 8754): 1.656760\n",
      "Batch #10\tAverage Generator Loss: 1446.947186\tAverage Discriminator Loss: 0.001151\n",
      "\n",
      "Train time for epoch #8755 (step 8755): 1.257895\n",
      "Batch #10\tAverage Generator Loss: 1476.421100\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #8756 (step 8756): 1.636081\n",
      "Batch #10\tAverage Generator Loss: 1414.190875\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8757 (step 8757): 1.376312\n",
      "Batch #10\tAverage Generator Loss: 1561.298779\tAverage Discriminator Loss: 0.012117\n",
      "\n",
      "Train time for epoch #8758 (step 8758): 1.650726\n",
      "Batch #10\tAverage Generator Loss: 1440.654913\tAverage Discriminator Loss: 0.000697\n",
      "\n",
      "Train time for epoch #8759 (step 8759): 1.344453\n",
      "Batch #10\tAverage Generator Loss: 1340.563135\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #8760 (step 8760): 1.645835\n",
      "Batch #10\tAverage Generator Loss: 1570.118604\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #8761 (step 8761): 1.401339\n",
      "Batch #10\tAverage Generator Loss: 1540.461584\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8762 (step 8762): 1.435152\n",
      "Batch #10\tAverage Generator Loss: 1307.932758\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8763 (step 8763): 1.588070\n",
      "Batch #10\tAverage Generator Loss: 1592.359985\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8764 (step 8764): 1.482899\n",
      "Batch #10\tAverage Generator Loss: 1376.647720\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8765 (step 8765): 1.667859\n",
      "Batch #10\tAverage Generator Loss: 1446.739618\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8766 (step 8766): 1.435778\n",
      "Batch #10\tAverage Generator Loss: 1615.875610\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8767 (step 8767): 1.641495\n",
      "Batch #10\tAverage Generator Loss: 1379.320190\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8768 (step 8768): 1.451420\n",
      "Batch #10\tAverage Generator Loss: 1454.062018\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8769 (step 8769): 1.736671\n",
      "Batch #10\tAverage Generator Loss: 1523.878424\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8770 (step 8770): 1.508144\n",
      "Batch #10\tAverage Generator Loss: 1482.200830\tAverage Discriminator Loss: 0.015120\n",
      "\n",
      "Train time for epoch #8771 (step 8771): 1.531298\n",
      "Batch #10\tAverage Generator Loss: 1397.941003\tAverage Discriminator Loss: 0.000027\n",
      "\n",
      "Train time for epoch #8772 (step 8772): 1.321306\n",
      "Batch #10\tAverage Generator Loss: 1403.693842\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #8773 (step 8773): 1.672132\n",
      "Batch #10\tAverage Generator Loss: 1693.744958\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #8774 (step 8774): 1.395142\n",
      "Batch #10\tAverage Generator Loss: 1439.114145\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #8775 (step 8775): 1.577437\n",
      "Batch #10\tAverage Generator Loss: 1438.107446\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #8776 (step 8776): 1.331622\n",
      "Batch #10\tAverage Generator Loss: 1316.467029\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #8777 (step 8777): 1.717854\n",
      "Batch #10\tAverage Generator Loss: 1394.117853\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #8778 (step 8778): 1.281567\n",
      "Batch #10\tAverage Generator Loss: 1409.192517\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #8779 (step 8779): 1.665756\n",
      "Batch #10\tAverage Generator Loss: 1457.869318\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #8780 (step 8780): 1.450794\n",
      "Batch #10\tAverage Generator Loss: 1400.584070\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #8781 (step 8781): 1.623940\n",
      "Batch #10\tAverage Generator Loss: 1409.556915\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #8782 (step 8782): 1.278285\n",
      "Batch #10\tAverage Generator Loss: 1414.055054\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #8783 (step 8783): 1.605441\n",
      "Batch #10\tAverage Generator Loss: 1413.455609\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8784 (step 8784): 1.283311\n",
      "Batch #10\tAverage Generator Loss: 1506.555493\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #8785 (step 8785): 1.652302\n",
      "Batch #10\tAverage Generator Loss: 1389.117322\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8786 (step 8786): 1.509088\n",
      "Batch #10\tAverage Generator Loss: 1462.964703\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8787 (step 8787): 1.303746\n",
      "Batch #10\tAverage Generator Loss: 1568.732520\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8788 (step 8788): 1.643372\n",
      "Batch #10\tAverage Generator Loss: 1461.887561\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8789 (step 8789): 1.376543\n",
      "Batch #10\tAverage Generator Loss: 1506.481061\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #8790 (step 8790): 1.554995\n",
      "Batch #10\tAverage Generator Loss: 1558.573322\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8791 (step 8791): 1.431656\n",
      "Batch #10\tAverage Generator Loss: 1554.373132\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8792 (step 8792): 1.607858\n",
      "Batch #10\tAverage Generator Loss: 1449.479120\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8793 (step 8793): 1.324989\n",
      "Batch #10\tAverage Generator Loss: 1610.675549\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8794 (step 8794): 1.642918\n",
      "Batch #10\tAverage Generator Loss: 1511.303809\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8795 (step 8795): 1.488565\n",
      "Batch #10\tAverage Generator Loss: 1368.977686\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8796 (step 8796): 1.776648\n",
      "Batch #10\tAverage Generator Loss: 1534.273108\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8797 (step 8797): 1.333443\n",
      "Batch #10\tAverage Generator Loss: 1446.853839\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8798 (step 8798): 1.286013\n",
      "Batch #10\tAverage Generator Loss: 1502.759650\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8799 (step 8799): 1.651547\n",
      "Batch #10\tAverage Generator Loss: 1497.248187\tAverage Discriminator Loss: 0.000001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #8800 (step 8800): 1.320221\n",
      "Batch #10\tAverage Generator Loss: 1711.041309\tAverage Discriminator Loss: 0.000843\n",
      "\n",
      "Train time for epoch #8801 (step 8801): 1.681779\n",
      "Batch #10\tAverage Generator Loss: 1348.563629\tAverage Discriminator Loss: 0.000206\n",
      "\n",
      "Train time for epoch #8802 (step 8802): 1.291628\n",
      "Batch #10\tAverage Generator Loss: 1432.369604\tAverage Discriminator Loss: 0.000051\n",
      "\n",
      "Train time for epoch #8803 (step 8803): 1.581969\n",
      "Batch #10\tAverage Generator Loss: 1562.091345\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #8804 (step 8804): 1.293059\n",
      "Batch #10\tAverage Generator Loss: 1484.654181\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #8805 (step 8805): 1.585288\n",
      "Batch #10\tAverage Generator Loss: 1666.209149\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #8806 (step 8806): 1.287828\n",
      "Batch #10\tAverage Generator Loss: 1458.661926\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #8807 (step 8807): 1.615196\n",
      "Batch #10\tAverage Generator Loss: 1462.162067\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #8808 (step 8808): 1.309077\n",
      "Batch #10\tAverage Generator Loss: 1491.010242\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #8809 (step 8809): 1.629201\n",
      "Batch #10\tAverage Generator Loss: 1477.974542\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #8810 (step 8810): 1.287557\n",
      "Batch #10\tAverage Generator Loss: 1500.439752\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #8811 (step 8811): 1.649403\n",
      "Batch #10\tAverage Generator Loss: 1446.590668\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #8812 (step 8812): 1.289483\n",
      "Batch #10\tAverage Generator Loss: 1462.013525\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #8813 (step 8813): 1.668123\n",
      "Batch #10\tAverage Generator Loss: 1290.386926\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8814 (step 8814): 1.269462\n",
      "Batch #10\tAverage Generator Loss: 1575.993567\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8815 (step 8815): 1.549967\n",
      "Batch #10\tAverage Generator Loss: 1382.245728\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #8816 (step 8816): 1.241250\n",
      "Batch #10\tAverage Generator Loss: 1448.107361\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #8817 (step 8817): 1.331636\n",
      "Batch #10\tAverage Generator Loss: 1585.452844\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #8818 (step 8818): 1.657110\n",
      "Batch #10\tAverage Generator Loss: 1484.381458\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8819 (step 8819): 1.339496\n",
      "Batch #10\tAverage Generator Loss: 1401.107831\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8820 (step 8820): 1.630962\n",
      "Batch #10\tAverage Generator Loss: 1642.702881\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8821 (step 8821): 1.332227\n",
      "Batch #10\tAverage Generator Loss: 1406.611096\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8822 (step 8822): 1.720082\n",
      "Batch #10\tAverage Generator Loss: 1382.486353\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8823 (step 8823): 1.280207\n",
      "Batch #10\tAverage Generator Loss: 1306.241574\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8824 (step 8824): 1.741592\n",
      "Batch #10\tAverage Generator Loss: 1304.454602\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8825 (step 8825): 1.375471\n",
      "Batch #10\tAverage Generator Loss: 1276.354169\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8826 (step 8826): 1.642201\n",
      "Batch #10\tAverage Generator Loss: 1606.454736\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8827 (step 8827): 1.281355\n",
      "Batch #10\tAverage Generator Loss: 1362.930762\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8828 (step 8828): 1.683707\n",
      "Batch #10\tAverage Generator Loss: 1374.332056\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8829 (step 8829): 1.423273\n",
      "Batch #10\tAverage Generator Loss: 1306.528168\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8830 (step 8830): 1.808063\n",
      "Batch #10\tAverage Generator Loss: 1466.819025\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8831 (step 8831): 1.315535\n",
      "Batch #10\tAverage Generator Loss: 1367.218079\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8832 (step 8832): 1.692606\n",
      "Batch #10\tAverage Generator Loss: 1351.651917\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8833 (step 8833): 1.275207\n",
      "Batch #10\tAverage Generator Loss: 1474.789349\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8834 (step 8834): 1.374106\n",
      "Batch #10\tAverage Generator Loss: 1457.534711\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8835 (step 8835): 1.686866\n",
      "Batch #10\tAverage Generator Loss: 1468.779041\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8836 (step 8836): 1.444089\n",
      "Batch #10\tAverage Generator Loss: 1387.902524\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8837 (step 8837): 1.604179\n",
      "Batch #10\tAverage Generator Loss: 1370.590363\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8838 (step 8838): 1.412093\n",
      "Batch #10\tAverage Generator Loss: 1551.922180\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8839 (step 8839): 1.633165\n",
      "Batch #10\tAverage Generator Loss: 1558.106799\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8840 (step 8840): 1.496149\n",
      "Batch #10\tAverage Generator Loss: 1507.315997\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8841 (step 8841): 1.583674\n",
      "Batch #10\tAverage Generator Loss: 1448.738031\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #8842 (step 8842): 1.443602\n",
      "Batch #10\tAverage Generator Loss: 1646.732605\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8843 (step 8843): 1.559389\n",
      "Batch #10\tAverage Generator Loss: 1446.969897\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8844 (step 8844): 1.348036\n",
      "Batch #10\tAverage Generator Loss: 1425.548889\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8845 (step 8845): 1.573115\n",
      "Batch #10\tAverage Generator Loss: 1543.120758\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8846 (step 8846): 1.286423\n",
      "Batch #10\tAverage Generator Loss: 1464.225879\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8847 (step 8847): 1.579245\n",
      "Batch #10\tAverage Generator Loss: 1488.361871\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8848 (step 8848): 1.305957\n",
      "Batch #10\tAverage Generator Loss: 1425.125256\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8849 (step 8849): 1.603395\n",
      "Batch #10\tAverage Generator Loss: 1361.250555\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8850 (step 8850): 1.393017\n",
      "Batch #10\tAverage Generator Loss: 1432.745496\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8851 (step 8851): 1.342389\n",
      "Batch #10\tAverage Generator Loss: 1479.839685\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8852 (step 8852): 1.650565\n",
      "Batch #10\tAverage Generator Loss: 1547.666614\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8853 (step 8853): 1.378399\n",
      "Batch #10\tAverage Generator Loss: 1467.581696\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8854 (step 8854): 1.750609\n",
      "Batch #10\tAverage Generator Loss: 1607.277802\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8855 (step 8855): 1.249544\n",
      "Batch #10\tAverage Generator Loss: 1417.121283\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8856 (step 8856): 1.612932\n",
      "Batch #10\tAverage Generator Loss: 1480.331964\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8857 (step 8857): 1.401137\n",
      "Batch #10\tAverage Generator Loss: 1536.149310\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8858 (step 8858): 1.573274\n",
      "Batch #10\tAverage Generator Loss: 1447.086542\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8859 (step 8859): 1.279494\n",
      "Batch #10\tAverage Generator Loss: 1510.711487\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8860 (step 8860): 1.720270\n",
      "Batch #10\tAverage Generator Loss: 1410.020230\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8861 (step 8861): 1.337593\n",
      "Batch #10\tAverage Generator Loss: 1547.062177\tAverage Discriminator Loss: 0.000001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #8862 (step 8862): 1.592992\n",
      "Batch #10\tAverage Generator Loss: 1489.648120\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8863 (step 8863): 1.324417\n",
      "Batch #10\tAverage Generator Loss: 1376.475317\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8864 (step 8864): 1.685980\n",
      "Batch #10\tAverage Generator Loss: 1439.505701\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8865 (step 8865): 1.351623\n",
      "Batch #10\tAverage Generator Loss: 1364.921405\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8866 (step 8866): 1.758314\n",
      "Batch #10\tAverage Generator Loss: 1429.617426\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8867 (step 8867): 1.356509\n",
      "Batch #10\tAverage Generator Loss: 1512.466193\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8868 (step 8868): 1.308476\n",
      "Batch #10\tAverage Generator Loss: 1568.410754\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8869 (step 8869): 1.709975\n",
      "Batch #10\tAverage Generator Loss: 1344.150415\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8870 (step 8870): 1.290313\n",
      "Batch #10\tAverage Generator Loss: 1526.253888\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8871 (step 8871): 1.740509\n",
      "Batch #10\tAverage Generator Loss: 1535.363300\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8872 (step 8872): 1.295726\n",
      "Batch #10\tAverage Generator Loss: 1463.254211\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8873 (step 8873): 1.635572\n",
      "Batch #10\tAverage Generator Loss: 1370.552112\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8874 (step 8874): 1.410474\n",
      "Batch #10\tAverage Generator Loss: 1563.094397\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8875 (step 8875): 1.601995\n",
      "Batch #10\tAverage Generator Loss: 1298.305530\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8876 (step 8876): 1.318702\n",
      "Batch #10\tAverage Generator Loss: 1466.941351\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8877 (step 8877): 1.688838\n",
      "Batch #10\tAverage Generator Loss: 1362.334518\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8878 (step 8878): 1.381208\n",
      "Batch #10\tAverage Generator Loss: 1419.957556\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8879 (step 8879): 1.699446\n",
      "Batch #10\tAverage Generator Loss: 1620.006799\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8880 (step 8880): 1.354518\n",
      "Batch #10\tAverage Generator Loss: 1366.136267\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8881 (step 8881): 1.636048\n",
      "Batch #10\tAverage Generator Loss: 1358.378973\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8882 (step 8882): 1.351022\n",
      "Batch #10\tAverage Generator Loss: 1340.752710\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8883 (step 8883): 1.615526\n",
      "Batch #10\tAverage Generator Loss: 1491.253308\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8884 (step 8884): 1.387166\n",
      "Batch #10\tAverage Generator Loss: 1298.339026\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8885 (step 8885): 1.337447\n",
      "Batch #10\tAverage Generator Loss: 1519.976086\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8886 (step 8886): 1.626450\n",
      "Batch #10\tAverage Generator Loss: 1445.241278\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8887 (step 8887): 1.325321\n",
      "Batch #10\tAverage Generator Loss: 1500.940222\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8888 (step 8888): 1.648751\n",
      "Batch #10\tAverage Generator Loss: 1284.557880\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8889 (step 8889): 1.282548\n",
      "Batch #10\tAverage Generator Loss: 1356.542419\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8890 (step 8890): 1.591198\n",
      "Batch #10\tAverage Generator Loss: 1633.730847\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8891 (step 8891): 1.290535\n",
      "Batch #10\tAverage Generator Loss: 1438.075751\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8892 (step 8892): 1.695016\n",
      "Batch #10\tAverage Generator Loss: 1495.627960\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8893 (step 8893): 1.297500\n",
      "Batch #10\tAverage Generator Loss: 1490.614331\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8894 (step 8894): 1.608921\n",
      "Batch #10\tAverage Generator Loss: 1523.478613\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8895 (step 8895): 1.413045\n",
      "Batch #10\tAverage Generator Loss: 1425.869788\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8896 (step 8896): 1.293797\n",
      "Batch #10\tAverage Generator Loss: 1524.437750\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8897 (step 8897): 1.878354\n",
      "Batch #10\tAverage Generator Loss: 1439.488904\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8898 (step 8898): 1.417326\n",
      "Batch #10\tAverage Generator Loss: 1571.149091\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8899 (step 8899): 1.627056\n",
      "Batch #10\tAverage Generator Loss: 1522.224750\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8900 (step 8900): 1.286882\n",
      "Batch #10\tAverage Generator Loss: 1455.478052\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8901 (step 8901): 1.613644\n",
      "Batch #10\tAverage Generator Loss: 1449.263226\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8902 (step 8902): 1.408601\n",
      "Batch #10\tAverage Generator Loss: 1466.009167\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8903 (step 8903): 1.328218\n",
      "Batch #10\tAverage Generator Loss: 1478.550671\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8904 (step 8904): 1.653699\n",
      "Batch #10\tAverage Generator Loss: 1367.062396\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8905 (step 8905): 1.497583\n",
      "Batch #10\tAverage Generator Loss: 1531.058466\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8906 (step 8906): 1.619949\n",
      "Batch #10\tAverage Generator Loss: 1447.166809\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8907 (step 8907): 1.318589\n",
      "Batch #10\tAverage Generator Loss: 1508.293628\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8908 (step 8908): 1.837969\n",
      "Batch #10\tAverage Generator Loss: 1475.809320\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8909 (step 8909): 1.380680\n",
      "Batch #10\tAverage Generator Loss: 1262.881427\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8910 (step 8910): 1.615557\n",
      "Batch #10\tAverage Generator Loss: 1541.574878\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8911 (step 8911): 1.305162\n",
      "Batch #10\tAverage Generator Loss: 1409.382147\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8912 (step 8912): 1.687474\n",
      "Batch #10\tAverage Generator Loss: 1559.823645\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8913 (step 8913): 1.292735\n",
      "Batch #10\tAverage Generator Loss: 1625.826538\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8914 (step 8914): 1.615727\n",
      "Batch #10\tAverage Generator Loss: 1400.580542\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8915 (step 8915): 1.298341\n",
      "Batch #10\tAverage Generator Loss: 1657.968506\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8916 (step 8916): 1.586568\n",
      "Batch #10\tAverage Generator Loss: 1539.060120\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8917 (step 8917): 1.281979\n",
      "Batch #10\tAverage Generator Loss: 1382.825830\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8918 (step 8918): 1.299093\n",
      "Batch #10\tAverage Generator Loss: 1378.647113\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8919 (step 8919): 1.584097\n",
      "Batch #10\tAverage Generator Loss: 1195.465863\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8920 (step 8920): 1.429370\n",
      "Batch #10\tAverage Generator Loss: 1353.179181\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8921 (step 8921): 1.625545\n",
      "Batch #10\tAverage Generator Loss: 1425.667267\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8922 (step 8922): 1.375010\n",
      "Batch #10\tAverage Generator Loss: 1517.468298\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8923 (step 8923): 1.618002\n",
      "Batch #10\tAverage Generator Loss: 1597.716101\tAverage Discriminator Loss: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #8924 (step 8924): 1.236531\n",
      "Batch #10\tAverage Generator Loss: 1283.372617\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8925 (step 8925): 1.628166\n",
      "Batch #10\tAverage Generator Loss: 1470.400134\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8926 (step 8926): 1.348548\n",
      "Batch #10\tAverage Generator Loss: 1478.518005\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8927 (step 8927): 1.683471\n",
      "Batch #10\tAverage Generator Loss: 1444.319562\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8928 (step 8928): 1.336169\n",
      "Batch #10\tAverage Generator Loss: 1520.353467\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8929 (step 8929): 1.581163\n",
      "Batch #10\tAverage Generator Loss: 1571.665259\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8930 (step 8930): 1.356635\n",
      "Batch #10\tAverage Generator Loss: 1388.041846\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #8931 (step 8931): 1.280486\n",
      "Batch #10\tAverage Generator Loss: 1312.548920\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8932 (step 8932): 1.647344\n",
      "Batch #10\tAverage Generator Loss: 1368.312695\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8933 (step 8933): 1.298485\n",
      "Batch #10\tAverage Generator Loss: 1353.456830\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8934 (step 8934): 1.639632\n",
      "Batch #10\tAverage Generator Loss: 1562.390936\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8935 (step 8935): 1.364215\n",
      "Batch #10\tAverage Generator Loss: 1593.502356\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8936 (step 8936): 1.664705\n",
      "Batch #10\tAverage Generator Loss: 1388.080756\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8937 (step 8937): 1.402742\n",
      "Batch #10\tAverage Generator Loss: 1480.754126\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8938 (step 8938): 1.605370\n",
      "Batch #10\tAverage Generator Loss: 1425.281110\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8939 (step 8939): 1.406620\n",
      "Batch #10\tAverage Generator Loss: 1316.165320\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8940 (step 8940): 1.616753\n",
      "Batch #10\tAverage Generator Loss: 1451.019360\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8941 (step 8941): 1.288261\n",
      "Batch #10\tAverage Generator Loss: 1343.355145\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8942 (step 8942): 1.747108\n",
      "Batch #10\tAverage Generator Loss: 1361.948792\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8943 (step 8943): 1.283410\n",
      "Batch #10\tAverage Generator Loss: 1537.688312\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8944 (step 8944): 1.297232\n",
      "Batch #10\tAverage Generator Loss: 1500.710150\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8945 (step 8945): 1.610744\n",
      "Batch #10\tAverage Generator Loss: 1477.529529\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8946 (step 8946): 1.338872\n",
      "Batch #10\tAverage Generator Loss: 1448.413300\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8947 (step 8947): 1.671623\n",
      "Batch #10\tAverage Generator Loss: 1289.452759\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8948 (step 8948): 1.355361\n",
      "Batch #10\tAverage Generator Loss: 1549.785791\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8949 (step 8949): 1.750636\n",
      "Batch #10\tAverage Generator Loss: 1331.196143\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8950 (step 8950): 1.330440\n",
      "Batch #10\tAverage Generator Loss: 1546.476904\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8951 (step 8951): 1.618122\n",
      "Batch #10\tAverage Generator Loss: 1414.534332\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8952 (step 8952): 1.280940\n",
      "Batch #10\tAverage Generator Loss: 1430.126324\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8953 (step 8953): 1.609320\n",
      "Batch #10\tAverage Generator Loss: 1401.997394\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8954 (step 8954): 1.323312\n",
      "Batch #10\tAverage Generator Loss: 1446.888623\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8955 (step 8955): 1.571458\n",
      "Batch #10\tAverage Generator Loss: 1351.087207\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8956 (step 8956): 1.293069\n",
      "Batch #10\tAverage Generator Loss: 1330.091846\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8957 (step 8957): 1.693626\n",
      "Batch #10\tAverage Generator Loss: 1551.776074\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8958 (step 8958): 1.331608\n",
      "Batch #10\tAverage Generator Loss: 1454.700720\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8959 (step 8959): 1.381553\n",
      "Batch #10\tAverage Generator Loss: 1526.039893\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8960 (step 8960): 1.604734\n",
      "Batch #10\tAverage Generator Loss: 1579.930627\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8961 (step 8961): 1.400259\n",
      "Batch #10\tAverage Generator Loss: 1414.971686\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8962 (step 8962): 1.602531\n",
      "Batch #10\tAverage Generator Loss: 1650.546448\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8963 (step 8963): 1.392851\n",
      "Batch #10\tAverage Generator Loss: 1534.894385\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8964 (step 8964): 1.598441\n",
      "Batch #10\tAverage Generator Loss: 1512.110950\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8965 (step 8965): 1.379041\n",
      "Batch #10\tAverage Generator Loss: 1275.514960\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8966 (step 8966): 1.653347\n",
      "Batch #10\tAverage Generator Loss: 1337.249811\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8967 (step 8967): 1.277837\n",
      "Batch #10\tAverage Generator Loss: 1456.137195\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8968 (step 8968): 1.332828\n",
      "Batch #10\tAverage Generator Loss: 1390.111316\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8969 (step 8969): 1.607965\n",
      "Batch #10\tAverage Generator Loss: 1481.305072\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8970 (step 8970): 1.272192\n",
      "Batch #10\tAverage Generator Loss: 1447.465247\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8971 (step 8971): 1.641353\n",
      "Batch #10\tAverage Generator Loss: 1601.538977\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8972 (step 8972): 1.415949\n",
      "Batch #10\tAverage Generator Loss: 1646.468103\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8973 (step 8973): 1.650129\n",
      "Batch #10\tAverage Generator Loss: 1645.096387\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8974 (step 8974): 1.280102\n",
      "Batch #10\tAverage Generator Loss: 1636.277002\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8975 (step 8975): 1.744586\n",
      "Batch #10\tAverage Generator Loss: 1527.011304\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8976 (step 8976): 1.328298\n",
      "Batch #10\tAverage Generator Loss: 1662.420544\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8977 (step 8977): 1.606434\n",
      "Batch #10\tAverage Generator Loss: 1492.527319\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8978 (step 8978): 1.330350\n",
      "Batch #10\tAverage Generator Loss: 1389.158405\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8979 (step 8979): 1.693045\n",
      "Batch #10\tAverage Generator Loss: 1400.632574\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8980 (step 8980): 1.284202\n",
      "Batch #10\tAverage Generator Loss: 1454.219513\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8981 (step 8981): 1.639771\n",
      "Batch #10\tAverage Generator Loss: 1471.203717\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8982 (step 8982): 1.288177\n",
      "Batch #10\tAverage Generator Loss: 1381.161810\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8983 (step 8983): 1.617235\n",
      "Batch #10\tAverage Generator Loss: 1559.911499\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8984 (step 8984): 1.343686\n",
      "Batch #10\tAverage Generator Loss: 1628.876691\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8985 (step 8985): 1.765157\n",
      "Batch #10\tAverage Generator Loss: 1385.987274\tAverage Discriminator Loss: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #8986 (step 8986): 1.309230\n",
      "Batch #10\tAverage Generator Loss: 1652.900916\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8987 (step 8987): 1.341708\n",
      "Batch #10\tAverage Generator Loss: 1435.610339\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8988 (step 8988): 1.572624\n",
      "Batch #10\tAverage Generator Loss: 1666.164331\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8989 (step 8989): 1.296761\n",
      "Batch #10\tAverage Generator Loss: 1488.775977\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8990 (step 8990): 1.602266\n",
      "Batch #10\tAverage Generator Loss: 1618.769739\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8991 (step 8991): 1.287094\n",
      "Batch #10\tAverage Generator Loss: 1452.744946\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8992 (step 8992): 1.692860\n",
      "Batch #10\tAverage Generator Loss: 1579.069098\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8993 (step 8993): 1.297778\n",
      "Batch #10\tAverage Generator Loss: 1643.288934\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8994 (step 8994): 1.698720\n",
      "Batch #10\tAverage Generator Loss: 1393.684552\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8995 (step 8995): 1.421995\n",
      "Batch #10\tAverage Generator Loss: 1383.708603\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8996 (step 8996): 1.422587\n",
      "Batch #10\tAverage Generator Loss: 1477.271167\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8997 (step 8997): 1.724354\n",
      "Batch #10\tAverage Generator Loss: 1511.907788\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8998 (step 8998): 1.373889\n",
      "Batch #10\tAverage Generator Loss: 1610.076862\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #8999 (step 8999): 1.674357\n",
      "Batch #10\tAverage Generator Loss: 1464.569250\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9000 (step 9000): 1.337360\n",
      "Batch #10\tAverage Generator Loss: 1500.212634\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9001 (step 9001): 1.739473\n",
      "Batch #10\tAverage Generator Loss: 1347.391617\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9002 (step 9002): 1.306678\n",
      "Batch #10\tAverage Generator Loss: 1546.677667\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9003 (step 9003): 1.644935\n",
      "Batch #10\tAverage Generator Loss: 1476.854810\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9004 (step 9004): 1.339012\n",
      "Batch #10\tAverage Generator Loss: 1586.858899\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9005 (step 9005): 1.695477\n",
      "Batch #10\tAverage Generator Loss: 1332.189124\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9006 (step 9006): 1.369381\n",
      "Batch #10\tAverage Generator Loss: 1340.026062\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9007 (step 9007): 1.755024\n",
      "Batch #10\tAverage Generator Loss: 1420.552966\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9008 (step 9008): 1.333560\n",
      "Batch #10\tAverage Generator Loss: 1497.829150\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9009 (step 9009): 1.628615\n",
      "Batch #10\tAverage Generator Loss: 1494.105127\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9010 (step 9010): 1.293934\n",
      "Batch #10\tAverage Generator Loss: 1499.445477\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9011 (step 9011): 1.299197\n",
      "Batch #10\tAverage Generator Loss: 1486.092279\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9012 (step 9012): 1.606474\n",
      "Batch #10\tAverage Generator Loss: 1321.097473\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9013 (step 9013): 1.380629\n",
      "Batch #10\tAverage Generator Loss: 1548.975085\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9014 (step 9014): 1.610985\n",
      "Batch #10\tAverage Generator Loss: 1416.602075\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9015 (step 9015): 1.363662\n",
      "Batch #10\tAverage Generator Loss: 1513.792395\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9016 (step 9016): 1.616205\n",
      "Batch #10\tAverage Generator Loss: 1424.868494\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9017 (step 9017): 1.369682\n",
      "Batch #10\tAverage Generator Loss: 1493.150891\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9018 (step 9018): 1.624193\n",
      "Batch #10\tAverage Generator Loss: 1577.298236\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9019 (step 9019): 1.347100\n",
      "Batch #10\tAverage Generator Loss: 1530.664447\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9020 (step 9020): 1.342076\n",
      "Batch #10\tAverage Generator Loss: 1470.318823\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9021 (step 9021): 1.617121\n",
      "Batch #10\tAverage Generator Loss: 1442.767993\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9022 (step 9022): 1.299764\n",
      "Batch #10\tAverage Generator Loss: 1426.485938\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9023 (step 9023): 1.633824\n",
      "Batch #10\tAverage Generator Loss: 1508.930725\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9024 (step 9024): 1.391968\n",
      "Batch #10\tAverage Generator Loss: 1357.008813\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9025 (step 9025): 1.607810\n",
      "Batch #10\tAverage Generator Loss: 1374.707593\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9026 (step 9026): 1.428475\n",
      "Batch #10\tAverage Generator Loss: 1415.685956\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9027 (step 9027): 1.665611\n",
      "Batch #10\tAverage Generator Loss: 1337.844604\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9028 (step 9028): 1.432376\n",
      "Batch #10\tAverage Generator Loss: 1650.936517\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9029 (step 9029): 1.794264\n",
      "Batch #10\tAverage Generator Loss: 1398.357492\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9030 (step 9030): 1.449780\n",
      "Batch #10\tAverage Generator Loss: 1541.085919\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9031 (step 9031): 1.616073\n",
      "Batch #10\tAverage Generator Loss: 1473.525330\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9032 (step 9032): 1.347024\n",
      "Batch #10\tAverage Generator Loss: 1544.534839\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9033 (step 9033): 1.641189\n",
      "Batch #10\tAverage Generator Loss: 1557.790735\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9034 (step 9034): 1.296251\n",
      "Batch #10\tAverage Generator Loss: 1497.498425\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9035 (step 9035): 1.304265\n",
      "Batch #10\tAverage Generator Loss: 1488.483685\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9036 (step 9036): 1.790613\n",
      "Batch #10\tAverage Generator Loss: 1401.966479\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9037 (step 9037): 1.274144\n",
      "Batch #10\tAverage Generator Loss: 1530.807288\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9038 (step 9038): 1.585636\n",
      "Batch #10\tAverage Generator Loss: 1324.848303\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9039 (step 9039): 1.342429\n",
      "Batch #10\tAverage Generator Loss: 1520.488666\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9040 (step 9040): 1.599236\n",
      "Batch #10\tAverage Generator Loss: 1416.478674\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9041 (step 9041): 1.305243\n",
      "Batch #10\tAverage Generator Loss: 1608.761865\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9042 (step 9042): 1.675989\n",
      "Batch #10\tAverage Generator Loss: 1302.289722\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9043 (step 9043): 1.300364\n",
      "Batch #10\tAverage Generator Loss: 1483.364136\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9044 (step 9044): 1.347851\n",
      "Batch #10\tAverage Generator Loss: 1508.067090\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9045 (step 9045): 1.651747\n",
      "Batch #10\tAverage Generator Loss: 1457.828186\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9046 (step 9046): 1.293787\n",
      "Batch #10\tAverage Generator Loss: 1360.324731\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9047 (step 9047): 1.662762\n",
      "Batch #10\tAverage Generator Loss: 1531.604211\tAverage Discriminator Loss: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #9048 (step 9048): 1.398546\n",
      "Batch #10\tAverage Generator Loss: 1575.559521\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9049 (step 9049): 1.612563\n",
      "Batch #10\tAverage Generator Loss: 1523.685718\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9050 (step 9050): 1.322777\n",
      "Batch #10\tAverage Generator Loss: 1563.919208\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9051 (step 9051): 1.754456\n",
      "Batch #10\tAverage Generator Loss: 1474.378580\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9052 (step 9052): 1.242840\n",
      "Batch #10\tAverage Generator Loss: 1494.668817\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9053 (step 9053): 1.566657\n",
      "Batch #10\tAverage Generator Loss: 1686.066138\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9054 (step 9054): 1.289948\n",
      "Batch #10\tAverage Generator Loss: 1442.795886\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9055 (step 9055): 1.721684\n",
      "Batch #10\tAverage Generator Loss: 1441.459628\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9056 (step 9056): 1.443578\n",
      "Batch #10\tAverage Generator Loss: 1263.406317\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9057 (step 9057): 1.316870\n",
      "Batch #10\tAverage Generator Loss: 1502.408014\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9058 (step 9058): 1.614723\n",
      "Batch #10\tAverage Generator Loss: 1693.194495\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9059 (step 9059): 1.291904\n",
      "Batch #10\tAverage Generator Loss: 1518.266351\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9060 (step 9060): 1.722000\n",
      "Batch #10\tAverage Generator Loss: 1703.664142\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9061 (step 9061): 1.323052\n",
      "Batch #10\tAverage Generator Loss: 1468.811383\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9062 (step 9062): 1.613811\n",
      "Batch #10\tAverage Generator Loss: 1470.293835\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9063 (step 9063): 1.374199\n",
      "Batch #10\tAverage Generator Loss: 1524.812659\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9064 (step 9064): 1.793907\n",
      "Batch #10\tAverage Generator Loss: 1266.232642\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9065 (step 9065): 1.398417\n",
      "Batch #10\tAverage Generator Loss: 1464.418994\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9066 (step 9066): 1.659745\n",
      "Batch #10\tAverage Generator Loss: 1474.199243\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9067 (step 9067): 1.338688\n",
      "Batch #10\tAverage Generator Loss: 1597.243481\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9068 (step 9068): 1.331138\n",
      "Batch #10\tAverage Generator Loss: 1520.549481\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9069 (step 9069): 1.559545\n",
      "Batch #10\tAverage Generator Loss: 1308.532187\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9070 (step 9070): 1.366480\n",
      "Batch #10\tAverage Generator Loss: 1388.161737\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9071 (step 9071): 1.599617\n",
      "Batch #10\tAverage Generator Loss: 1453.380219\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9072 (step 9072): 1.396929\n",
      "Batch #10\tAverage Generator Loss: 1435.870813\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9073 (step 9073): 1.571456\n",
      "Batch #10\tAverage Generator Loss: 1396.064111\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9074 (step 9074): 1.363317\n",
      "Batch #10\tAverage Generator Loss: 1394.629877\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9075 (step 9075): 1.632394\n",
      "Batch #10\tAverage Generator Loss: 1461.611530\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9076 (step 9076): 1.344437\n",
      "Batch #10\tAverage Generator Loss: 1492.297632\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9077 (step 9077): 1.432579\n",
      "Batch #10\tAverage Generator Loss: 1551.909595\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9078 (step 9078): 1.600938\n",
      "Batch #10\tAverage Generator Loss: 1344.211237\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9079 (step 9079): 1.294795\n",
      "Batch #10\tAverage Generator Loss: 1528.990259\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9080 (step 9080): 1.718399\n",
      "Batch #10\tAverage Generator Loss: 1214.864438\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9081 (step 9081): 1.436764\n",
      "Batch #10\tAverage Generator Loss: 1625.241431\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9082 (step 9082): 1.651855\n",
      "Batch #10\tAverage Generator Loss: 1398.276215\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9083 (step 9083): 1.459055\n",
      "Batch #10\tAverage Generator Loss: 1550.322479\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9084 (step 9084): 1.602992\n",
      "Batch #10\tAverage Generator Loss: 1478.962585\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9085 (step 9085): 1.381348\n",
      "Batch #10\tAverage Generator Loss: 1522.030402\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9086 (step 9086): 1.292634\n",
      "Batch #10\tAverage Generator Loss: 1507.680774\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9087 (step 9087): 1.702498\n",
      "Batch #10\tAverage Generator Loss: 1386.684241\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9088 (step 9088): 1.444154\n",
      "Batch #10\tAverage Generator Loss: 1518.840417\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9089 (step 9089): 1.654213\n",
      "Batch #10\tAverage Generator Loss: 1320.739499\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9090 (step 9090): 1.325294\n",
      "Batch #10\tAverage Generator Loss: 1331.738678\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9091 (step 9091): 1.671187\n",
      "Batch #10\tAverage Generator Loss: 1422.167358\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9092 (step 9092): 1.348325\n",
      "Batch #10\tAverage Generator Loss: 1543.782568\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9093 (step 9093): 1.646966\n",
      "Batch #10\tAverage Generator Loss: 1474.540741\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9094 (step 9094): 1.372201\n",
      "Batch #10\tAverage Generator Loss: 1515.220923\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9095 (step 9095): 1.620140\n",
      "Batch #10\tAverage Generator Loss: 1555.986090\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9096 (step 9096): 1.530844\n",
      "Batch #10\tAverage Generator Loss: 1394.281079\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9097 (step 9097): 1.297833\n",
      "Batch #10\tAverage Generator Loss: 1472.139929\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9098 (step 9098): 1.645746\n",
      "Batch #10\tAverage Generator Loss: 1392.485199\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9099 (step 9099): 1.342185\n",
      "Batch #10\tAverage Generator Loss: 1450.042908\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9100 (step 9100): 1.616313\n",
      "Batch #10\tAverage Generator Loss: 1469.814474\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9101 (step 9101): 1.299479\n",
      "Batch #10\tAverage Generator Loss: 1804.618359\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9102 (step 9102): 1.594480\n",
      "Batch #10\tAverage Generator Loss: 1384.487317\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9103 (step 9103): 1.383083\n",
      "Batch #10\tAverage Generator Loss: 1550.191516\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9104 (step 9104): 1.624510\n",
      "Batch #10\tAverage Generator Loss: 1406.194342\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9105 (step 9105): 1.352410\n",
      "Batch #10\tAverage Generator Loss: 1556.957385\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9106 (step 9106): 1.709321\n",
      "Batch #10\tAverage Generator Loss: 1486.469812\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9107 (step 9107): 1.351107\n",
      "Batch #10\tAverage Generator Loss: 1433.256744\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9108 (step 9108): 1.757933\n",
      "Batch #10\tAverage Generator Loss: 1470.089368\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9109 (step 9109): 1.333938\n",
      "Batch #10\tAverage Generator Loss: 1541.978827\tAverage Discriminator Loss: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #9110 (step 9110): 1.388032\n",
      "Batch #10\tAverage Generator Loss: 1479.642163\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9111 (step 9111): 1.695521\n",
      "Batch #10\tAverage Generator Loss: 1418.306305\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9112 (step 9112): 1.464552\n",
      "Batch #10\tAverage Generator Loss: 1623.623547\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9113 (step 9113): 1.697244\n",
      "Batch #10\tAverage Generator Loss: 1415.932013\tAverage Discriminator Loss: 0.048396\n",
      "\n",
      "Train time for epoch #9114 (step 9114): 1.291536\n",
      "Batch #10\tAverage Generator Loss: 1787.949182\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9115 (step 9115): 1.571540\n",
      "Batch #10\tAverage Generator Loss: 1801.554980\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9116 (step 9116): 1.279752\n",
      "Batch #10\tAverage Generator Loss: 2105.584546\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9117 (step 9117): 1.569368\n",
      "Batch #10\tAverage Generator Loss: 1973.058136\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9118 (step 9118): 1.322172\n",
      "Batch #10\tAverage Generator Loss: 2209.175684\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9119 (step 9119): 1.237418\n",
      "Batch #10\tAverage Generator Loss: 2446.872864\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9120 (step 9120): 1.652440\n",
      "Batch #10\tAverage Generator Loss: 2069.247620\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9121 (step 9121): 1.290832\n",
      "Batch #10\tAverage Generator Loss: 3012.679858\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9122 (step 9122): 1.612633\n",
      "Batch #10\tAverage Generator Loss: 2421.662097\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9123 (step 9123): 1.380273\n",
      "Batch #10\tAverage Generator Loss: 2445.306238\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9124 (step 9124): 1.601853\n",
      "Batch #10\tAverage Generator Loss: 2207.121179\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9125 (step 9125): 1.323974\n",
      "Batch #10\tAverage Generator Loss: 2295.180200\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9126 (step 9126): 1.578054\n",
      "Batch #10\tAverage Generator Loss: 2722.967310\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9127 (step 9127): 1.301835\n",
      "Batch #10\tAverage Generator Loss: 2588.373267\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9128 (step 9128): 1.809043\n",
      "Batch #10\tAverage Generator Loss: 2732.916882\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9129 (step 9129): 1.288642\n",
      "Batch #10\tAverage Generator Loss: 3168.809558\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9130 (step 9130): 1.748927\n",
      "Batch #10\tAverage Generator Loss: 2070.765710\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9131 (step 9131): 1.353871\n",
      "Batch #10\tAverage Generator Loss: 2446.871008\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9132 (step 9132): 1.750640\n",
      "Batch #10\tAverage Generator Loss: 2619.847668\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9133 (step 9133): 1.416819\n",
      "Batch #10\tAverage Generator Loss: 2704.312073\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9134 (step 9134): 1.332330\n",
      "Batch #10\tAverage Generator Loss: 1868.436304\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9135 (step 9135): 1.713363\n",
      "Batch #10\tAverage Generator Loss: 2402.853125\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9136 (step 9136): 1.381975\n",
      "Batch #10\tAverage Generator Loss: 2267.359070\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9137 (step 9137): 1.610234\n",
      "Batch #10\tAverage Generator Loss: 2265.143213\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9138 (step 9138): 1.388290\n",
      "Batch #10\tAverage Generator Loss: 2050.219562\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9139 (step 9139): 1.622564\n",
      "Batch #10\tAverage Generator Loss: 2288.832178\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9140 (step 9140): 1.433751\n",
      "Batch #10\tAverage Generator Loss: 1916.792029\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9141 (step 9141): 1.769896\n",
      "Batch #10\tAverage Generator Loss: 2227.335181\tAverage Discriminator Loss: 0.033872\n",
      "\n",
      "Train time for epoch #9142 (step 9142): 1.290352\n",
      "Batch #10\tAverage Generator Loss: 1932.069458\tAverage Discriminator Loss: 0.009187\n",
      "\n",
      "Train time for epoch #9143 (step 9143): 1.629142\n",
      "Batch #10\tAverage Generator Loss: 1884.746454\tAverage Discriminator Loss: 0.089298\n",
      "\n",
      "Train time for epoch #9144 (step 9144): 1.410254\n",
      "Batch #10\tAverage Generator Loss: 1628.906598\tAverage Discriminator Loss: 0.010152\n",
      "\n",
      "Train time for epoch #9145 (step 9145): 1.253692\n",
      "Batch #10\tAverage Generator Loss: 1069.727002\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9146 (step 9146): 1.623167\n",
      "Batch #10\tAverage Generator Loss: 1379.735513\tAverage Discriminator Loss: 0.023215\n",
      "\n",
      "Train time for epoch #9147 (step 9147): 1.349001\n",
      "Batch #10\tAverage Generator Loss: 1754.510522\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9148 (step 9148): 1.712083\n",
      "Batch #10\tAverage Generator Loss: 1615.377930\tAverage Discriminator Loss: 0.019740\n",
      "\n",
      "Train time for epoch #9149 (step 9149): 1.411538\n",
      "Batch #10\tAverage Generator Loss: 1496.714188\tAverage Discriminator Loss: 2.179378\n",
      "\n",
      "Train time for epoch #9150 (step 9150): 1.616369\n",
      "Batch #10\tAverage Generator Loss: 1986.747070\tAverage Discriminator Loss: 0.006117\n",
      "\n",
      "Train time for epoch #9151 (step 9151): 1.340925\n",
      "Batch #10\tAverage Generator Loss: 2259.338171\tAverage Discriminator Loss: 0.498803\n",
      "\n",
      "Train time for epoch #9152 (step 9152): 1.335521\n",
      "Batch #10\tAverage Generator Loss: 2565.440906\tAverage Discriminator Loss: 0.020195\n",
      "\n",
      "Train time for epoch #9153 (step 9153): 1.605668\n",
      "Batch #10\tAverage Generator Loss: 2389.084607\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #9154 (step 9154): 1.287100\n",
      "Batch #10\tAverage Generator Loss: 2832.905591\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #9155 (step 9155): 1.707641\n",
      "Batch #10\tAverage Generator Loss: 2308.818481\tAverage Discriminator Loss: 0.023219\n",
      "\n",
      "Train time for epoch #9156 (step 9156): 1.396051\n",
      "Batch #10\tAverage Generator Loss: 2450.621704\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9157 (step 9157): 1.638972\n",
      "Batch #10\tAverage Generator Loss: 1922.702948\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9158 (step 9158): 1.383545\n",
      "Batch #10\tAverage Generator Loss: 2205.194067\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9159 (step 9159): 1.648514\n",
      "Batch #10\tAverage Generator Loss: 2669.269165\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9160 (step 9160): 1.473175\n",
      "Batch #10\tAverage Generator Loss: 2373.888068\tAverage Discriminator Loss: 0.895911\n",
      "\n",
      "Train time for epoch #9161 (step 9161): 1.650626\n",
      "Batch #10\tAverage Generator Loss: 2196.529016\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9162 (step 9162): 1.438442\n",
      "Batch #10\tAverage Generator Loss: 2519.667163\tAverage Discriminator Loss: 0.004200\n",
      "\n",
      "Train time for epoch #9163 (step 9163): 1.284874\n",
      "Batch #10\tAverage Generator Loss: 2143.997070\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #9164 (step 9164): 1.704614\n",
      "Batch #10\tAverage Generator Loss: 1993.258881\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9165 (step 9165): 1.335438\n",
      "Batch #10\tAverage Generator Loss: 2379.172632\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9166 (step 9166): 1.689084\n",
      "Batch #10\tAverage Generator Loss: 2221.827563\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9167 (step 9167): 1.354279\n",
      "Batch #10\tAverage Generator Loss: 2274.889673\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9168 (step 9168): 1.670857\n",
      "Batch #10\tAverage Generator Loss: 2191.403284\tAverage Discriminator Loss: 0.028006\n",
      "\n",
      "Train time for epoch #9169 (step 9169): 1.337426\n",
      "Batch #10\tAverage Generator Loss: 1912.776453\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9170 (step 9170): 1.563576\n",
      "Batch #10\tAverage Generator Loss: 1915.212866\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9171 (step 9171): 1.381519\n",
      "Batch #10\tAverage Generator Loss: 2099.174496\tAverage Discriminator Loss: 0.000002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #9172 (step 9172): 1.658004\n",
      "Batch #10\tAverage Generator Loss: 2412.547656\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #9173 (step 9173): 1.331306\n",
      "Batch #10\tAverage Generator Loss: 2130.637701\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #9174 (step 9174): 1.423218\n",
      "Batch #10\tAverage Generator Loss: 2215.815503\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #9175 (step 9175): 1.662447\n",
      "Batch #10\tAverage Generator Loss: 2462.701495\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #9176 (step 9176): 1.369922\n",
      "Batch #10\tAverage Generator Loss: 2259.639874\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #9177 (step 9177): 1.664270\n",
      "Batch #10\tAverage Generator Loss: 2100.255774\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9178 (step 9178): 1.293110\n",
      "Batch #10\tAverage Generator Loss: 2153.196094\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #9179 (step 9179): 1.611604\n",
      "Batch #10\tAverage Generator Loss: 1810.972748\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #9180 (step 9180): 1.492914\n",
      "Batch #10\tAverage Generator Loss: 2250.755164\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #9181 (step 9181): 1.663677\n",
      "Batch #10\tAverage Generator Loss: 2558.402283\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #9182 (step 9182): 1.398201\n",
      "Batch #10\tAverage Generator Loss: 2574.562537\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #9183 (step 9183): 1.658566\n",
      "Batch #10\tAverage Generator Loss: 1887.753314\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9184 (step 9184): 1.303458\n",
      "Batch #10\tAverage Generator Loss: 2454.262573\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9185 (step 9185): 1.429502\n",
      "Batch #10\tAverage Generator Loss: 2461.395996\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9186 (step 9186): 1.686122\n",
      "Batch #10\tAverage Generator Loss: 2189.629163\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #9187 (step 9187): 1.344229\n",
      "Batch #10\tAverage Generator Loss: 2347.349988\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9188 (step 9188): 1.729076\n",
      "Batch #10\tAverage Generator Loss: 1957.700708\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9189 (step 9189): 1.287611\n",
      "Batch #10\tAverage Generator Loss: 2216.384607\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9190 (step 9190): 1.737327\n",
      "Batch #10\tAverage Generator Loss: 2588.446338\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9191 (step 9191): 1.391975\n",
      "Batch #10\tAverage Generator Loss: 2381.597241\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9192 (step 9192): 1.593594\n",
      "Batch #10\tAverage Generator Loss: 2430.988354\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9193 (step 9193): 1.352471\n",
      "Batch #10\tAverage Generator Loss: 2350.009399\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #9194 (step 9194): 1.705739\n",
      "Batch #10\tAverage Generator Loss: 2854.063892\tAverage Discriminator Loss: 0.000031\n",
      "\n",
      "Train time for epoch #9195 (step 9195): 1.442888\n",
      "Batch #10\tAverage Generator Loss: 2182.372925\tAverage Discriminator Loss: 0.118307\n",
      "\n",
      "Train time for epoch #9196 (step 9196): 1.374234\n",
      "Batch #10\tAverage Generator Loss: 2062.073999\tAverage Discriminator Loss: 0.012372\n",
      "\n",
      "Train time for epoch #9197 (step 9197): 1.598244\n",
      "Batch #10\tAverage Generator Loss: 2266.960724\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9198 (step 9198): 1.320760\n",
      "Batch #10\tAverage Generator Loss: 1961.178998\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9199 (step 9199): 1.700377\n",
      "Batch #10\tAverage Generator Loss: 2140.495093\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9200 (step 9200): 1.337751\n",
      "Batch #10\tAverage Generator Loss: 2276.460193\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9201 (step 9201): 1.600682\n",
      "Batch #10\tAverage Generator Loss: 2068.417303\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9202 (step 9202): 1.292545\n",
      "Batch #10\tAverage Generator Loss: 1824.294879\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9203 (step 9203): 1.626595\n",
      "Batch #10\tAverage Generator Loss: 2104.356201\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9204 (step 9204): 1.296187\n",
      "Batch #10\tAverage Generator Loss: 2102.797229\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9205 (step 9205): 1.652616\n",
      "Batch #10\tAverage Generator Loss: 2186.556335\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9206 (step 9206): 1.433151\n",
      "Batch #10\tAverage Generator Loss: 2039.180853\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9207 (step 9207): 1.342625\n",
      "Batch #10\tAverage Generator Loss: 2165.908179\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9208 (step 9208): 1.702044\n",
      "Batch #10\tAverage Generator Loss: 1982.511035\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9209 (step 9209): 1.288873\n",
      "Batch #10\tAverage Generator Loss: 2197.744446\tAverage Discriminator Loss: 0.000067\n",
      "\n",
      "Train time for epoch #9210 (step 9210): 1.600465\n",
      "Batch #10\tAverage Generator Loss: 2131.444287\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9211 (step 9211): 1.282014\n",
      "Batch #10\tAverage Generator Loss: 1927.848517\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9212 (step 9212): 1.663512\n",
      "Batch #10\tAverage Generator Loss: 2105.622839\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9213 (step 9213): 1.294432\n",
      "Batch #10\tAverage Generator Loss: 1956.291821\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9214 (step 9214): 1.650565\n",
      "Batch #10\tAverage Generator Loss: 1935.977881\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9215 (step 9215): 1.451673\n",
      "Batch #10\tAverage Generator Loss: 2016.119788\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9216 (step 9216): 1.685019\n",
      "Batch #10\tAverage Generator Loss: 2322.069263\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9217 (step 9217): 1.350594\n",
      "Batch #10\tAverage Generator Loss: 2036.539227\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9218 (step 9218): 1.478731\n",
      "Batch #10\tAverage Generator Loss: 2217.063965\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9219 (step 9219): 1.679142\n",
      "Batch #10\tAverage Generator Loss: 1846.384119\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9220 (step 9220): 1.327437\n",
      "Batch #10\tAverage Generator Loss: 1822.044858\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9221 (step 9221): 1.625895\n",
      "Batch #10\tAverage Generator Loss: 2245.849988\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9222 (step 9222): 1.300470\n",
      "Batch #10\tAverage Generator Loss: 2199.227917\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9223 (step 9223): 1.600827\n",
      "Batch #10\tAverage Generator Loss: 1920.317554\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9224 (step 9224): 1.400717\n",
      "Batch #10\tAverage Generator Loss: 1878.624915\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9225 (step 9225): 1.616817\n",
      "Batch #10\tAverage Generator Loss: 1912.645795\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9226 (step 9226): 1.288226\n",
      "Batch #10\tAverage Generator Loss: 2050.349792\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9227 (step 9227): 1.336203\n",
      "Batch #10\tAverage Generator Loss: 2238.036963\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9228 (step 9228): 1.690823\n",
      "Batch #10\tAverage Generator Loss: 1626.450446\tAverage Discriminator Loss: 0.005686\n",
      "\n",
      "Train time for epoch #9229 (step 9229): 1.468479\n",
      "Batch #10\tAverage Generator Loss: 2304.565906\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9230 (step 9230): 1.652265\n",
      "Batch #10\tAverage Generator Loss: 2103.254749\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #9231 (step 9231): 1.372341\n",
      "Batch #10\tAverage Generator Loss: 2440.053699\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9232 (step 9232): 1.671705\n",
      "Batch #10\tAverage Generator Loss: 2268.996960\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9233 (step 9233): 1.252883\n",
      "Batch #10\tAverage Generator Loss: 1909.359747\tAverage Discriminator Loss: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #9234 (step 9234): 1.671995\n",
      "Batch #10\tAverage Generator Loss: 2103.848340\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9235 (step 9235): 1.476077\n",
      "Batch #10\tAverage Generator Loss: 2046.925256\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9236 (step 9236): 1.308358\n",
      "Batch #10\tAverage Generator Loss: 1721.833801\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9237 (step 9237): 1.640227\n",
      "Batch #10\tAverage Generator Loss: 1804.892548\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9238 (step 9238): 1.277400\n",
      "Batch #10\tAverage Generator Loss: 1912.836664\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9239 (step 9239): 1.671226\n",
      "Batch #10\tAverage Generator Loss: 1981.007556\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9240 (step 9240): 1.301217\n",
      "Batch #10\tAverage Generator Loss: 2063.818420\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9241 (step 9241): 1.592562\n",
      "Batch #10\tAverage Generator Loss: 2020.088074\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9242 (step 9242): 1.335411\n",
      "Batch #10\tAverage Generator Loss: 2034.429578\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9243 (step 9243): 1.640144\n",
      "Batch #10\tAverage Generator Loss: 1729.093689\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9244 (step 9244): 1.292110\n",
      "Batch #10\tAverage Generator Loss: 2175.106311\tAverage Discriminator Loss: 0.342446\n",
      "\n",
      "Train time for epoch #9245 (step 9245): 1.606289\n",
      "Batch #10\tAverage Generator Loss: 2902.478516\tAverage Discriminator Loss: 0.079974\n",
      "\n",
      "Train time for epoch #9246 (step 9246): 1.320999\n",
      "Batch #10\tAverage Generator Loss: 3015.957178\tAverage Discriminator Loss: 0.001297\n",
      "\n",
      "Train time for epoch #9247 (step 9247): 1.369610\n",
      "Batch #10\tAverage Generator Loss: 2904.813501\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9248 (step 9248): 1.647203\n",
      "Batch #10\tAverage Generator Loss: 2837.567657\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9249 (step 9249): 1.376426\n",
      "Batch #10\tAverage Generator Loss: 2948.276990\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9250 (step 9250): 1.625392\n",
      "Batch #10\tAverage Generator Loss: 2579.611563\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9251 (step 9251): 1.239594\n",
      "Batch #10\tAverage Generator Loss: 2580.840039\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9252 (step 9252): 1.676046\n",
      "Batch #10\tAverage Generator Loss: 3002.540454\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9253 (step 9253): 1.328125\n",
      "Batch #10\tAverage Generator Loss: 2934.303308\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9254 (step 9254): 1.747914\n",
      "Batch #10\tAverage Generator Loss: 2779.491541\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9255 (step 9255): 1.330981\n",
      "Batch #10\tAverage Generator Loss: 2660.923450\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9256 (step 9256): 1.669391\n",
      "Batch #10\tAverage Generator Loss: 2895.756506\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9257 (step 9257): 1.295572\n",
      "Batch #10\tAverage Generator Loss: 2716.765906\tAverage Discriminator Loss: 0.044547\n",
      "\n",
      "Train time for epoch #9258 (step 9258): 1.477921\n",
      "Batch #10\tAverage Generator Loss: 2605.275635\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9259 (step 9259): 1.667618\n",
      "Batch #10\tAverage Generator Loss: 3237.132275\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9260 (step 9260): 1.292449\n",
      "Batch #10\tAverage Generator Loss: 2728.359595\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9261 (step 9261): 1.778939\n",
      "Batch #10\tAverage Generator Loss: 3147.411707\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9262 (step 9262): 1.348351\n",
      "Batch #10\tAverage Generator Loss: 2966.512158\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9263 (step 9263): 1.630697\n",
      "Batch #10\tAverage Generator Loss: 2498.826599\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9264 (step 9264): 1.396144\n",
      "Batch #10\tAverage Generator Loss: 3112.319897\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9265 (step 9265): 1.713360\n",
      "Batch #10\tAverage Generator Loss: 2820.665552\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9266 (step 9266): 1.284687\n",
      "Batch #10\tAverage Generator Loss: 2737.311853\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9267 (step 9267): 1.701098\n",
      "Batch #10\tAverage Generator Loss: 2729.438525\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9268 (step 9268): 1.326930\n",
      "Batch #10\tAverage Generator Loss: 2870.893054\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9269 (step 9269): 1.604377\n",
      "Batch #10\tAverage Generator Loss: 2765.301727\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9270 (step 9270): 1.382070\n",
      "Batch #10\tAverage Generator Loss: 2967.538965\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9271 (step 9271): 1.294785\n",
      "Batch #10\tAverage Generator Loss: 2453.599323\tAverage Discriminator Loss: 0.008322\n",
      "\n",
      "Train time for epoch #9272 (step 9272): 1.692837\n",
      "Batch #10\tAverage Generator Loss: 2751.629468\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9273 (step 9273): 1.244214\n",
      "Batch #10\tAverage Generator Loss: 2727.261707\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9274 (step 9274): 1.622201\n",
      "Batch #10\tAverage Generator Loss: 2759.679590\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9275 (step 9275): 1.481085\n",
      "Batch #10\tAverage Generator Loss: 2884.800903\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9276 (step 9276): 1.596107\n",
      "Batch #10\tAverage Generator Loss: 2595.395935\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9277 (step 9277): 1.302374\n",
      "Batch #10\tAverage Generator Loss: 3104.071594\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9278 (step 9278): 1.656314\n",
      "Batch #10\tAverage Generator Loss: 2675.849780\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9279 (step 9279): 1.294910\n",
      "Batch #10\tAverage Generator Loss: 2617.384399\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9280 (step 9280): 1.342727\n",
      "Batch #10\tAverage Generator Loss: 2715.171899\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9281 (step 9281): 1.675176\n",
      "Batch #10\tAverage Generator Loss: 2398.252179\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9282 (step 9282): 1.405061\n",
      "Batch #10\tAverage Generator Loss: 2923.004517\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9283 (step 9283): 1.580675\n",
      "Batch #10\tAverage Generator Loss: 2851.527417\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9284 (step 9284): 1.439394\n",
      "Batch #10\tAverage Generator Loss: 3031.115735\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9285 (step 9285): 1.652990\n",
      "Batch #10\tAverage Generator Loss: 2356.813660\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9286 (step 9286): 1.323707\n",
      "Batch #10\tAverage Generator Loss: 2664.496155\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9287 (step 9287): 1.640631\n",
      "Batch #10\tAverage Generator Loss: 2518.581323\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9288 (step 9288): 1.307226\n",
      "Batch #10\tAverage Generator Loss: 2656.884845\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9289 (step 9289): 1.707149\n",
      "Batch #10\tAverage Generator Loss: 3049.091870\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9290 (step 9290): 1.345441\n",
      "Batch #10\tAverage Generator Loss: 2625.156677\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9291 (step 9291): 1.383025\n",
      "Batch #10\tAverage Generator Loss: 2946.679517\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9292 (step 9292): 1.621078\n",
      "Batch #10\tAverage Generator Loss: 2476.741248\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9293 (step 9293): 1.298434\n",
      "Batch #10\tAverage Generator Loss: 2793.949768\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9294 (step 9294): 1.695141\n",
      "Batch #10\tAverage Generator Loss: 2696.030151\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9295 (step 9295): 1.373110\n",
      "Batch #10\tAverage Generator Loss: 2769.084827\tAverage Discriminator Loss: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #9296 (step 9296): 1.666584\n",
      "Batch #10\tAverage Generator Loss: 2634.937756\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9297 (step 9297): 1.289452\n",
      "Batch #10\tAverage Generator Loss: 2992.180017\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9298 (step 9298): 1.614180\n",
      "Batch #10\tAverage Generator Loss: 2783.431519\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9299 (step 9299): 1.286165\n",
      "Batch #10\tAverage Generator Loss: 2424.714264\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9300 (step 9300): 1.610145\n",
      "Batch #10\tAverage Generator Loss: 2778.299609\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9301 (step 9301): 1.353129\n",
      "Batch #10\tAverage Generator Loss: 2611.576587\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9302 (step 9302): 1.466779\n",
      "Batch #10\tAverage Generator Loss: 2827.783240\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9303 (step 9303): 1.764251\n",
      "Batch #10\tAverage Generator Loss: 2596.115442\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9304 (step 9304): 1.366669\n",
      "Batch #10\tAverage Generator Loss: 2495.470941\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9305 (step 9305): 1.622037\n",
      "Batch #10\tAverage Generator Loss: 2800.541577\tAverage Discriminator Loss: 0.006312\n",
      "\n",
      "Train time for epoch #9306 (step 9306): 1.381274\n",
      "Batch #10\tAverage Generator Loss: 2675.892139\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9307 (step 9307): 1.614416\n",
      "Batch #10\tAverage Generator Loss: 2600.715442\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9308 (step 9308): 1.283206\n",
      "Batch #10\tAverage Generator Loss: 2881.663263\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9309 (step 9309): 1.599443\n",
      "Batch #10\tAverage Generator Loss: 2507.916980\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9310 (step 9310): 1.345706\n",
      "Batch #10\tAverage Generator Loss: 2977.972498\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9311 (step 9311): 1.252023\n",
      "Batch #10\tAverage Generator Loss: 2456.839966\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9312 (step 9312): 1.784660\n",
      "Batch #10\tAverage Generator Loss: 2607.783997\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9313 (step 9313): 1.286602\n",
      "Batch #10\tAverage Generator Loss: 2414.559955\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9314 (step 9314): 1.653690\n",
      "Batch #10\tAverage Generator Loss: 2931.605542\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9315 (step 9315): 1.441791\n",
      "Batch #10\tAverage Generator Loss: 2755.751941\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9316 (step 9316): 1.642349\n",
      "Batch #10\tAverage Generator Loss: 2804.186938\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9317 (step 9317): 1.343348\n",
      "Batch #10\tAverage Generator Loss: 2686.709241\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9318 (step 9318): 1.684788\n",
      "Batch #10\tAverage Generator Loss: 2805.369482\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9319 (step 9319): 1.343822\n",
      "Batch #10\tAverage Generator Loss: 2713.667126\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9320 (step 9320): 1.330130\n",
      "Batch #10\tAverage Generator Loss: 2692.632391\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9321 (step 9321): 1.603376\n",
      "Batch #10\tAverage Generator Loss: 2804.840381\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9322 (step 9322): 1.343387\n",
      "Batch #10\tAverage Generator Loss: 2437.980713\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9323 (step 9323): 1.716168\n",
      "Batch #10\tAverage Generator Loss: 2483.324902\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9324 (step 9324): 1.295938\n",
      "Batch #10\tAverage Generator Loss: 2755.140833\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9325 (step 9325): 1.606507\n",
      "Batch #10\tAverage Generator Loss: 3006.577795\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9326 (step 9326): 1.334388\n",
      "Batch #10\tAverage Generator Loss: 2730.260156\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9327 (step 9327): 1.671994\n",
      "Batch #10\tAverage Generator Loss: 2969.618335\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9328 (step 9328): 1.285334\n",
      "Batch #10\tAverage Generator Loss: 2492.332886\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9329 (step 9329): 1.620854\n",
      "Batch #10\tAverage Generator Loss: 2779.744739\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9330 (step 9330): 1.292222\n",
      "Batch #10\tAverage Generator Loss: 3119.357886\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9331 (step 9331): 1.288366\n",
      "Batch #10\tAverage Generator Loss: 2397.174872\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9332 (step 9332): 1.578953\n",
      "Batch #10\tAverage Generator Loss: 2590.283929\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9333 (step 9333): 1.353862\n",
      "Batch #10\tAverage Generator Loss: 2607.251288\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9334 (step 9334): 1.674972\n",
      "Batch #10\tAverage Generator Loss: 2683.609119\tAverage Discriminator Loss: 0.000048\n",
      "\n",
      "Train time for epoch #9335 (step 9335): 1.237465\n",
      "Batch #10\tAverage Generator Loss: 2578.447461\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9336 (step 9336): 1.714190\n",
      "Batch #10\tAverage Generator Loss: 2799.364099\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9337 (step 9337): 1.288150\n",
      "Batch #10\tAverage Generator Loss: 2274.517957\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9338 (step 9338): 1.667125\n",
      "Batch #10\tAverage Generator Loss: 2355.667734\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9339 (step 9339): 1.304422\n",
      "Batch #10\tAverage Generator Loss: 2150.750220\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9340 (step 9340): 1.765608\n",
      "Batch #10\tAverage Generator Loss: 2525.313568\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9341 (step 9341): 1.290068\n",
      "Batch #10\tAverage Generator Loss: 2457.397192\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9342 (step 9342): 1.668486\n",
      "Batch #10\tAverage Generator Loss: 2887.725256\tAverage Discriminator Loss: 0.111650\n",
      "\n",
      "Train time for epoch #9343 (step 9343): 1.334605\n",
      "Batch #10\tAverage Generator Loss: 2683.692871\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9344 (step 9344): 1.298247\n",
      "Batch #10\tAverage Generator Loss: 2636.312207\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9345 (step 9345): 1.673116\n",
      "Batch #10\tAverage Generator Loss: 3022.902966\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9346 (step 9346): 1.407858\n",
      "Batch #10\tAverage Generator Loss: 2305.514703\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9347 (step 9347): 1.700369\n",
      "Batch #10\tAverage Generator Loss: 2223.180780\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9348 (step 9348): 1.421625\n",
      "Batch #10\tAverage Generator Loss: 2722.109814\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9349 (step 9349): 1.603445\n",
      "Batch #10\tAverage Generator Loss: 2555.573621\tAverage Discriminator Loss: 0.076023\n",
      "\n",
      "Train time for epoch #9350 (step 9350): 1.344218\n",
      "Batch #10\tAverage Generator Loss: 2831.172925\tAverage Discriminator Loss: 0.001358\n",
      "\n",
      "Train time for epoch #9351 (step 9351): 1.609575\n",
      "Batch #10\tAverage Generator Loss: 2565.573071\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #9352 (step 9352): 1.342159\n",
      "Batch #10\tAverage Generator Loss: 2737.112042\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9353 (step 9353): 1.597406\n",
      "Batch #10\tAverage Generator Loss: 2355.790198\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9354 (step 9354): 1.394434\n",
      "Batch #10\tAverage Generator Loss: 2452.106311\tAverage Discriminator Loss: 0.031659\n",
      "\n",
      "Train time for epoch #9355 (step 9355): 1.388669\n",
      "Batch #10\tAverage Generator Loss: 2631.377454\tAverage Discriminator Loss: 0.000632\n",
      "\n",
      "Train time for epoch #9356 (step 9356): 1.656277\n",
      "Batch #10\tAverage Generator Loss: 2353.012994\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9357 (step 9357): 1.349891\n",
      "Batch #10\tAverage Generator Loss: 2507.765894\tAverage Discriminator Loss: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #9358 (step 9358): 1.651428\n",
      "Batch #10\tAverage Generator Loss: 2625.357312\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9359 (step 9359): 1.346809\n",
      "Batch #10\tAverage Generator Loss: 2641.515637\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9360 (step 9360): 1.589183\n",
      "Batch #10\tAverage Generator Loss: 2673.487988\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9361 (step 9361): 1.291378\n",
      "Batch #10\tAverage Generator Loss: 2676.705475\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9362 (step 9362): 1.595453\n",
      "Batch #10\tAverage Generator Loss: 2859.299768\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9363 (step 9363): 1.259612\n",
      "Batch #10\tAverage Generator Loss: 2481.105371\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9364 (step 9364): 1.405656\n",
      "Batch #10\tAverage Generator Loss: 2644.610815\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9365 (step 9365): 1.694042\n",
      "Batch #10\tAverage Generator Loss: 2753.679883\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9366 (step 9366): 1.338310\n",
      "Batch #10\tAverage Generator Loss: 2637.765259\tAverage Discriminator Loss: 0.004597\n",
      "\n",
      "Train time for epoch #9367 (step 9367): 1.611566\n",
      "Batch #10\tAverage Generator Loss: 2651.718445\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #9368 (step 9368): 1.291187\n",
      "Batch #10\tAverage Generator Loss: 3005.888672\tAverage Discriminator Loss: 0.000032\n",
      "\n",
      "Train time for epoch #9369 (step 9369): 1.684785\n",
      "Batch #10\tAverage Generator Loss: 2763.918823\tAverage Discriminator Loss: 0.000035\n",
      "\n",
      "Train time for epoch #9370 (step 9370): 1.422408\n",
      "Batch #10\tAverage Generator Loss: 2919.494092\tAverage Discriminator Loss: 0.000027\n",
      "\n",
      "Train time for epoch #9371 (step 9371): 1.767957\n",
      "Batch #10\tAverage Generator Loss: 2698.092712\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #9372 (step 9372): 1.366646\n",
      "Batch #10\tAverage Generator Loss: 2864.793567\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #9373 (step 9373): 1.622840\n",
      "Batch #10\tAverage Generator Loss: 2820.622656\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #9374 (step 9374): 1.252076\n",
      "Batch #10\tAverage Generator Loss: 2724.171472\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #9375 (step 9375): 1.365295\n",
      "Batch #10\tAverage Generator Loss: 2561.757843\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #9376 (step 9376): 1.740915\n",
      "Batch #10\tAverage Generator Loss: 2491.027649\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #9377 (step 9377): 1.339431\n",
      "Batch #10\tAverage Generator Loss: 2991.376636\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #9378 (step 9378): 1.685659\n",
      "Batch #10\tAverage Generator Loss: 2725.410217\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #9379 (step 9379): 1.291285\n",
      "Batch #10\tAverage Generator Loss: 2411.629431\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #9380 (step 9380): 1.618010\n",
      "Batch #10\tAverage Generator Loss: 2570.435437\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #9381 (step 9381): 1.427650\n",
      "Batch #10\tAverage Generator Loss: 3248.781445\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #9382 (step 9382): 1.393788\n",
      "Batch #10\tAverage Generator Loss: 2947.138696\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9383 (step 9383): 1.705756\n",
      "Batch #10\tAverage Generator Loss: 2879.783618\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #9384 (step 9384): 1.280836\n",
      "Batch #10\tAverage Generator Loss: 2762.824353\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #9385 (step 9385): 1.612266\n",
      "Batch #10\tAverage Generator Loss: 3015.270764\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #9386 (step 9386): 1.348362\n",
      "Batch #10\tAverage Generator Loss: 2795.856445\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #9387 (step 9387): 1.801320\n",
      "Batch #10\tAverage Generator Loss: 2930.237964\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #9388 (step 9388): 1.402627\n",
      "Batch #10\tAverage Generator Loss: 2468.263104\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #9389 (step 9389): 1.573220\n",
      "Batch #10\tAverage Generator Loss: 3057.677258\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #9390 (step 9390): 1.431309\n",
      "Batch #10\tAverage Generator Loss: 2662.274609\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #9391 (step 9391): 1.572192\n",
      "Batch #10\tAverage Generator Loss: 3633.047778\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #9392 (step 9392): 1.345454\n",
      "Batch #10\tAverage Generator Loss: 2373.983948\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9393 (step 9393): 1.340925\n",
      "Batch #10\tAverage Generator Loss: 2344.710791\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #9394 (step 9394): 1.641608\n",
      "Batch #10\tAverage Generator Loss: 2722.827222\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9395 (step 9395): 1.371366\n",
      "Batch #10\tAverage Generator Loss: 2623.615466\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9396 (step 9396): 1.654788\n",
      "Batch #10\tAverage Generator Loss: 2699.847552\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9397 (step 9397): 1.323716\n",
      "Batch #10\tAverage Generator Loss: 2183.321423\tAverage Discriminator Loss: 0.000361\n",
      "\n",
      "Train time for epoch #9398 (step 9398): 1.767074\n",
      "Batch #10\tAverage Generator Loss: 2562.637134\tAverage Discriminator Loss: 0.000026\n",
      "\n",
      "Train time for epoch #9399 (step 9399): 1.339876\n",
      "Batch #10\tAverage Generator Loss: 2484.677771\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #9400 (step 9400): 1.653326\n",
      "Batch #10\tAverage Generator Loss: 3038.878003\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9401 (step 9401): 1.311348\n",
      "Batch #10\tAverage Generator Loss: 2425.211963\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #9402 (step 9402): 1.743863\n",
      "Batch #10\tAverage Generator Loss: 2831.175183\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #9403 (step 9403): 1.396878\n",
      "Batch #10\tAverage Generator Loss: 2750.794604\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #9404 (step 9404): 1.296271\n",
      "Batch #10\tAverage Generator Loss: 2882.307703\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9405 (step 9405): 1.596111\n",
      "Batch #10\tAverage Generator Loss: 2816.433386\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9406 (step 9406): 1.318813\n",
      "Batch #10\tAverage Generator Loss: 3127.095129\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #9407 (step 9407): 1.642302\n",
      "Batch #10\tAverage Generator Loss: 2878.195520\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #9408 (step 9408): 1.391267\n",
      "Batch #10\tAverage Generator Loss: 2658.239496\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #9409 (step 9409): 1.708542\n",
      "Batch #10\tAverage Generator Loss: 2946.066394\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #9410 (step 9410): 1.424890\n",
      "Batch #10\tAverage Generator Loss: 2834.744922\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #9411 (step 9411): 1.388981\n",
      "Batch #10\tAverage Generator Loss: 2357.138696\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #9412 (step 9412): 1.642620\n",
      "Batch #10\tAverage Generator Loss: 2757.747485\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #9413 (step 9413): 1.327060\n",
      "Batch #10\tAverage Generator Loss: 2797.828442\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9414 (step 9414): 1.616687\n",
      "Batch #10\tAverage Generator Loss: 2931.563098\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #9415 (step 9415): 1.392506\n",
      "Batch #10\tAverage Generator Loss: 2944.437524\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9416 (step 9416): 1.734577\n",
      "Batch #10\tAverage Generator Loss: 2549.450482\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #9417 (step 9417): 1.386184\n",
      "Batch #10\tAverage Generator Loss: 2414.026465\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #9418 (step 9418): 1.623767\n",
      "Batch #10\tAverage Generator Loss: 2950.969495\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #9419 (step 9419): 1.279767\n",
      "Batch #10\tAverage Generator Loss: 2543.448401\tAverage Discriminator Loss: 0.000001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #9420 (step 9420): 1.713121\n",
      "Batch #10\tAverage Generator Loss: 2933.855151\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #9421 (step 9421): 1.359072\n",
      "Batch #10\tAverage Generator Loss: 2590.960419\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9422 (step 9422): 1.355172\n",
      "Batch #10\tAverage Generator Loss: 2736.726172\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9423 (step 9423): 1.583461\n",
      "Batch #10\tAverage Generator Loss: 2868.848145\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9424 (step 9424): 1.323325\n",
      "Batch #10\tAverage Generator Loss: 2675.386548\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9425 (step 9425): 1.667728\n",
      "Batch #10\tAverage Generator Loss: 2532.591565\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9426 (step 9426): 1.299546\n",
      "Batch #10\tAverage Generator Loss: 2836.647034\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #9427 (step 9427): 1.631550\n",
      "Batch #10\tAverage Generator Loss: 2167.941357\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9428 (step 9428): 1.294303\n",
      "Batch #10\tAverage Generator Loss: 2569.483435\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9429 (step 9429): 1.698186\n",
      "Batch #10\tAverage Generator Loss: 2784.185132\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #9430 (step 9430): 1.287010\n",
      "Batch #10\tAverage Generator Loss: 3089.000598\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #9431 (step 9431): 1.703171\n",
      "Batch #10\tAverage Generator Loss: 2134.235101\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #9432 (step 9432): 1.294318\n",
      "Batch #10\tAverage Generator Loss: 2779.886414\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9433 (step 9433): 1.332921\n",
      "Batch #10\tAverage Generator Loss: 2926.423096\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #9434 (step 9434): 1.734569\n",
      "Batch #10\tAverage Generator Loss: 2772.748883\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9435 (step 9435): 1.334561\n",
      "Batch #10\tAverage Generator Loss: 2631.115527\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9436 (step 9436): 1.646873\n",
      "Batch #10\tAverage Generator Loss: 2413.461694\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9437 (step 9437): 1.409423\n",
      "Batch #10\tAverage Generator Loss: 2465.143457\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #9438 (step 9438): 1.611964\n",
      "Batch #10\tAverage Generator Loss: 2669.223743\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #9439 (step 9439): 1.296279\n",
      "Batch #10\tAverage Generator Loss: 2666.058630\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9440 (step 9440): 1.299062\n",
      "Batch #10\tAverage Generator Loss: 2750.369641\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9441 (step 9441): 1.598368\n",
      "Batch #10\tAverage Generator Loss: 2760.719763\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9442 (step 9442): 1.384394\n",
      "Batch #10\tAverage Generator Loss: 2482.712659\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9443 (step 9443): 1.695626\n",
      "Batch #10\tAverage Generator Loss: 2270.468390\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9444 (step 9444): 1.289137\n",
      "Batch #10\tAverage Generator Loss: 2947.892786\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9445 (step 9445): 1.655926\n",
      "Batch #10\tAverage Generator Loss: 2687.305359\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9446 (step 9446): 1.289488\n",
      "Batch #10\tAverage Generator Loss: 2243.619861\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9447 (step 9447): 1.616604\n",
      "Batch #10\tAverage Generator Loss: 2549.368372\tAverage Discriminator Loss: 0.019332\n",
      "\n",
      "Train time for epoch #9448 (step 9448): 1.339914\n",
      "Batch #10\tAverage Generator Loss: 2664.534692\tAverage Discriminator Loss: 0.003559\n",
      "\n",
      "Train time for epoch #9449 (step 9449): 1.704401\n",
      "Batch #10\tAverage Generator Loss: 2977.787122\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9450 (step 9450): 1.335775\n",
      "Batch #10\tAverage Generator Loss: 2213.515607\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9451 (step 9451): 1.338506\n",
      "Batch #10\tAverage Generator Loss: 2842.655481\tAverage Discriminator Loss: 0.073519\n",
      "\n",
      "Train time for epoch #9452 (step 9452): 1.710431\n",
      "Batch #10\tAverage Generator Loss: 2479.979492\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9453 (step 9453): 1.376866\n",
      "Batch #10\tAverage Generator Loss: 2246.651050\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9454 (step 9454): 1.794979\n",
      "Batch #10\tAverage Generator Loss: 2150.532593\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9455 (step 9455): 1.282115\n",
      "Batch #10\tAverage Generator Loss: 2479.660132\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9456 (step 9456): 1.337200\n",
      "Batch #10\tAverage Generator Loss: 2753.632916\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9457 (step 9457): 1.708812\n",
      "Batch #10\tAverage Generator Loss: 2344.427771\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9458 (step 9458): 1.243158\n",
      "Batch #10\tAverage Generator Loss: 2475.958105\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9459 (step 9459): 1.675991\n",
      "Batch #10\tAverage Generator Loss: 2299.883569\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9460 (step 9460): 1.385488\n",
      "Batch #10\tAverage Generator Loss: 2631.123145\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9461 (step 9461): 1.631962\n",
      "Batch #10\tAverage Generator Loss: 2797.363647\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9462 (step 9462): 1.284288\n",
      "Batch #10\tAverage Generator Loss: 2599.521790\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9463 (step 9463): 1.629128\n",
      "Batch #10\tAverage Generator Loss: 2256.240527\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9464 (step 9464): 1.292210\n",
      "Batch #10\tAverage Generator Loss: 2527.976947\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9465 (step 9465): 1.390011\n",
      "Batch #10\tAverage Generator Loss: 2451.578235\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9466 (step 9466): 1.608337\n",
      "Batch #10\tAverage Generator Loss: 2524.612421\tAverage Discriminator Loss: 0.003629\n",
      "\n",
      "Train time for epoch #9467 (step 9467): 1.326910\n",
      "Batch #10\tAverage Generator Loss: 2393.651892\tAverage Discriminator Loss: 0.001936\n",
      "\n",
      "Train time for epoch #9468 (step 9468): 1.726434\n",
      "Batch #10\tAverage Generator Loss: 2472.704639\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9469 (step 9469): 1.280471\n",
      "Batch #10\tAverage Generator Loss: 2983.089111\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9470 (step 9470): 1.572395\n",
      "Batch #10\tAverage Generator Loss: 2941.056189\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9471 (step 9471): 1.242386\n",
      "Batch #10\tAverage Generator Loss: 2655.474878\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9472 (step 9472): 1.654383\n",
      "Batch #10\tAverage Generator Loss: 2653.814856\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9473 (step 9473): 1.297692\n",
      "Batch #10\tAverage Generator Loss: 2726.194479\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9474 (step 9474): 1.374142\n",
      "Batch #10\tAverage Generator Loss: 2688.758374\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9475 (step 9475): 1.611318\n",
      "Batch #10\tAverage Generator Loss: 2928.472693\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9476 (step 9476): 1.406446\n",
      "Batch #10\tAverage Generator Loss: 2543.627563\tAverage Discriminator Loss: 0.085413\n",
      "\n",
      "Train time for epoch #9477 (step 9477): 1.600782\n",
      "Batch #10\tAverage Generator Loss: 2372.997839\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9478 (step 9478): 1.459749\n",
      "Batch #10\tAverage Generator Loss: 2665.667419\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9479 (step 9479): 1.652078\n",
      "Batch #10\tAverage Generator Loss: 2474.718188\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9480 (step 9480): 1.446955\n",
      "Batch #10\tAverage Generator Loss: 2743.088037\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9481 (step 9481): 1.761805\n",
      "Batch #10\tAverage Generator Loss: 2761.376929\tAverage Discriminator Loss: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #9482 (step 9482): 1.384310\n",
      "Batch #10\tAverage Generator Loss: 2428.899878\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9483 (step 9483): 1.302853\n",
      "Batch #10\tAverage Generator Loss: 2604.081757\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9484 (step 9484): 1.779543\n",
      "Batch #10\tAverage Generator Loss: 2366.211169\tAverage Discriminator Loss: 0.037209\n",
      "\n",
      "Train time for epoch #9485 (step 9485): 1.280241\n",
      "Batch #10\tAverage Generator Loss: 2611.134473\tAverage Discriminator Loss: 0.000605\n",
      "\n",
      "Train time for epoch #9486 (step 9486): 1.663127\n",
      "Batch #10\tAverage Generator Loss: 3153.637463\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #9487 (step 9487): 1.290601\n",
      "Batch #10\tAverage Generator Loss: 2707.415833\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #9488 (step 9488): 1.842140\n",
      "Batch #10\tAverage Generator Loss: 2646.131299\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #9489 (step 9489): 1.304741\n",
      "Batch #10\tAverage Generator Loss: 2325.648151\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9490 (step 9490): 1.721096\n",
      "Batch #10\tAverage Generator Loss: 2294.465735\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #9491 (step 9491): 1.390983\n",
      "Batch #10\tAverage Generator Loss: 2578.822571\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9492 (step 9492): 1.333511\n",
      "Batch #10\tAverage Generator Loss: 2561.635022\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9493 (step 9493): 1.688603\n",
      "Batch #10\tAverage Generator Loss: 2970.658154\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9494 (step 9494): 1.370826\n",
      "Batch #10\tAverage Generator Loss: 2656.151392\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9495 (step 9495): 1.707796\n",
      "Batch #10\tAverage Generator Loss: 2573.928882\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9496 (step 9496): 1.404422\n",
      "Batch #10\tAverage Generator Loss: 2580.985059\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9497 (step 9497): 1.633063\n",
      "Batch #10\tAverage Generator Loss: 2524.989221\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9498 (step 9498): 1.323722\n",
      "Batch #10\tAverage Generator Loss: 2697.171899\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9499 (step 9499): 1.684849\n",
      "Batch #10\tAverage Generator Loss: 2763.396094\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9500 (step 9500): 1.295692\n",
      "Batch #10\tAverage Generator Loss: 2959.029456\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9501 (step 9501): 1.306045\n",
      "Batch #10\tAverage Generator Loss: 2400.561804\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9502 (step 9502): 1.580732\n",
      "Batch #10\tAverage Generator Loss: 2530.320032\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9503 (step 9503): 1.444541\n",
      "Batch #10\tAverage Generator Loss: 2585.889966\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9504 (step 9504): 1.618760\n",
      "Batch #10\tAverage Generator Loss: 2403.285669\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9505 (step 9505): 1.301747\n",
      "Batch #10\tAverage Generator Loss: 2512.231323\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9506 (step 9506): 1.743690\n",
      "Batch #10\tAverage Generator Loss: 2377.177673\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9507 (step 9507): 1.300959\n",
      "Batch #10\tAverage Generator Loss: 2560.887317\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9508 (step 9508): 1.637707\n",
      "Batch #10\tAverage Generator Loss: 2355.252148\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9509 (step 9509): 1.348392\n",
      "Batch #10\tAverage Generator Loss: 2616.179321\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9510 (step 9510): 1.647756\n",
      "Batch #10\tAverage Generator Loss: 2496.222168\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9511 (step 9511): 1.421612\n",
      "Batch #10\tAverage Generator Loss: 2531.854260\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9512 (step 9512): 1.315550\n",
      "Batch #10\tAverage Generator Loss: 2394.345142\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9513 (step 9513): 1.591049\n",
      "Batch #10\tAverage Generator Loss: 2418.824854\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9514 (step 9514): 1.349357\n",
      "Batch #10\tAverage Generator Loss: 3013.374695\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9515 (step 9515): 1.664619\n",
      "Batch #10\tAverage Generator Loss: 2380.398425\tAverage Discriminator Loss: 0.076921\n",
      "\n",
      "Train time for epoch #9516 (step 9516): 1.357698\n",
      "Batch #10\tAverage Generator Loss: 2745.466223\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9517 (step 9517): 1.645731\n",
      "Batch #10\tAverage Generator Loss: 3126.570190\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9518 (step 9518): 1.346244\n",
      "Batch #10\tAverage Generator Loss: 2608.344067\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9519 (step 9519): 2.122641\n",
      "Batch #10\tAverage Generator Loss: 2628.908960\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9520 (step 9520): 1.388531\n",
      "Batch #10\tAverage Generator Loss: 2700.912390\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9521 (step 9521): 1.353628\n",
      "Batch #10\tAverage Generator Loss: 3266.505005\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9522 (step 9522): 1.654474\n",
      "Batch #10\tAverage Generator Loss: 2848.715796\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9523 (step 9523): 1.334794\n",
      "Batch #10\tAverage Generator Loss: 2691.566663\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9524 (step 9524): 1.660784\n",
      "Batch #10\tAverage Generator Loss: 2820.470654\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9525 (step 9525): 1.294429\n",
      "Batch #10\tAverage Generator Loss: 2830.052502\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9526 (step 9526): 1.622435\n",
      "Batch #10\tAverage Generator Loss: 2804.631262\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9527 (step 9527): 1.330526\n",
      "Batch #10\tAverage Generator Loss: 2868.340369\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9528 (step 9528): 1.607660\n",
      "Batch #10\tAverage Generator Loss: 2681.426160\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9529 (step 9529): 1.277031\n",
      "Batch #10\tAverage Generator Loss: 2506.990674\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9530 (step 9530): 1.314351\n",
      "Batch #10\tAverage Generator Loss: 2958.876965\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9531 (step 9531): 1.626911\n",
      "Batch #10\tAverage Generator Loss: 3045.166785\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9532 (step 9532): 1.388566\n",
      "Batch #10\tAverage Generator Loss: 2724.021509\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9533 (step 9533): 1.708276\n",
      "Batch #10\tAverage Generator Loss: 2939.937280\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9534 (step 9534): 1.350564\n",
      "Batch #10\tAverage Generator Loss: 2766.969763\tAverage Discriminator Loss: 0.015659\n",
      "\n",
      "Train time for epoch #9535 (step 9535): 1.610882\n",
      "Batch #10\tAverage Generator Loss: 3098.601709\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9536 (step 9536): 1.523457\n",
      "Batch #10\tAverage Generator Loss: 2540.599829\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9537 (step 9537): 1.681972\n",
      "Batch #10\tAverage Generator Loss: 2906.097009\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9538 (step 9538): 1.314641\n",
      "Batch #10\tAverage Generator Loss: 2680.279651\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9539 (step 9539): 1.319938\n",
      "Batch #10\tAverage Generator Loss: 2903.630347\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9540 (step 9540): 1.729675\n",
      "Batch #10\tAverage Generator Loss: 3138.236975\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9541 (step 9541): 1.240025\n",
      "Batch #10\tAverage Generator Loss: 2763.211847\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9542 (step 9542): 1.637905\n",
      "Batch #10\tAverage Generator Loss: 2615.631616\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9543 (step 9543): 1.288027\n",
      "Batch #10\tAverage Generator Loss: 2980.641370\tAverage Discriminator Loss: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #9544 (step 9544): 1.582259\n",
      "Batch #10\tAverage Generator Loss: 3059.534973\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9545 (step 9545): 1.301041\n",
      "Batch #10\tAverage Generator Loss: 2536.232324\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9546 (step 9546): 1.390591\n",
      "Batch #10\tAverage Generator Loss: 2966.409961\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9547 (step 9547): 1.710911\n",
      "Batch #10\tAverage Generator Loss: 2865.057019\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9548 (step 9548): 1.364468\n",
      "Batch #10\tAverage Generator Loss: 2228.508459\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9549 (step 9549): 1.686241\n",
      "Batch #10\tAverage Generator Loss: 2634.619080\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9550 (step 9550): 1.351243\n",
      "Batch #10\tAverage Generator Loss: 3123.189697\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9551 (step 9551): 1.595020\n",
      "Batch #10\tAverage Generator Loss: 2901.997363\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9552 (step 9552): 1.338533\n",
      "Batch #10\tAverage Generator Loss: 2477.761121\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9553 (step 9553): 1.654793\n",
      "Batch #10\tAverage Generator Loss: 2741.241028\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9554 (step 9554): 1.302972\n",
      "Batch #10\tAverage Generator Loss: 3124.476880\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9555 (step 9555): 1.368207\n",
      "Batch #10\tAverage Generator Loss: 2709.384131\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9556 (step 9556): 1.611138\n",
      "Batch #10\tAverage Generator Loss: 2591.855286\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9557 (step 9557): 1.550853\n",
      "Batch #10\tAverage Generator Loss: 2787.392249\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9558 (step 9558): 1.606672\n",
      "Batch #10\tAverage Generator Loss: 2614.281396\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9559 (step 9559): 1.298067\n",
      "Batch #10\tAverage Generator Loss: 2974.074799\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9560 (step 9560): 1.685371\n",
      "Batch #10\tAverage Generator Loss: 2279.243219\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9561 (step 9561): 1.247650\n",
      "Batch #10\tAverage Generator Loss: 2448.429980\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9562 (step 9562): 1.680700\n",
      "Batch #10\tAverage Generator Loss: 2736.540222\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9563 (step 9563): 1.285028\n",
      "Batch #10\tAverage Generator Loss: 2474.977185\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9564 (step 9564): 1.402566\n",
      "Batch #10\tAverage Generator Loss: 2473.886829\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9565 (step 9565): 1.607689\n",
      "Batch #10\tAverage Generator Loss: 2646.687781\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9566 (step 9566): 1.324521\n",
      "Batch #10\tAverage Generator Loss: 2288.408655\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9567 (step 9567): 1.663365\n",
      "Batch #10\tAverage Generator Loss: 2758.048462\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9568 (step 9568): 1.301138\n",
      "Batch #10\tAverage Generator Loss: 2792.009332\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9569 (step 9569): 1.801373\n",
      "Batch #10\tAverage Generator Loss: 2758.128967\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9570 (step 9570): 1.298528\n",
      "Batch #10\tAverage Generator Loss: 2918.793799\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9571 (step 9571): 1.640184\n",
      "Batch #10\tAverage Generator Loss: 2017.395203\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9572 (step 9572): 1.395164\n",
      "Batch #10\tAverage Generator Loss: 2382.269232\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9573 (step 9573): 1.340120\n",
      "Batch #10\tAverage Generator Loss: 2585.104028\tAverage Discriminator Loss: 0.016060\n",
      "\n",
      "Train time for epoch #9574 (step 9574): 1.816738\n",
      "Batch #10\tAverage Generator Loss: 2764.760718\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #9575 (step 9575): 1.335047\n",
      "Batch #10\tAverage Generator Loss: 2626.434241\tAverage Discriminator Loss: 0.000280\n",
      "\n",
      "Train time for epoch #9576 (step 9576): 1.687791\n",
      "Batch #10\tAverage Generator Loss: 3157.278357\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9577 (step 9577): 1.239824\n",
      "Batch #10\tAverage Generator Loss: 2567.942126\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9578 (step 9578): 1.631040\n",
      "Batch #10\tAverage Generator Loss: 2654.436731\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9579 (step 9579): 1.461454\n",
      "Batch #10\tAverage Generator Loss: 2738.380798\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9580 (step 9580): 1.730631\n",
      "Batch #10\tAverage Generator Loss: 2676.184290\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9581 (step 9581): 1.290209\n",
      "Batch #10\tAverage Generator Loss: 2596.928821\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9582 (step 9582): 1.720594\n",
      "Batch #10\tAverage Generator Loss: 3013.009077\tAverage Discriminator Loss: 0.888158\n",
      "\n",
      "Train time for epoch #9583 (step 9583): 1.284914\n",
      "Batch #10\tAverage Generator Loss: 2052.119177\tAverage Discriminator Loss: 0.046822\n",
      "\n",
      "Train time for epoch #9584 (step 9584): 1.299345\n",
      "Batch #10\tAverage Generator Loss: 1954.603577\tAverage Discriminator Loss: 0.005767\n",
      "\n",
      "Train time for epoch #9585 (step 9585): 1.630031\n",
      "Batch #10\tAverage Generator Loss: 1833.148218\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9586 (step 9586): 1.268792\n",
      "Batch #10\tAverage Generator Loss: 1617.783612\tAverage Discriminator Loss: 0.188796\n",
      "\n",
      "Train time for epoch #9587 (step 9587): 1.620561\n",
      "Batch #10\tAverage Generator Loss: 2424.797168\tAverage Discriminator Loss: 0.015484\n",
      "\n",
      "Train time for epoch #9588 (step 9588): 1.457729\n",
      "Batch #10\tAverage Generator Loss: 2160.467456\tAverage Discriminator Loss: 0.022339\n",
      "\n",
      "Train time for epoch #9589 (step 9589): 1.664170\n",
      "Batch #10\tAverage Generator Loss: 1813.824826\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #9590 (step 9590): 1.368470\n",
      "Batch #10\tAverage Generator Loss: 1861.399622\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #9591 (step 9591): 1.816549\n",
      "Batch #10\tAverage Generator Loss: 2143.383801\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #9592 (step 9592): 1.418263\n",
      "Batch #10\tAverage Generator Loss: 1982.261707\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #9593 (step 9593): 1.328535\n",
      "Batch #10\tAverage Generator Loss: 2017.207373\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #9594 (step 9594): 1.585738\n",
      "Batch #10\tAverage Generator Loss: 1902.113269\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #9595 (step 9595): 1.386884\n",
      "Batch #10\tAverage Generator Loss: 2023.566956\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9596 (step 9596): 1.604801\n",
      "Batch #10\tAverage Generator Loss: 2081.117334\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #9597 (step 9597): 1.342396\n",
      "Batch #10\tAverage Generator Loss: 1910.825378\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9598 (step 9598): 1.743626\n",
      "Batch #10\tAverage Generator Loss: 1738.803418\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9599 (step 9599): 1.285105\n",
      "Batch #10\tAverage Generator Loss: 1945.330737\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9600 (step 9600): 1.785311\n",
      "Batch #10\tAverage Generator Loss: 2093.729163\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9601 (step 9601): 1.400351\n",
      "Batch #10\tAverage Generator Loss: 2051.882257\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9602 (step 9602): 1.232352\n",
      "Batch #10\tAverage Generator Loss: 2039.980249\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9603 (step 9603): 1.772590\n",
      "Batch #10\tAverage Generator Loss: 2003.490991\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9604 (step 9604): 1.238425\n",
      "Batch #10\tAverage Generator Loss: 1982.358386\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9605 (step 9605): 1.665326\n",
      "Batch #10\tAverage Generator Loss: 1818.979224\tAverage Discriminator Loss: 0.000001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #9606 (step 9606): 1.365281\n",
      "Batch #10\tAverage Generator Loss: 1675.270990\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9607 (step 9607): 1.693278\n",
      "Batch #10\tAverage Generator Loss: 1940.617175\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9608 (step 9608): 1.396070\n",
      "Batch #10\tAverage Generator Loss: 1683.034912\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9609 (step 9609): 1.282470\n",
      "Batch #10\tAverage Generator Loss: 1952.562903\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9610 (step 9610): 1.773450\n",
      "Batch #10\tAverage Generator Loss: 1832.980151\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9611 (step 9611): 1.286051\n",
      "Batch #10\tAverage Generator Loss: 2237.800085\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9612 (step 9612): 1.598385\n",
      "Batch #10\tAverage Generator Loss: 1965.166150\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9613 (step 9613): 1.295790\n",
      "Batch #10\tAverage Generator Loss: 1767.952130\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9614 (step 9614): 1.610731\n",
      "Batch #10\tAverage Generator Loss: 2017.864740\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9615 (step 9615): 1.279563\n",
      "Batch #10\tAverage Generator Loss: 1986.603601\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9616 (step 9616): 1.396751\n",
      "Batch #10\tAverage Generator Loss: 2122.244153\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9617 (step 9617): 1.665162\n",
      "Batch #10\tAverage Generator Loss: 1795.036456\tAverage Discriminator Loss: 0.025054\n",
      "\n",
      "Train time for epoch #9618 (step 9618): 1.405899\n",
      "Batch #10\tAverage Generator Loss: 1725.476837\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9619 (step 9619): 1.728506\n",
      "Batch #10\tAverage Generator Loss: 1662.148615\tAverage Discriminator Loss: 0.092848\n",
      "\n",
      "Train time for epoch #9620 (step 9620): 1.328401\n",
      "Batch #10\tAverage Generator Loss: 1814.855066\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9621 (step 9621): 1.735358\n",
      "Batch #10\tAverage Generator Loss: 1712.108191\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9622 (step 9622): 1.334491\n",
      "Batch #10\tAverage Generator Loss: 1626.193011\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9623 (step 9623): 1.629497\n",
      "Batch #10\tAverage Generator Loss: 1717.584808\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9624 (step 9624): 1.404645\n",
      "Batch #10\tAverage Generator Loss: 1687.303326\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9625 (step 9625): 1.427058\n",
      "Batch #10\tAverage Generator Loss: 1573.161584\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9626 (step 9626): 1.624965\n",
      "Batch #10\tAverage Generator Loss: 1870.405908\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9627 (step 9627): 1.345142\n",
      "Batch #10\tAverage Generator Loss: 1840.583417\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9628 (step 9628): 1.618790\n",
      "Batch #10\tAverage Generator Loss: 2124.054712\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9629 (step 9629): 1.346056\n",
      "Batch #10\tAverage Generator Loss: 1944.344507\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9630 (step 9630): 1.706022\n",
      "Batch #10\tAverage Generator Loss: 1824.120331\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9631 (step 9631): 1.326359\n",
      "Batch #10\tAverage Generator Loss: 1657.731088\tAverage Discriminator Loss: 0.000027\n",
      "\n",
      "Train time for epoch #9632 (step 9632): 1.803875\n",
      "Batch #10\tAverage Generator Loss: 1682.472601\tAverage Discriminator Loss: 0.241839\n",
      "\n",
      "Train time for epoch #9633 (step 9633): 1.279476\n",
      "Batch #10\tAverage Generator Loss: 1410.868225\tAverage Discriminator Loss: 0.025417\n",
      "\n",
      "Train time for epoch #9634 (step 9634): 1.344584\n",
      "Batch #10\tAverage Generator Loss: 1725.438037\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9635 (step 9635): 1.665090\n",
      "Batch #10\tAverage Generator Loss: 1644.368842\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9636 (step 9636): 1.371519\n",
      "Batch #10\tAverage Generator Loss: 1546.547385\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9637 (step 9637): 1.637662\n",
      "Batch #10\tAverage Generator Loss: 1655.982568\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9638 (step 9638): 1.261754\n",
      "Batch #10\tAverage Generator Loss: 1450.796362\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9639 (step 9639): 1.331241\n",
      "Batch #10\tAverage Generator Loss: 1606.568390\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9640 (step 9640): 1.613418\n",
      "Batch #10\tAverage Generator Loss: 1497.323419\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9641 (step 9641): 1.408038\n",
      "Batch #10\tAverage Generator Loss: 1608.266608\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9642 (step 9642): 1.605910\n",
      "Batch #10\tAverage Generator Loss: 1544.435956\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9643 (step 9643): 1.290551\n",
      "Batch #10\tAverage Generator Loss: 1518.036688\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9644 (step 9644): 1.602507\n",
      "Batch #10\tAverage Generator Loss: 1536.469464\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9645 (step 9645): 1.276390\n",
      "Batch #10\tAverage Generator Loss: 1487.547928\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9646 (step 9646): 1.639153\n",
      "Batch #10\tAverage Generator Loss: 1741.000940\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9647 (step 9647): 1.301402\n",
      "Batch #10\tAverage Generator Loss: 1399.532037\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9648 (step 9648): 1.672065\n",
      "Batch #10\tAverage Generator Loss: 1698.570215\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9649 (step 9649): 1.339260\n",
      "Batch #10\tAverage Generator Loss: 1690.246997\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9650 (step 9650): 1.621279\n",
      "Batch #10\tAverage Generator Loss: 1657.899200\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9651 (step 9651): 1.234159\n",
      "Batch #10\tAverage Generator Loss: 1771.064056\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9652 (step 9652): 1.384621\n",
      "Batch #10\tAverage Generator Loss: 1641.800977\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9653 (step 9653): 1.701823\n",
      "Batch #10\tAverage Generator Loss: 1671.663403\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9654 (step 9654): 1.420136\n",
      "Batch #10\tAverage Generator Loss: 1619.159534\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9655 (step 9655): 1.806342\n",
      "Batch #10\tAverage Generator Loss: 1690.528711\tAverage Discriminator Loss: 0.226666\n",
      "\n",
      "Train time for epoch #9656 (step 9656): 1.301769\n",
      "Batch #10\tAverage Generator Loss: 1655.501569\tAverage Discriminator Loss: 0.000336\n",
      "\n",
      "Train time for epoch #9657 (step 9657): 1.622613\n",
      "Batch #10\tAverage Generator Loss: 1661.171912\tAverage Discriminator Loss: 0.000068\n",
      "\n",
      "Train time for epoch #9658 (step 9658): 1.435569\n",
      "Batch #10\tAverage Generator Loss: 1676.872498\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #9659 (step 9659): 1.777524\n",
      "Batch #10\tAverage Generator Loss: 1486.500751\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #9660 (step 9660): 1.329532\n",
      "Batch #10\tAverage Generator Loss: 1486.050903\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #9661 (step 9661): 1.344265\n",
      "Batch #10\tAverage Generator Loss: 1605.767749\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #9662 (step 9662): 1.657866\n",
      "Batch #10\tAverage Generator Loss: 1644.771722\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #9663 (step 9663): 1.331740\n",
      "Batch #10\tAverage Generator Loss: 1874.598267\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #9664 (step 9664): 1.629454\n",
      "Batch #10\tAverage Generator Loss: 1737.317029\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #9665 (step 9665): 1.341524\n",
      "Batch #10\tAverage Generator Loss: 1530.148065\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #9666 (step 9666): 1.602555\n",
      "Batch #10\tAverage Generator Loss: 1564.880188\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #9667 (step 9667): 1.324452\n",
      "Batch #10\tAverage Generator Loss: 1577.673651\tAverage Discriminator Loss: 0.000007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #9668 (step 9668): 1.681502\n",
      "Batch #10\tAverage Generator Loss: 1680.527429\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #9669 (step 9669): 1.283545\n",
      "Batch #10\tAverage Generator Loss: 1507.349506\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #9670 (step 9670): 1.392403\n",
      "Batch #10\tAverage Generator Loss: 1653.082507\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #9671 (step 9671): 1.619712\n",
      "Batch #10\tAverage Generator Loss: 1699.743634\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #9672 (step 9672): 1.475887\n",
      "Batch #10\tAverage Generator Loss: 1428.104059\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #9673 (step 9673): 1.582235\n",
      "Batch #10\tAverage Generator Loss: 1497.441547\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #9674 (step 9674): 1.277318\n",
      "Batch #10\tAverage Generator Loss: 1508.429431\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #9675 (step 9675): 1.658582\n",
      "Batch #10\tAverage Generator Loss: 1743.863843\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #9676 (step 9676): 1.325144\n",
      "Batch #10\tAverage Generator Loss: 1624.112982\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #9677 (step 9677): 1.283223\n",
      "Batch #10\tAverage Generator Loss: 1662.952612\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #9678 (step 9678): 1.696163\n",
      "Batch #10\tAverage Generator Loss: 1478.883966\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #9679 (step 9679): 1.498151\n",
      "Batch #10\tAverage Generator Loss: 1492.207745\tAverage Discriminator Loss: 0.000022\n",
      "\n",
      "Train time for epoch #9680 (step 9680): 1.615953\n",
      "Batch #10\tAverage Generator Loss: 1591.520648\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #9681 (step 9681): 1.343885\n",
      "Batch #10\tAverage Generator Loss: 1604.628632\tAverage Discriminator Loss: 0.000044\n",
      "\n",
      "Train time for epoch #9682 (step 9682): 1.805308\n",
      "Batch #10\tAverage Generator Loss: 1542.213831\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #9683 (step 9683): 1.253303\n",
      "Batch #10\tAverage Generator Loss: 1701.386536\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #9684 (step 9684): 1.745280\n",
      "Batch #10\tAverage Generator Loss: 1562.906384\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #9685 (step 9685): 1.297668\n",
      "Batch #10\tAverage Generator Loss: 1545.355396\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #9686 (step 9686): 1.306396\n",
      "Batch #10\tAverage Generator Loss: 1530.062064\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #9687 (step 9687): 1.629033\n",
      "Batch #10\tAverage Generator Loss: 1349.755402\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #9688 (step 9688): 1.274495\n",
      "Batch #10\tAverage Generator Loss: 1653.291370\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #9689 (step 9689): 1.662745\n",
      "Batch #10\tAverage Generator Loss: 1646.158429\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #9690 (step 9690): 1.382304\n",
      "Batch #10\tAverage Generator Loss: 1592.361621\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #9691 (step 9691): 1.718478\n",
      "Batch #10\tAverage Generator Loss: 1564.472864\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #9692 (step 9692): 1.484422\n",
      "Batch #10\tAverage Generator Loss: 1562.424524\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #9693 (step 9693): 1.451511\n",
      "Batch #10\tAverage Generator Loss: 1598.529907\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #9694 (step 9694): 1.756148\n",
      "Batch #10\tAverage Generator Loss: 1452.688422\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #9695 (step 9695): 1.292149\n",
      "Batch #10\tAverage Generator Loss: 1616.489966\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #9696 (step 9696): 1.635703\n",
      "Batch #10\tAverage Generator Loss: 1727.802673\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #9697 (step 9697): 1.231473\n",
      "Batch #10\tAverage Generator Loss: 1742.669531\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #9698 (step 9698): 1.709943\n",
      "Batch #10\tAverage Generator Loss: 1725.862769\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #9699 (step 9699): 1.291389\n",
      "Batch #10\tAverage Generator Loss: 1545.042279\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #9700 (step 9700): 1.450180\n",
      "Batch #10\tAverage Generator Loss: 1774.978564\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #9701 (step 9701): 1.720466\n",
      "Batch #10\tAverage Generator Loss: 1758.773157\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #9702 (step 9702): 1.292168\n",
      "Batch #10\tAverage Generator Loss: 1732.318323\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #9703 (step 9703): 1.645303\n",
      "Batch #10\tAverage Generator Loss: 1668.651819\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #9704 (step 9704): 1.295986\n",
      "Batch #10\tAverage Generator Loss: 1502.334015\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #9705 (step 9705): 1.643638\n",
      "Batch #10\tAverage Generator Loss: 1872.393396\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #9706 (step 9706): 1.305108\n",
      "Batch #10\tAverage Generator Loss: 1288.689166\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #9707 (step 9707): 1.754006\n",
      "Batch #10\tAverage Generator Loss: 1478.657013\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #9708 (step 9708): 1.378953\n",
      "Batch #10\tAverage Generator Loss: 1713.856982\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #9709 (step 9709): 1.284567\n",
      "Batch #10\tAverage Generator Loss: 1498.328412\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #9710 (step 9710): 1.654660\n",
      "Batch #10\tAverage Generator Loss: 1615.289996\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #9711 (step 9711): 1.380250\n",
      "Batch #10\tAverage Generator Loss: 1413.722215\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #9712 (step 9712): 1.610358\n",
      "Batch #10\tAverage Generator Loss: 1501.389694\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #9713 (step 9713): 1.305373\n",
      "Batch #10\tAverage Generator Loss: 1487.925449\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #9714 (step 9714): 1.746873\n",
      "Batch #10\tAverage Generator Loss: 1622.854053\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #9715 (step 9715): 1.463481\n",
      "Batch #10\tAverage Generator Loss: 1651.740845\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #9716 (step 9716): 1.265584\n",
      "Batch #10\tAverage Generator Loss: 1658.999115\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #9717 (step 9717): 1.622213\n",
      "Batch #10\tAverage Generator Loss: 1676.524042\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #9718 (step 9718): 1.290528\n",
      "Batch #10\tAverage Generator Loss: 1726.522253\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #9719 (step 9719): 1.603488\n",
      "Batch #10\tAverage Generator Loss: 1525.031641\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #9720 (step 9720): 1.372560\n",
      "Batch #10\tAverage Generator Loss: 1696.038525\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #9721 (step 9721): 1.679458\n",
      "Batch #10\tAverage Generator Loss: 1644.601770\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #9722 (step 9722): 1.343690\n",
      "Batch #10\tAverage Generator Loss: 1504.088654\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #9723 (step 9723): 1.376365\n",
      "Batch #10\tAverage Generator Loss: 1741.630273\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #9724 (step 9724): 1.676884\n",
      "Batch #10\tAverage Generator Loss: 1621.227362\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #9725 (step 9725): 1.298810\n",
      "Batch #10\tAverage Generator Loss: 1733.273859\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #9726 (step 9726): 1.687030\n",
      "Batch #10\tAverage Generator Loss: 1318.110916\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #9727 (step 9727): 1.399867\n",
      "Batch #10\tAverage Generator Loss: 1752.096753\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #9728 (step 9728): 1.639398\n",
      "Batch #10\tAverage Generator Loss: 1563.752112\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #9729 (step 9729): 1.311721\n",
      "Batch #10\tAverage Generator Loss: 1705.485284\tAverage Discriminator Loss: 0.000002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #9730 (step 9730): 1.343371\n",
      "Batch #10\tAverage Generator Loss: 1576.211060\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #9731 (step 9731): 1.677241\n",
      "Batch #10\tAverage Generator Loss: 1702.899792\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #9732 (step 9732): 1.360425\n",
      "Batch #10\tAverage Generator Loss: 1628.125836\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #9733 (step 9733): 1.588937\n",
      "Batch #10\tAverage Generator Loss: 1532.536621\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #9734 (step 9734): 1.391218\n",
      "Batch #10\tAverage Generator Loss: 1494.443115\tAverage Discriminator Loss: 0.002251\n",
      "\n",
      "Train time for epoch #9735 (step 9735): 1.621930\n",
      "Batch #10\tAverage Generator Loss: 1521.600653\tAverage Discriminator Loss: 0.000030\n",
      "\n",
      "Train time for epoch #9736 (step 9736): 1.391188\n",
      "Batch #10\tAverage Generator Loss: 1588.703467\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #9737 (step 9737): 1.457785\n",
      "Batch #10\tAverage Generator Loss: 1539.235498\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #9738 (step 9738): 1.677685\n",
      "Batch #10\tAverage Generator Loss: 1693.034973\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9739 (step 9739): 1.441462\n",
      "Batch #10\tAverage Generator Loss: 1397.027692\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9740 (step 9740): 1.665786\n",
      "Batch #10\tAverage Generator Loss: 1655.636523\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9741 (step 9741): 1.298388\n",
      "Batch #10\tAverage Generator Loss: 1266.920563\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9742 (step 9742): 1.631595\n",
      "Batch #10\tAverage Generator Loss: 1717.567310\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9743 (step 9743): 1.354309\n",
      "Batch #10\tAverage Generator Loss: 1586.100357\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9744 (step 9744): 1.297039\n",
      "Batch #10\tAverage Generator Loss: 1848.228064\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9745 (step 9745): 1.624320\n",
      "Batch #10\tAverage Generator Loss: 1440.553094\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9746 (step 9746): 1.366546\n",
      "Batch #10\tAverage Generator Loss: 1803.253497\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9747 (step 9747): 1.617740\n",
      "Batch #10\tAverage Generator Loss: 1555.478455\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9748 (step 9748): 1.292457\n",
      "Batch #10\tAverage Generator Loss: 1469.948743\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9749 (step 9749): 1.648197\n",
      "Batch #10\tAverage Generator Loss: 1594.815808\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9750 (step 9750): 1.285101\n",
      "Batch #10\tAverage Generator Loss: 1605.111108\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9751 (step 9751): 1.346000\n",
      "Batch #10\tAverage Generator Loss: 1768.667041\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9752 (step 9752): 1.666450\n",
      "Batch #10\tAverage Generator Loss: 1694.754053\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #9753 (step 9753): 1.249144\n",
      "Batch #10\tAverage Generator Loss: 1653.073944\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9754 (step 9754): 1.650103\n",
      "Batch #10\tAverage Generator Loss: 1676.267517\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9755 (step 9755): 1.327345\n",
      "Batch #10\tAverage Generator Loss: 1546.071075\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9756 (step 9756): 1.732582\n",
      "Batch #10\tAverage Generator Loss: 1775.893518\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9757 (step 9757): 1.292121\n",
      "Batch #10\tAverage Generator Loss: 1763.672699\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9758 (step 9758): 1.666384\n",
      "Batch #10\tAverage Generator Loss: 1523.779364\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9759 (step 9759): 1.359110\n",
      "Batch #10\tAverage Generator Loss: 1633.052509\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9760 (step 9760): 1.723052\n",
      "Batch #10\tAverage Generator Loss: 1756.329541\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9761 (step 9761): 1.334832\n",
      "Batch #10\tAverage Generator Loss: 1556.687244\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9762 (step 9762): 1.290888\n",
      "Batch #10\tAverage Generator Loss: 1453.005548\tAverage Discriminator Loss: 0.046881\n",
      "\n",
      "Train time for epoch #9763 (step 9763): 1.681374\n",
      "Batch #10\tAverage Generator Loss: 1601.979993\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9764 (step 9764): 1.296579\n",
      "Batch #10\tAverage Generator Loss: 1496.809100\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9765 (step 9765): 1.681592\n",
      "Batch #10\tAverage Generator Loss: 1428.456079\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9766 (step 9766): 1.295217\n",
      "Batch #10\tAverage Generator Loss: 1651.388147\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9767 (step 9767): 1.631999\n",
      "Batch #10\tAverage Generator Loss: 1607.306787\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9768 (step 9768): 1.365336\n",
      "Batch #10\tAverage Generator Loss: 1630.147894\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9769 (step 9769): 1.676243\n",
      "Batch #10\tAverage Generator Loss: 1531.913470\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9770 (step 9770): 1.299491\n",
      "Batch #10\tAverage Generator Loss: 1552.361938\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9771 (step 9771): 1.383007\n",
      "Batch #10\tAverage Generator Loss: 1667.024780\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9772 (step 9772): 1.620533\n",
      "Batch #10\tAverage Generator Loss: 1602.273651\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9773 (step 9773): 1.430850\n",
      "Batch #10\tAverage Generator Loss: 1644.566748\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9774 (step 9774): 1.670208\n",
      "Batch #10\tAverage Generator Loss: 1189.254465\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #9775 (step 9775): 1.344543\n",
      "Batch #10\tAverage Generator Loss: 1390.461200\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9776 (step 9776): 1.681428\n",
      "Batch #10\tAverage Generator Loss: 1474.822595\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9777 (step 9777): 1.383176\n",
      "Batch #10\tAverage Generator Loss: 1747.157690\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9778 (step 9778): 1.297410\n",
      "Batch #10\tAverage Generator Loss: 1570.846631\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9779 (step 9779): 1.647474\n",
      "Batch #10\tAverage Generator Loss: 1490.122571\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9780 (step 9780): 1.484315\n",
      "Batch #10\tAverage Generator Loss: 1579.053723\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9781 (step 9781): 1.755930\n",
      "Batch #10\tAverage Generator Loss: 1536.500433\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9782 (step 9782): 1.336676\n",
      "Batch #10\tAverage Generator Loss: 1568.178802\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9783 (step 9783): 1.661319\n",
      "Batch #10\tAverage Generator Loss: 1745.880933\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9784 (step 9784): 1.414536\n",
      "Batch #10\tAverage Generator Loss: 1690.868555\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9785 (step 9785): 1.390254\n",
      "Batch #10\tAverage Generator Loss: 1428.932617\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9786 (step 9786): 1.717738\n",
      "Batch #10\tAverage Generator Loss: 1412.195325\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9787 (step 9787): 1.293620\n",
      "Batch #10\tAverage Generator Loss: 1448.757928\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9788 (step 9788): 1.651639\n",
      "Batch #10\tAverage Generator Loss: 1526.301068\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9789 (step 9789): 1.290340\n",
      "Batch #10\tAverage Generator Loss: 1518.506750\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9790 (step 9790): 1.696061\n",
      "Batch #10\tAverage Generator Loss: 1587.795087\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9791 (step 9791): 1.318850\n",
      "Batch #10\tAverage Generator Loss: 1337.234998\tAverage Discriminator Loss: 0.000001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #9792 (step 9792): 1.341779\n",
      "Batch #10\tAverage Generator Loss: 1408.714136\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9793 (step 9793): 1.629511\n",
      "Batch #10\tAverage Generator Loss: 1419.588959\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9794 (step 9794): 1.330992\n",
      "Batch #10\tAverage Generator Loss: 1659.696216\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9795 (step 9795): 1.770934\n",
      "Batch #10\tAverage Generator Loss: 1484.388464\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9796 (step 9796): 1.299536\n",
      "Batch #10\tAverage Generator Loss: 1464.091809\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9797 (step 9797): 1.611469\n",
      "Batch #10\tAverage Generator Loss: 1591.224622\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9798 (step 9798): 1.284336\n",
      "Batch #10\tAverage Generator Loss: 1588.720154\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9799 (step 9799): 1.718112\n",
      "Batch #10\tAverage Generator Loss: 1610.173065\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9800 (step 9800): 1.346040\n",
      "Batch #10\tAverage Generator Loss: 1454.666229\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9801 (step 9801): 1.472032\n",
      "Batch #10\tAverage Generator Loss: 1757.884839\tAverage Discriminator Loss: 0.005821\n",
      "\n",
      "Train time for epoch #9802 (step 9802): 1.616395\n",
      "Batch #10\tAverage Generator Loss: 1946.779346\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #9803 (step 9803): 1.292082\n",
      "Batch #10\tAverage Generator Loss: 1719.419562\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9804 (step 9804): 1.678474\n",
      "Batch #10\tAverage Generator Loss: 1636.753192\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9805 (step 9805): 1.298625\n",
      "Batch #10\tAverage Generator Loss: 1677.826971\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9806 (step 9806): 1.691434\n",
      "Batch #10\tAverage Generator Loss: 1466.509045\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9807 (step 9807): 1.293951\n",
      "Batch #10\tAverage Generator Loss: 1608.278601\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9808 (step 9808): 1.636345\n",
      "Batch #10\tAverage Generator Loss: 1706.869324\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9809 (step 9809): 1.343766\n",
      "Batch #10\tAverage Generator Loss: 1618.563306\tAverage Discriminator Loss: 0.001269\n",
      "\n",
      "Train time for epoch #9810 (step 9810): 1.393646\n",
      "Batch #10\tAverage Generator Loss: 2113.134521\tAverage Discriminator Loss: 0.017786\n",
      "\n",
      "Train time for epoch #9811 (step 9811): 1.686938\n",
      "Batch #10\tAverage Generator Loss: 1662.816827\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9812 (step 9812): 1.405081\n",
      "Batch #10\tAverage Generator Loss: 1724.268933\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9813 (step 9813): 1.695061\n",
      "Batch #10\tAverage Generator Loss: 1527.987610\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9814 (step 9814): 1.311358\n",
      "Batch #10\tAverage Generator Loss: 1649.327960\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9815 (step 9815): 1.732448\n",
      "Batch #10\tAverage Generator Loss: 1544.228381\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9816 (step 9816): 1.363742\n",
      "Batch #10\tAverage Generator Loss: 1463.795087\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9817 (step 9817): 1.404263\n",
      "Batch #10\tAverage Generator Loss: 1650.649780\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9818 (step 9818): 1.645742\n",
      "Batch #10\tAverage Generator Loss: 1454.219568\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9819 (step 9819): 1.342240\n",
      "Batch #10\tAverage Generator Loss: 1663.301483\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9820 (step 9820): 1.626240\n",
      "Batch #10\tAverage Generator Loss: 1476.417377\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9821 (step 9821): 1.232464\n",
      "Batch #10\tAverage Generator Loss: 1637.519489\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9822 (step 9822): 1.673472\n",
      "Batch #10\tAverage Generator Loss: 1762.869043\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9823 (step 9823): 1.348608\n",
      "Batch #10\tAverage Generator Loss: 1635.863025\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9824 (step 9824): 1.660046\n",
      "Batch #10\tAverage Generator Loss: 1300.957065\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9825 (step 9825): 1.275615\n",
      "Batch #10\tAverage Generator Loss: 1469.624213\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9826 (step 9826): 1.641458\n",
      "Batch #10\tAverage Generator Loss: 1651.357846\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9827 (step 9827): 1.342353\n",
      "Batch #10\tAverage Generator Loss: 1822.394055\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9828 (step 9828): 1.257987\n",
      "Batch #10\tAverage Generator Loss: 1623.965393\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9829 (step 9829): 1.618284\n",
      "Batch #10\tAverage Generator Loss: 1752.853943\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9830 (step 9830): 1.238271\n",
      "Batch #10\tAverage Generator Loss: 1745.782965\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9831 (step 9831): 1.698702\n",
      "Batch #10\tAverage Generator Loss: 1616.653357\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9832 (step 9832): 1.296482\n",
      "Batch #10\tAverage Generator Loss: 1581.356476\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9833 (step 9833): 1.562835\n",
      "Batch #10\tAverage Generator Loss: 1677.043335\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9834 (step 9834): 1.337428\n",
      "Batch #10\tAverage Generator Loss: 1766.656604\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9835 (step 9835): 1.327766\n",
      "Batch #10\tAverage Generator Loss: 1625.507513\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9836 (step 9836): 1.559005\n",
      "Batch #10\tAverage Generator Loss: 1809.034814\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9837 (step 9837): 1.490478\n",
      "Batch #10\tAverage Generator Loss: 1429.809906\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9838 (step 9838): 1.625310\n",
      "Batch #10\tAverage Generator Loss: 1713.153241\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9839 (step 9839): 1.292158\n",
      "Batch #10\tAverage Generator Loss: 1792.653125\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9840 (step 9840): 1.669326\n",
      "Batch #10\tAverage Generator Loss: 1684.193188\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9841 (step 9841): 1.341578\n",
      "Batch #10\tAverage Generator Loss: 1644.963708\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9842 (step 9842): 1.689022\n",
      "Batch #10\tAverage Generator Loss: 1739.517194\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9843 (step 9843): 1.348872\n",
      "Batch #10\tAverage Generator Loss: 1483.431775\tAverage Discriminator Loss: 0.000246\n",
      "\n",
      "Train time for epoch #9844 (step 9844): 1.392351\n",
      "Batch #10\tAverage Generator Loss: 1587.195697\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #9845 (step 9845): 1.693532\n",
      "Batch #10\tAverage Generator Loss: 1278.788196\tAverage Discriminator Loss: 0.014716\n",
      "\n",
      "Train time for epoch #9846 (step 9846): 1.322746\n",
      "Batch #10\tAverage Generator Loss: 1406.975165\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9847 (step 9847): 1.679274\n",
      "Batch #10\tAverage Generator Loss: 1509.877655\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9848 (step 9848): 1.410267\n",
      "Batch #10\tAverage Generator Loss: 1530.552765\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9849 (step 9849): 1.334602\n",
      "Batch #10\tAverage Generator Loss: 1510.491663\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9850 (step 9850): 1.861883\n",
      "Batch #10\tAverage Generator Loss: 1487.644183\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9851 (step 9851): 1.323625\n",
      "Batch #10\tAverage Generator Loss: 1284.911874\tAverage Discriminator Loss: 0.039926\n",
      "\n",
      "Train time for epoch #9852 (step 9852): 1.748914\n",
      "Batch #10\tAverage Generator Loss: 1517.120007\tAverage Discriminator Loss: 0.021243\n",
      "\n",
      "Train time for epoch #9853 (step 9853): 1.305706\n",
      "Batch #10\tAverage Generator Loss: 1937.483301\tAverage Discriminator Loss: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #9854 (step 9854): 1.638379\n",
      "Batch #10\tAverage Generator Loss: 1906.560870\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9855 (step 9855): 1.243858\n",
      "Batch #10\tAverage Generator Loss: 1918.535693\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9856 (step 9856): 1.289310\n",
      "Batch #10\tAverage Generator Loss: 1887.872955\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9857 (step 9857): 1.889482\n",
      "Batch #10\tAverage Generator Loss: 1839.393811\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9858 (step 9858): 1.291400\n",
      "Batch #10\tAverage Generator Loss: 1819.341730\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9859 (step 9859): 1.822180\n",
      "Batch #10\tAverage Generator Loss: 1857.698798\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9860 (step 9860): 1.340985\n",
      "Batch #10\tAverage Generator Loss: 1965.586627\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9861 (step 9861): 1.305283\n",
      "Batch #10\tAverage Generator Loss: 2191.706311\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9862 (step 9862): 1.675118\n",
      "Batch #10\tAverage Generator Loss: 1920.272076\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9863 (step 9863): 1.334708\n",
      "Batch #10\tAverage Generator Loss: 2208.834814\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9864 (step 9864): 1.657484\n",
      "Batch #10\tAverage Generator Loss: 2232.721570\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9865 (step 9865): 1.362833\n",
      "Batch #10\tAverage Generator Loss: 2181.357288\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9866 (step 9866): 1.710050\n",
      "Batch #10\tAverage Generator Loss: 1921.437170\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9867 (step 9867): 1.282654\n",
      "Batch #10\tAverage Generator Loss: 2413.424353\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9868 (step 9868): 1.262736\n",
      "Batch #10\tAverage Generator Loss: 1996.586719\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9869 (step 9869): 1.629028\n",
      "Batch #10\tAverage Generator Loss: 2324.732703\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9870 (step 9870): 1.342630\n",
      "Batch #10\tAverage Generator Loss: 2465.518225\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9871 (step 9871): 1.717725\n",
      "Batch #10\tAverage Generator Loss: 2121.538049\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9872 (step 9872): 1.294785\n",
      "Batch #10\tAverage Generator Loss: 1954.706818\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9873 (step 9873): 1.762234\n",
      "Batch #10\tAverage Generator Loss: 1806.963556\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9874 (step 9874): 1.351034\n",
      "Batch #10\tAverage Generator Loss: 2230.470294\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9875 (step 9875): 1.417753\n",
      "Batch #10\tAverage Generator Loss: 2197.467426\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9876 (step 9876): 1.603513\n",
      "Batch #10\tAverage Generator Loss: 1926.856451\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9877 (step 9877): 1.377753\n",
      "Batch #10\tAverage Generator Loss: 1920.398230\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9878 (step 9878): 1.776295\n",
      "Batch #10\tAverage Generator Loss: 1960.207281\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9879 (step 9879): 1.277448\n",
      "Batch #10\tAverage Generator Loss: 1887.274854\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9880 (step 9880): 1.716749\n",
      "Batch #10\tAverage Generator Loss: 2016.996127\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9881 (step 9881): 1.243413\n",
      "Batch #10\tAverage Generator Loss: 1959.424084\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9882 (step 9882): 1.282447\n",
      "Batch #10\tAverage Generator Loss: 2059.311591\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #9883 (step 9883): 1.624878\n",
      "Batch #10\tAverage Generator Loss: 2237.091663\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9884 (step 9884): 1.315676\n",
      "Batch #10\tAverage Generator Loss: 1920.780731\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9885 (step 9885): 1.728204\n",
      "Batch #10\tAverage Generator Loss: 2451.259778\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9886 (step 9886): 1.308725\n",
      "Batch #10\tAverage Generator Loss: 2070.546509\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9887 (step 9887): 1.687242\n",
      "Batch #10\tAverage Generator Loss: 2101.467163\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9888 (step 9888): 1.299914\n",
      "Batch #10\tAverage Generator Loss: 1776.392371\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9889 (step 9889): 1.344554\n",
      "Batch #10\tAverage Generator Loss: 2128.395880\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9890 (step 9890): 1.776398\n",
      "Batch #10\tAverage Generator Loss: 2281.695959\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9891 (step 9891): 1.310221\n",
      "Batch #10\tAverage Generator Loss: 2212.142065\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9892 (step 9892): 1.667095\n",
      "Batch #10\tAverage Generator Loss: 2226.514630\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9893 (step 9893): 1.336042\n",
      "Batch #10\tAverage Generator Loss: 1827.261023\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9894 (step 9894): 1.723742\n",
      "Batch #10\tAverage Generator Loss: 1998.206201\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9895 (step 9895): 1.340630\n",
      "Batch #10\tAverage Generator Loss: 2175.099591\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9896 (step 9896): 1.469027\n",
      "Batch #10\tAverage Generator Loss: 2228.287317\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9897 (step 9897): 1.750189\n",
      "Batch #10\tAverage Generator Loss: 2116.361841\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #9898 (step 9898): 1.447305\n",
      "Batch #10\tAverage Generator Loss: 1923.841882\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9899 (step 9899): 1.591828\n",
      "Batch #10\tAverage Generator Loss: 1796.581256\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9900 (step 9900): 1.402676\n",
      "Batch #10\tAverage Generator Loss: 1888.240234\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9901 (step 9901): 1.768564\n",
      "Batch #10\tAverage Generator Loss: 2185.002380\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9902 (step 9902): 1.298785\n",
      "Batch #10\tAverage Generator Loss: 2043.796088\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9903 (step 9903): 1.710038\n",
      "Batch #10\tAverage Generator Loss: 2226.453711\tAverage Discriminator Loss: 0.024039\n",
      "\n",
      "Train time for epoch #9904 (step 9904): 1.371444\n",
      "Batch #10\tAverage Generator Loss: 1986.931824\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9905 (step 9905): 1.338473\n",
      "Batch #10\tAverage Generator Loss: 1860.527692\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9906 (step 9906): 1.615775\n",
      "Batch #10\tAverage Generator Loss: 2035.322852\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9907 (step 9907): 1.258997\n",
      "Batch #10\tAverage Generator Loss: 1811.985608\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9908 (step 9908): 1.724868\n",
      "Batch #10\tAverage Generator Loss: 2308.476282\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9909 (step 9909): 1.412178\n",
      "Batch #10\tAverage Generator Loss: 1643.416644\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9910 (step 9910): 1.735756\n",
      "Batch #10\tAverage Generator Loss: 1728.491736\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9911 (step 9911): 1.248905\n",
      "Batch #10\tAverage Generator Loss: 1910.934900\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9912 (step 9912): 1.324915\n",
      "Batch #10\tAverage Generator Loss: 1905.153125\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9913 (step 9913): 1.612040\n",
      "Batch #10\tAverage Generator Loss: 1796.686389\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9914 (step 9914): 1.283647\n",
      "Batch #10\tAverage Generator Loss: 1726.733228\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #9915 (step 9915): 1.616797\n",
      "Batch #10\tAverage Generator Loss: 2165.755151\tAverage Discriminator Loss: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #9916 (step 9916): 1.296868\n",
      "Batch #10\tAverage Generator Loss: 2111.022766\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9917 (step 9917): 1.666100\n",
      "Batch #10\tAverage Generator Loss: 1678.932593\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9918 (step 9918): 1.236467\n",
      "Batch #10\tAverage Generator Loss: 1743.342798\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9919 (step 9919): 1.338613\n",
      "Batch #10\tAverage Generator Loss: 1916.202533\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9920 (step 9920): 1.644792\n",
      "Batch #10\tAverage Generator Loss: 2183.005066\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9921 (step 9921): 1.280867\n",
      "Batch #10\tAverage Generator Loss: 2047.258414\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9922 (step 9922): 1.669879\n",
      "Batch #10\tAverage Generator Loss: 1883.509668\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9923 (step 9923): 1.441767\n",
      "Batch #10\tAverage Generator Loss: 1855.346716\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9924 (step 9924): 1.399131\n",
      "Batch #10\tAverage Generator Loss: 2060.049829\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9925 (step 9925): 1.685739\n",
      "Batch #10\tAverage Generator Loss: 1998.757581\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9926 (step 9926): 1.409405\n",
      "Batch #10\tAverage Generator Loss: 1913.289124\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9927 (step 9927): 1.629359\n",
      "Batch #10\tAverage Generator Loss: 1714.372122\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9928 (step 9928): 1.317219\n",
      "Batch #10\tAverage Generator Loss: 1805.676691\tAverage Discriminator Loss: 0.004616\n",
      "\n",
      "Train time for epoch #9929 (step 9929): 1.648494\n",
      "Batch #10\tAverage Generator Loss: 1860.469653\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #9930 (step 9930): 1.382570\n",
      "Batch #10\tAverage Generator Loss: 1704.959552\tAverage Discriminator Loss: 0.000091\n",
      "\n",
      "Train time for epoch #9931 (step 9931): 1.287010\n",
      "Batch #10\tAverage Generator Loss: 1848.103699\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #9932 (step 9932): 1.674831\n",
      "Batch #10\tAverage Generator Loss: 1609.542169\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #9933 (step 9933): 1.299674\n",
      "Batch #10\tAverage Generator Loss: 1652.698819\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #9934 (step 9934): 1.685893\n",
      "Batch #10\tAverage Generator Loss: 2026.858093\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #9935 (step 9935): 1.315299\n",
      "Batch #10\tAverage Generator Loss: 1852.931995\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #9936 (step 9936): 1.707250\n",
      "Batch #10\tAverage Generator Loss: 1659.320062\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #9937 (step 9937): 1.397349\n",
      "Batch #10\tAverage Generator Loss: 1775.351892\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #9938 (step 9938): 1.611033\n",
      "Batch #10\tAverage Generator Loss: 1734.366266\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #9939 (step 9939): 1.331920\n",
      "Batch #10\tAverage Generator Loss: 1860.205322\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #9940 (step 9940): 1.291214\n",
      "Batch #10\tAverage Generator Loss: 1951.789441\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9941 (step 9941): 1.697514\n",
      "Batch #10\tAverage Generator Loss: 1933.909454\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #9942 (step 9942): 1.244408\n",
      "Batch #10\tAverage Generator Loss: 1800.202557\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #9943 (step 9943): 1.627783\n",
      "Batch #10\tAverage Generator Loss: 1663.360669\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #9944 (step 9944): 1.292691\n",
      "Batch #10\tAverage Generator Loss: 2000.012793\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9945 (step 9945): 1.660234\n",
      "Batch #10\tAverage Generator Loss: 1937.399969\tAverage Discriminator Loss: 0.114585\n",
      "\n",
      "Train time for epoch #9946 (step 9946): 1.330098\n",
      "Batch #10\tAverage Generator Loss: 1798.236572\tAverage Discriminator Loss: 0.118109\n",
      "\n",
      "Train time for epoch #9947 (step 9947): 1.744579\n",
      "Batch #10\tAverage Generator Loss: 1937.650854\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9948 (step 9948): 1.425673\n",
      "Batch #10\tAverage Generator Loss: 1785.832983\tAverage Discriminator Loss: 0.003191\n",
      "\n",
      "Train time for epoch #9949 (step 9949): 1.337753\n",
      "Batch #10\tAverage Generator Loss: 1757.933240\tAverage Discriminator Loss: 0.000707\n",
      "\n",
      "Train time for epoch #9950 (step 9950): 1.677485\n",
      "Batch #10\tAverage Generator Loss: 1819.958386\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #9951 (step 9951): 1.377323\n",
      "Batch #10\tAverage Generator Loss: 1630.657533\tAverage Discriminator Loss: 1.961781\n",
      "\n",
      "Train time for epoch #9952 (step 9952): 1.603146\n",
      "Batch #10\tAverage Generator Loss: 1387.639661\tAverage Discriminator Loss: 0.029875\n",
      "\n",
      "Train time for epoch #9953 (step 9953): 1.339957\n",
      "Batch #10\tAverage Generator Loss: 1392.790436\tAverage Discriminator Loss: 0.024654\n",
      "\n",
      "Train time for epoch #9954 (step 9954): 1.724237\n",
      "Batch #10\tAverage Generator Loss: 1343.161469\tAverage Discriminator Loss: 0.070651\n",
      "\n",
      "Train time for epoch #9955 (step 9955): 1.287948\n",
      "Batch #10\tAverage Generator Loss: 1591.503510\tAverage Discriminator Loss: 0.025401\n",
      "\n",
      "Train time for epoch #9956 (step 9956): 1.587582\n",
      "Batch #10\tAverage Generator Loss: 1531.789191\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9957 (step 9957): 1.288015\n",
      "Batch #10\tAverage Generator Loss: 1622.154037\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9958 (step 9958): 1.397104\n",
      "Batch #10\tAverage Generator Loss: 1716.138788\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9959 (step 9959): 1.648238\n",
      "Batch #10\tAverage Generator Loss: 1555.192596\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9960 (step 9960): 1.279973\n",
      "Batch #10\tAverage Generator Loss: 1379.824890\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9961 (step 9961): 1.697979\n",
      "Batch #10\tAverage Generator Loss: 1429.877728\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9962 (step 9962): 1.336569\n",
      "Batch #10\tAverage Generator Loss: 1554.377368\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9963 (step 9963): 1.350965\n",
      "Batch #10\tAverage Generator Loss: 1497.837689\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9964 (step 9964): 1.636961\n",
      "Batch #10\tAverage Generator Loss: 1210.485071\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9965 (step 9965): 1.285672\n",
      "Batch #10\tAverage Generator Loss: 1466.754889\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9966 (step 9966): 1.640891\n",
      "Batch #10\tAverage Generator Loss: 1430.536102\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9967 (step 9967): 1.410787\n",
      "Batch #10\tAverage Generator Loss: 1441.793323\tAverage Discriminator Loss: 0.002462\n",
      "\n",
      "Train time for epoch #9968 (step 9968): 1.730261\n",
      "Batch #10\tAverage Generator Loss: 1366.031860\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9969 (step 9969): 1.300282\n",
      "Batch #10\tAverage Generator Loss: 1572.900037\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9970 (step 9970): 1.840487\n",
      "Batch #10\tAverage Generator Loss: 1703.803223\tAverage Discriminator Loss: 0.000111\n",
      "\n",
      "Train time for epoch #9971 (step 9971): 1.331378\n",
      "Batch #10\tAverage Generator Loss: 1658.682306\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9972 (step 9972): 1.344928\n",
      "Batch #10\tAverage Generator Loss: 1409.929944\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9973 (step 9973): 1.824268\n",
      "Batch #10\tAverage Generator Loss: 1814.939862\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9974 (step 9974): 1.291057\n",
      "Batch #10\tAverage Generator Loss: 1593.363757\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9975 (step 9975): 1.749681\n",
      "Batch #10\tAverage Generator Loss: 1713.246442\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9976 (step 9976): 1.338678\n",
      "Batch #10\tAverage Generator Loss: 1541.567188\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9977 (step 9977): 1.646654\n",
      "Batch #10\tAverage Generator Loss: 1492.588855\tAverage Discriminator Loss: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #9978 (step 9978): 1.336528\n",
      "Batch #10\tAverage Generator Loss: 1604.518579\tAverage Discriminator Loss: 0.024814\n",
      "\n",
      "Train time for epoch #9979 (step 9979): 1.295800\n",
      "Batch #10\tAverage Generator Loss: 1872.171130\tAverage Discriminator Loss: 0.017277\n",
      "\n",
      "Train time for epoch #9980 (step 9980): 1.641867\n",
      "Batch #10\tAverage Generator Loss: 1526.942120\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9981 (step 9981): 1.364035\n",
      "Batch #10\tAverage Generator Loss: 1441.295361\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9982 (step 9982): 1.667873\n",
      "Batch #10\tAverage Generator Loss: 1699.902692\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9983 (step 9983): 1.292048\n",
      "Batch #10\tAverage Generator Loss: 1506.776410\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9984 (step 9984): 1.752714\n",
      "Batch #10\tAverage Generator Loss: 1488.674292\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9985 (step 9985): 1.287722\n",
      "Batch #10\tAverage Generator Loss: 1672.373895\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9986 (step 9986): 1.355382\n",
      "Batch #10\tAverage Generator Loss: 1445.664209\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9987 (step 9987): 1.628239\n",
      "Batch #10\tAverage Generator Loss: 1391.071814\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9988 (step 9988): 1.297801\n",
      "Batch #10\tAverage Generator Loss: 1630.899426\tAverage Discriminator Loss: 0.002459\n",
      "\n",
      "Train time for epoch #9989 (step 9989): 1.575070\n",
      "Batch #10\tAverage Generator Loss: 1310.056311\tAverage Discriminator Loss: 0.000795\n",
      "\n",
      "Train time for epoch #9990 (step 9990): 1.377282\n",
      "Batch #10\tAverage Generator Loss: 1581.321155\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9991 (step 9991): 1.730420\n",
      "Batch #10\tAverage Generator Loss: 1533.805975\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9992 (step 9992): 1.445845\n",
      "Batch #10\tAverage Generator Loss: 1689.282416\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9993 (step 9993): 1.312217\n",
      "Batch #10\tAverage Generator Loss: 1248.438751\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #9994 (step 9994): 1.636865\n",
      "Batch #10\tAverage Generator Loss: 1601.804761\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9995 (step 9995): 1.287914\n",
      "Batch #10\tAverage Generator Loss: 1467.173737\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9996 (step 9996): 1.707021\n",
      "Batch #10\tAverage Generator Loss: 1526.763110\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9997 (step 9997): 1.302082\n",
      "Batch #10\tAverage Generator Loss: 1586.418555\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #9998 (step 9998): 1.711470\n",
      "Batch #10\tAverage Generator Loss: 1502.780652\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #9999 (step 9999): 1.317829\n",
      "Batch #10\tAverage Generator Loss: 1611.698474\tAverage Discriminator Loss: 0.000253\n",
      "\n",
      "Train time for epoch #10000 (step 10000): 1.673978\n",
      "Batch #10\tAverage Generator Loss: 1545.912634\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #10001 (step 10001): 1.358778\n",
      "Batch #10\tAverage Generator Loss: 1499.206335\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10002 (step 10002): 1.357649\n",
      "Batch #10\tAverage Generator Loss: 1658.515619\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #10003 (step 10003): 1.643149\n",
      "Batch #10\tAverage Generator Loss: 1483.621112\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #10004 (step 10004): 1.910810\n",
      "Batch #10\tAverage Generator Loss: 1528.828229\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #10005 (step 10005): 1.715961\n",
      "Batch #10\tAverage Generator Loss: 1638.168091\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #10006 (step 10006): 1.348893\n",
      "Batch #10\tAverage Generator Loss: 1809.172925\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #10007 (step 10007): 1.306672\n",
      "Batch #10\tAverage Generator Loss: 1679.870526\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #10008 (step 10008): 1.689317\n",
      "Batch #10\tAverage Generator Loss: 1525.550977\tAverage Discriminator Loss: 0.000055\n",
      "\n",
      "Train time for epoch #10009 (step 10009): 1.412535\n",
      "Batch #10\tAverage Generator Loss: 1477.529059\tAverage Discriminator Loss: 0.000068\n",
      "\n",
      "Train time for epoch #10010 (step 10010): 1.692607\n",
      "Batch #10\tAverage Generator Loss: 1630.617548\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #10011 (step 10011): 1.242668\n",
      "Batch #10\tAverage Generator Loss: 1625.108459\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #10012 (step 10012): 1.650767\n",
      "Batch #10\tAverage Generator Loss: 1681.813293\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #10013 (step 10013): 1.345397\n",
      "Batch #10\tAverage Generator Loss: 1559.197815\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #10014 (step 10014): 1.749003\n",
      "Batch #10\tAverage Generator Loss: 1338.900177\tAverage Discriminator Loss: 0.040758\n",
      "\n",
      "Train time for epoch #10015 (step 10015): 1.326727\n",
      "Batch #10\tAverage Generator Loss: 1474.218658\tAverage Discriminator Loss: 0.004036\n",
      "\n",
      "Train time for epoch #10016 (step 10016): 1.331656\n",
      "Batch #10\tAverage Generator Loss: 1409.465686\tAverage Discriminator Loss: 0.000057\n",
      "\n",
      "Train time for epoch #10017 (step 10017): 1.642699\n",
      "Batch #10\tAverage Generator Loss: 1765.262231\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #10018 (step 10018): 1.377054\n",
      "Batch #10\tAverage Generator Loss: 1532.882312\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #10019 (step 10019): 1.681609\n",
      "Batch #10\tAverage Generator Loss: 1591.103143\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #10020 (step 10020): 1.282160\n",
      "Batch #10\tAverage Generator Loss: 1326.424661\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #10021 (step 10021): 1.625201\n",
      "Batch #10\tAverage Generator Loss: 1515.602649\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #10022 (step 10022): 1.330269\n",
      "Batch #10\tAverage Generator Loss: 1485.453406\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #10023 (step 10023): 1.411569\n",
      "Batch #10\tAverage Generator Loss: 1480.222131\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #10024 (step 10024): 1.692624\n",
      "Batch #10\tAverage Generator Loss: 1479.641962\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #10025 (step 10025): 1.356314\n",
      "Batch #10\tAverage Generator Loss: 1637.647571\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10026 (step 10026): 1.605992\n",
      "Batch #10\tAverage Generator Loss: 1367.819189\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #10027 (step 10027): 1.291040\n",
      "Batch #10\tAverage Generator Loss: 1520.343915\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #10028 (step 10028): 1.617484\n",
      "Batch #10\tAverage Generator Loss: 1669.854193\tAverage Discriminator Loss: 0.009030\n",
      "\n",
      "Train time for epoch #10029 (step 10029): 1.352351\n",
      "Batch #10\tAverage Generator Loss: 1516.820587\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #10030 (step 10030): 1.328043\n",
      "Batch #10\tAverage Generator Loss: 1319.342194\tAverage Discriminator Loss: 0.002335\n",
      "\n",
      "Train time for epoch #10031 (step 10031): 1.665838\n",
      "Batch #10\tAverage Generator Loss: 1475.613965\tAverage Discriminator Loss: 0.000067\n",
      "\n",
      "Train time for epoch #10032 (step 10032): 1.451916\n",
      "Batch #10\tAverage Generator Loss: 1632.935620\tAverage Discriminator Loss: 0.000106\n",
      "\n",
      "Train time for epoch #10033 (step 10033): 1.694824\n",
      "Batch #10\tAverage Generator Loss: 1513.874152\tAverage Discriminator Loss: 0.000037\n",
      "\n",
      "Train time for epoch #10034 (step 10034): 1.380040\n",
      "Batch #10\tAverage Generator Loss: 1588.134396\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #10035 (step 10035): 1.300242\n",
      "Batch #10\tAverage Generator Loss: 1331.473401\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #10036 (step 10036): 1.620328\n",
      "Batch #10\tAverage Generator Loss: 1478.160272\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #10037 (step 10037): 1.439050\n",
      "Batch #10\tAverage Generator Loss: 1667.289581\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #10038 (step 10038): 1.625832\n",
      "Batch #10\tAverage Generator Loss: 1638.529687\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #10039 (step 10039): 1.391665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 1614.259607\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #10040 (step 10040): 1.763504\n",
      "Batch #10\tAverage Generator Loss: 1520.058813\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #10041 (step 10041): 1.443847\n",
      "Batch #10\tAverage Generator Loss: 1474.774826\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #10042 (step 10042): 1.293036\n",
      "Batch #10\tAverage Generator Loss: 1470.905438\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #10043 (step 10043): 1.637991\n",
      "Batch #10\tAverage Generator Loss: 1503.935059\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #10044 (step 10044): 1.445764\n",
      "Batch #10\tAverage Generator Loss: 1580.064624\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #10045 (step 10045): 1.693246\n",
      "Batch #10\tAverage Generator Loss: 1361.018549\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #10046 (step 10046): 1.472872\n",
      "Batch #10\tAverage Generator Loss: 1327.388501\tAverage Discriminator Loss: 0.004386\n",
      "\n",
      "Train time for epoch #10047 (step 10047): 1.300700\n",
      "Batch #10\tAverage Generator Loss: 1431.653394\tAverage Discriminator Loss: 0.000026\n",
      "\n",
      "Train time for epoch #10048 (step 10048): 1.707202\n",
      "Batch #10\tAverage Generator Loss: 1370.634460\tAverage Discriminator Loss: 0.000042\n",
      "\n",
      "Train time for epoch #10049 (step 10049): 1.345705\n",
      "Batch #10\tAverage Generator Loss: 1720.023334\tAverage Discriminator Loss: 0.000025\n",
      "\n",
      "Train time for epoch #10050 (step 10050): 1.743505\n",
      "Batch #10\tAverage Generator Loss: 1412.864008\tAverage Discriminator Loss: 0.000020\n",
      "\n",
      "Train time for epoch #10051 (step 10051): 1.290357\n",
      "Batch #10\tAverage Generator Loss: 1401.175806\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #10052 (step 10052): 1.801535\n",
      "Batch #10\tAverage Generator Loss: 1621.277338\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #10053 (step 10053): 1.274780\n",
      "Batch #10\tAverage Generator Loss: 1486.691248\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #10054 (step 10054): 1.404175\n",
      "Batch #10\tAverage Generator Loss: 1356.195850\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #10055 (step 10055): 1.607511\n",
      "Batch #10\tAverage Generator Loss: 1598.655646\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #10056 (step 10056): 1.378179\n",
      "Batch #10\tAverage Generator Loss: 1547.126996\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #10057 (step 10057): 1.676565\n",
      "Batch #10\tAverage Generator Loss: 1591.848279\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #10058 (step 10058): 1.340584\n",
      "Batch #10\tAverage Generator Loss: 1323.485333\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #10059 (step 10059): 1.344080\n",
      "Batch #10\tAverage Generator Loss: 1632.000427\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #10060 (step 10060): 1.588694\n",
      "Batch #10\tAverage Generator Loss: 1432.062244\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #10061 (step 10061): 1.388002\n",
      "Batch #10\tAverage Generator Loss: 1400.971967\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #10062 (step 10062): 1.692939\n",
      "Batch #10\tAverage Generator Loss: 1283.551331\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #10063 (step 10063): 1.348140\n",
      "Batch #10\tAverage Generator Loss: 1299.047296\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #10064 (step 10064): 1.690312\n",
      "Batch #10\tAverage Generator Loss: 1513.375189\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #10065 (step 10065): 1.308152\n",
      "Batch #10\tAverage Generator Loss: 1412.167554\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #10066 (step 10066): 1.499650\n",
      "Batch #10\tAverage Generator Loss: 1600.167596\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #10067 (step 10067): 1.631803\n",
      "Batch #10\tAverage Generator Loss: 1554.601453\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #10068 (step 10068): 1.452035\n",
      "Batch #10\tAverage Generator Loss: 1432.441812\tAverage Discriminator Loss: 0.000531\n",
      "\n",
      "Train time for epoch #10069 (step 10069): 1.627522\n",
      "Batch #10\tAverage Generator Loss: 1595.330048\tAverage Discriminator Loss: 0.005380\n",
      "\n",
      "Train time for epoch #10070 (step 10070): 1.319745\n",
      "Batch #10\tAverage Generator Loss: 1307.283380\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #10071 (step 10071): 1.336685\n",
      "Batch #10\tAverage Generator Loss: 1498.990656\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #10072 (step 10072): 1.644874\n",
      "Batch #10\tAverage Generator Loss: 1521.419067\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #10073 (step 10073): 1.391185\n",
      "Batch #10\tAverage Generator Loss: 1331.580719\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #10074 (step 10074): 1.793149\n",
      "Batch #10\tAverage Generator Loss: 1284.221289\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10075 (step 10075): 1.279701\n",
      "Batch #10\tAverage Generator Loss: 1407.960437\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #10076 (step 10076): 1.748274\n",
      "Batch #10\tAverage Generator Loss: 1369.502832\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #10077 (step 10077): 1.292868\n",
      "Batch #10\tAverage Generator Loss: 1637.026813\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #10078 (step 10078): 1.381168\n",
      "Batch #10\tAverage Generator Loss: 1288.043494\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #10079 (step 10079): 1.647214\n",
      "Batch #10\tAverage Generator Loss: 1519.598871\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #10080 (step 10080): 1.448621\n",
      "Batch #10\tAverage Generator Loss: 1414.951453\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #10081 (step 10081): 1.705753\n",
      "Batch #10\tAverage Generator Loss: 1454.165735\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10082 (step 10082): 1.461195\n",
      "Batch #10\tAverage Generator Loss: 1606.025446\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #10083 (step 10083): 1.591239\n",
      "Batch #10\tAverage Generator Loss: 1486.876605\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10084 (step 10084): 1.363970\n",
      "Batch #10\tAverage Generator Loss: 1453.656683\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10085 (step 10085): 1.423777\n",
      "Batch #10\tAverage Generator Loss: 1506.461011\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10086 (step 10086): 1.651837\n",
      "Batch #10\tAverage Generator Loss: 1622.310150\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #10087 (step 10087): 1.302095\n",
      "Batch #10\tAverage Generator Loss: 1711.877448\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10088 (step 10088): 1.785607\n",
      "Batch #10\tAverage Generator Loss: 1522.717310\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #10089 (step 10089): 1.374227\n",
      "Batch #10\tAverage Generator Loss: 1511.774164\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10090 (step 10090): 1.648654\n",
      "Batch #10\tAverage Generator Loss: 1537.244800\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10091 (step 10091): 1.289409\n",
      "Batch #10\tAverage Generator Loss: 1322.829492\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10092 (step 10092): 1.281457\n",
      "Batch #10\tAverage Generator Loss: 1435.639905\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10093 (step 10093): 1.654677\n",
      "Batch #10\tAverage Generator Loss: 1590.931415\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10094 (step 10094): 1.320435\n",
      "Batch #10\tAverage Generator Loss: 1309.093225\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10095 (step 10095): 1.693158\n",
      "Batch #10\tAverage Generator Loss: 1545.290344\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10096 (step 10096): 1.364300\n",
      "Batch #10\tAverage Generator Loss: 1487.585895\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10097 (step 10097): 1.744762\n",
      "Batch #10\tAverage Generator Loss: 1481.009204\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #10098 (step 10098): 1.364824\n",
      "Batch #10\tAverage Generator Loss: 1510.838501\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10099 (step 10099): 1.294496\n",
      "Batch #10\tAverage Generator Loss: 1265.973645\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10100 (step 10100): 1.724421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 1624.966492\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10101 (step 10101): 1.304775\n",
      "Batch #10\tAverage Generator Loss: 1339.505206\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10102 (step 10102): 1.630780\n",
      "Batch #10\tAverage Generator Loss: 1584.334277\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10103 (step 10103): 1.302236\n",
      "Batch #10\tAverage Generator Loss: 1561.995483\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10104 (step 10104): 1.642242\n",
      "Batch #10\tAverage Generator Loss: 1430.409393\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10105 (step 10105): 1.444585\n",
      "Batch #10\tAverage Generator Loss: 1561.617334\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10106 (step 10106): 1.297662\n",
      "Batch #10\tAverage Generator Loss: 1547.008020\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10107 (step 10107): 1.742335\n",
      "Batch #10\tAverage Generator Loss: 1649.168628\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10108 (step 10108): 1.295833\n",
      "Batch #10\tAverage Generator Loss: 1500.286023\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10109 (step 10109): 1.670393\n",
      "Batch #10\tAverage Generator Loss: 1472.424115\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10110 (step 10110): 1.325156\n",
      "Batch #10\tAverage Generator Loss: 1592.499200\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10111 (step 10111): 1.355653\n",
      "Batch #10\tAverage Generator Loss: 1348.808398\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10112 (step 10112): 1.824567\n",
      "Batch #10\tAverage Generator Loss: 1600.822723\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10113 (step 10113): 1.470944\n",
      "Batch #10\tAverage Generator Loss: 1368.252863\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10114 (step 10114): 1.709525\n",
      "Batch #10\tAverage Generator Loss: 1462.816858\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10115 (step 10115): 1.294025\n",
      "Batch #10\tAverage Generator Loss: 1484.320435\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10116 (step 10116): 1.738011\n",
      "Batch #10\tAverage Generator Loss: 1520.153796\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10117 (step 10117): 1.296447\n",
      "Batch #10\tAverage Generator Loss: 1377.594049\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10118 (step 10118): 1.654226\n",
      "Batch #10\tAverage Generator Loss: 1507.758844\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10119 (step 10119): 1.285019\n",
      "Batch #10\tAverage Generator Loss: 1333.191684\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10120 (step 10120): 1.325386\n",
      "Batch #10\tAverage Generator Loss: 1472.113989\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10121 (step 10121): 1.647353\n",
      "Batch #10\tAverage Generator Loss: 1480.869781\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10122 (step 10122): 1.279863\n",
      "Batch #10\tAverage Generator Loss: 1524.039502\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10123 (step 10123): 1.638776\n",
      "Batch #10\tAverage Generator Loss: 1575.601465\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10124 (step 10124): 1.277220\n",
      "Batch #10\tAverage Generator Loss: 1532.938293\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10125 (step 10125): 1.804353\n",
      "Batch #10\tAverage Generator Loss: 1359.578033\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10126 (step 10126): 1.350477\n",
      "Batch #10\tAverage Generator Loss: 1411.209436\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10127 (step 10127): 1.332558\n",
      "Batch #10\tAverage Generator Loss: 1377.553387\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10128 (step 10128): 1.698698\n",
      "Batch #10\tAverage Generator Loss: 1145.776288\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10129 (step 10129): 1.341991\n",
      "Batch #10\tAverage Generator Loss: 1419.597284\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10130 (step 10130): 1.629669\n",
      "Batch #10\tAverage Generator Loss: 1491.740344\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10131 (step 10131): 1.433695\n",
      "Batch #10\tAverage Generator Loss: 1461.170807\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10132 (step 10132): 1.699679\n",
      "Batch #10\tAverage Generator Loss: 1331.414972\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10133 (step 10133): 1.320508\n",
      "Batch #10\tAverage Generator Loss: 1347.893256\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10134 (step 10134): 1.738404\n",
      "Batch #10\tAverage Generator Loss: 1554.024487\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10135 (step 10135): 1.293681\n",
      "Batch #10\tAverage Generator Loss: 1589.547803\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10136 (step 10136): 1.557417\n",
      "Batch #10\tAverage Generator Loss: 1426.683337\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10137 (step 10137): 1.673180\n",
      "Batch #10\tAverage Generator Loss: 1468.344421\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10138 (step 10138): 1.286603\n",
      "Batch #10\tAverage Generator Loss: 1472.892981\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10139 (step 10139): 1.897719\n",
      "Batch #10\tAverage Generator Loss: 1556.140894\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10140 (step 10140): 1.292230\n",
      "Batch #10\tAverage Generator Loss: 1328.149847\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10141 (step 10141): 1.695983\n",
      "Batch #10\tAverage Generator Loss: 1103.626056\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10142 (step 10142): 1.347755\n",
      "Batch #10\tAverage Generator Loss: 1544.493561\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10143 (step 10143): 1.331885\n",
      "Batch #10\tAverage Generator Loss: 1368.867633\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10144 (step 10144): 1.675135\n",
      "Batch #10\tAverage Generator Loss: 1300.697745\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10145 (step 10145): 1.294792\n",
      "Batch #10\tAverage Generator Loss: 1324.838434\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10146 (step 10146): 1.625700\n",
      "Batch #10\tAverage Generator Loss: 1549.349207\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10147 (step 10147): 1.342659\n",
      "Batch #10\tAverage Generator Loss: 1323.749988\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10148 (step 10148): 1.663427\n",
      "Batch #10\tAverage Generator Loss: 1506.848120\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10149 (step 10149): 1.311528\n",
      "Batch #10\tAverage Generator Loss: 1450.290729\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10150 (step 10150): 1.344478\n",
      "Batch #10\tAverage Generator Loss: 1455.516418\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10151 (step 10151): 1.771917\n",
      "Batch #10\tAverage Generator Loss: 1340.762634\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10152 (step 10152): 1.337927\n",
      "Batch #10\tAverage Generator Loss: 1390.785004\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10153 (step 10153): 1.721308\n",
      "Batch #10\tAverage Generator Loss: 1675.026093\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10154 (step 10154): 1.355299\n",
      "Batch #10\tAverage Generator Loss: 1501.495551\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10155 (step 10155): 1.641598\n",
      "Batch #10\tAverage Generator Loss: 1699.574121\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10156 (step 10156): 1.340110\n",
      "Batch #10\tAverage Generator Loss: 1523.060248\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10157 (step 10157): 1.331723\n",
      "Batch #10\tAverage Generator Loss: 1442.365955\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10158 (step 10158): 1.738839\n",
      "Batch #10\tAverage Generator Loss: 1528.233124\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10159 (step 10159): 1.292744\n",
      "Batch #10\tAverage Generator Loss: 1459.223773\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10160 (step 10160): 1.750160\n",
      "Batch #10\tAverage Generator Loss: 1362.868304\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10161 (step 10161): 1.453754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 1548.812933\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10162 (step 10162): 1.702641\n",
      "Batch #10\tAverage Generator Loss: 1437.238440\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10163 (step 10163): 1.293604\n",
      "Batch #10\tAverage Generator Loss: 1482.827692\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10164 (step 10164): 1.240719\n",
      "Batch #10\tAverage Generator Loss: 1474.191168\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10165 (step 10165): 1.714347\n",
      "Batch #10\tAverage Generator Loss: 1464.278247\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10166 (step 10166): 1.386923\n",
      "Batch #10\tAverage Generator Loss: 1491.755591\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10167 (step 10167): 1.731380\n",
      "Batch #10\tAverage Generator Loss: 1335.760626\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10168 (step 10168): 1.384235\n",
      "Batch #10\tAverage Generator Loss: 1520.935632\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10169 (step 10169): 1.693722\n",
      "Batch #10\tAverage Generator Loss: 1423.407782\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10170 (step 10170): 1.292432\n",
      "Batch #10\tAverage Generator Loss: 1653.206238\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10171 (step 10171): 1.288476\n",
      "Batch #10\tAverage Generator Loss: 1361.614288\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10172 (step 10172): 1.714490\n",
      "Batch #10\tAverage Generator Loss: 1518.058484\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10173 (step 10173): 1.282854\n",
      "Batch #10\tAverage Generator Loss: 1324.376355\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10174 (step 10174): 1.804376\n",
      "Batch #10\tAverage Generator Loss: 1498.865942\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10175 (step 10175): 1.346565\n",
      "Batch #10\tAverage Generator Loss: 1263.536389\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10176 (step 10176): 1.685881\n",
      "Batch #10\tAverage Generator Loss: 1395.645990\tAverage Discriminator Loss: 0.000031\n",
      "\n",
      "Train time for epoch #10177 (step 10177): 1.377536\n",
      "Batch #10\tAverage Generator Loss: 1508.368140\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10178 (step 10178): 1.295576\n",
      "Batch #10\tAverage Generator Loss: 1341.494122\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10179 (step 10179): 1.774606\n",
      "Batch #10\tAverage Generator Loss: 1291.248157\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10180 (step 10180): 1.372371\n",
      "Batch #10\tAverage Generator Loss: 1301.811780\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10181 (step 10181): 1.683173\n",
      "Batch #10\tAverage Generator Loss: 1362.797528\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10182 (step 10182): 1.333563\n",
      "Batch #10\tAverage Generator Loss: 1456.497504\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10183 (step 10183): 1.679444\n",
      "Batch #10\tAverage Generator Loss: 1628.187469\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10184 (step 10184): 1.342983\n",
      "Batch #10\tAverage Generator Loss: 1661.473462\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10185 (step 10185): 1.286594\n",
      "Batch #10\tAverage Generator Loss: 1494.832831\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10186 (step 10186): 1.635551\n",
      "Batch #10\tAverage Generator Loss: 1350.257245\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10187 (step 10187): 1.435472\n",
      "Batch #10\tAverage Generator Loss: 1342.530695\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10188 (step 10188): 1.688806\n",
      "Batch #10\tAverage Generator Loss: 1230.783130\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10189 (step 10189): 1.345317\n",
      "Batch #10\tAverage Generator Loss: 1486.524780\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10190 (step 10190): 1.742404\n",
      "Batch #10\tAverage Generator Loss: 1536.517877\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10191 (step 10191): 1.473432\n",
      "Batch #10\tAverage Generator Loss: 1354.570514\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10192 (step 10192): 1.345783\n",
      "Batch #10\tAverage Generator Loss: 1412.074762\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10193 (step 10193): 1.664044\n",
      "Batch #10\tAverage Generator Loss: 1500.751685\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10194 (step 10194): 1.279072\n",
      "Batch #10\tAverage Generator Loss: 1587.970618\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10195 (step 10195): 1.630547\n",
      "Batch #10\tAverage Generator Loss: 1494.097192\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10196 (step 10196): 1.320008\n",
      "Batch #10\tAverage Generator Loss: 1349.623712\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10197 (step 10197): 1.688736\n",
      "Batch #10\tAverage Generator Loss: 1503.542395\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10198 (step 10198): 1.292254\n",
      "Batch #10\tAverage Generator Loss: 1561.338892\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10199 (step 10199): 1.281706\n",
      "Batch #10\tAverage Generator Loss: 1207.303235\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10200 (step 10200): 1.644114\n",
      "Batch #10\tAverage Generator Loss: 1411.342609\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10201 (step 10201): 1.344408\n",
      "Batch #10\tAverage Generator Loss: 1310.547083\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #10202 (step 10202): 1.697113\n",
      "Batch #10\tAverage Generator Loss: 1395.964502\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10203 (step 10203): 1.315406\n",
      "Batch #10\tAverage Generator Loss: 1392.735260\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10204 (step 10204): 1.611812\n",
      "Batch #10\tAverage Generator Loss: 1294.828308\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10205 (step 10205): 1.296661\n",
      "Batch #10\tAverage Generator Loss: 1335.084308\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10206 (step 10206): 1.337056\n",
      "Batch #10\tAverage Generator Loss: 1724.775220\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10207 (step 10207): 1.692884\n",
      "Batch #10\tAverage Generator Loss: 1414.373041\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10208 (step 10208): 1.296798\n",
      "Batch #10\tAverage Generator Loss: 1224.611700\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10209 (step 10209): 1.704002\n",
      "Batch #10\tAverage Generator Loss: 1553.762091\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10210 (step 10210): 1.378896\n",
      "Batch #10\tAverage Generator Loss: 1522.648749\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10211 (step 10211): 1.725979\n",
      "Batch #10\tAverage Generator Loss: 1527.449713\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10212 (step 10212): 1.331277\n",
      "Batch #10\tAverage Generator Loss: 1321.552655\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10213 (step 10213): 1.349774\n",
      "Batch #10\tAverage Generator Loss: 1509.634851\tAverage Discriminator Loss: 0.002989\n",
      "\n",
      "Train time for epoch #10214 (step 10214): 1.702925\n",
      "Batch #10\tAverage Generator Loss: 1610.230212\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10215 (step 10215): 1.379211\n",
      "Batch #10\tAverage Generator Loss: 1393.645819\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10216 (step 10216): 1.677574\n",
      "Batch #10\tAverage Generator Loss: 1460.307928\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10217 (step 10217): 1.343404\n",
      "Batch #10\tAverage Generator Loss: 1505.791980\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10218 (step 10218): 1.725876\n",
      "Batch #10\tAverage Generator Loss: 1356.856158\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10219 (step 10219): 1.378921\n",
      "Batch #10\tAverage Generator Loss: 1377.573840\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10220 (step 10220): 1.301127\n",
      "Batch #10\tAverage Generator Loss: 1300.438409\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10221 (step 10221): 1.707757\n",
      "Batch #10\tAverage Generator Loss: 1541.318774\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #10222 (step 10222): 1.339254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 1227.809857\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10223 (step 10223): 1.627600\n",
      "Batch #10\tAverage Generator Loss: 1493.840271\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10224 (step 10224): 1.375232\n",
      "Batch #10\tAverage Generator Loss: 1544.407977\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10225 (step 10225): 1.626996\n",
      "Batch #10\tAverage Generator Loss: 1460.589423\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10226 (step 10226): 1.293687\n",
      "Batch #10\tAverage Generator Loss: 1533.429187\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10227 (step 10227): 1.396434\n",
      "Batch #10\tAverage Generator Loss: 1608.672357\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10228 (step 10228): 1.613045\n",
      "Batch #10\tAverage Generator Loss: 1461.939331\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10229 (step 10229): 1.286054\n",
      "Batch #10\tAverage Generator Loss: 1457.160980\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10230 (step 10230): 1.631433\n",
      "Batch #10\tAverage Generator Loss: 1660.478552\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10231 (step 10231): 1.341134\n",
      "Batch #10\tAverage Generator Loss: 1241.321991\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #10232 (step 10232): 1.701946\n",
      "Batch #10\tAverage Generator Loss: 1439.050977\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10233 (step 10233): 1.289232\n",
      "Batch #10\tAverage Generator Loss: 1648.598242\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10234 (step 10234): 1.241103\n",
      "Batch #10\tAverage Generator Loss: 1597.615161\tAverage Discriminator Loss: 0.000306\n",
      "\n",
      "Train time for epoch #10235 (step 10235): 1.709096\n",
      "Batch #10\tAverage Generator Loss: 1561.524268\tAverage Discriminator Loss: 0.000549\n",
      "\n",
      "Train time for epoch #10236 (step 10236): 1.346722\n",
      "Batch #10\tAverage Generator Loss: 1207.486371\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10237 (step 10237): 1.705559\n",
      "Batch #10\tAverage Generator Loss: 1654.665466\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10238 (step 10238): 1.354297\n",
      "Batch #10\tAverage Generator Loss: 1343.797705\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10239 (step 10239): 1.736734\n",
      "Batch #10\tAverage Generator Loss: 1571.840747\tAverage Discriminator Loss: 0.107126\n",
      "\n",
      "Train time for epoch #10240 (step 10240): 1.291132\n",
      "Batch #10\tAverage Generator Loss: 1370.351215\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10241 (step 10241): 1.356410\n",
      "Batch #10\tAverage Generator Loss: 1629.551929\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10242 (step 10242): 1.595939\n",
      "Batch #10\tAverage Generator Loss: 1845.891010\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10243 (step 10243): 1.392584\n",
      "Batch #10\tAverage Generator Loss: 1505.963031\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10244 (step 10244): 1.758398\n",
      "Batch #10\tAverage Generator Loss: 1776.951331\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10245 (step 10245): 1.348761\n",
      "Batch #10\tAverage Generator Loss: 1599.280750\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10246 (step 10246): 1.348662\n",
      "Batch #10\tAverage Generator Loss: 1756.245227\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10247 (step 10247): 1.742538\n",
      "Batch #10\tAverage Generator Loss: 1627.021783\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10248 (step 10248): 1.345276\n",
      "Batch #10\tAverage Generator Loss: 1938.695764\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10249 (step 10249): 1.696633\n",
      "Batch #10\tAverage Generator Loss: 2067.197852\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10250 (step 10250): 1.372081\n",
      "Batch #10\tAverage Generator Loss: 1768.837134\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10251 (step 10251): 1.647685\n",
      "Batch #10\tAverage Generator Loss: 1766.267883\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10252 (step 10252): 1.299080\n",
      "Batch #10\tAverage Generator Loss: 1746.997455\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10253 (step 10253): 1.277678\n",
      "Batch #10\tAverage Generator Loss: 1479.954688\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10254 (step 10254): 1.671163\n",
      "Batch #10\tAverage Generator Loss: 2408.243811\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10255 (step 10255): 1.294727\n",
      "Batch #10\tAverage Generator Loss: 1762.069672\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10256 (step 10256): 1.714064\n",
      "Batch #10\tAverage Generator Loss: 1568.239172\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10257 (step 10257): 1.289961\n",
      "Batch #10\tAverage Generator Loss: 1779.570410\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10258 (step 10258): 1.693703\n",
      "Batch #10\tAverage Generator Loss: 1468.947064\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10259 (step 10259): 1.434376\n",
      "Batch #10\tAverage Generator Loss: 1554.942392\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10260 (step 10260): 1.419892\n",
      "Batch #10\tAverage Generator Loss: 1873.906250\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10261 (step 10261): 1.628417\n",
      "Batch #10\tAverage Generator Loss: 1777.911560\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10262 (step 10262): 1.293342\n",
      "Batch #10\tAverage Generator Loss: 1770.998981\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10263 (step 10263): 1.627680\n",
      "Batch #10\tAverage Generator Loss: 1779.948151\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10264 (step 10264): 1.258471\n",
      "Batch #10\tAverage Generator Loss: 2035.619843\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10265 (step 10265): 1.395560\n",
      "Batch #10\tAverage Generator Loss: 1495.707895\tAverage Discriminator Loss: 0.001773\n",
      "\n",
      "Train time for epoch #10266 (step 10266): 1.628345\n",
      "Batch #10\tAverage Generator Loss: 1653.356628\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10267 (step 10267): 1.293736\n",
      "Batch #10\tAverage Generator Loss: 1918.889441\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10268 (step 10268): 1.671979\n",
      "Batch #10\tAverage Generator Loss: 1630.702148\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10269 (step 10269): 1.355446\n",
      "Batch #10\tAverage Generator Loss: 1626.178992\tAverage Discriminator Loss: 0.005088\n",
      "\n",
      "Train time for epoch #10270 (step 10270): 1.761500\n",
      "Batch #10\tAverage Generator Loss: 2060.407800\tAverage Discriminator Loss: 0.000344\n",
      "\n",
      "Train time for epoch #10271 (step 10271): 1.403085\n",
      "Batch #10\tAverage Generator Loss: 1884.506140\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10272 (step 10272): 1.710683\n",
      "Batch #10\tAverage Generator Loss: 1529.783582\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10273 (step 10273): 1.288623\n",
      "Batch #10\tAverage Generator Loss: 1900.557471\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10274 (step 10274): 1.353093\n",
      "Batch #10\tAverage Generator Loss: 1866.507275\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10275 (step 10275): 1.670470\n",
      "Batch #10\tAverage Generator Loss: 1625.563318\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10276 (step 10276): 1.492062\n",
      "Batch #10\tAverage Generator Loss: 1683.924646\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10277 (step 10277): 1.737292\n",
      "Batch #10\tAverage Generator Loss: 1438.999347\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10278 (step 10278): 1.349468\n",
      "Batch #10\tAverage Generator Loss: 1646.183661\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10279 (step 10279): 1.343230\n",
      "Batch #10\tAverage Generator Loss: 1622.180414\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10280 (step 10280): 1.694569\n",
      "Batch #10\tAverage Generator Loss: 1482.153937\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10281 (step 10281): 1.413703\n",
      "Batch #10\tAverage Generator Loss: 1637.213177\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10282 (step 10282): 1.790426\n",
      "Batch #10\tAverage Generator Loss: 1768.581549\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10283 (step 10283): 1.333417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 1548.815857\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10284 (step 10284): 1.716693\n",
      "Batch #10\tAverage Generator Loss: 1547.187558\tAverage Discriminator Loss: 0.049495\n",
      "\n",
      "Train time for epoch #10285 (step 10285): 1.385932\n",
      "Batch #10\tAverage Generator Loss: 1704.828943\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10286 (step 10286): 1.283358\n",
      "Batch #10\tAverage Generator Loss: 1450.153491\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10287 (step 10287): 1.693107\n",
      "Batch #10\tAverage Generator Loss: 1568.742224\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10288 (step 10288): 1.286893\n",
      "Batch #10\tAverage Generator Loss: 1537.815735\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10289 (step 10289): 1.755037\n",
      "Batch #10\tAverage Generator Loss: 1800.966174\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10290 (step 10290): 1.295078\n",
      "Batch #10\tAverage Generator Loss: 1586.096918\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10291 (step 10291): 1.344516\n",
      "Batch #10\tAverage Generator Loss: 1615.982220\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10292 (step 10292): 1.655783\n",
      "Batch #10\tAverage Generator Loss: 1665.505615\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10293 (step 10293): 1.282425\n",
      "Batch #10\tAverage Generator Loss: 1802.366394\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10294 (step 10294): 1.833686\n",
      "Batch #10\tAverage Generator Loss: 1374.826929\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10295 (step 10295): 1.339331\n",
      "Batch #10\tAverage Generator Loss: 1723.130493\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10296 (step 10296): 1.717178\n",
      "Batch #10\tAverage Generator Loss: 1684.981653\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10297 (step 10297): 1.404535\n",
      "Batch #10\tAverage Generator Loss: 1458.984949\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10298 (step 10298): 1.706516\n",
      "Batch #10\tAverage Generator Loss: 1582.849634\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10299 (step 10299): 1.380985\n",
      "Batch #10\tAverage Generator Loss: 1609.408521\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10300 (step 10300): 1.298525\n",
      "Batch #10\tAverage Generator Loss: 1538.279852\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10301 (step 10301): 1.666579\n",
      "Batch #10\tAverage Generator Loss: 1499.098853\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10302 (step 10302): 1.344133\n",
      "Batch #10\tAverage Generator Loss: 1464.629980\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10303 (step 10303): 1.659364\n",
      "Batch #10\tAverage Generator Loss: 1416.071472\tAverage Discriminator Loss: 0.157667\n",
      "\n",
      "Train time for epoch #10304 (step 10304): 1.295220\n",
      "Batch #10\tAverage Generator Loss: 1979.827109\tAverage Discriminator Loss: 0.013165\n",
      "\n",
      "Train time for epoch #10305 (step 10305): 1.661359\n",
      "Batch #10\tAverage Generator Loss: 2074.140912\tAverage Discriminator Loss: 0.065510\n",
      "\n",
      "Train time for epoch #10306 (step 10306): 1.343894\n",
      "Batch #10\tAverage Generator Loss: 2159.300867\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10307 (step 10307): 1.420630\n",
      "Batch #10\tAverage Generator Loss: 2628.596533\tAverage Discriminator Loss: 0.001765\n",
      "\n",
      "Train time for epoch #10308 (step 10308): 1.711325\n",
      "Batch #10\tAverage Generator Loss: 2343.555762\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10309 (step 10309): 1.326972\n",
      "Batch #10\tAverage Generator Loss: 2472.528247\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10310 (step 10310): 1.764002\n",
      "Batch #10\tAverage Generator Loss: 2449.444531\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10311 (step 10311): 1.326818\n",
      "Batch #10\tAverage Generator Loss: 2447.588525\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10312 (step 10312): 1.728543\n",
      "Batch #10\tAverage Generator Loss: 2643.824463\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10313 (step 10313): 1.353716\n",
      "Batch #10\tAverage Generator Loss: 2966.183850\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10314 (step 10314): 1.642537\n",
      "Batch #10\tAverage Generator Loss: 2745.810730\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10315 (step 10315): 1.384638\n",
      "Batch #10\tAverage Generator Loss: 2074.453217\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10316 (step 10316): 1.342517\n",
      "Batch #10\tAverage Generator Loss: 2508.695776\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10317 (step 10317): 1.651266\n",
      "Batch #10\tAverage Generator Loss: 2279.895538\tAverage Discriminator Loss: 0.163707\n",
      "\n",
      "Train time for epoch #10318 (step 10318): 1.291666\n",
      "Batch #10\tAverage Generator Loss: 2490.788953\tAverage Discriminator Loss: 0.216496\n",
      "\n",
      "Train time for epoch #10319 (step 10319): 1.645131\n",
      "Batch #10\tAverage Generator Loss: 2401.559778\tAverage Discriminator Loss: 0.437444\n",
      "\n",
      "Train time for epoch #10320 (step 10320): 1.298488\n",
      "Batch #10\tAverage Generator Loss: 2117.057532\tAverage Discriminator Loss: 0.016531\n",
      "\n",
      "Train time for epoch #10321 (step 10321): 1.337421\n",
      "Batch #10\tAverage Generator Loss: 2395.688916\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10322 (step 10322): 1.717822\n",
      "Batch #10\tAverage Generator Loss: 2428.685950\tAverage Discriminator Loss: 0.088921\n",
      "\n",
      "Train time for epoch #10323 (step 10323): 1.434506\n",
      "Batch #10\tAverage Generator Loss: 2474.751160\tAverage Discriminator Loss: 0.001386\n",
      "\n",
      "Train time for epoch #10324 (step 10324): 1.736177\n",
      "Batch #10\tAverage Generator Loss: 2643.462946\tAverage Discriminator Loss: 0.039882\n",
      "\n",
      "Train time for epoch #10325 (step 10325): 1.394662\n",
      "Batch #10\tAverage Generator Loss: 3124.231213\tAverage Discriminator Loss: 0.004290\n",
      "\n",
      "Train time for epoch #10326 (step 10326): 1.340713\n",
      "Batch #10\tAverage Generator Loss: 2746.940576\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10327 (step 10327): 1.664001\n",
      "Batch #10\tAverage Generator Loss: 2587.442029\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10328 (step 10328): 1.346557\n",
      "Batch #10\tAverage Generator Loss: 2390.215210\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10329 (step 10329): 1.702551\n",
      "Batch #10\tAverage Generator Loss: 2605.605225\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10330 (step 10330): 1.331082\n",
      "Batch #10\tAverage Generator Loss: 2345.778845\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10331 (step 10331): 1.702621\n",
      "Batch #10\tAverage Generator Loss: 2694.290332\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10332 (step 10332): 1.337444\n",
      "Batch #10\tAverage Generator Loss: 2304.930591\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10333 (step 10333): 1.280894\n",
      "Batch #10\tAverage Generator Loss: 2466.596948\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10334 (step 10334): 1.708863\n",
      "Batch #10\tAverage Generator Loss: 2518.875043\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10335 (step 10335): 1.357082\n",
      "Batch #10\tAverage Generator Loss: 2595.037256\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10336 (step 10336): 1.708125\n",
      "Batch #10\tAverage Generator Loss: 2439.852527\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10337 (step 10337): 1.360486\n",
      "Batch #10\tAverage Generator Loss: 2671.790137\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10338 (step 10338): 1.274370\n",
      "Batch #10\tAverage Generator Loss: 2490.676685\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10339 (step 10339): 1.745456\n",
      "Batch #10\tAverage Generator Loss: 2396.904236\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10340 (step 10340): 1.399068\n",
      "Batch #10\tAverage Generator Loss: 2709.079431\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10341 (step 10341): 1.671078\n",
      "Batch #10\tAverage Generator Loss: 2480.285205\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10342 (step 10342): 1.326587\n",
      "Batch #10\tAverage Generator Loss: 2486.485962\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10343 (step 10343): 1.731956\n",
      "Batch #10\tAverage Generator Loss: 2239.513013\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10344 (step 10344): 1.374105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2386.454114\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10345 (step 10345): 1.377035\n",
      "Batch #10\tAverage Generator Loss: 2230.001208\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10346 (step 10346): 1.575170\n",
      "Batch #10\tAverage Generator Loss: 2574.192041\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10347 (step 10347): 1.413307\n",
      "Batch #10\tAverage Generator Loss: 2526.920374\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10348 (step 10348): 1.689286\n",
      "Batch #10\tAverage Generator Loss: 2502.485437\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10349 (step 10349): 1.339417\n",
      "Batch #10\tAverage Generator Loss: 2320.106653\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10350 (step 10350): 1.771421\n",
      "Batch #10\tAverage Generator Loss: 2232.075641\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10351 (step 10351): 1.378423\n",
      "Batch #10\tAverage Generator Loss: 2204.309668\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10352 (step 10352): 1.343532\n",
      "Batch #10\tAverage Generator Loss: 2139.172644\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10353 (step 10353): 1.699314\n",
      "Batch #10\tAverage Generator Loss: 2228.742590\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10354 (step 10354): 1.339631\n",
      "Batch #10\tAverage Generator Loss: 1997.968015\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10355 (step 10355): 1.694059\n",
      "Batch #10\tAverage Generator Loss: 2287.481360\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10356 (step 10356): 1.299409\n",
      "Batch #10\tAverage Generator Loss: 2335.901263\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10357 (step 10357): 1.395391\n",
      "Batch #10\tAverage Generator Loss: 2556.124829\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10358 (step 10358): 1.755234\n",
      "Batch #10\tAverage Generator Loss: 2609.994031\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10359 (step 10359): 1.334065\n",
      "Batch #10\tAverage Generator Loss: 2443.746484\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10360 (step 10360): 1.658230\n",
      "Batch #10\tAverage Generator Loss: 1888.703174\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10361 (step 10361): 1.279071\n",
      "Batch #10\tAverage Generator Loss: 2393.243665\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10362 (step 10362): 1.733706\n",
      "Batch #10\tAverage Generator Loss: 2112.312555\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10363 (step 10363): 1.285216\n",
      "Batch #10\tAverage Generator Loss: 2424.270117\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10364 (step 10364): 1.253477\n",
      "Batch #10\tAverage Generator Loss: 2503.323047\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10365 (step 10365): 1.760139\n",
      "Batch #10\tAverage Generator Loss: 2687.517822\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10366 (step 10366): 1.268402\n",
      "Batch #10\tAverage Generator Loss: 2457.782422\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10367 (step 10367): 1.644362\n",
      "Batch #10\tAverage Generator Loss: 2184.878088\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10368 (step 10368): 1.433085\n",
      "Batch #10\tAverage Generator Loss: 2452.630786\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10369 (step 10369): 1.339194\n",
      "Batch #10\tAverage Generator Loss: 2331.201660\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10370 (step 10370): 1.732888\n",
      "Batch #10\tAverage Generator Loss: 2066.476025\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10371 (step 10371): 1.338057\n",
      "Batch #10\tAverage Generator Loss: 2125.175708\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10372 (step 10372): 1.756580\n",
      "Batch #10\tAverage Generator Loss: 2343.705334\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10373 (step 10373): 1.299255\n",
      "Batch #10\tAverage Generator Loss: 2108.227655\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10374 (step 10374): 1.740592\n",
      "Batch #10\tAverage Generator Loss: 2776.277771\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10375 (step 10375): 1.369915\n",
      "Batch #10\tAverage Generator Loss: 2477.243323\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10376 (step 10376): 1.247557\n",
      "Batch #10\tAverage Generator Loss: 2118.143396\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10377 (step 10377): 1.840650\n",
      "Batch #10\tAverage Generator Loss: 2492.899365\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10378 (step 10378): 1.330333\n",
      "Batch #10\tAverage Generator Loss: 2427.555994\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10379 (step 10379): 1.613302\n",
      "Batch #10\tAverage Generator Loss: 2103.635706\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10380 (step 10380): 1.342689\n",
      "Batch #10\tAverage Generator Loss: 2683.505884\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10381 (step 10381): 1.629776\n",
      "Batch #10\tAverage Generator Loss: 2367.873645\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10382 (step 10382): 1.383455\n",
      "Batch #10\tAverage Generator Loss: 1998.807068\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10383 (step 10383): 1.298806\n",
      "Batch #10\tAverage Generator Loss: 2609.592065\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10384 (step 10384): 1.736362\n",
      "Batch #10\tAverage Generator Loss: 2546.472913\tAverage Discriminator Loss: 0.018377\n",
      "\n",
      "Train time for epoch #10385 (step 10385): 1.294487\n",
      "Batch #10\tAverage Generator Loss: 2449.812256\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10386 (step 10386): 1.723611\n",
      "Batch #10\tAverage Generator Loss: 1986.698181\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10387 (step 10387): 1.439598\n",
      "Batch #10\tAverage Generator Loss: 2580.958960\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10388 (step 10388): 1.351802\n",
      "Batch #10\tAverage Generator Loss: 2623.226422\tAverage Discriminator Loss: 0.038145\n",
      "\n",
      "Train time for epoch #10389 (step 10389): 1.677677\n",
      "Batch #10\tAverage Generator Loss: 2519.408252\tAverage Discriminator Loss: 0.000174\n",
      "\n",
      "Train time for epoch #10390 (step 10390): 1.278034\n",
      "Batch #10\tAverage Generator Loss: 2202.021582\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #10391 (step 10391): 1.647837\n",
      "Batch #10\tAverage Generator Loss: 2323.816028\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #10392 (step 10392): 1.426182\n",
      "Batch #10\tAverage Generator Loss: 2423.401160\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #10393 (step 10393): 1.414643\n",
      "Batch #10\tAverage Generator Loss: 2153.938757\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #10394 (step 10394): 1.700187\n",
      "Batch #10\tAverage Generator Loss: 2251.269678\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #10395 (step 10395): 1.348935\n",
      "Batch #10\tAverage Generator Loss: 2168.111670\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10396 (step 10396): 1.790908\n",
      "Batch #10\tAverage Generator Loss: 2287.004785\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #10397 (step 10397): 1.396441\n",
      "Batch #10\tAverage Generator Loss: 2662.389258\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #10398 (step 10398): 1.733478\n",
      "Batch #10\tAverage Generator Loss: 2610.554272\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #10399 (step 10399): 1.327304\n",
      "Batch #10\tAverage Generator Loss: 2432.178564\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10400 (step 10400): 1.598520\n",
      "Batch #10\tAverage Generator Loss: 2507.232666\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10401 (step 10401): 1.673997\n",
      "Batch #10\tAverage Generator Loss: 2424.004834\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #10402 (step 10402): 1.339272\n",
      "Batch #10\tAverage Generator Loss: 1877.089056\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #10403 (step 10403): 1.695042\n",
      "Batch #10\tAverage Generator Loss: 2162.942975\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #10404 (step 10404): 1.293057\n",
      "Batch #10\tAverage Generator Loss: 2222.294495\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10405 (step 10405): 1.346037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2133.248694\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #10406 (step 10406): 1.785756\n",
      "Batch #10\tAverage Generator Loss: 2290.456335\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10407 (step 10407): 1.311524\n",
      "Batch #10\tAverage Generator Loss: 2138.847241\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10408 (step 10408): 1.659533\n",
      "Batch #10\tAverage Generator Loss: 2233.023901\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10409 (step 10409): 1.335292\n",
      "Batch #10\tAverage Generator Loss: 2108.838251\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10410 (step 10410): 1.711253\n",
      "Batch #10\tAverage Generator Loss: 2335.048315\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10411 (step 10411): 1.352975\n",
      "Batch #10\tAverage Generator Loss: 2151.448218\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10412 (step 10412): 1.281712\n",
      "Batch #10\tAverage Generator Loss: 2481.095105\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10413 (step 10413): 1.738227\n",
      "Batch #10\tAverage Generator Loss: 2346.002209\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10414 (step 10414): 1.286850\n",
      "Batch #10\tAverage Generator Loss: 2160.650122\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10415 (step 10415): 1.693442\n",
      "Batch #10\tAverage Generator Loss: 2376.557214\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10416 (step 10416): 1.281765\n",
      "Batch #10\tAverage Generator Loss: 2128.203821\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10417 (step 10417): 1.704873\n",
      "Batch #10\tAverage Generator Loss: 2200.663342\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10418 (step 10418): 1.463598\n",
      "Batch #10\tAverage Generator Loss: 2358.213757\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10419 (step 10419): 1.455531\n",
      "Batch #10\tAverage Generator Loss: 2273.375732\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10420 (step 10420): 1.674064\n",
      "Batch #10\tAverage Generator Loss: 2308.302783\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10421 (step 10421): 1.284442\n",
      "Batch #10\tAverage Generator Loss: 1937.850128\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10422 (step 10422): 1.631137\n",
      "Batch #10\tAverage Generator Loss: 2202.835791\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10423 (step 10423): 1.307321\n",
      "Batch #10\tAverage Generator Loss: 2105.520941\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10424 (step 10424): 1.300446\n",
      "Batch #10\tAverage Generator Loss: 2264.903296\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10425 (step 10425): 1.687633\n",
      "Batch #10\tAverage Generator Loss: 2411.249744\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10426 (step 10426): 1.477901\n",
      "Batch #10\tAverage Generator Loss: 2241.036328\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10427 (step 10427): 1.758524\n",
      "Batch #10\tAverage Generator Loss: 2129.613745\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10428 (step 10428): 1.347014\n",
      "Batch #10\tAverage Generator Loss: 2253.100305\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10429 (step 10429): 1.356792\n",
      "Batch #10\tAverage Generator Loss: 2194.379492\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10430 (step 10430): 1.680853\n",
      "Batch #10\tAverage Generator Loss: 2302.224939\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10431 (step 10431): 1.404613\n",
      "Batch #10\tAverage Generator Loss: 1916.262769\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10432 (step 10432): 1.650447\n",
      "Batch #10\tAverage Generator Loss: 1918.509534\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10433 (step 10433): 1.374014\n",
      "Batch #10\tAverage Generator Loss: 2521.241602\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10434 (step 10434): 1.435355\n",
      "Batch #10\tAverage Generator Loss: 2256.738977\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10435 (step 10435): 1.711657\n",
      "Batch #10\tAverage Generator Loss: 2311.593188\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10436 (step 10436): 1.293448\n",
      "Batch #10\tAverage Generator Loss: 2253.711682\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10437 (step 10437): 1.612647\n",
      "Batch #10\tAverage Generator Loss: 1856.765912\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10438 (step 10438): 1.302049\n",
      "Batch #10\tAverage Generator Loss: 2106.381824\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10439 (step 10439): 1.506301\n",
      "Batch #10\tAverage Generator Loss: 2367.647607\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10440 (step 10440): 1.758226\n",
      "Batch #10\tAverage Generator Loss: 2403.622424\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10441 (step 10441): 1.385953\n",
      "Batch #10\tAverage Generator Loss: 2419.491364\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10442 (step 10442): 1.701477\n",
      "Batch #10\tAverage Generator Loss: 2212.844293\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10443 (step 10443): 1.393902\n",
      "Batch #10\tAverage Generator Loss: 2420.942010\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10444 (step 10444): 1.718242\n",
      "Batch #10\tAverage Generator Loss: 2533.274792\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10445 (step 10445): 1.341724\n",
      "Batch #10\tAverage Generator Loss: 2208.066516\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10446 (step 10446): 1.290937\n",
      "Batch #10\tAverage Generator Loss: 2586.832867\tAverage Discriminator Loss: 0.000033\n",
      "\n",
      "Train time for epoch #10447 (step 10447): 1.706904\n",
      "Batch #10\tAverage Generator Loss: 2473.340527\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10448 (step 10448): 1.351282\n",
      "Batch #10\tAverage Generator Loss: 2609.241858\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10449 (step 10449): 1.668197\n",
      "Batch #10\tAverage Generator Loss: 2293.820581\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10450 (step 10450): 1.290460\n",
      "Batch #10\tAverage Generator Loss: 2138.481738\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10451 (step 10451): 1.552335\n",
      "Batch #10\tAverage Generator Loss: 2144.065137\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10452 (step 10452): 1.678611\n",
      "Batch #10\tAverage Generator Loss: 2073.181781\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10453 (step 10453): 1.353226\n",
      "Batch #10\tAverage Generator Loss: 2314.290015\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10454 (step 10454): 1.727895\n",
      "Batch #10\tAverage Generator Loss: 2102.220618\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10455 (step 10455): 1.350867\n",
      "Batch #10\tAverage Generator Loss: 2496.964209\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10456 (step 10456): 1.682076\n",
      "Batch #10\tAverage Generator Loss: 2383.705371\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10457 (step 10457): 1.481763\n",
      "Batch #10\tAverage Generator Loss: 2665.829126\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10458 (step 10458): 1.448737\n",
      "Batch #10\tAverage Generator Loss: 2331.867957\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10459 (step 10459): 1.679735\n",
      "Batch #10\tAverage Generator Loss: 2187.167224\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10460 (step 10460): 1.295995\n",
      "Batch #10\tAverage Generator Loss: 2308.154102\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10461 (step 10461): 1.631186\n",
      "Batch #10\tAverage Generator Loss: 1849.499939\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10462 (step 10462): 1.393123\n",
      "Batch #10\tAverage Generator Loss: 2214.681921\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10463 (step 10463): 1.687207\n",
      "Batch #10\tAverage Generator Loss: 2319.361096\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10464 (step 10464): 1.353070\n",
      "Batch #10\tAverage Generator Loss: 2062.995160\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10465 (step 10465): 1.367134\n",
      "Batch #10\tAverage Generator Loss: 2173.651538\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10466 (step 10466): 1.590679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2387.642761\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10467 (step 10467): 1.288876\n",
      "Batch #10\tAverage Generator Loss: 2473.411267\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10468 (step 10468): 1.634015\n",
      "Batch #10\tAverage Generator Loss: 2087.274158\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10469 (step 10469): 1.348633\n",
      "Batch #10\tAverage Generator Loss: 2160.776758\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10470 (step 10470): 1.288957\n",
      "Batch #10\tAverage Generator Loss: 2233.270801\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10471 (step 10471): 1.716950\n",
      "Batch #10\tAverage Generator Loss: 2311.677945\tAverage Discriminator Loss: 0.009373\n",
      "\n",
      "Train time for epoch #10472 (step 10472): 1.365274\n",
      "Batch #10\tAverage Generator Loss: 2083.907922\tAverage Discriminator Loss: 0.000499\n",
      "\n",
      "Train time for epoch #10473 (step 10473): 1.674042\n",
      "Batch #10\tAverage Generator Loss: 2058.652368\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10474 (step 10474): 1.311930\n",
      "Batch #10\tAverage Generator Loss: 2137.269971\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10475 (step 10475): 1.404835\n",
      "Batch #10\tAverage Generator Loss: 2334.199353\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10476 (step 10476): 1.957482\n",
      "Batch #10\tAverage Generator Loss: 2290.981128\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10477 (step 10477): 1.299734\n",
      "Batch #10\tAverage Generator Loss: 2230.216687\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10478 (step 10478): 1.658800\n",
      "Batch #10\tAverage Generator Loss: 2448.181384\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10479 (step 10479): 1.403524\n",
      "Batch #10\tAverage Generator Loss: 2261.520886\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10480 (step 10480): 1.734145\n",
      "Batch #10\tAverage Generator Loss: 2251.953601\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10481 (step 10481): 1.654219\n",
      "Batch #10\tAverage Generator Loss: 2442.129785\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10482 (step 10482): 1.326808\n",
      "Batch #10\tAverage Generator Loss: 2128.399866\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10483 (step 10483): 2.728295\n",
      "Batch #10\tAverage Generator Loss: 1911.737616\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10484 (step 10484): 1.335015\n",
      "Batch #10\tAverage Generator Loss: 2250.687787\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10485 (step 10485): 1.838253\n",
      "Batch #10\tAverage Generator Loss: 2102.294482\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10486 (step 10486): 1.330798\n",
      "Batch #10\tAverage Generator Loss: 2173.503827\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10487 (step 10487): 3.270592\n",
      "Batch #10\tAverage Generator Loss: 2001.525061\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10488 (step 10488): 1.357425\n",
      "Batch #10\tAverage Generator Loss: 2037.496521\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10489 (step 10489): 1.329887\n",
      "Batch #10\tAverage Generator Loss: 2172.657068\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10490 (step 10490): 2.083884\n",
      "Batch #10\tAverage Generator Loss: 1945.010461\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10491 (step 10491): 1.286918\n",
      "Batch #10\tAverage Generator Loss: 2065.731091\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10492 (step 10492): 2.110446\n",
      "Batch #10\tAverage Generator Loss: 2124.474652\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10493 (step 10493): 1.303960\n",
      "Batch #10\tAverage Generator Loss: 2059.926111\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10494 (step 10494): 1.337088\n",
      "Batch #10\tAverage Generator Loss: 1943.363159\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10495 (step 10495): 1.670710\n",
      "Batch #10\tAverage Generator Loss: 2148.991736\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10496 (step 10496): 1.344330\n",
      "Batch #10\tAverage Generator Loss: 2179.150549\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10497 (step 10497): 1.731110\n",
      "Batch #10\tAverage Generator Loss: 2221.771271\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10498 (step 10498): 1.339354\n",
      "Batch #10\tAverage Generator Loss: 2254.811475\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10499 (step 10499): 1.716283\n",
      "Batch #10\tAverage Generator Loss: 2134.267041\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10500 (step 10500): 1.373769\n",
      "Batch #10\tAverage Generator Loss: 2017.674219\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10501 (step 10501): 1.337437\n",
      "Batch #10\tAverage Generator Loss: 2496.029236\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10502 (step 10502): 1.645065\n",
      "Batch #10\tAverage Generator Loss: 2167.551147\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10503 (step 10503): 1.344509\n",
      "Batch #10\tAverage Generator Loss: 2143.086127\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10504 (step 10504): 1.748885\n",
      "Batch #10\tAverage Generator Loss: 2432.201074\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10505 (step 10505): 1.383769\n",
      "Batch #10\tAverage Generator Loss: 2152.487744\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10506 (step 10506): 1.289989\n",
      "Batch #10\tAverage Generator Loss: 2314.518109\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10507 (step 10507): 1.741554\n",
      "Batch #10\tAverage Generator Loss: 2102.648657\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10508 (step 10508): 1.368347\n",
      "Batch #10\tAverage Generator Loss: 1582.708545\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10509 (step 10509): 1.630257\n",
      "Batch #10\tAverage Generator Loss: 2196.134937\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10510 (step 10510): 1.339468\n",
      "Batch #10\tAverage Generator Loss: 2064.887329\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10511 (step 10511): 1.290810\n",
      "Batch #10\tAverage Generator Loss: 2107.208667\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10512 (step 10512): 1.642781\n",
      "Batch #10\tAverage Generator Loss: 2420.743921\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10513 (step 10513): 1.479805\n",
      "Batch #10\tAverage Generator Loss: 2248.765381\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10514 (step 10514): 1.710987\n",
      "Batch #10\tAverage Generator Loss: 2399.929016\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10515 (step 10515): 1.502412\n",
      "Batch #10\tAverage Generator Loss: 2099.958405\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10516 (step 10516): 1.657944\n",
      "Batch #10\tAverage Generator Loss: 1811.704761\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10517 (step 10517): 1.378909\n",
      "Batch #10\tAverage Generator Loss: 2207.496283\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10518 (step 10518): 1.325210\n",
      "Batch #10\tAverage Generator Loss: 2143.128186\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10519 (step 10519): 1.665070\n",
      "Batch #10\tAverage Generator Loss: 2250.567529\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10520 (step 10520): 1.401248\n",
      "Batch #10\tAverage Generator Loss: 2052.484467\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10521 (step 10521): 1.704770\n",
      "Batch #10\tAverage Generator Loss: 2190.990430\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10522 (step 10522): 1.438318\n",
      "Batch #10\tAverage Generator Loss: 2077.069421\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10523 (step 10523): 1.287333\n",
      "Batch #10\tAverage Generator Loss: 2075.314014\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10524 (step 10524): 2.129922\n",
      "Batch #10\tAverage Generator Loss: 2355.541223\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10525 (step 10525): 1.367547\n",
      "Batch #10\tAverage Generator Loss: 2053.979993\tAverage Discriminator Loss: 0.220787\n",
      "\n",
      "Train time for epoch #10526 (step 10526): 1.712190\n",
      "Batch #10\tAverage Generator Loss: 2130.654980\tAverage Discriminator Loss: 0.012384\n",
      "\n",
      "Train time for epoch #10527 (step 10527): 1.283227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 1718.641418\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10528 (step 10528): 1.289855\n",
      "Batch #10\tAverage Generator Loss: 1664.244055\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10529 (step 10529): 1.702502\n",
      "Batch #10\tAverage Generator Loss: 2009.330151\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10530 (step 10530): 1.345265\n",
      "Batch #10\tAverage Generator Loss: 1938.825995\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10531 (step 10531): 1.697514\n",
      "Batch #10\tAverage Generator Loss: 1658.641376\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10532 (step 10532): 1.346157\n",
      "Batch #10\tAverage Generator Loss: 1950.929407\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10533 (step 10533): 1.319635\n",
      "Batch #10\tAverage Generator Loss: 1605.519812\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10534 (step 10534): 1.585485\n",
      "Batch #10\tAverage Generator Loss: 1656.139581\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10535 (step 10535): 1.291425\n",
      "Batch #10\tAverage Generator Loss: 1900.453223\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10536 (step 10536): 1.639139\n",
      "Batch #10\tAverage Generator Loss: 1770.461768\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #10537 (step 10537): 1.286081\n",
      "Batch #10\tAverage Generator Loss: 1966.099243\tAverage Discriminator Loss: 0.191211\n",
      "\n",
      "Train time for epoch #10538 (step 10538): 1.733039\n",
      "Batch #10\tAverage Generator Loss: 1817.976355\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10539 (step 10539): 1.325944\n",
      "Batch #10\tAverage Generator Loss: 1656.728503\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10540 (step 10540): 1.298747\n",
      "Batch #10\tAverage Generator Loss: 1870.345557\tAverage Discriminator Loss: 0.001030\n",
      "\n",
      "Train time for epoch #10541 (step 10541): 1.635872\n",
      "Batch #10\tAverage Generator Loss: 1913.890631\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10542 (step 10542): 1.380186\n",
      "Batch #10\tAverage Generator Loss: 2038.311731\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10543 (step 10543): 1.629961\n",
      "Batch #10\tAverage Generator Loss: 1701.119354\tAverage Discriminator Loss: 0.078664\n",
      "\n",
      "Train time for epoch #10544 (step 10544): 1.293175\n",
      "Batch #10\tAverage Generator Loss: 2030.268176\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10545 (step 10545): 1.293249\n",
      "Batch #10\tAverage Generator Loss: 1857.109521\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10546 (step 10546): 1.706582\n",
      "Batch #10\tAverage Generator Loss: 1861.957263\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10547 (step 10547): 1.233380\n",
      "Batch #10\tAverage Generator Loss: 1769.058118\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10548 (step 10548): 1.672011\n",
      "Batch #10\tAverage Generator Loss: 1460.110287\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10549 (step 10549): 1.396432\n",
      "Batch #10\tAverage Generator Loss: 1765.216772\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10550 (step 10550): 1.350235\n",
      "Batch #10\tAverage Generator Loss: 1523.056934\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10551 (step 10551): 1.741454\n",
      "Batch #10\tAverage Generator Loss: 1545.688495\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10552 (step 10552): 1.296455\n",
      "Batch #10\tAverage Generator Loss: 1572.208124\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10553 (step 10553): 1.651774\n",
      "Batch #10\tAverage Generator Loss: 1886.426917\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10554 (step 10554): 1.357785\n",
      "Batch #10\tAverage Generator Loss: 1745.393921\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10555 (step 10555): 1.720204\n",
      "Batch #10\tAverage Generator Loss: 1791.354285\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10556 (step 10556): 1.372779\n",
      "Batch #10\tAverage Generator Loss: 1714.880328\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10557 (step 10557): 1.330947\n",
      "Batch #10\tAverage Generator Loss: 1815.012885\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10558 (step 10558): 1.766312\n",
      "Batch #10\tAverage Generator Loss: 1773.754932\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10559 (step 10559): 1.288566\n",
      "Batch #10\tAverage Generator Loss: 1689.832288\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10560 (step 10560): 1.722178\n",
      "Batch #10\tAverage Generator Loss: 1533.387158\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10561 (step 10561): 1.393042\n",
      "Batch #10\tAverage Generator Loss: 1908.319434\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10562 (step 10562): 1.366426\n",
      "Batch #10\tAverage Generator Loss: 1977.319031\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10563 (step 10563): 1.702020\n",
      "Batch #10\tAverage Generator Loss: 1840.248877\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10564 (step 10564): 1.386507\n",
      "Batch #10\tAverage Generator Loss: 1653.463635\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10565 (step 10565): 1.626749\n",
      "Batch #10\tAverage Generator Loss: 1668.114709\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10566 (step 10566): 1.325502\n",
      "Batch #10\tAverage Generator Loss: 1843.873328\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10567 (step 10567): 1.336980\n",
      "Batch #10\tAverage Generator Loss: 1796.771240\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10568 (step 10568): 1.757887\n",
      "Batch #10\tAverage Generator Loss: 1727.693506\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10569 (step 10569): 1.328980\n",
      "Batch #10\tAverage Generator Loss: 1874.663416\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10570 (step 10570): 1.660651\n",
      "Batch #10\tAverage Generator Loss: 1688.528741\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10571 (step 10571): 1.389240\n",
      "Batch #10\tAverage Generator Loss: 1603.633813\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10572 (step 10572): 1.683274\n",
      "Batch #10\tAverage Generator Loss: 1703.939612\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10573 (step 10573): 1.409137\n",
      "Batch #10\tAverage Generator Loss: 1785.583618\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10574 (step 10574): 1.392065\n",
      "Batch #10\tAverage Generator Loss: 1650.145471\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10575 (step 10575): 1.592102\n",
      "Batch #10\tAverage Generator Loss: 1589.058948\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10576 (step 10576): 1.329555\n",
      "Batch #10\tAverage Generator Loss: 1886.216748\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10577 (step 10577): 1.665394\n",
      "Batch #10\tAverage Generator Loss: 1745.429419\tAverage Discriminator Loss: 0.335612\n",
      "\n",
      "Train time for epoch #10578 (step 10578): 1.406256\n",
      "Batch #10\tAverage Generator Loss: 1332.807397\tAverage Discriminator Loss: 0.000041\n",
      "\n",
      "Train time for epoch #10579 (step 10579): 1.353945\n",
      "Batch #10\tAverage Generator Loss: 1433.308368\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10580 (step 10580): 1.683123\n",
      "Batch #10\tAverage Generator Loss: 1441.758630\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10581 (step 10581): 1.303344\n",
      "Batch #10\tAverage Generator Loss: 1381.394238\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10582 (step 10582): 1.680877\n",
      "Batch #10\tAverage Generator Loss: 1230.511359\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10583 (step 10583): 1.485132\n",
      "Batch #10\tAverage Generator Loss: 1305.878998\tAverage Discriminator Loss: 0.031236\n",
      "\n",
      "Train time for epoch #10584 (step 10584): 1.600152\n",
      "Batch #10\tAverage Generator Loss: 1428.787506\tAverage Discriminator Loss: 0.008668\n",
      "\n",
      "Train time for epoch #10585 (step 10585): 1.731267\n",
      "Batch #10\tAverage Generator Loss: 1355.653302\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #10586 (step 10586): 1.292023\n",
      "Batch #10\tAverage Generator Loss: 1566.399792\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #10587 (step 10587): 1.662921\n",
      "Batch #10\tAverage Generator Loss: 1505.798920\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10588 (step 10588): 1.308325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 1420.240771\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #10589 (step 10589): 1.707788\n",
      "Batch #10\tAverage Generator Loss: 1411.415356\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10590 (step 10590): 1.441318\n",
      "Batch #10\tAverage Generator Loss: 1651.923822\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10591 (step 10591): 1.396481\n",
      "Batch #10\tAverage Generator Loss: 1433.557599\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10592 (step 10592): 1.683061\n",
      "Batch #10\tAverage Generator Loss: 1531.121918\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10593 (step 10593): 1.347282\n",
      "Batch #10\tAverage Generator Loss: 1607.197607\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10594 (step 10594): 1.773214\n",
      "Batch #10\tAverage Generator Loss: 1479.615466\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10595 (step 10595): 1.308789\n",
      "Batch #10\tAverage Generator Loss: 1342.255103\tAverage Discriminator Loss: 0.000204\n",
      "\n",
      "Train time for epoch #10596 (step 10596): 1.286043\n",
      "Batch #10\tAverage Generator Loss: 1474.049371\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10597 (step 10597): 1.839380\n",
      "Batch #10\tAverage Generator Loss: 1770.967493\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #10598 (step 10598): 1.442501\n",
      "Batch #10\tAverage Generator Loss: 1497.273480\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10599 (step 10599): 1.650446\n",
      "Batch #10\tAverage Generator Loss: 1631.862842\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10600 (step 10600): 1.284957\n",
      "Batch #10\tAverage Generator Loss: 1657.049878\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10601 (step 10601): 1.653757\n",
      "Batch #10\tAverage Generator Loss: 1684.001575\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10602 (step 10602): 1.363409\n",
      "Batch #10\tAverage Generator Loss: 1665.478796\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10603 (step 10603): 1.293005\n",
      "Batch #10\tAverage Generator Loss: 1550.134399\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10604 (step 10604): 1.657497\n",
      "Batch #10\tAverage Generator Loss: 1568.206805\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10605 (step 10605): 1.342312\n",
      "Batch #10\tAverage Generator Loss: 1527.731647\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10606 (step 10606): 1.682818\n",
      "Batch #10\tAverage Generator Loss: 1299.841132\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10607 (step 10607): 1.393425\n",
      "Batch #10\tAverage Generator Loss: 1466.748499\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10608 (step 10608): 1.343888\n",
      "Batch #10\tAverage Generator Loss: 1525.206152\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10609 (step 10609): 1.687513\n",
      "Batch #10\tAverage Generator Loss: 1607.960266\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10610 (step 10610): 1.415667\n",
      "Batch #10\tAverage Generator Loss: 1621.793713\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10611 (step 10611): 1.739280\n",
      "Batch #10\tAverage Generator Loss: 1546.162933\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10612 (step 10612): 1.279530\n",
      "Batch #10\tAverage Generator Loss: 1561.993030\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10613 (step 10613): 1.442005\n",
      "Batch #10\tAverage Generator Loss: 1832.214008\tAverage Discriminator Loss: 0.011022\n",
      "\n",
      "Train time for epoch #10614 (step 10614): 1.790688\n",
      "Batch #10\tAverage Generator Loss: 1794.085840\tAverage Discriminator Loss: 0.000114\n",
      "\n",
      "Train time for epoch #10615 (step 10615): 1.283358\n",
      "Batch #10\tAverage Generator Loss: 1743.038660\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10616 (step 10616): 1.689107\n",
      "Batch #10\tAverage Generator Loss: 1837.752136\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10617 (step 10617): 1.296183\n",
      "Batch #10\tAverage Generator Loss: 1653.043622\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10618 (step 10618): 1.351987\n",
      "Batch #10\tAverage Generator Loss: 1708.761426\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10619 (step 10619): 1.770065\n",
      "Batch #10\tAverage Generator Loss: 1933.199744\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10620 (step 10620): 1.289661\n",
      "Batch #10\tAverage Generator Loss: 1745.277515\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10621 (step 10621): 1.629959\n",
      "Batch #10\tAverage Generator Loss: 1697.428784\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10622 (step 10622): 1.343351\n",
      "Batch #10\tAverage Generator Loss: 1791.496387\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10623 (step 10623): 1.331856\n",
      "Batch #10\tAverage Generator Loss: 1659.691760\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10624 (step 10624): 1.721100\n",
      "Batch #10\tAverage Generator Loss: 1722.728821\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10625 (step 10625): 1.289377\n",
      "Batch #10\tAverage Generator Loss: 1686.299866\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10626 (step 10626): 1.698294\n",
      "Batch #10\tAverage Generator Loss: 1801.274683\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10627 (step 10627): 1.406373\n",
      "Batch #10\tAverage Generator Loss: 1695.392334\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10628 (step 10628): 1.778618\n",
      "Batch #10\tAverage Generator Loss: 1666.313922\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10629 (step 10629): 1.550845\n",
      "Batch #10\tAverage Generator Loss: 1745.704968\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10630 (step 10630): 1.427866\n",
      "Batch #10\tAverage Generator Loss: 1802.918567\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10631 (step 10631): 1.705542\n",
      "Batch #10\tAverage Generator Loss: 1937.311255\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10632 (step 10632): 1.293276\n",
      "Batch #10\tAverage Generator Loss: 1616.376086\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10633 (step 10633): 1.703763\n",
      "Batch #10\tAverage Generator Loss: 1939.300897\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10634 (step 10634): 1.374781\n",
      "Batch #10\tAverage Generator Loss: 1733.891577\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10635 (step 10635): 1.326046\n",
      "Batch #10\tAverage Generator Loss: 1716.098438\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10636 (step 10636): 1.749606\n",
      "Batch #10\tAverage Generator Loss: 1849.671838\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10637 (step 10637): 1.420194\n",
      "Batch #10\tAverage Generator Loss: 1941.866089\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10638 (step 10638): 1.773574\n",
      "Batch #10\tAverage Generator Loss: 1989.666174\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10639 (step 10639): 1.296235\n",
      "Batch #10\tAverage Generator Loss: 1763.593921\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10640 (step 10640): 1.753722\n",
      "Batch #10\tAverage Generator Loss: 1916.145837\tAverage Discriminator Loss: 0.000166\n",
      "\n",
      "Train time for epoch #10641 (step 10641): 1.331682\n",
      "Batch #10\tAverage Generator Loss: 1953.583105\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10642 (step 10642): 1.346238\n",
      "Batch #10\tAverage Generator Loss: 1750.283423\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10643 (step 10643): 1.665346\n",
      "Batch #10\tAverage Generator Loss: 1659.435388\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10644 (step 10644): 1.290119\n",
      "Batch #10\tAverage Generator Loss: 1955.323645\tAverage Discriminator Loss: 0.000996\n",
      "\n",
      "Train time for epoch #10645 (step 10645): 1.902146\n",
      "Batch #10\tAverage Generator Loss: 1982.962183\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10646 (step 10646): 1.295021\n",
      "Batch #10\tAverage Generator Loss: 2006.839990\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #10647 (step 10647): 1.431557\n",
      "Batch #10\tAverage Generator Loss: 2058.286499\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10648 (step 10648): 1.738406\n",
      "Batch #10\tAverage Generator Loss: 1829.638928\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #10649 (step 10649): 1.336621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 1808.770422\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #10650 (step 10650): 1.758936\n",
      "Batch #10\tAverage Generator Loss: 1892.597083\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10651 (step 10651): 1.348861\n",
      "Batch #10\tAverage Generator Loss: 2027.239819\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #10652 (step 10652): 1.304207\n",
      "Batch #10\tAverage Generator Loss: 1875.841980\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10653 (step 10653): 1.637766\n",
      "Batch #10\tAverage Generator Loss: 2000.414948\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10654 (step 10654): 1.306195\n",
      "Batch #10\tAverage Generator Loss: 1835.471307\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10655 (step 10655): 1.643977\n",
      "Batch #10\tAverage Generator Loss: 1716.939961\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10656 (step 10656): 1.345694\n",
      "Batch #10\tAverage Generator Loss: 1801.472455\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10657 (step 10657): 1.689906\n",
      "Batch #10\tAverage Generator Loss: 1736.756482\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10658 (step 10658): 1.338133\n",
      "Batch #10\tAverage Generator Loss: 1733.733997\tAverage Discriminator Loss: 0.000237\n",
      "\n",
      "Train time for epoch #10659 (step 10659): 1.349767\n",
      "Batch #10\tAverage Generator Loss: 1725.976135\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #10660 (step 10660): 1.646279\n",
      "Batch #10\tAverage Generator Loss: 1779.433649\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #10661 (step 10661): 1.377810\n",
      "Batch #10\tAverage Generator Loss: 1554.654913\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #10662 (step 10662): 1.748645\n",
      "Batch #10\tAverage Generator Loss: 1769.758643\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #10663 (step 10663): 1.393170\n",
      "Batch #10\tAverage Generator Loss: 1615.930505\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #10664 (step 10664): 1.334754\n",
      "Batch #10\tAverage Generator Loss: 1842.895825\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #10665 (step 10665): 1.727319\n",
      "Batch #10\tAverage Generator Loss: 1667.373938\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10666 (step 10666): 1.348669\n",
      "Batch #10\tAverage Generator Loss: 1929.205566\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #10667 (step 10667): 1.702104\n",
      "Batch #10\tAverage Generator Loss: 1973.578442\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #10668 (step 10668): 1.291282\n",
      "Batch #10\tAverage Generator Loss: 1865.370239\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #10669 (step 10669): 1.342622\n",
      "Batch #10\tAverage Generator Loss: 2045.552417\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #10670 (step 10670): 1.697573\n",
      "Batch #10\tAverage Generator Loss: 1827.521667\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #10671 (step 10671): 1.335251\n",
      "Batch #10\tAverage Generator Loss: 1662.960492\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #10672 (step 10672): 1.643036\n",
      "Batch #10\tAverage Generator Loss: 1378.690546\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10673 (step 10673): 1.365863\n",
      "Batch #10\tAverage Generator Loss: 1935.227380\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #10674 (step 10674): 1.714721\n",
      "Batch #10\tAverage Generator Loss: 1796.690332\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10675 (step 10675): 1.348533\n",
      "Batch #10\tAverage Generator Loss: 2012.179846\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10676 (step 10676): 1.341924\n",
      "Batch #10\tAverage Generator Loss: 1982.811316\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10677 (step 10677): 1.646878\n",
      "Batch #10\tAverage Generator Loss: 1838.519434\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10678 (step 10678): 1.403315\n",
      "Batch #10\tAverage Generator Loss: 1721.480762\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10679 (step 10679): 1.295188\n",
      "Batch #10\tAverage Generator Loss: 1822.108569\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10680 (step 10680): 1.720741\n",
      "Batch #10\tAverage Generator Loss: 1907.876245\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10681 (step 10681): 1.331383\n",
      "Batch #10\tAverage Generator Loss: 1632.145673\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10682 (step 10682): 1.647215\n",
      "Batch #10\tAverage Generator Loss: 1575.737146\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10683 (step 10683): 1.489635\n",
      "Batch #10\tAverage Generator Loss: 1669.179028\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10684 (step 10684): 1.655930\n",
      "Batch #10\tAverage Generator Loss: 1877.461255\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10685 (step 10685): 1.334768\n",
      "Batch #10\tAverage Generator Loss: 1754.504706\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10686 (step 10686): 1.377928\n",
      "Batch #10\tAverage Generator Loss: 1755.839404\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10687 (step 10687): 1.730272\n",
      "Batch #10\tAverage Generator Loss: 1895.930261\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10688 (step 10688): 1.282464\n",
      "Batch #10\tAverage Generator Loss: 1668.611606\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10689 (step 10689): 1.727864\n",
      "Batch #10\tAverage Generator Loss: 2099.875989\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10690 (step 10690): 1.321001\n",
      "Batch #10\tAverage Generator Loss: 1827.482269\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10691 (step 10691): 1.287735\n",
      "Batch #10\tAverage Generator Loss: 2023.024011\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10692 (step 10692): 1.647242\n",
      "Batch #10\tAverage Generator Loss: 1825.928491\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10693 (step 10693): 1.334349\n",
      "Batch #10\tAverage Generator Loss: 2070.457080\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10694 (step 10694): 1.742736\n",
      "Batch #10\tAverage Generator Loss: 2099.233179\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10695 (step 10695): 1.290497\n",
      "Batch #10\tAverage Generator Loss: 1897.986719\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10696 (step 10696): 1.365885\n",
      "Batch #10\tAverage Generator Loss: 1850.109906\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10697 (step 10697): 1.659741\n",
      "Batch #10\tAverage Generator Loss: 1520.826825\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10698 (step 10698): 1.390662\n",
      "Batch #10\tAverage Generator Loss: 1941.329517\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10699 (step 10699): 1.712167\n",
      "Batch #10\tAverage Generator Loss: 1845.085132\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10700 (step 10700): 1.347128\n",
      "Batch #10\tAverage Generator Loss: 1907.421716\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10701 (step 10701): 1.753905\n",
      "Batch #10\tAverage Generator Loss: 2009.123450\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10702 (step 10702): 1.288101\n",
      "Batch #10\tAverage Generator Loss: 1884.689929\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10703 (step 10703): 1.343954\n",
      "Batch #10\tAverage Generator Loss: 1608.277374\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10704 (step 10704): 1.632571\n",
      "Batch #10\tAverage Generator Loss: 1915.996997\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10705 (step 10705): 1.319978\n",
      "Batch #10\tAverage Generator Loss: 1790.493689\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10706 (step 10706): 1.622284\n",
      "Batch #10\tAverage Generator Loss: 2191.452539\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10707 (step 10707): 1.296884\n",
      "Batch #10\tAverage Generator Loss: 1799.786755\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10708 (step 10708): 1.340492\n",
      "Batch #10\tAverage Generator Loss: 1850.151746\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10709 (step 10709): 1.705051\n",
      "Batch #10\tAverage Generator Loss: 1746.548126\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10710 (step 10710): 1.280484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 1979.579688\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10711 (step 10711): 1.723581\n",
      "Batch #10\tAverage Generator Loss: 1789.216431\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10712 (step 10712): 1.547751\n",
      "Batch #10\tAverage Generator Loss: 1957.359607\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10713 (step 10713): 1.283247\n",
      "Batch #10\tAverage Generator Loss: 1594.858020\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10714 (step 10714): 1.760725\n",
      "Batch #10\tAverage Generator Loss: 1793.037140\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10715 (step 10715): 1.438366\n",
      "Batch #10\tAverage Generator Loss: 1640.413770\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10716 (step 10716): 1.670616\n",
      "Batch #10\tAverage Generator Loss: 1736.966101\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10717 (step 10717): 1.449501\n",
      "Batch #10\tAverage Generator Loss: 1728.274866\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10718 (step 10718): 1.288154\n",
      "Batch #10\tAverage Generator Loss: 1866.115186\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10719 (step 10719): 1.709888\n",
      "Batch #10\tAverage Generator Loss: 1790.455988\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10720 (step 10720): 1.292728\n",
      "Batch #10\tAverage Generator Loss: 1661.213501\tAverage Discriminator Loss: 0.010991\n",
      "\n",
      "Train time for epoch #10721 (step 10721): 1.696665\n",
      "Batch #10\tAverage Generator Loss: 1686.973694\tAverage Discriminator Loss: 0.003865\n",
      "\n",
      "Train time for epoch #10722 (step 10722): 1.298408\n",
      "Batch #10\tAverage Generator Loss: 2054.718921\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10723 (step 10723): 1.352569\n",
      "Batch #10\tAverage Generator Loss: 1706.708783\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10724 (step 10724): 1.784236\n",
      "Batch #10\tAverage Generator Loss: 1857.289285\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10725 (step 10725): 1.381205\n",
      "Batch #10\tAverage Generator Loss: 1893.246753\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10726 (step 10726): 1.700056\n",
      "Batch #10\tAverage Generator Loss: 1716.924481\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #10727 (step 10727): 1.385023\n",
      "Batch #10\tAverage Generator Loss: 1930.555261\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10728 (step 10728): 1.304832\n",
      "Batch #10\tAverage Generator Loss: 1878.197906\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10729 (step 10729): 1.654484\n",
      "Batch #10\tAverage Generator Loss: 1742.624725\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10730 (step 10730): 1.289456\n",
      "Batch #10\tAverage Generator Loss: 1920.277527\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10731 (step 10731): 1.648070\n",
      "Batch #10\tAverage Generator Loss: 1753.405286\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10732 (step 10732): 1.299360\n",
      "Batch #10\tAverage Generator Loss: 1746.297925\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10733 (step 10733): 1.695582\n",
      "Batch #10\tAverage Generator Loss: 1582.020691\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #10734 (step 10734): 1.336711\n",
      "Batch #10\tAverage Generator Loss: 1828.903162\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10735 (step 10735): 1.251401\n",
      "Batch #10\tAverage Generator Loss: 1847.330560\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10736 (step 10736): 1.623650\n",
      "Batch #10\tAverage Generator Loss: 1850.934875\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10737 (step 10737): 1.353066\n",
      "Batch #10\tAverage Generator Loss: 1966.452698\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10738 (step 10738): 1.699101\n",
      "Batch #10\tAverage Generator Loss: 1773.055994\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10739 (step 10739): 1.277268\n",
      "Batch #10\tAverage Generator Loss: 1900.892395\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10740 (step 10740): 1.690763\n",
      "Batch #10\tAverage Generator Loss: 1800.460571\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10741 (step 10741): 1.289860\n",
      "Batch #10\tAverage Generator Loss: 1949.609045\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10742 (step 10742): 1.434752\n",
      "Batch #10\tAverage Generator Loss: 1927.586749\tAverage Discriminator Loss: 0.000701\n",
      "\n",
      "Train time for epoch #10743 (step 10743): 1.682673\n",
      "Batch #10\tAverage Generator Loss: 1576.468353\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10744 (step 10744): 1.292575\n",
      "Batch #10\tAverage Generator Loss: 1789.875769\tAverage Discriminator Loss: 0.000680\n",
      "\n",
      "Train time for epoch #10745 (step 10745): 1.648926\n",
      "Batch #10\tAverage Generator Loss: 1849.406055\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10746 (step 10746): 1.290322\n",
      "Batch #10\tAverage Generator Loss: 1661.267413\tAverage Discriminator Loss: 0.011057\n",
      "\n",
      "Train time for epoch #10747 (step 10747): 1.330534\n",
      "Batch #10\tAverage Generator Loss: 1821.717908\tAverage Discriminator Loss: 0.015014\n",
      "\n",
      "Train time for epoch #10748 (step 10748): 1.706294\n",
      "Batch #10\tAverage Generator Loss: 2086.389465\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10749 (step 10749): 1.332981\n",
      "Batch #10\tAverage Generator Loss: 1515.828131\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10750 (step 10750): 1.334579\n",
      "Batch #10\tAverage Generator Loss: 1824.788806\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10751 (step 10751): 1.668487\n",
      "Batch #10\tAverage Generator Loss: 1550.700433\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10752 (step 10752): 1.479842\n",
      "Batch #10\tAverage Generator Loss: 1612.465704\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10753 (step 10753): 1.648801\n",
      "Batch #10\tAverage Generator Loss: 1511.785986\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10754 (step 10754): 1.295202\n",
      "Batch #10\tAverage Generator Loss: 1856.680591\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10755 (step 10755): 1.404231\n",
      "Batch #10\tAverage Generator Loss: 1867.662085\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10756 (step 10756): 1.663294\n",
      "Batch #10\tAverage Generator Loss: 2003.807751\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10757 (step 10757): 1.382644\n",
      "Batch #10\tAverage Generator Loss: 1551.903595\tAverage Discriminator Loss: 0.398434\n",
      "\n",
      "Train time for epoch #10758 (step 10758): 1.802835\n",
      "Batch #10\tAverage Generator Loss: 1398.112952\tAverage Discriminator Loss: 0.002095\n",
      "\n",
      "Train time for epoch #10759 (step 10759): 1.280681\n",
      "Batch #10\tAverage Generator Loss: 1317.502277\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10760 (step 10760): 1.391051\n",
      "Batch #10\tAverage Generator Loss: 1451.853864\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10761 (step 10761): 1.730661\n",
      "Batch #10\tAverage Generator Loss: 1412.244202\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10762 (step 10762): 1.287662\n",
      "Batch #10\tAverage Generator Loss: 1615.509100\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10763 (step 10763): 1.658711\n",
      "Batch #10\tAverage Generator Loss: 1643.843066\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10764 (step 10764): 1.298342\n",
      "Batch #10\tAverage Generator Loss: 1427.671173\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10765 (step 10765): 1.747258\n",
      "Batch #10\tAverage Generator Loss: 1411.968811\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10766 (step 10766): 1.290337\n",
      "Batch #10\tAverage Generator Loss: 1424.274573\tAverage Discriminator Loss: 0.000025\n",
      "\n",
      "Train time for epoch #10767 (step 10767): 1.286236\n",
      "Batch #10\tAverage Generator Loss: 1633.720789\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10768 (step 10768): 1.667742\n",
      "Batch #10\tAverage Generator Loss: 1394.313019\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10769 (step 10769): 1.359578\n",
      "Batch #10\tAverage Generator Loss: 1600.355927\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10770 (step 10770): 1.701809\n",
      "Batch #10\tAverage Generator Loss: 1438.380109\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10771 (step 10771): 1.361763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 1355.842401\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10772 (step 10772): 1.447765\n",
      "Batch #10\tAverage Generator Loss: 1512.735120\tAverage Discriminator Loss: 0.000358\n",
      "\n",
      "Train time for epoch #10773 (step 10773): 1.590976\n",
      "Batch #10\tAverage Generator Loss: 1319.653131\tAverage Discriminator Loss: 0.040188\n",
      "\n",
      "Train time for epoch #10774 (step 10774): 1.247338\n",
      "Batch #10\tAverage Generator Loss: 1872.081543\tAverage Discriminator Loss: 0.026209\n",
      "\n",
      "Train time for epoch #10775 (step 10775): 1.645805\n",
      "Batch #10\tAverage Generator Loss: 1847.134607\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10776 (step 10776): 1.357841\n",
      "Batch #10\tAverage Generator Loss: 1653.848480\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10777 (step 10777): 1.397011\n",
      "Batch #10\tAverage Generator Loss: 1604.340869\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10778 (step 10778): 1.773361\n",
      "Batch #10\tAverage Generator Loss: 1638.025616\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10779 (step 10779): 1.336242\n",
      "Batch #10\tAverage Generator Loss: 1759.187622\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10780 (step 10780): 1.732354\n",
      "Batch #10\tAverage Generator Loss: 1658.933929\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10781 (step 10781): 1.334121\n",
      "Batch #10\tAverage Generator Loss: 1814.417187\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10782 (step 10782): 1.686560\n",
      "Batch #10\tAverage Generator Loss: 1655.840979\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10783 (step 10783): 1.418133\n",
      "Batch #10\tAverage Generator Loss: 1614.379980\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10784 (step 10784): 1.317073\n",
      "Batch #10\tAverage Generator Loss: 1663.626648\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10785 (step 10785): 1.691391\n",
      "Batch #10\tAverage Generator Loss: 1792.282605\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10786 (step 10786): 1.354825\n",
      "Batch #10\tAverage Generator Loss: 1563.495612\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10787 (step 10787): 1.760848\n",
      "Batch #10\tAverage Generator Loss: 1418.624701\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10788 (step 10788): 1.382063\n",
      "Batch #10\tAverage Generator Loss: 1557.975494\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10789 (step 10789): 1.431628\n",
      "Batch #10\tAverage Generator Loss: 1884.993512\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10790 (step 10790): 1.693286\n",
      "Batch #10\tAverage Generator Loss: 1592.216443\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10791 (step 10791): 1.354154\n",
      "Batch #10\tAverage Generator Loss: 1767.994141\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10792 (step 10792): 1.666214\n",
      "Batch #10\tAverage Generator Loss: 1995.995996\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10793 (step 10793): 1.447102\n",
      "Batch #10\tAverage Generator Loss: 1671.207288\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10794 (step 10794): 1.443183\n",
      "Batch #10\tAverage Generator Loss: 1675.553418\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10795 (step 10795): 1.705647\n",
      "Batch #10\tAverage Generator Loss: 1987.506201\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10796 (step 10796): 1.293198\n",
      "Batch #10\tAverage Generator Loss: 1798.771680\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10797 (step 10797): 1.846656\n",
      "Batch #10\tAverage Generator Loss: 1657.384644\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10798 (step 10798): 1.604286\n",
      "Batch #10\tAverage Generator Loss: 1878.807300\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10799 (step 10799): 1.663408\n",
      "Batch #10\tAverage Generator Loss: 1776.603851\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10800 (step 10800): 1.315171\n",
      "Batch #10\tAverage Generator Loss: 1752.759753\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10801 (step 10801): 1.296228\n",
      "Batch #10\tAverage Generator Loss: 1711.056042\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10802 (step 10802): 1.730815\n",
      "Batch #10\tAverage Generator Loss: 1783.974524\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10803 (step 10803): 1.375687\n",
      "Batch #10\tAverage Generator Loss: 1490.915216\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10804 (step 10804): 1.659813\n",
      "Batch #10\tAverage Generator Loss: 1614.624506\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10805 (step 10805): 1.300972\n",
      "Batch #10\tAverage Generator Loss: 1535.281024\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10806 (step 10806): 1.722540\n",
      "Batch #10\tAverage Generator Loss: 1627.223816\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10807 (step 10807): 1.283791\n",
      "Batch #10\tAverage Generator Loss: 1586.829938\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10808 (step 10808): 1.322913\n",
      "Batch #10\tAverage Generator Loss: 1558.440216\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10809 (step 10809): 1.707553\n",
      "Batch #10\tAverage Generator Loss: 1423.806293\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10810 (step 10810): 1.436272\n",
      "Batch #10\tAverage Generator Loss: 1502.103192\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10811 (step 10811): 1.730988\n",
      "Batch #10\tAverage Generator Loss: 1764.059338\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10812 (step 10812): 1.297202\n",
      "Batch #10\tAverage Generator Loss: 1462.852802\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10813 (step 10813): 1.358495\n",
      "Batch #10\tAverage Generator Loss: 1443.903265\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10814 (step 10814): 1.727351\n",
      "Batch #10\tAverage Generator Loss: 1662.863489\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10815 (step 10815): 1.242524\n",
      "Batch #10\tAverage Generator Loss: 1603.117682\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10816 (step 10816): 1.685933\n",
      "Batch #10\tAverage Generator Loss: 1566.424164\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10817 (step 10817): 1.334534\n",
      "Batch #10\tAverage Generator Loss: 1591.189868\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10818 (step 10818): 1.413273\n",
      "Batch #10\tAverage Generator Loss: 1411.238580\tAverage Discriminator Loss: 0.018912\n",
      "\n",
      "Train time for epoch #10819 (step 10819): 1.659119\n",
      "Batch #10\tAverage Generator Loss: 1624.820520\tAverage Discriminator Loss: 0.000635\n",
      "\n",
      "Train time for epoch #10820 (step 10820): 1.307676\n",
      "Batch #10\tAverage Generator Loss: 1735.890881\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #10821 (step 10821): 1.798546\n",
      "Batch #10\tAverage Generator Loss: 1520.089349\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #10822 (step 10822): 1.384896\n",
      "Batch #10\tAverage Generator Loss: 1483.313501\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10823 (step 10823): 1.307447\n",
      "Batch #10\tAverage Generator Loss: 1790.017090\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10824 (step 10824): 1.710943\n",
      "Batch #10\tAverage Generator Loss: 1345.059088\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10825 (step 10825): 1.334404\n",
      "Batch #10\tAverage Generator Loss: 1595.519592\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10826 (step 10826): 1.692344\n",
      "Batch #10\tAverage Generator Loss: 1775.489929\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10827 (step 10827): 1.335073\n",
      "Batch #10\tAverage Generator Loss: 1489.560730\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10828 (step 10828): 1.291553\n",
      "Batch #10\tAverage Generator Loss: 1702.734528\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10829 (step 10829): 1.711640\n",
      "Batch #10\tAverage Generator Loss: 1616.731757\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10830 (step 10830): 1.342669\n",
      "Batch #10\tAverage Generator Loss: 1595.901520\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10831 (step 10831): 1.692221\n",
      "Batch #10\tAverage Generator Loss: 1347.453967\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10832 (step 10832): 1.247968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 1598.990546\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10833 (step 10833): 1.467640\n",
      "Batch #10\tAverage Generator Loss: 1547.830469\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10834 (step 10834): 1.824280\n",
      "Batch #10\tAverage Generator Loss: 1590.178076\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10835 (step 10835): 1.328652\n",
      "Batch #10\tAverage Generator Loss: 1536.376935\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10836 (step 10836): 1.793163\n",
      "Batch #10\tAverage Generator Loss: 1503.543195\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10837 (step 10837): 1.330045\n",
      "Batch #10\tAverage Generator Loss: 1484.653479\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10838 (step 10838): 1.669698\n",
      "Batch #10\tAverage Generator Loss: 1556.059021\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10839 (step 10839): 1.280159\n",
      "Batch #10\tAverage Generator Loss: 1526.778278\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10840 (step 10840): 1.296113\n",
      "Batch #10\tAverage Generator Loss: 1527.133917\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10841 (step 10841): 1.669709\n",
      "Batch #10\tAverage Generator Loss: 1624.766797\tAverage Discriminator Loss: 0.000583\n",
      "\n",
      "Train time for epoch #10842 (step 10842): 1.339092\n",
      "Batch #10\tAverage Generator Loss: 1472.192603\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #10843 (step 10843): 1.810796\n",
      "Batch #10\tAverage Generator Loss: 1601.765637\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10844 (step 10844): 1.351720\n",
      "Batch #10\tAverage Generator Loss: 1833.850195\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10845 (step 10845): 1.404542\n",
      "Batch #10\tAverage Generator Loss: 1421.841882\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #10846 (step 10846): 1.815255\n",
      "Batch #10\tAverage Generator Loss: 1590.006274\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10847 (step 10847): 1.276486\n",
      "Batch #10\tAverage Generator Loss: 1709.688123\tAverage Discriminator Loss: 0.001008\n",
      "\n",
      "Train time for epoch #10848 (step 10848): 1.673323\n",
      "Batch #10\tAverage Generator Loss: 1517.380469\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #10849 (step 10849): 1.493382\n",
      "Batch #10\tAverage Generator Loss: 1662.906213\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #10850 (step 10850): 1.730997\n",
      "Batch #10\tAverage Generator Loss: 1814.774011\tAverage Discriminator Loss: 0.013175\n",
      "\n",
      "Train time for epoch #10851 (step 10851): 1.504138\n",
      "Batch #10\tAverage Generator Loss: 1929.028754\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10852 (step 10852): 1.320503\n",
      "Batch #10\tAverage Generator Loss: 1714.613306\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10853 (step 10853): 1.778721\n",
      "Batch #10\tAverage Generator Loss: 1827.226041\tAverage Discriminator Loss: 0.025870\n",
      "\n",
      "Train time for epoch #10854 (step 10854): 1.387240\n",
      "Batch #10\tAverage Generator Loss: 1674.733301\tAverage Discriminator Loss: 0.000021\n",
      "\n",
      "Train time for epoch #10855 (step 10855): 1.744072\n",
      "Batch #10\tAverage Generator Loss: 1885.411121\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10856 (step 10856): 1.334517\n",
      "Batch #10\tAverage Generator Loss: 1728.825293\tAverage Discriminator Loss: 0.001250\n",
      "\n",
      "Train time for epoch #10857 (step 10857): 1.296205\n",
      "Batch #10\tAverage Generator Loss: 1899.157471\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #10858 (step 10858): 1.683288\n",
      "Batch #10\tAverage Generator Loss: 1990.911761\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10859 (step 10859): 1.476580\n",
      "Batch #10\tAverage Generator Loss: 2004.416449\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #10860 (step 10860): 1.670985\n",
      "Batch #10\tAverage Generator Loss: 1736.020569\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #10861 (step 10861): 1.294625\n",
      "Batch #10\tAverage Generator Loss: 1720.230536\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10862 (step 10862): 1.340661\n",
      "Batch #10\tAverage Generator Loss: 2004.058154\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10863 (step 10863): 1.665055\n",
      "Batch #10\tAverage Generator Loss: 1609.134503\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10864 (step 10864): 1.295565\n",
      "Batch #10\tAverage Generator Loss: 1907.555145\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #10865 (step 10865): 1.669312\n",
      "Batch #10\tAverage Generator Loss: 1612.129358\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #10866 (step 10866): 1.402579\n",
      "Batch #10\tAverage Generator Loss: 2042.697839\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #10867 (step 10867): 1.665845\n",
      "Batch #10\tAverage Generator Loss: 1366.860443\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #10868 (step 10868): 1.403972\n",
      "Batch #10\tAverage Generator Loss: 1803.211536\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #10869 (step 10869): 1.487945\n",
      "Batch #10\tAverage Generator Loss: 2079.378571\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #10870 (step 10870): 1.649715\n",
      "Batch #10\tAverage Generator Loss: 1870.307800\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #10871 (step 10871): 1.305713\n",
      "Batch #10\tAverage Generator Loss: 1997.400122\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10872 (step 10872): 1.372930\n",
      "Batch #10\tAverage Generator Loss: 1811.546948\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #10873 (step 10873): 1.669773\n",
      "Batch #10\tAverage Generator Loss: 1716.969971\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10874 (step 10874): 1.338288\n",
      "Batch #10\tAverage Generator Loss: 1880.065515\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10875 (step 10875): 1.786178\n",
      "Batch #10\tAverage Generator Loss: 1820.199548\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10876 (step 10876): 1.441723\n",
      "Batch #10\tAverage Generator Loss: 1909.437311\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10877 (step 10877): 1.307818\n",
      "Batch #10\tAverage Generator Loss: 2007.737354\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10878 (step 10878): 1.773216\n",
      "Batch #10\tAverage Generator Loss: 1913.167493\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10879 (step 10879): 1.369450\n",
      "Batch #10\tAverage Generator Loss: 2079.181677\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10880 (step 10880): 1.683251\n",
      "Batch #10\tAverage Generator Loss: 2188.748499\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10881 (step 10881): 1.325834\n",
      "Batch #10\tAverage Generator Loss: 2009.995032\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10882 (step 10882): 1.355667\n",
      "Batch #10\tAverage Generator Loss: 1851.148627\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10883 (step 10883): 1.721369\n",
      "Batch #10\tAverage Generator Loss: 2050.665820\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10884 (step 10884): 1.425442\n",
      "Batch #10\tAverage Generator Loss: 2104.061597\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10885 (step 10885): 1.705977\n",
      "Batch #10\tAverage Generator Loss: 2093.430957\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10886 (step 10886): 1.324893\n",
      "Batch #10\tAverage Generator Loss: 1869.826746\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10887 (step 10887): 1.300952\n",
      "Batch #10\tAverage Generator Loss: 1947.467615\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10888 (step 10888): 1.603333\n",
      "Batch #10\tAverage Generator Loss: 2006.768738\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10889 (step 10889): 1.338855\n",
      "Batch #10\tAverage Generator Loss: 1934.146069\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10890 (step 10890): 1.732142\n",
      "Batch #10\tAverage Generator Loss: 2050.869055\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10891 (step 10891): 1.353003\n",
      "Batch #10\tAverage Generator Loss: 1790.399283\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10892 (step 10892): 1.339283\n",
      "Batch #10\tAverage Generator Loss: 1717.606677\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10893 (step 10893): 1.836026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 1887.448437\tAverage Discriminator Loss: 0.000085\n",
      "\n",
      "Train time for epoch #10894 (step 10894): 1.281130\n",
      "Batch #10\tAverage Generator Loss: 1986.354871\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10895 (step 10895): 1.670979\n",
      "Batch #10\tAverage Generator Loss: 2009.655823\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #10896 (step 10896): 1.335021\n",
      "Batch #10\tAverage Generator Loss: 2120.633313\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10897 (step 10897): 1.303906\n",
      "Batch #10\tAverage Generator Loss: 1818.850818\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #10898 (step 10898): 1.800432\n",
      "Batch #10\tAverage Generator Loss: 1932.915506\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #10899 (step 10899): 1.303941\n",
      "Batch #10\tAverage Generator Loss: 1955.432666\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #10900 (step 10900): 1.760695\n",
      "Batch #10\tAverage Generator Loss: 2028.661572\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #10901 (step 10901): 1.344356\n",
      "Batch #10\tAverage Generator Loss: 2064.567371\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10902 (step 10902): 1.677902\n",
      "Batch #10\tAverage Generator Loss: 2021.649365\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10903 (step 10903): 1.340816\n",
      "Batch #10\tAverage Generator Loss: 1958.878320\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10904 (step 10904): 1.280664\n",
      "Batch #10\tAverage Generator Loss: 1934.189722\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10905 (step 10905): 1.744185\n",
      "Batch #10\tAverage Generator Loss: 1815.870697\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10906 (step 10906): 1.277258\n",
      "Batch #10\tAverage Generator Loss: 2026.607239\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10907 (step 10907): 1.410469\n",
      "Batch #10\tAverage Generator Loss: 1785.959790\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10908 (step 10908): 1.680967\n",
      "Batch #10\tAverage Generator Loss: 1907.444836\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10909 (step 10909): 1.333715\n",
      "Batch #10\tAverage Generator Loss: 2064.297107\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10910 (step 10910): 1.730418\n",
      "Batch #10\tAverage Generator Loss: 1899.360303\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10911 (step 10911): 1.300551\n",
      "Batch #10\tAverage Generator Loss: 1871.495581\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10912 (step 10912): 1.751833\n",
      "Batch #10\tAverage Generator Loss: 1857.361292\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10913 (step 10913): 1.336415\n",
      "Batch #10\tAverage Generator Loss: 2050.953003\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10914 (step 10914): 1.289568\n",
      "Batch #10\tAverage Generator Loss: 1804.926514\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10915 (step 10915): 1.756529\n",
      "Batch #10\tAverage Generator Loss: 1805.086414\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10916 (step 10916): 1.287925\n",
      "Batch #10\tAverage Generator Loss: 1654.624200\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10917 (step 10917): 1.723735\n",
      "Batch #10\tAverage Generator Loss: 1644.122961\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10918 (step 10918): 1.391529\n",
      "Batch #10\tAverage Generator Loss: 1909.474664\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10919 (step 10919): 1.317088\n",
      "Batch #10\tAverage Generator Loss: 1984.454688\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10920 (step 10920): 1.753546\n",
      "Batch #10\tAverage Generator Loss: 1796.079626\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10921 (step 10921): 1.292332\n",
      "Batch #10\tAverage Generator Loss: 2132.809058\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10922 (step 10922): 1.331651\n",
      "Batch #10\tAverage Generator Loss: 1982.627234\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #10923 (step 10923): 1.609975\n",
      "Batch #10\tAverage Generator Loss: 1861.763080\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10924 (step 10924): 1.298042\n",
      "Batch #10\tAverage Generator Loss: 1600.319116\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10925 (step 10925): 1.719093\n",
      "Batch #10\tAverage Generator Loss: 1917.485675\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10926 (step 10926): 1.359406\n",
      "Batch #10\tAverage Generator Loss: 2053.319189\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10927 (step 10927): 1.755667\n",
      "Batch #10\tAverage Generator Loss: 1978.409290\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10928 (step 10928): 1.385157\n",
      "Batch #10\tAverage Generator Loss: 1930.883765\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10929 (step 10929): 1.279537\n",
      "Batch #10\tAverage Generator Loss: 1969.149353\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10930 (step 10930): 1.745762\n",
      "Batch #10\tAverage Generator Loss: 1624.545691\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10931 (step 10931): 1.323622\n",
      "Batch #10\tAverage Generator Loss: 1724.684753\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #10932 (step 10932): 1.694484\n",
      "Batch #10\tAverage Generator Loss: 1884.924628\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10933 (step 10933): 1.432844\n",
      "Batch #10\tAverage Generator Loss: 1817.719147\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10934 (step 10934): 1.339134\n",
      "Batch #10\tAverage Generator Loss: 1900.155432\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10935 (step 10935): 1.606647\n",
      "Batch #10\tAverage Generator Loss: 1838.167297\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10936 (step 10936): 1.254998\n",
      "Batch #10\tAverage Generator Loss: 1964.832471\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10937 (step 10937): 1.697766\n",
      "Batch #10\tAverage Generator Loss: 1918.512042\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10938 (step 10938): 1.391983\n",
      "Batch #10\tAverage Generator Loss: 1921.470374\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10939 (step 10939): 1.293576\n",
      "Batch #10\tAverage Generator Loss: 1762.890930\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10940 (step 10940): 1.707134\n",
      "Batch #10\tAverage Generator Loss: 1801.142480\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10941 (step 10941): 1.340753\n",
      "Batch #10\tAverage Generator Loss: 2101.975586\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10942 (step 10942): 1.740112\n",
      "Batch #10\tAverage Generator Loss: 1741.649634\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10943 (step 10943): 1.339725\n",
      "Batch #10\tAverage Generator Loss: 1803.207690\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10944 (step 10944): 1.347681\n",
      "Batch #10\tAverage Generator Loss: 1866.620996\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10945 (step 10945): 1.751716\n",
      "Batch #10\tAverage Generator Loss: 1808.000745\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10946 (step 10946): 1.290340\n",
      "Batch #10\tAverage Generator Loss: 1781.531946\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10947 (step 10947): 1.721588\n",
      "Batch #10\tAverage Generator Loss: 1644.187817\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10948 (step 10948): 1.296294\n",
      "Batch #10\tAverage Generator Loss: 1475.448834\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10949 (step 10949): 1.455644\n",
      "Batch #10\tAverage Generator Loss: 1752.857983\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10950 (step 10950): 1.682815\n",
      "Batch #10\tAverage Generator Loss: 1786.658337\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10951 (step 10951): 1.437996\n",
      "Batch #10\tAverage Generator Loss: 2068.642737\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10952 (step 10952): 1.710218\n",
      "Batch #10\tAverage Generator Loss: 1886.969141\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10953 (step 10953): 1.299399\n",
      "Batch #10\tAverage Generator Loss: 2039.342419\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10954 (step 10954): 1.299030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 1733.127405\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10955 (step 10955): 1.672614\n",
      "Batch #10\tAverage Generator Loss: 1940.182031\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10956 (step 10956): 1.410575\n",
      "Batch #10\tAverage Generator Loss: 2008.013147\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10957 (step 10957): 1.654611\n",
      "Batch #10\tAverage Generator Loss: 1838.935828\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10958 (step 10958): 1.379753\n",
      "Batch #10\tAverage Generator Loss: 1734.651538\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10959 (step 10959): 1.290738\n",
      "Batch #10\tAverage Generator Loss: 1970.687439\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10960 (step 10960): 1.744647\n",
      "Batch #10\tAverage Generator Loss: 2179.939673\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10961 (step 10961): 1.343000\n",
      "Batch #10\tAverage Generator Loss: 1773.985864\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10962 (step 10962): 1.681286\n",
      "Batch #10\tAverage Generator Loss: 2074.414941\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10963 (step 10963): 1.303291\n",
      "Batch #10\tAverage Generator Loss: 1866.604926\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10964 (step 10964): 1.280140\n",
      "Batch #10\tAverage Generator Loss: 1946.251306\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10965 (step 10965): 1.672514\n",
      "Batch #10\tAverage Generator Loss: 1786.141193\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10966 (step 10966): 1.376160\n",
      "Batch #10\tAverage Generator Loss: 1936.287561\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10967 (step 10967): 1.686439\n",
      "Batch #10\tAverage Generator Loss: 1873.322168\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10968 (step 10968): 1.327610\n",
      "Batch #10\tAverage Generator Loss: 1764.149451\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10969 (step 10969): 1.305949\n",
      "Batch #10\tAverage Generator Loss: 2226.044165\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10970 (step 10970): 1.697785\n",
      "Batch #10\tAverage Generator Loss: 2244.586157\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10971 (step 10971): 1.469066\n",
      "Batch #10\tAverage Generator Loss: 1978.846912\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10972 (step 10972): 1.639426\n",
      "Batch #10\tAverage Generator Loss: 1916.238000\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10973 (step 10973): 1.337128\n",
      "Batch #10\tAverage Generator Loss: 1919.394482\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10974 (step 10974): 1.318500\n",
      "Batch #10\tAverage Generator Loss: 2002.602930\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10975 (step 10975): 1.642750\n",
      "Batch #10\tAverage Generator Loss: 2023.685010\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10976 (step 10976): 1.328927\n",
      "Batch #10\tAverage Generator Loss: 1936.965784\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10977 (step 10977): 1.656370\n",
      "Batch #10\tAverage Generator Loss: 1857.287854\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10978 (step 10978): 1.304979\n",
      "Batch #10\tAverage Generator Loss: 1811.344366\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10979 (step 10979): 1.415825\n",
      "Batch #10\tAverage Generator Loss: 1964.306390\tAverage Discriminator Loss: 0.233665\n",
      "\n",
      "Train time for epoch #10980 (step 10980): 1.605956\n",
      "Batch #10\tAverage Generator Loss: 1862.758038\tAverage Discriminator Loss: 0.017997\n",
      "\n",
      "Train time for epoch #10981 (step 10981): 1.389939\n",
      "Batch #10\tAverage Generator Loss: 2569.042230\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10982 (step 10982): 1.640051\n",
      "Batch #10\tAverage Generator Loss: 1873.235217\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10983 (step 10983): 1.300259\n",
      "Batch #10\tAverage Generator Loss: 2376.031616\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10984 (step 10984): 1.806884\n",
      "Batch #10\tAverage Generator Loss: 2267.087219\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10985 (step 10985): 1.336855\n",
      "Batch #10\tAverage Generator Loss: 2050.317285\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10986 (step 10986): 1.372478\n",
      "Batch #10\tAverage Generator Loss: 1877.903824\tAverage Discriminator Loss: 0.056320\n",
      "\n",
      "Train time for epoch #10987 (step 10987): 1.726083\n",
      "Batch #10\tAverage Generator Loss: 2619.844031\tAverage Discriminator Loss: 0.017437\n",
      "\n",
      "Train time for epoch #10988 (step 10988): 1.360339\n",
      "Batch #10\tAverage Generator Loss: 1753.939862\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10989 (step 10989): 1.696444\n",
      "Batch #10\tAverage Generator Loss: 2346.861816\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10990 (step 10990): 1.401984\n",
      "Batch #10\tAverage Generator Loss: 2084.674304\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10991 (step 10991): 1.339620\n",
      "Batch #10\tAverage Generator Loss: 1893.617529\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10992 (step 10992): 1.703728\n",
      "Batch #10\tAverage Generator Loss: 2730.162231\tAverage Discriminator Loss: 0.169593\n",
      "\n",
      "Train time for epoch #10993 (step 10993): 1.295749\n",
      "Batch #10\tAverage Generator Loss: 2536.811169\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #10994 (step 10994): 1.723591\n",
      "Batch #10\tAverage Generator Loss: 2719.170752\tAverage Discriminator Loss: 0.054109\n",
      "\n",
      "Train time for epoch #10995 (step 10995): 1.395771\n",
      "Batch #10\tAverage Generator Loss: 2573.647791\tAverage Discriminator Loss: 0.005169\n",
      "\n",
      "Train time for epoch #10996 (step 10996): 1.709164\n",
      "Batch #10\tAverage Generator Loss: 2552.886145\tAverage Discriminator Loss: 0.012019\n",
      "\n",
      "Train time for epoch #10997 (step 10997): 1.371616\n",
      "Batch #10\tAverage Generator Loss: 2651.575562\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #10998 (step 10998): 1.477897\n",
      "Batch #10\tAverage Generator Loss: 2802.048132\tAverage Discriminator Loss: 0.000466\n",
      "\n",
      "Train time for epoch #10999 (step 10999): 1.681410\n",
      "Batch #10\tAverage Generator Loss: 2824.081287\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11000 (step 11000): 1.341356\n",
      "Batch #10\tAverage Generator Loss: 2775.291443\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11001 (step 11001): 1.773289\n",
      "Batch #10\tAverage Generator Loss: 2532.785144\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11002 (step 11002): 1.291235\n",
      "Batch #10\tAverage Generator Loss: 2808.719434\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11003 (step 11003): 1.290563\n",
      "Batch #10\tAverage Generator Loss: 2491.274609\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11004 (step 11004): 1.680505\n",
      "Batch #10\tAverage Generator Loss: 2590.225464\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11005 (step 11005): 1.330302\n",
      "Batch #10\tAverage Generator Loss: 2560.945349\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11006 (step 11006): 1.651599\n",
      "Batch #10\tAverage Generator Loss: 2980.366394\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11007 (step 11007): 1.338604\n",
      "Batch #10\tAverage Generator Loss: 2688.103552\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11008 (step 11008): 1.314409\n",
      "Batch #10\tAverage Generator Loss: 2701.411145\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11009 (step 11009): 1.694947\n",
      "Batch #10\tAverage Generator Loss: 2963.126733\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11010 (step 11010): 1.341304\n",
      "Batch #10\tAverage Generator Loss: 2824.767273\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11011 (step 11011): 1.643011\n",
      "Batch #10\tAverage Generator Loss: 2464.172583\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11012 (step 11012): 1.440552\n",
      "Batch #10\tAverage Generator Loss: 2992.698926\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11013 (step 11013): 1.342777\n",
      "Batch #10\tAverage Generator Loss: 2507.011719\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11014 (step 11014): 1.779360\n",
      "Batch #10\tAverage Generator Loss: 2786.787134\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11015 (step 11015): 1.348381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2654.147729\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11016 (step 11016): 1.744019\n",
      "Batch #10\tAverage Generator Loss: 2657.662109\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11017 (step 11017): 1.300927\n",
      "Batch #10\tAverage Generator Loss: 2612.943958\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11018 (step 11018): 1.290267\n",
      "Batch #10\tAverage Generator Loss: 2527.908203\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11019 (step 11019): 1.728194\n",
      "Batch #10\tAverage Generator Loss: 3392.994653\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11020 (step 11020): 1.416649\n",
      "Batch #10\tAverage Generator Loss: 3110.673279\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11021 (step 11021): 1.704993\n",
      "Batch #10\tAverage Generator Loss: 2609.034644\tAverage Discriminator Loss: 0.019462\n",
      "\n",
      "Train time for epoch #11022 (step 11022): 1.324784\n",
      "Batch #10\tAverage Generator Loss: 2420.384106\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11023 (step 11023): 1.292358\n",
      "Batch #10\tAverage Generator Loss: 2680.450269\tAverage Discriminator Loss: 0.000097\n",
      "\n",
      "Train time for epoch #11024 (step 11024): 1.746758\n",
      "Batch #10\tAverage Generator Loss: 2496.338953\tAverage Discriminator Loss: 0.000022\n",
      "\n",
      "Train time for epoch #11025 (step 11025): 1.294445\n",
      "Batch #10\tAverage Generator Loss: 2740.084656\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #11026 (step 11026): 1.762220\n",
      "Batch #10\tAverage Generator Loss: 2431.560858\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #11027 (step 11027): 1.336199\n",
      "Batch #10\tAverage Generator Loss: 2373.192126\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #11028 (step 11028): 1.457072\n",
      "Batch #10\tAverage Generator Loss: 2119.437830\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #11029 (step 11029): 1.673549\n",
      "Batch #10\tAverage Generator Loss: 2771.380444\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #11030 (step 11030): 1.287384\n",
      "Batch #10\tAverage Generator Loss: 2601.990771\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #11031 (step 11031): 1.832430\n",
      "Batch #10\tAverage Generator Loss: 2631.837354\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #11032 (step 11032): 1.381811\n",
      "Batch #10\tAverage Generator Loss: 2700.393933\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #11033 (step 11033): 1.371809\n",
      "Batch #10\tAverage Generator Loss: 2671.274939\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #11034 (step 11034): 1.853101\n",
      "Batch #10\tAverage Generator Loss: 2793.966144\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11035 (step 11035): 1.442493\n",
      "Batch #10\tAverage Generator Loss: 2040.400940\tAverage Discriminator Loss: 0.333387\n",
      "\n",
      "Train time for epoch #11036 (step 11036): 1.722166\n",
      "Batch #10\tAverage Generator Loss: 2621.607056\tAverage Discriminator Loss: 0.077224\n",
      "\n",
      "Train time for epoch #11037 (step 11037): 1.366069\n",
      "Batch #10\tAverage Generator Loss: 2113.478589\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11038 (step 11038): 1.341596\n",
      "Batch #10\tAverage Generator Loss: 2689.380347\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11039 (step 11039): 1.706579\n",
      "Batch #10\tAverage Generator Loss: 2446.851672\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11040 (step 11040): 1.542858\n",
      "Batch #10\tAverage Generator Loss: 2298.517200\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11041 (step 11041): 1.737331\n",
      "Batch #10\tAverage Generator Loss: 2408.884253\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11042 (step 11042): 1.304033\n",
      "Batch #10\tAverage Generator Loss: 2143.856256\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11043 (step 11043): 1.337020\n",
      "Batch #10\tAverage Generator Loss: 2415.637915\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11044 (step 11044): 1.655847\n",
      "Batch #10\tAverage Generator Loss: 2409.048224\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #11045 (step 11045): 1.288017\n",
      "Batch #10\tAverage Generator Loss: 2095.955627\tAverage Discriminator Loss: 0.009771\n",
      "\n",
      "Train time for epoch #11046 (step 11046): 1.699889\n",
      "Batch #10\tAverage Generator Loss: 2439.096375\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11047 (step 11047): 1.293309\n",
      "Batch #10\tAverage Generator Loss: 2003.724249\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11048 (step 11048): 1.279440\n",
      "Batch #10\tAverage Generator Loss: 2299.537390\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #11049 (step 11049): 1.643065\n",
      "Batch #10\tAverage Generator Loss: 2126.375757\tAverage Discriminator Loss: 0.027512\n",
      "\n",
      "Train time for epoch #11050 (step 11050): 1.299760\n",
      "Batch #10\tAverage Generator Loss: 2060.020755\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11051 (step 11051): 1.645516\n",
      "Batch #10\tAverage Generator Loss: 2360.083936\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11052 (step 11052): 1.353183\n",
      "Batch #10\tAverage Generator Loss: 2156.284436\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11053 (step 11053): 1.701493\n",
      "Batch #10\tAverage Generator Loss: 2406.102759\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11054 (step 11054): 1.282880\n",
      "Batch #10\tAverage Generator Loss: 2290.597803\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11055 (step 11055): 1.307964\n",
      "Batch #10\tAverage Generator Loss: 2381.524573\tAverage Discriminator Loss: 0.207359\n",
      "\n",
      "Train time for epoch #11056 (step 11056): 1.695791\n",
      "Batch #10\tAverage Generator Loss: 2257.183374\tAverage Discriminator Loss: 0.016822\n",
      "\n",
      "Train time for epoch #11057 (step 11057): 1.239626\n",
      "Batch #10\tAverage Generator Loss: 2218.140381\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #11058 (step 11058): 1.760938\n",
      "Batch #10\tAverage Generator Loss: 2356.074072\tAverage Discriminator Loss: 0.001329\n",
      "\n",
      "Train time for epoch #11059 (step 11059): 1.343320\n",
      "Batch #10\tAverage Generator Loss: 2234.797137\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11060 (step 11060): 1.371088\n",
      "Batch #10\tAverage Generator Loss: 2175.325049\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11061 (step 11061): 1.645161\n",
      "Batch #10\tAverage Generator Loss: 2125.055225\tAverage Discriminator Loss: 0.000105\n",
      "\n",
      "Train time for epoch #11062 (step 11062): 1.352089\n",
      "Batch #10\tAverage Generator Loss: 1933.484583\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11063 (step 11063): 1.669038\n",
      "Batch #10\tAverage Generator Loss: 2367.157983\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11064 (step 11064): 1.350509\n",
      "Batch #10\tAverage Generator Loss: 2207.681763\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11065 (step 11065): 1.382804\n",
      "Batch #10\tAverage Generator Loss: 1975.314868\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11066 (step 11066): 1.674763\n",
      "Batch #10\tAverage Generator Loss: 1957.114905\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11067 (step 11067): 1.285141\n",
      "Batch #10\tAverage Generator Loss: 2400.520593\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11068 (step 11068): 1.669613\n",
      "Batch #10\tAverage Generator Loss: 2000.711432\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11069 (step 11069): 1.267324\n",
      "Batch #10\tAverage Generator Loss: 1916.724121\tAverage Discriminator Loss: 0.017779\n",
      "\n",
      "Train time for epoch #11070 (step 11070): 1.355889\n",
      "Batch #10\tAverage Generator Loss: 2176.142334\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11071 (step 11071): 1.682683\n",
      "Batch #10\tAverage Generator Loss: 1960.567792\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #11072 (step 11072): 1.393626\n",
      "Batch #10\tAverage Generator Loss: 2344.698572\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #11073 (step 11073): 1.682995\n",
      "Batch #10\tAverage Generator Loss: 2298.333295\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #11074 (step 11074): 1.435185\n",
      "Batch #10\tAverage Generator Loss: 2205.228442\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #11075 (step 11075): 1.303703\n",
      "Batch #10\tAverage Generator Loss: 1814.921222\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #11076 (step 11076): 1.711888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2089.950928\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #11077 (step 11077): 1.328414\n",
      "Batch #10\tAverage Generator Loss: 2316.443835\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #11078 (step 11078): 1.818033\n",
      "Batch #10\tAverage Generator Loss: 2131.094873\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #11079 (step 11079): 1.344333\n",
      "Batch #10\tAverage Generator Loss: 2358.889673\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11080 (step 11080): 1.412745\n",
      "Batch #10\tAverage Generator Loss: 2522.442236\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11081 (step 11081): 1.732830\n",
      "Batch #10\tAverage Generator Loss: 2549.405786\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11082 (step 11082): 1.294210\n",
      "Batch #10\tAverage Generator Loss: 2249.634680\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11083 (step 11083): 1.891321\n",
      "Batch #10\tAverage Generator Loss: 2190.524426\tAverage Discriminator Loss: 0.004066\n",
      "\n",
      "Train time for epoch #11084 (step 11084): 1.332311\n",
      "Batch #10\tAverage Generator Loss: 2067.793707\tAverage Discriminator Loss: 0.000289\n",
      "\n",
      "Train time for epoch #11085 (step 11085): 1.305065\n",
      "Batch #10\tAverage Generator Loss: 2192.798352\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #11086 (step 11086): 1.657602\n",
      "Batch #10\tAverage Generator Loss: 2289.056604\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11087 (step 11087): 1.294008\n",
      "Batch #10\tAverage Generator Loss: 2368.330493\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11088 (step 11088): 1.634404\n",
      "Batch #10\tAverage Generator Loss: 2112.422095\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11089 (step 11089): 1.429138\n",
      "Batch #10\tAverage Generator Loss: 2596.108850\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11090 (step 11090): 1.323703\n",
      "Batch #10\tAverage Generator Loss: 2081.232910\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11091 (step 11091): 1.644331\n",
      "Batch #10\tAverage Generator Loss: 2380.777100\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11092 (step 11092): 1.292302\n",
      "Batch #10\tAverage Generator Loss: 2375.972498\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11093 (step 11093): 1.758014\n",
      "Batch #10\tAverage Generator Loss: 2342.336963\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11094 (step 11094): 1.354990\n",
      "Batch #10\tAverage Generator Loss: 2421.619641\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11095 (step 11095): 1.297101\n",
      "Batch #10\tAverage Generator Loss: 2372.212854\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11096 (step 11096): 1.819151\n",
      "Batch #10\tAverage Generator Loss: 2141.038934\tAverage Discriminator Loss: 0.034040\n",
      "\n",
      "Train time for epoch #11097 (step 11097): 1.285077\n",
      "Batch #10\tAverage Generator Loss: 2432.500146\tAverage Discriminator Loss: 0.001173\n",
      "\n",
      "Train time for epoch #11098 (step 11098): 1.681212\n",
      "Batch #10\tAverage Generator Loss: 2094.192438\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11099 (step 11099): 1.381575\n",
      "Batch #10\tAverage Generator Loss: 2291.334741\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11100 (step 11100): 1.292313\n",
      "Batch #10\tAverage Generator Loss: 2229.461841\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11101 (step 11101): 1.753516\n",
      "Batch #10\tAverage Generator Loss: 2404.712634\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11102 (step 11102): 1.357752\n",
      "Batch #10\tAverage Generator Loss: 2177.058624\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11103 (step 11103): 1.785273\n",
      "Batch #10\tAverage Generator Loss: 2494.851025\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11104 (step 11104): 1.343765\n",
      "Batch #10\tAverage Generator Loss: 2425.177429\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11105 (step 11105): 1.328854\n",
      "Batch #10\tAverage Generator Loss: 2191.045227\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11106 (step 11106): 1.686057\n",
      "Batch #10\tAverage Generator Loss: 2325.087805\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11107 (step 11107): 1.363751\n",
      "Batch #10\tAverage Generator Loss: 2267.099927\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11108 (step 11108): 1.723778\n",
      "Batch #10\tAverage Generator Loss: 2336.198218\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11109 (step 11109): 1.354125\n",
      "Batch #10\tAverage Generator Loss: 1931.229877\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11110 (step 11110): 1.297178\n",
      "Batch #10\tAverage Generator Loss: 2240.835474\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11111 (step 11111): 1.683574\n",
      "Batch #10\tAverage Generator Loss: 2299.506738\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11112 (step 11112): 1.306767\n",
      "Batch #10\tAverage Generator Loss: 2410.410352\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11113 (step 11113): 1.789774\n",
      "Batch #10\tAverage Generator Loss: 2155.269592\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11114 (step 11114): 1.321014\n",
      "Batch #10\tAverage Generator Loss: 1939.819690\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11115 (step 11115): 1.244567\n",
      "Batch #10\tAverage Generator Loss: 2484.466724\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11116 (step 11116): 1.715921\n",
      "Batch #10\tAverage Generator Loss: 2444.371179\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11117 (step 11117): 1.377214\n",
      "Batch #10\tAverage Generator Loss: 2200.096832\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11118 (step 11118): 1.672822\n",
      "Batch #10\tAverage Generator Loss: 2375.914441\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11119 (step 11119): 1.347350\n",
      "Batch #10\tAverage Generator Loss: 2427.764417\tAverage Discriminator Loss: 0.000773\n",
      "\n",
      "Train time for epoch #11120 (step 11120): 1.305899\n",
      "Batch #10\tAverage Generator Loss: 2374.348914\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11121 (step 11121): 1.837683\n",
      "Batch #10\tAverage Generator Loss: 2157.287354\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11122 (step 11122): 1.377874\n",
      "Batch #10\tAverage Generator Loss: 2332.695703\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11123 (step 11123): 1.706150\n",
      "Batch #10\tAverage Generator Loss: 2082.786719\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11124 (step 11124): 1.343600\n",
      "Batch #10\tAverage Generator Loss: 2469.815515\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11125 (step 11125): 1.350671\n",
      "Batch #10\tAverage Generator Loss: 2157.983301\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11126 (step 11126): 1.688759\n",
      "Batch #10\tAverage Generator Loss: 1989.631641\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11127 (step 11127): 1.338385\n",
      "Batch #10\tAverage Generator Loss: 2660.470667\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11128 (step 11128): 1.677351\n",
      "Batch #10\tAverage Generator Loss: 2414.581958\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11129 (step 11129): 1.388834\n",
      "Batch #10\tAverage Generator Loss: 2118.904614\tAverage Discriminator Loss: 0.000248\n",
      "\n",
      "Train time for epoch #11130 (step 11130): 1.293083\n",
      "Batch #10\tAverage Generator Loss: 2087.538794\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #11131 (step 11131): 1.705984\n",
      "Batch #10\tAverage Generator Loss: 2438.683765\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #11132 (step 11132): 1.337694\n",
      "Batch #10\tAverage Generator Loss: 2165.125439\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11133 (step 11133): 1.695353\n",
      "Batch #10\tAverage Generator Loss: 2680.568250\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #11134 (step 11134): 1.399771\n",
      "Batch #10\tAverage Generator Loss: 2154.477032\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #11135 (step 11135): 1.451800\n",
      "Batch #10\tAverage Generator Loss: 2406.631006\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11136 (step 11136): 1.704353\n",
      "Batch #10\tAverage Generator Loss: 2140.476245\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #11137 (step 11137): 1.579059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2056.533350\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #11138 (step 11138): 1.772843\n",
      "Batch #10\tAverage Generator Loss: 2241.249988\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #11139 (step 11139): 1.350395\n",
      "Batch #10\tAverage Generator Loss: 2088.303564\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #11140 (step 11140): 1.249540\n",
      "Batch #10\tAverage Generator Loss: 2403.806055\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11141 (step 11141): 1.729220\n",
      "Batch #10\tAverage Generator Loss: 2414.379700\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #11142 (step 11142): 1.382452\n",
      "Batch #10\tAverage Generator Loss: 2096.184775\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #11143 (step 11143): 1.783642\n",
      "Batch #10\tAverage Generator Loss: 2129.775940\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #11144 (step 11144): 1.380779\n",
      "Batch #10\tAverage Generator Loss: 2200.549902\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11145 (step 11145): 1.351655\n",
      "Batch #10\tAverage Generator Loss: 1919.153577\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #11146 (step 11146): 1.676667\n",
      "Batch #10\tAverage Generator Loss: 2218.278088\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #11147 (step 11147): 1.247245\n",
      "Batch #10\tAverage Generator Loss: 2099.381836\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11148 (step 11148): 1.716526\n",
      "Batch #10\tAverage Generator Loss: 2131.422272\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11149 (step 11149): 1.435675\n",
      "Batch #10\tAverage Generator Loss: 1958.520618\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11150 (step 11150): 1.444220\n",
      "Batch #10\tAverage Generator Loss: 2079.977258\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11151 (step 11151): 1.732218\n",
      "Batch #10\tAverage Generator Loss: 2584.696558\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11152 (step 11152): 1.344089\n",
      "Batch #10\tAverage Generator Loss: 2188.576904\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11153 (step 11153): 1.747548\n",
      "Batch #10\tAverage Generator Loss: 2289.152429\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11154 (step 11154): 1.296356\n",
      "Batch #10\tAverage Generator Loss: 2136.051013\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11155 (step 11155): 1.329755\n",
      "Batch #10\tAverage Generator Loss: 2495.657581\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11156 (step 11156): 1.748334\n",
      "Batch #10\tAverage Generator Loss: 2237.198828\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11157 (step 11157): 1.343811\n",
      "Batch #10\tAverage Generator Loss: 2290.688208\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11158 (step 11158): 1.703508\n",
      "Batch #10\tAverage Generator Loss: 2139.411389\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11159 (step 11159): 1.296539\n",
      "Batch #10\tAverage Generator Loss: 2096.442187\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11160 (step 11160): 1.347425\n",
      "Batch #10\tAverage Generator Loss: 2239.531677\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11161 (step 11161): 1.812798\n",
      "Batch #10\tAverage Generator Loss: 2057.112714\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11162 (step 11162): 1.284835\n",
      "Batch #10\tAverage Generator Loss: 2324.771338\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11163 (step 11163): 1.660837\n",
      "Batch #10\tAverage Generator Loss: 2466.295837\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11164 (step 11164): 1.446375\n",
      "Batch #10\tAverage Generator Loss: 2163.351697\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11165 (step 11165): 1.364388\n",
      "Batch #10\tAverage Generator Loss: 2114.990430\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11166 (step 11166): 1.719031\n",
      "Batch #10\tAverage Generator Loss: 2358.888708\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11167 (step 11167): 1.262193\n",
      "Batch #10\tAverage Generator Loss: 2249.945337\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11168 (step 11168): 1.608765\n",
      "Batch #10\tAverage Generator Loss: 2164.539264\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11169 (step 11169): 1.350425\n",
      "Batch #10\tAverage Generator Loss: 2000.046802\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11170 (step 11170): 1.263088\n",
      "Batch #10\tAverage Generator Loss: 2044.181677\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11171 (step 11171): 1.649860\n",
      "Batch #10\tAverage Generator Loss: 2354.198645\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11172 (step 11172): 1.297652\n",
      "Batch #10\tAverage Generator Loss: 2200.277893\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11173 (step 11173): 1.698064\n",
      "Batch #10\tAverage Generator Loss: 2022.841272\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11174 (step 11174): 1.348736\n",
      "Batch #10\tAverage Generator Loss: 2308.646863\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11175 (step 11175): 1.299992\n",
      "Batch #10\tAverage Generator Loss: 2177.143011\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11176 (step 11176): 1.660778\n",
      "Batch #10\tAverage Generator Loss: 2010.589551\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11177 (step 11177): 1.336289\n",
      "Batch #10\tAverage Generator Loss: 2400.254980\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11178 (step 11178): 1.233670\n",
      "Batch #10\tAverage Generator Loss: 2056.565887\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11179 (step 11179): 1.675946\n",
      "Batch #10\tAverage Generator Loss: 2379.900403\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11180 (step 11180): 1.249446\n",
      "Batch #10\tAverage Generator Loss: 1910.511255\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11181 (step 11181): 1.706279\n",
      "Batch #10\tAverage Generator Loss: 2198.651917\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11182 (step 11182): 1.339773\n",
      "Batch #10\tAverage Generator Loss: 1742.190350\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11183 (step 11183): 1.295865\n",
      "Batch #10\tAverage Generator Loss: 2297.288904\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11184 (step 11184): 1.732995\n",
      "Batch #10\tAverage Generator Loss: 2197.525360\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11185 (step 11185): 1.336511\n",
      "Batch #10\tAverage Generator Loss: 2191.042810\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11186 (step 11186): 1.679733\n",
      "Batch #10\tAverage Generator Loss: 2178.974432\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11187 (step 11187): 1.296261\n",
      "Batch #10\tAverage Generator Loss: 1933.398706\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11188 (step 11188): 1.400678\n",
      "Batch #10\tAverage Generator Loss: 2265.249615\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11189 (step 11189): 1.753863\n",
      "Batch #10\tAverage Generator Loss: 2305.417688\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11190 (step 11190): 1.287114\n",
      "Batch #10\tAverage Generator Loss: 2290.928613\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11191 (step 11191): 1.857689\n",
      "Batch #10\tAverage Generator Loss: 2599.714380\tAverage Discriminator Loss: 0.222583\n",
      "\n",
      "Train time for epoch #11192 (step 11192): 1.292460\n",
      "Batch #10\tAverage Generator Loss: 2791.211829\tAverage Discriminator Loss: 0.000065\n",
      "\n",
      "Train time for epoch #11193 (step 11193): 1.390057\n",
      "Batch #10\tAverage Generator Loss: 2820.419568\tAverage Discriminator Loss: 0.000111\n",
      "\n",
      "Train time for epoch #11194 (step 11194): 1.686502\n",
      "Batch #10\tAverage Generator Loss: 2501.541248\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #11195 (step 11195): 1.332049\n",
      "Batch #10\tAverage Generator Loss: 2651.556592\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #11196 (step 11196): 1.726209\n",
      "Batch #10\tAverage Generator Loss: 2956.828186\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11197 (step 11197): 1.468326\n",
      "Batch #10\tAverage Generator Loss: 2759.138477\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11198 (step 11198): 1.292695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2369.312903\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11199 (step 11199): 1.740179\n",
      "Batch #10\tAverage Generator Loss: 2926.457935\tAverage Discriminator Loss: 0.190449\n",
      "\n",
      "Train time for epoch #11200 (step 11200): 1.389038\n",
      "Batch #10\tAverage Generator Loss: 1953.160193\tAverage Discriminator Loss: 0.000359\n",
      "\n",
      "Train time for epoch #11201 (step 11201): 1.282139\n",
      "Batch #10\tAverage Generator Loss: 2124.130493\tAverage Discriminator Loss: 0.000075\n",
      "\n",
      "Train time for epoch #11202 (step 11202): 1.611132\n",
      "Batch #10\tAverage Generator Loss: 2348.854187\tAverage Discriminator Loss: 0.000029\n",
      "\n",
      "Train time for epoch #11203 (step 11203): 1.432856\n",
      "Batch #10\tAverage Generator Loss: 2106.617053\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #11204 (step 11204): 1.656882\n",
      "Batch #10\tAverage Generator Loss: 2177.194666\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #11205 (step 11205): 1.302768\n",
      "Batch #10\tAverage Generator Loss: 2123.696249\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #11206 (step 11206): 1.753477\n",
      "Batch #10\tAverage Generator Loss: 2192.019788\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #11207 (step 11207): 1.459687\n",
      "Batch #10\tAverage Generator Loss: 1983.915527\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #11208 (step 11208): 1.291888\n",
      "Batch #10\tAverage Generator Loss: 2035.498828\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #11209 (step 11209): 1.765652\n",
      "Batch #10\tAverage Generator Loss: 2020.810419\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #11210 (step 11210): 1.287744\n",
      "Batch #10\tAverage Generator Loss: 1842.894287\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #11211 (step 11211): 1.688202\n",
      "Batch #10\tAverage Generator Loss: 2117.169702\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #11212 (step 11212): 1.295440\n",
      "Batch #10\tAverage Generator Loss: 2013.885797\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #11213 (step 11213): 1.439473\n",
      "Batch #10\tAverage Generator Loss: 2049.437982\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #11214 (step 11214): 1.685287\n",
      "Batch #10\tAverage Generator Loss: 2033.280554\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #11215 (step 11215): 1.363438\n",
      "Batch #10\tAverage Generator Loss: 1957.150153\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #11216 (step 11216): 1.538426\n",
      "Batch #10\tAverage Generator Loss: 1962.227991\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #11217 (step 11217): 1.705256\n",
      "Batch #10\tAverage Generator Loss: 2023.377686\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #11218 (step 11218): 1.258840\n",
      "Batch #10\tAverage Generator Loss: 2251.496179\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #11219 (step 11219): 1.665591\n",
      "Batch #10\tAverage Generator Loss: 1909.174597\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #11220 (step 11220): 1.355414\n",
      "Batch #10\tAverage Generator Loss: 1766.727222\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #11221 (step 11221): 1.328738\n",
      "Batch #10\tAverage Generator Loss: 1803.929053\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #11222 (step 11222): 1.653187\n",
      "Batch #10\tAverage Generator Loss: 2060.711499\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #11223 (step 11223): 1.248317\n",
      "Batch #10\tAverage Generator Loss: 1991.345441\tAverage Discriminator Loss: 0.004830\n",
      "\n",
      "Train time for epoch #11224 (step 11224): 1.799160\n",
      "Batch #10\tAverage Generator Loss: 2173.472601\tAverage Discriminator Loss: 0.008036\n",
      "\n",
      "Train time for epoch #11225 (step 11225): 1.297682\n",
      "Batch #10\tAverage Generator Loss: 1999.940503\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11226 (step 11226): 1.676152\n",
      "Batch #10\tAverage Generator Loss: 1951.844647\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11227 (step 11227): 1.291776\n",
      "Batch #10\tAverage Generator Loss: 2120.330420\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11228 (step 11228): 1.282262\n",
      "Batch #10\tAverage Generator Loss: 2078.456616\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11229 (step 11229): 1.727216\n",
      "Batch #10\tAverage Generator Loss: 2052.928821\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11230 (step 11230): 1.337092\n",
      "Batch #10\tAverage Generator Loss: 2224.033008\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11231 (step 11231): 1.377512\n",
      "Batch #10\tAverage Generator Loss: 1508.590527\tAverage Discriminator Loss: 0.096192\n",
      "\n",
      "Train time for epoch #11232 (step 11232): 1.714095\n",
      "Batch #10\tAverage Generator Loss: 1696.918250\tAverage Discriminator Loss: 0.000412\n",
      "\n",
      "Train time for epoch #11233 (step 11233): 1.361255\n",
      "Batch #10\tAverage Generator Loss: 1933.437463\tAverage Discriminator Loss: 0.007805\n",
      "\n",
      "Train time for epoch #11234 (step 11234): 1.681509\n",
      "Batch #10\tAverage Generator Loss: 1935.814990\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11235 (step 11235): 1.293126\n",
      "Batch #10\tAverage Generator Loss: 1726.545551\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11236 (step 11236): 1.325076\n",
      "Batch #10\tAverage Generator Loss: 1902.592065\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11237 (step 11237): 1.773085\n",
      "Batch #10\tAverage Generator Loss: 1722.067212\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11238 (step 11238): 1.342325\n",
      "Batch #10\tAverage Generator Loss: 1659.873120\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11239 (step 11239): 1.776935\n",
      "Batch #10\tAverage Generator Loss: 1805.142731\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11240 (step 11240): 1.350855\n",
      "Batch #10\tAverage Generator Loss: 1776.108984\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11241 (step 11241): 1.362478\n",
      "Batch #10\tAverage Generator Loss: 1758.524054\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11242 (step 11242): 1.722936\n",
      "Batch #10\tAverage Generator Loss: 1870.485284\tAverage Discriminator Loss: 0.118057\n",
      "\n",
      "Train time for epoch #11243 (step 11243): 1.387998\n",
      "Batch #10\tAverage Generator Loss: 1717.169031\tAverage Discriminator Loss: 0.030602\n",
      "\n",
      "Train time for epoch #11244 (step 11244): 1.642487\n",
      "Batch #10\tAverage Generator Loss: 1683.261896\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #11245 (step 11245): 1.435736\n",
      "Batch #10\tAverage Generator Loss: 1826.924878\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11246 (step 11246): 1.289424\n",
      "Batch #10\tAverage Generator Loss: 1704.538739\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11247 (step 11247): 1.614690\n",
      "Batch #10\tAverage Generator Loss: 1737.369116\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11248 (step 11248): 1.293169\n",
      "Batch #10\tAverage Generator Loss: 1449.623547\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11249 (step 11249): 1.701857\n",
      "Batch #10\tAverage Generator Loss: 2083.041675\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11250 (step 11250): 1.337998\n",
      "Batch #10\tAverage Generator Loss: 1665.195312\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11251 (step 11251): 1.383927\n",
      "Batch #10\tAverage Generator Loss: 1696.650433\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11252 (step 11252): 1.662536\n",
      "Batch #10\tAverage Generator Loss: 1653.982422\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11253 (step 11253): 1.336349\n",
      "Batch #10\tAverage Generator Loss: 1504.723743\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11254 (step 11254): 1.647900\n",
      "Batch #10\tAverage Generator Loss: 1663.967590\tAverage Discriminator Loss: 0.435847\n",
      "\n",
      "Train time for epoch #11255 (step 11255): 1.355429\n",
      "Batch #10\tAverage Generator Loss: 1361.629269\tAverage Discriminator Loss: 0.006257\n",
      "\n",
      "Train time for epoch #11256 (step 11256): 1.419655\n",
      "Batch #10\tAverage Generator Loss: 1518.426215\tAverage Discriminator Loss: 0.000023\n",
      "\n",
      "Train time for epoch #11257 (step 11257): 1.746890\n",
      "Batch #10\tAverage Generator Loss: 1425.029736\tAverage Discriminator Loss: 0.000125\n",
      "\n",
      "Train time for epoch #11258 (step 11258): 1.301395\n",
      "Batch #10\tAverage Generator Loss: 1468.446295\tAverage Discriminator Loss: 0.091163\n",
      "\n",
      "Train time for epoch #11259 (step 11259): 1.766054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 1385.885413\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #11260 (step 11260): 1.286614\n",
      "Batch #10\tAverage Generator Loss: 1392.875888\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11261 (step 11261): 1.379645\n",
      "Batch #10\tAverage Generator Loss: 1520.815717\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11262 (step 11262): 1.666342\n",
      "Batch #10\tAverage Generator Loss: 1381.186261\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11263 (step 11263): 1.289770\n",
      "Batch #10\tAverage Generator Loss: 1613.300134\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11264 (step 11264): 1.643962\n",
      "Batch #10\tAverage Generator Loss: 1913.929791\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11265 (step 11265): 1.345320\n",
      "Batch #10\tAverage Generator Loss: 1639.326105\tAverage Discriminator Loss: 0.000040\n",
      "\n",
      "Train time for epoch #11266 (step 11266): 1.382051\n",
      "Batch #10\tAverage Generator Loss: 1726.525488\tAverage Discriminator Loss: 0.001113\n",
      "\n",
      "Train time for epoch #11267 (step 11267): 1.677811\n",
      "Batch #10\tAverage Generator Loss: 1712.840271\tAverage Discriminator Loss: 0.000099\n",
      "\n",
      "Train time for epoch #11268 (step 11268): 1.295023\n",
      "Batch #10\tAverage Generator Loss: 1645.321777\tAverage Discriminator Loss: 0.000031\n",
      "\n",
      "Train time for epoch #11269 (step 11269): 1.769041\n",
      "Batch #10\tAverage Generator Loss: 1419.670752\tAverage Discriminator Loss: 0.000027\n",
      "\n",
      "Train time for epoch #11270 (step 11270): 1.280730\n",
      "Batch #10\tAverage Generator Loss: 1610.604797\tAverage Discriminator Loss: 0.000019\n",
      "\n",
      "Train time for epoch #11271 (step 11271): 1.675501\n",
      "Batch #10\tAverage Generator Loss: 1681.618384\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #11272 (step 11272): 1.380562\n",
      "Batch #10\tAverage Generator Loss: 1638.560297\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #11273 (step 11273): 1.395902\n",
      "Batch #10\tAverage Generator Loss: 1899.619604\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #11274 (step 11274): 1.684382\n",
      "Batch #10\tAverage Generator Loss: 1814.950073\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #11275 (step 11275): 1.377208\n",
      "Batch #10\tAverage Generator Loss: 1689.381232\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #11276 (step 11276): 1.748515\n",
      "Batch #10\tAverage Generator Loss: 1924.965967\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #11277 (step 11277): 1.279668\n",
      "Batch #10\tAverage Generator Loss: 1456.950964\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #11278 (step 11278): 1.327100\n",
      "Batch #10\tAverage Generator Loss: 1686.587646\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #11279 (step 11279): 1.757715\n",
      "Batch #10\tAverage Generator Loss: 1831.254865\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #11280 (step 11280): 1.351095\n",
      "Batch #10\tAverage Generator Loss: 1718.973621\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #11281 (step 11281): 1.853739\n",
      "Batch #10\tAverage Generator Loss: 1577.821545\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #11282 (step 11282): 1.287439\n",
      "Batch #10\tAverage Generator Loss: 1785.807312\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #11283 (step 11283): 1.299711\n",
      "Batch #10\tAverage Generator Loss: 1414.007101\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #11284 (step 11284): 1.726527\n",
      "Batch #10\tAverage Generator Loss: 1720.102032\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #11285 (step 11285): 1.283124\n",
      "Batch #10\tAverage Generator Loss: 1818.335901\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #11286 (step 11286): 1.800060\n",
      "Batch #10\tAverage Generator Loss: 1841.788379\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #11287 (step 11287): 1.460315\n",
      "Batch #10\tAverage Generator Loss: 1505.500751\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #11288 (step 11288): 1.273191\n",
      "Batch #10\tAverage Generator Loss: 1839.219226\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #11289 (step 11289): 1.768267\n",
      "Batch #10\tAverage Generator Loss: 1682.918958\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #11290 (step 11290): 1.430650\n",
      "Batch #10\tAverage Generator Loss: 1644.505438\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #11291 (step 11291): 1.677638\n",
      "Batch #10\tAverage Generator Loss: 1691.781396\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #11292 (step 11292): 1.393633\n",
      "Batch #10\tAverage Generator Loss: 1803.512598\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #11293 (step 11293): 1.273576\n",
      "Batch #10\tAverage Generator Loss: 1748.720984\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #11294 (step 11294): 1.663735\n",
      "Batch #10\tAverage Generator Loss: 1624.963318\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #11295 (step 11295): 1.332680\n",
      "Batch #10\tAverage Generator Loss: 1795.757532\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11296 (step 11296): 1.405432\n",
      "Batch #10\tAverage Generator Loss: 1705.023401\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11297 (step 11297): 1.706870\n",
      "Batch #10\tAverage Generator Loss: 1724.870233\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11298 (step 11298): 1.285401\n",
      "Batch #10\tAverage Generator Loss: 1741.368274\tAverage Discriminator Loss: 0.004981\n",
      "\n",
      "Train time for epoch #11299 (step 11299): 1.714391\n",
      "Batch #10\tAverage Generator Loss: 1655.697058\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #11300 (step 11300): 1.290092\n",
      "Batch #10\tAverage Generator Loss: 1569.410040\tAverage Discriminator Loss: 0.000023\n",
      "\n",
      "Train time for epoch #11301 (step 11301): 1.389870\n",
      "Batch #10\tAverage Generator Loss: 1677.981458\tAverage Discriminator Loss: 0.000022\n",
      "\n",
      "Train time for epoch #11302 (step 11302): 1.727815\n",
      "Batch #10\tAverage Generator Loss: 1889.895868\tAverage Discriminator Loss: 0.000019\n",
      "\n",
      "Train time for epoch #11303 (step 11303): 1.501679\n",
      "Batch #10\tAverage Generator Loss: 1582.721655\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #11304 (step 11304): 1.734735\n",
      "Batch #10\tAverage Generator Loss: 1421.263873\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #11305 (step 11305): 1.441514\n",
      "Batch #10\tAverage Generator Loss: 1547.829333\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #11306 (step 11306): 1.514425\n",
      "Batch #10\tAverage Generator Loss: 1989.564038\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #11307 (step 11307): 1.832105\n",
      "Batch #10\tAverage Generator Loss: 1639.899579\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #11308 (step 11308): 1.351381\n",
      "Batch #10\tAverage Generator Loss: 1906.831256\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #11309 (step 11309): 1.286808\n",
      "Batch #10\tAverage Generator Loss: 1914.263977\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #11310 (step 11310): 1.662387\n",
      "Batch #10\tAverage Generator Loss: 1790.212964\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #11311 (step 11311): 1.447573\n",
      "Batch #10\tAverage Generator Loss: 1769.146332\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #11312 (step 11312): 1.729418\n",
      "Batch #10\tAverage Generator Loss: 1768.084680\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #11313 (step 11313): 1.360012\n",
      "Batch #10\tAverage Generator Loss: 1642.488666\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #11314 (step 11314): 1.280751\n",
      "Batch #10\tAverage Generator Loss: 1849.955591\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #11315 (step 11315): 1.730320\n",
      "Batch #10\tAverage Generator Loss: 1787.368945\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #11316 (step 11316): 1.286192\n",
      "Batch #10\tAverage Generator Loss: 1790.142456\tAverage Discriminator Loss: 0.020860\n",
      "\n",
      "Train time for epoch #11317 (step 11317): 1.285024\n",
      "Batch #10\tAverage Generator Loss: 1971.477393\tAverage Discriminator Loss: 0.005083\n",
      "\n",
      "Train time for epoch #11318 (step 11318): 1.714270\n",
      "Batch #10\tAverage Generator Loss: 1814.853882\tAverage Discriminator Loss: 0.000056\n",
      "\n",
      "Train time for epoch #11319 (step 11319): 1.323573\n",
      "Batch #10\tAverage Generator Loss: 2190.450403\tAverage Discriminator Loss: 0.000022\n",
      "\n",
      "Train time for epoch #11320 (step 11320): 1.762825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 1786.077039\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #11321 (step 11321): 1.465207\n",
      "Batch #10\tAverage Generator Loss: 1759.271265\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #11322 (step 11322): 1.757741\n",
      "Batch #10\tAverage Generator Loss: 1894.507764\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #11323 (step 11323): 1.302005\n",
      "Batch #10\tAverage Generator Loss: 2043.131262\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #11324 (step 11324): 1.302101\n",
      "Batch #10\tAverage Generator Loss: 1745.449097\tAverage Discriminator Loss: 0.005097\n",
      "\n",
      "Train time for epoch #11325 (step 11325): 1.648780\n",
      "Batch #10\tAverage Generator Loss: 1581.300464\tAverage Discriminator Loss: 0.000057\n",
      "\n",
      "Train time for epoch #11326 (step 11326): 1.352424\n",
      "Batch #10\tAverage Generator Loss: 1684.759497\tAverage Discriminator Loss: 0.000047\n",
      "\n",
      "Train time for epoch #11327 (step 11327): 1.454626\n",
      "Batch #10\tAverage Generator Loss: 1824.433868\tAverage Discriminator Loss: 0.000052\n",
      "\n",
      "Train time for epoch #11328 (step 11328): 1.657209\n",
      "Batch #10\tAverage Generator Loss: 1879.917273\tAverage Discriminator Loss: 0.000033\n",
      "\n",
      "Train time for epoch #11329 (step 11329): 1.383207\n",
      "Batch #10\tAverage Generator Loss: 1768.046039\tAverage Discriminator Loss: 0.000033\n",
      "\n",
      "Train time for epoch #11330 (step 11330): 1.679068\n",
      "Batch #10\tAverage Generator Loss: 1721.050629\tAverage Discriminator Loss: 0.000020\n",
      "\n",
      "Train time for epoch #11331 (step 11331): 1.385047\n",
      "Batch #10\tAverage Generator Loss: 1955.235492\tAverage Discriminator Loss: 0.000019\n",
      "\n",
      "Train time for epoch #11332 (step 11332): 1.283399\n",
      "Batch #10\tAverage Generator Loss: 1923.781519\tAverage Discriminator Loss: 0.000023\n",
      "\n",
      "Train time for epoch #11333 (step 11333): 1.637267\n",
      "Batch #10\tAverage Generator Loss: 1584.693268\tAverage Discriminator Loss: 0.000021\n",
      "\n",
      "Train time for epoch #11334 (step 11334): 1.323396\n",
      "Batch #10\tAverage Generator Loss: 1852.899646\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #11335 (step 11335): 1.718502\n",
      "Batch #10\tAverage Generator Loss: 1639.881091\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #11336 (step 11336): 1.419196\n",
      "Batch #10\tAverage Generator Loss: 1714.893341\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #11337 (step 11337): 1.458014\n",
      "Batch #10\tAverage Generator Loss: 1898.027051\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #11338 (step 11338): 1.625082\n",
      "Batch #10\tAverage Generator Loss: 1476.501221\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #11339 (step 11339): 1.294016\n",
      "Batch #10\tAverage Generator Loss: 1786.276044\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #11340 (step 11340): 1.712975\n",
      "Batch #10\tAverage Generator Loss: 1746.487567\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #11341 (step 11341): 1.366085\n",
      "Batch #10\tAverage Generator Loss: 1801.907251\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #11342 (step 11342): 1.309277\n",
      "Batch #10\tAverage Generator Loss: 1737.756030\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #11343 (step 11343): 1.686510\n",
      "Batch #10\tAverage Generator Loss: 1864.484912\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #11344 (step 11344): 1.297577\n",
      "Batch #10\tAverage Generator Loss: 1949.174573\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #11345 (step 11345): 1.768691\n",
      "Batch #10\tAverage Generator Loss: 1637.281836\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #11346 (step 11346): 1.290499\n",
      "Batch #10\tAverage Generator Loss: 1695.758350\tAverage Discriminator Loss: 0.059333\n",
      "\n",
      "Train time for epoch #11347 (step 11347): 1.326623\n",
      "Batch #10\tAverage Generator Loss: 1787.694629\tAverage Discriminator Loss: 0.002186\n",
      "\n",
      "Train time for epoch #11348 (step 11348): 1.786956\n",
      "Batch #10\tAverage Generator Loss: 1921.410144\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #11349 (step 11349): 1.364093\n",
      "Batch #10\tAverage Generator Loss: 1772.691211\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #11350 (step 11350): 1.317604\n",
      "Batch #10\tAverage Generator Loss: 1592.297449\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11351 (step 11351): 1.797811\n",
      "Batch #10\tAverage Generator Loss: 1785.795367\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11352 (step 11352): 1.298804\n",
      "Batch #10\tAverage Generator Loss: 1905.853375\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #11353 (step 11353): 1.685653\n",
      "Batch #10\tAverage Generator Loss: 1842.189465\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11354 (step 11354): 1.383771\n",
      "Batch #10\tAverage Generator Loss: 1826.283826\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11355 (step 11355): 1.353050\n",
      "Batch #10\tAverage Generator Loss: 1748.622510\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11356 (step 11356): 1.681635\n",
      "Batch #10\tAverage Generator Loss: 1822.441504\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11357 (step 11357): 1.288057\n",
      "Batch #10\tAverage Generator Loss: 1762.887152\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11358 (step 11358): 1.765795\n",
      "Batch #10\tAverage Generator Loss: 1721.773828\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11359 (step 11359): 1.343667\n",
      "Batch #10\tAverage Generator Loss: 1773.672675\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11360 (step 11360): 1.383050\n",
      "Batch #10\tAverage Generator Loss: 1713.813501\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11361 (step 11361): 1.713193\n",
      "Batch #10\tAverage Generator Loss: 1806.726782\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11362 (step 11362): 1.366822\n",
      "Batch #10\tAverage Generator Loss: 1618.890112\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11363 (step 11363): 1.341787\n",
      "Batch #10\tAverage Generator Loss: 1549.439178\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11364 (step 11364): 1.651148\n",
      "Batch #10\tAverage Generator Loss: 1805.084802\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11365 (step 11365): 1.295545\n",
      "Batch #10\tAverage Generator Loss: 2049.323169\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11366 (step 11366): 1.680328\n",
      "Batch #10\tAverage Generator Loss: 1642.863147\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11367 (step 11367): 1.392646\n",
      "Batch #10\tAverage Generator Loss: 1720.438574\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11368 (step 11368): 1.339126\n",
      "Batch #10\tAverage Generator Loss: 1606.109406\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11369 (step 11369): 1.704533\n",
      "Batch #10\tAverage Generator Loss: 1477.697076\tAverage Discriminator Loss: 0.000668\n",
      "\n",
      "Train time for epoch #11370 (step 11370): 1.426378\n",
      "Batch #10\tAverage Generator Loss: 1774.706079\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #11371 (step 11371): 1.656538\n",
      "Batch #10\tAverage Generator Loss: 1664.880121\tAverage Discriminator Loss: 0.000054\n",
      "\n",
      "Train time for epoch #11372 (step 11372): 1.449492\n",
      "Batch #10\tAverage Generator Loss: 1789.899500\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #11373 (step 11373): 1.328326\n",
      "Batch #10\tAverage Generator Loss: 1744.377466\tAverage Discriminator Loss: 0.000020\n",
      "\n",
      "Train time for epoch #11374 (step 11374): 1.667822\n",
      "Batch #10\tAverage Generator Loss: 1688.627118\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #11375 (step 11375): 1.445765\n",
      "Batch #10\tAverage Generator Loss: 1663.890436\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #11376 (step 11376): 1.709975\n",
      "Batch #10\tAverage Generator Loss: 1658.252631\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #11377 (step 11377): 1.388025\n",
      "Batch #10\tAverage Generator Loss: 1856.112164\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #11378 (step 11378): 1.310166\n",
      "Batch #10\tAverage Generator Loss: 1833.529114\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #11379 (step 11379): 1.697526\n",
      "Batch #10\tAverage Generator Loss: 1619.588171\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #11380 (step 11380): 1.352145\n",
      "Batch #10\tAverage Generator Loss: 1724.999683\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #11381 (step 11381): 1.680799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 1790.465051\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #11382 (step 11382): 1.543363\n",
      "Batch #10\tAverage Generator Loss: 1652.105746\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #11383 (step 11383): 1.349076\n",
      "Batch #10\tAverage Generator Loss: 1722.554138\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #11384 (step 11384): 1.681874\n",
      "Batch #10\tAverage Generator Loss: 1919.839978\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #11385 (step 11385): 1.291141\n",
      "Batch #10\tAverage Generator Loss: 1720.638660\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #11386 (step 11386): 1.730980\n",
      "Batch #10\tAverage Generator Loss: 1782.286157\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11387 (step 11387): 1.391065\n",
      "Batch #10\tAverage Generator Loss: 1856.447711\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #11388 (step 11388): 1.331516\n",
      "Batch #10\tAverage Generator Loss: 1907.147449\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #11389 (step 11389): 1.733439\n",
      "Batch #10\tAverage Generator Loss: 2086.250037\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11390 (step 11390): 1.358534\n",
      "Batch #10\tAverage Generator Loss: 1641.728113\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #11391 (step 11391): 1.687399\n",
      "Batch #10\tAverage Generator Loss: 1862.416467\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #11392 (step 11392): 1.305081\n",
      "Batch #10\tAverage Generator Loss: 1442.626923\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #11393 (step 11393): 1.288305\n",
      "Batch #10\tAverage Generator Loss: 2010.152863\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #11394 (step 11394): 1.746748\n",
      "Batch #10\tAverage Generator Loss: 1771.111230\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #11395 (step 11395): 1.293567\n",
      "Batch #10\tAverage Generator Loss: 1911.070203\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11396 (step 11396): 1.239480\n",
      "Batch #10\tAverage Generator Loss: 1679.146777\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #11397 (step 11397): 1.716338\n",
      "Batch #10\tAverage Generator Loss: 1629.361047\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11398 (step 11398): 1.288536\n",
      "Batch #10\tAverage Generator Loss: 1691.011322\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11399 (step 11399): 1.730749\n",
      "Batch #10\tAverage Generator Loss: 1242.342944\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11400 (step 11400): 1.339791\n",
      "Batch #10\tAverage Generator Loss: 1723.022888\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11401 (step 11401): 1.298105\n",
      "Batch #10\tAverage Generator Loss: 1795.133569\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11402 (step 11402): 1.668404\n",
      "Batch #10\tAverage Generator Loss: 1740.917032\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11403 (step 11403): 1.317876\n",
      "Batch #10\tAverage Generator Loss: 1517.299890\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11404 (step 11404): 1.842166\n",
      "Batch #10\tAverage Generator Loss: 1617.634503\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11405 (step 11405): 1.289989\n",
      "Batch #10\tAverage Generator Loss: 1803.110889\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11406 (step 11406): 1.345045\n",
      "Batch #10\tAverage Generator Loss: 1522.692896\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11407 (step 11407): 1.704842\n",
      "Batch #10\tAverage Generator Loss: 1552.933282\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11408 (step 11408): 1.284786\n",
      "Batch #10\tAverage Generator Loss: 1832.154736\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11409 (step 11409): 1.660550\n",
      "Batch #10\tAverage Generator Loss: 1601.339172\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11410 (step 11410): 1.363078\n",
      "Batch #10\tAverage Generator Loss: 1747.757568\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11411 (step 11411): 1.336450\n",
      "Batch #10\tAverage Generator Loss: 1438.927350\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11412 (step 11412): 1.738477\n",
      "Batch #10\tAverage Generator Loss: 2063.873096\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11413 (step 11413): 1.390769\n",
      "Batch #10\tAverage Generator Loss: 1765.999323\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11414 (step 11414): 1.778855\n",
      "Batch #10\tAverage Generator Loss: 1666.219153\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11415 (step 11415): 1.350988\n",
      "Batch #10\tAverage Generator Loss: 1765.304053\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11416 (step 11416): 1.326663\n",
      "Batch #10\tAverage Generator Loss: 1743.194080\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11417 (step 11417): 1.790777\n",
      "Batch #10\tAverage Generator Loss: 1803.319751\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11418 (step 11418): 1.342278\n",
      "Batch #10\tAverage Generator Loss: 1518.906909\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11419 (step 11419): 1.433188\n",
      "Batch #10\tAverage Generator Loss: 1470.310510\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11420 (step 11420): 1.844139\n",
      "Batch #10\tAverage Generator Loss: 1661.615430\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11421 (step 11421): 1.307375\n",
      "Batch #10\tAverage Generator Loss: 1672.209473\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11422 (step 11422): 1.737693\n",
      "Batch #10\tAverage Generator Loss: 1631.449139\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11423 (step 11423): 1.345963\n",
      "Batch #10\tAverage Generator Loss: 2171.934515\tAverage Discriminator Loss: 1.251410\n",
      "\n",
      "Train time for epoch #11424 (step 11424): 1.300558\n",
      "Batch #10\tAverage Generator Loss: 1986.186554\tAverage Discriminator Loss: 0.002162\n",
      "\n",
      "Train time for epoch #11425 (step 11425): 1.720410\n",
      "Batch #10\tAverage Generator Loss: 2224.883911\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11426 (step 11426): 1.287127\n",
      "Batch #10\tAverage Generator Loss: 1859.624109\tAverage Discriminator Loss: 0.010197\n",
      "\n",
      "Train time for epoch #11427 (step 11427): 1.383053\n",
      "Batch #10\tAverage Generator Loss: 1712.162219\tAverage Discriminator Loss: 0.085025\n",
      "\n",
      "Train time for epoch #11428 (step 11428): 1.707771\n",
      "Batch #10\tAverage Generator Loss: 1761.164526\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11429 (step 11429): 1.442007\n",
      "Batch #10\tAverage Generator Loss: 1685.600952\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11430 (step 11430): 1.885458\n",
      "Batch #10\tAverage Generator Loss: 1513.946140\tAverage Discriminator Loss: 0.004858\n",
      "\n",
      "Train time for epoch #11431 (step 11431): 1.379293\n",
      "Batch #10\tAverage Generator Loss: 1678.694916\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11432 (step 11432): 1.376345\n",
      "Batch #10\tAverage Generator Loss: 1704.444666\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11433 (step 11433): 1.823000\n",
      "Batch #10\tAverage Generator Loss: 1661.506744\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11434 (step 11434): 1.331683\n",
      "Batch #10\tAverage Generator Loss: 1789.704541\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11435 (step 11435): 1.738838\n",
      "Batch #10\tAverage Generator Loss: 1541.927960\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11436 (step 11436): 1.577103\n",
      "Batch #10\tAverage Generator Loss: 1598.973865\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11437 (step 11437): 1.341661\n",
      "Batch #10\tAverage Generator Loss: 1968.334558\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11438 (step 11438): 1.781075\n",
      "Batch #10\tAverage Generator Loss: 1634.336456\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11439 (step 11439): 1.442562\n",
      "Batch #10\tAverage Generator Loss: 1755.771277\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11440 (step 11440): 1.674345\n",
      "Batch #10\tAverage Generator Loss: 1557.805902\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11441 (step 11441): 1.364864\n",
      "Batch #10\tAverage Generator Loss: 1962.584387\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11442 (step 11442): 1.316003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 1651.857916\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11443 (step 11443): 1.713995\n",
      "Batch #10\tAverage Generator Loss: 1824.937744\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11444 (step 11444): 1.515338\n",
      "Batch #10\tAverage Generator Loss: 1669.563263\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11445 (step 11445): 1.655501\n",
      "Batch #10\tAverage Generator Loss: 1905.064063\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11446 (step 11446): 1.393310\n",
      "Batch #10\tAverage Generator Loss: 1539.110828\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11447 (step 11447): 1.300308\n",
      "Batch #10\tAverage Generator Loss: 1642.141290\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11448 (step 11448): 1.868358\n",
      "Batch #10\tAverage Generator Loss: 1607.308606\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11449 (step 11449): 1.334227\n",
      "Batch #10\tAverage Generator Loss: 1743.604370\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11450 (step 11450): 1.294976\n",
      "Batch #10\tAverage Generator Loss: 1838.233710\tAverage Discriminator Loss: 0.000035\n",
      "\n",
      "Train time for epoch #11451 (step 11451): 1.819274\n",
      "Batch #10\tAverage Generator Loss: 1630.872980\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11452 (step 11452): 1.294169\n",
      "Batch #10\tAverage Generator Loss: 1755.545667\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11453 (step 11453): 1.760494\n",
      "Batch #10\tAverage Generator Loss: 1671.810925\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11454 (step 11454): 1.550470\n",
      "Batch #10\tAverage Generator Loss: 1727.313733\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11455 (step 11455): 1.343708\n",
      "Batch #10\tAverage Generator Loss: 1550.672302\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11456 (step 11456): 1.675828\n",
      "Batch #10\tAverage Generator Loss: 1742.599841\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11457 (step 11457): 1.437203\n",
      "Batch #10\tAverage Generator Loss: 1794.241785\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11458 (step 11458): 1.623763\n",
      "Batch #10\tAverage Generator Loss: 1559.148761\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11459 (step 11459): 1.243285\n",
      "Batch #10\tAverage Generator Loss: 1855.642157\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11460 (step 11460): 1.344718\n",
      "Batch #10\tAverage Generator Loss: 1787.948230\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11461 (step 11461): 1.693533\n",
      "Batch #10\tAverage Generator Loss: 1614.093335\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11462 (step 11462): 1.399642\n",
      "Batch #10\tAverage Generator Loss: 1732.727020\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11463 (step 11463): 1.340798\n",
      "Batch #10\tAverage Generator Loss: 1719.598230\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11464 (step 11464): 1.782073\n",
      "Batch #10\tAverage Generator Loss: 1645.242096\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11465 (step 11465): 1.337683\n",
      "Batch #10\tAverage Generator Loss: 1869.422839\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11466 (step 11466): 1.681211\n",
      "Batch #10\tAverage Generator Loss: 1697.249200\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11467 (step 11467): 1.295550\n",
      "Batch #10\tAverage Generator Loss: 1851.644666\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11468 (step 11468): 1.241951\n",
      "Batch #10\tAverage Generator Loss: 1853.397351\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11469 (step 11469): 1.775936\n",
      "Batch #10\tAverage Generator Loss: 1712.633295\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11470 (step 11470): 1.338624\n",
      "Batch #10\tAverage Generator Loss: 1810.804016\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11471 (step 11471): 1.743276\n",
      "Batch #10\tAverage Generator Loss: 1742.376306\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11472 (step 11472): 1.281108\n",
      "Batch #10\tAverage Generator Loss: 1838.627509\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11473 (step 11473): 1.309848\n",
      "Batch #10\tAverage Generator Loss: 1972.448621\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11474 (step 11474): 1.713566\n",
      "Batch #10\tAverage Generator Loss: 1724.038367\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11475 (step 11475): 1.298809\n",
      "Batch #10\tAverage Generator Loss: 1686.860620\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11476 (step 11476): 1.729245\n",
      "Batch #10\tAverage Generator Loss: 1711.299890\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11477 (step 11477): 1.457417\n",
      "Batch #10\tAverage Generator Loss: 1743.001233\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11478 (step 11478): 1.343490\n",
      "Batch #10\tAverage Generator Loss: 1514.059711\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11479 (step 11479): 1.646452\n",
      "Batch #10\tAverage Generator Loss: 1861.219165\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11480 (step 11480): 1.244174\n",
      "Batch #10\tAverage Generator Loss: 1829.531934\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11481 (step 11481): 1.777825\n",
      "Batch #10\tAverage Generator Loss: 1881.201526\tAverage Discriminator Loss: 0.003409\n",
      "\n",
      "Train time for epoch #11482 (step 11482): 1.331785\n",
      "Batch #10\tAverage Generator Loss: 1782.928394\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11483 (step 11483): 1.346219\n",
      "Batch #10\tAverage Generator Loss: 1802.857806\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11484 (step 11484): 1.663304\n",
      "Batch #10\tAverage Generator Loss: 1689.584888\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11485 (step 11485): 1.339264\n",
      "Batch #10\tAverage Generator Loss: 1893.662146\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11486 (step 11486): 1.360057\n",
      "Batch #10\tAverage Generator Loss: 1712.190387\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11487 (step 11487): 1.741028\n",
      "Batch #10\tAverage Generator Loss: 1555.908643\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11488 (step 11488): 1.297266\n",
      "Batch #10\tAverage Generator Loss: 1696.707642\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11489 (step 11489): 1.765389\n",
      "Batch #10\tAverage Generator Loss: 1727.150024\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11490 (step 11490): 1.255311\n",
      "Batch #10\tAverage Generator Loss: 1583.814221\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11491 (step 11491): 1.303353\n",
      "Batch #10\tAverage Generator Loss: 1778.441608\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11492 (step 11492): 1.765250\n",
      "Batch #10\tAverage Generator Loss: 1579.174854\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11493 (step 11493): 1.450044\n",
      "Batch #10\tAverage Generator Loss: 1847.728381\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11494 (step 11494): 1.794277\n",
      "Batch #10\tAverage Generator Loss: 1611.191199\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11495 (step 11495): 1.394339\n",
      "Batch #10\tAverage Generator Loss: 1729.771796\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11496 (step 11496): 1.359032\n",
      "Batch #10\tAverage Generator Loss: 1868.980829\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11497 (step 11497): 1.773791\n",
      "Batch #10\tAverage Generator Loss: 1634.365558\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11498 (step 11498): 1.333814\n",
      "Batch #10\tAverage Generator Loss: 1905.670221\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11499 (step 11499): 1.731577\n",
      "Batch #10\tAverage Generator Loss: 1550.142853\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11500 (step 11500): 1.289522\n",
      "Batch #10\tAverage Generator Loss: 1649.029944\tAverage Discriminator Loss: 0.132906\n",
      "\n",
      "Train time for epoch #11501 (step 11501): 1.323830\n",
      "Batch #10\tAverage Generator Loss: 1749.592938\tAverage Discriminator Loss: 0.249487\n",
      "\n",
      "Train time for epoch #11502 (step 11502): 1.746130\n",
      "Batch #10\tAverage Generator Loss: 1668.174365\tAverage Discriminator Loss: 0.000027\n",
      "\n",
      "Train time for epoch #11503 (step 11503): 1.361508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 1752.373499\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11504 (step 11504): 1.762165\n",
      "Batch #10\tAverage Generator Loss: 1569.191241\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11505 (step 11505): 1.331481\n",
      "Batch #10\tAverage Generator Loss: 1695.477515\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11506 (step 11506): 1.345925\n",
      "Batch #10\tAverage Generator Loss: 2046.312854\tAverage Discriminator Loss: 0.023854\n",
      "\n",
      "Train time for epoch #11507 (step 11507): 1.683807\n",
      "Batch #10\tAverage Generator Loss: 2022.280518\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11508 (step 11508): 1.429301\n",
      "Batch #10\tAverage Generator Loss: 2583.261926\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11509 (step 11509): 1.632672\n",
      "Batch #10\tAverage Generator Loss: 2006.391589\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11510 (step 11510): 1.353663\n",
      "Batch #10\tAverage Generator Loss: 2109.762726\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11511 (step 11511): 1.424626\n",
      "Batch #10\tAverage Generator Loss: 1992.578064\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11512 (step 11512): 1.752306\n",
      "Batch #10\tAverage Generator Loss: 1911.895709\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11513 (step 11513): 1.380613\n",
      "Batch #10\tAverage Generator Loss: 2055.024622\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11514 (step 11514): 1.307945\n",
      "Batch #10\tAverage Generator Loss: 2108.491333\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11515 (step 11515): 1.686668\n",
      "Batch #10\tAverage Generator Loss: 2049.836230\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11516 (step 11516): 1.291458\n",
      "Batch #10\tAverage Generator Loss: 1984.265649\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11517 (step 11517): 1.664785\n",
      "Batch #10\tAverage Generator Loss: 1955.760602\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11518 (step 11518): 1.241411\n",
      "Batch #10\tAverage Generator Loss: 1904.014001\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11519 (step 11519): 1.290192\n",
      "Batch #10\tAverage Generator Loss: 2219.455383\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11520 (step 11520): 1.729751\n",
      "Batch #10\tAverage Generator Loss: 1982.466382\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11521 (step 11521): 1.295446\n",
      "Batch #10\tAverage Generator Loss: 2110.926477\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11522 (step 11522): 1.665900\n",
      "Batch #10\tAverage Generator Loss: 2206.490363\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11523 (step 11523): 1.399666\n",
      "Batch #10\tAverage Generator Loss: 1825.376697\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11524 (step 11524): 1.393002\n",
      "Batch #10\tAverage Generator Loss: 1774.088300\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11525 (step 11525): 1.642166\n",
      "Batch #10\tAverage Generator Loss: 2175.678613\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11526 (step 11526): 1.404640\n",
      "Batch #10\tAverage Generator Loss: 2117.934204\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11527 (step 11527): 1.727619\n",
      "Batch #10\tAverage Generator Loss: 2054.096124\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11528 (step 11528): 1.392191\n",
      "Batch #10\tAverage Generator Loss: 2030.107043\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11529 (step 11529): 1.285039\n",
      "Batch #10\tAverage Generator Loss: 2035.952075\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11530 (step 11530): 1.690046\n",
      "Batch #10\tAverage Generator Loss: 1875.902429\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11531 (step 11531): 1.337980\n",
      "Batch #10\tAverage Generator Loss: 1845.979443\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11532 (step 11532): 1.342848\n",
      "Batch #10\tAverage Generator Loss: 1935.028534\tAverage Discriminator Loss: 0.010329\n",
      "\n",
      "Train time for epoch #11533 (step 11533): 1.829874\n",
      "Batch #10\tAverage Generator Loss: 1950.966077\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11534 (step 11534): 1.341186\n",
      "Batch #10\tAverage Generator Loss: 2113.181134\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11535 (step 11535): 1.727629\n",
      "Batch #10\tAverage Generator Loss: 1968.167365\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11536 (step 11536): 1.344759\n",
      "Batch #10\tAverage Generator Loss: 2066.770691\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11537 (step 11537): 1.434289\n",
      "Batch #10\tAverage Generator Loss: 1990.542694\tAverage Discriminator Loss: 0.024255\n",
      "\n",
      "Train time for epoch #11538 (step 11538): 1.733322\n",
      "Batch #10\tAverage Generator Loss: 2068.156439\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11539 (step 11539): 1.292532\n",
      "Batch #10\tAverage Generator Loss: 1867.864056\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11540 (step 11540): 1.660208\n",
      "Batch #10\tAverage Generator Loss: 1815.213062\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11541 (step 11541): 1.426674\n",
      "Batch #10\tAverage Generator Loss: 2012.637390\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11542 (step 11542): 1.296651\n",
      "Batch #10\tAverage Generator Loss: 1950.989380\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11543 (step 11543): 1.806699\n",
      "Batch #10\tAverage Generator Loss: 1593.161731\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11544 (step 11544): 1.287118\n",
      "Batch #10\tAverage Generator Loss: 1954.777686\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11545 (step 11545): 1.337781\n",
      "Batch #10\tAverage Generator Loss: 2153.379010\tAverage Discriminator Loss: 0.005972\n",
      "\n",
      "Train time for epoch #11546 (step 11546): 1.815549\n",
      "Batch #10\tAverage Generator Loss: 1825.340302\tAverage Discriminator Loss: 0.000132\n",
      "\n",
      "Train time for epoch #11547 (step 11547): 1.292494\n",
      "Batch #10\tAverage Generator Loss: 1981.831079\tAverage Discriminator Loss: 0.000025\n",
      "\n",
      "Train time for epoch #11548 (step 11548): 1.796820\n",
      "Batch #10\tAverage Generator Loss: 2075.700085\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #11549 (step 11549): 1.303092\n",
      "Batch #10\tAverage Generator Loss: 2071.000610\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #11550 (step 11550): 1.391009\n",
      "Batch #10\tAverage Generator Loss: 1917.872595\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #11551 (step 11551): 1.783816\n",
      "Batch #10\tAverage Generator Loss: 2000.038171\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #11552 (step 11552): 1.343328\n",
      "Batch #10\tAverage Generator Loss: 1879.474384\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #11553 (step 11553): 1.786338\n",
      "Batch #10\tAverage Generator Loss: 2096.154163\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #11554 (step 11554): 1.296550\n",
      "Batch #10\tAverage Generator Loss: 1945.134198\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #11555 (step 11555): 1.393690\n",
      "Batch #10\tAverage Generator Loss: 1895.881287\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #11556 (step 11556): 1.697422\n",
      "Batch #10\tAverage Generator Loss: 1862.114355\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #11557 (step 11557): 1.346136\n",
      "Batch #10\tAverage Generator Loss: 2217.691016\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #11558 (step 11558): 1.401380\n",
      "Batch #10\tAverage Generator Loss: 2001.974646\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #11559 (step 11559): 1.703200\n",
      "Batch #10\tAverage Generator Loss: 1800.976062\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #11560 (step 11560): 1.299418\n",
      "Batch #10\tAverage Generator Loss: 1996.338049\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #11561 (step 11561): 1.761998\n",
      "Batch #10\tAverage Generator Loss: 2270.342346\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11562 (step 11562): 1.285058\n",
      "Batch #10\tAverage Generator Loss: 1945.345667\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #11563 (step 11563): 1.294934\n",
      "Batch #10\tAverage Generator Loss: 1873.716589\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11564 (step 11564): 1.625044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 1913.767767\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11565 (step 11565): 1.341615\n",
      "Batch #10\tAverage Generator Loss: 2031.779297\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11566 (step 11566): 1.714454\n",
      "Batch #10\tAverage Generator Loss: 2095.882037\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11567 (step 11567): 1.394912\n",
      "Batch #10\tAverage Generator Loss: 2025.527985\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11568 (step 11568): 1.395426\n",
      "Batch #10\tAverage Generator Loss: 1794.960559\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11569 (step 11569): 1.676975\n",
      "Batch #10\tAverage Generator Loss: 1971.757074\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11570 (step 11570): 1.333788\n",
      "Batch #10\tAverage Generator Loss: 2062.915076\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11571 (step 11571): 1.746865\n",
      "Batch #10\tAverage Generator Loss: 1956.857275\tAverage Discriminator Loss: 0.008342\n",
      "\n",
      "Train time for epoch #11572 (step 11572): 1.293791\n",
      "Batch #10\tAverage Generator Loss: 1937.737097\tAverage Discriminator Loss: 0.000057\n",
      "\n",
      "Train time for epoch #11573 (step 11573): 1.448081\n",
      "Batch #10\tAverage Generator Loss: 2020.507202\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #11574 (step 11574): 1.646222\n",
      "Batch #10\tAverage Generator Loss: 2115.346179\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #11575 (step 11575): 1.463378\n",
      "Batch #10\tAverage Generator Loss: 1942.124399\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #11576 (step 11576): 1.678331\n",
      "Batch #10\tAverage Generator Loss: 2052.117407\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #11577 (step 11577): 1.327928\n",
      "Batch #10\tAverage Generator Loss: 1953.566895\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11578 (step 11578): 1.382408\n",
      "Batch #10\tAverage Generator Loss: 1760.008734\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #11579 (step 11579): 1.792655\n",
      "Batch #10\tAverage Generator Loss: 1871.049585\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #11580 (step 11580): 1.350088\n",
      "Batch #10\tAverage Generator Loss: 1923.510413\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11581 (step 11581): 1.391396\n",
      "Batch #10\tAverage Generator Loss: 1868.937683\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11582 (step 11582): 1.689119\n",
      "Batch #10\tAverage Generator Loss: 1922.561536\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11583 (step 11583): 1.325703\n",
      "Batch #10\tAverage Generator Loss: 1994.590637\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #11584 (step 11584): 1.838051\n",
      "Batch #10\tAverage Generator Loss: 1826.082922\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #11585 (step 11585): 1.240943\n",
      "Batch #10\tAverage Generator Loss: 1917.830298\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #11586 (step 11586): 1.436717\n",
      "Batch #10\tAverage Generator Loss: 1799.014880\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #11587 (step 11587): 1.791879\n",
      "Batch #10\tAverage Generator Loss: 1671.861493\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #11588 (step 11588): 1.334552\n",
      "Batch #10\tAverage Generator Loss: 2079.145142\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11589 (step 11589): 1.465992\n",
      "Batch #10\tAverage Generator Loss: 1947.943951\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11590 (step 11590): 1.735525\n",
      "Batch #10\tAverage Generator Loss: 1894.983533\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11591 (step 11591): 1.281855\n",
      "Batch #10\tAverage Generator Loss: 1941.474255\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11592 (step 11592): 1.763642\n",
      "Batch #10\tAverage Generator Loss: 1908.355371\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11593 (step 11593): 1.275105\n",
      "Batch #10\tAverage Generator Loss: 1945.423682\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11594 (step 11594): 1.247854\n",
      "Batch #10\tAverage Generator Loss: 1755.767017\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11595 (step 11595): 1.749941\n",
      "Batch #10\tAverage Generator Loss: 1948.974585\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11596 (step 11596): 1.282829\n",
      "Batch #10\tAverage Generator Loss: 1977.793164\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11597 (step 11597): 1.678602\n",
      "Batch #10\tAverage Generator Loss: 1930.278247\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11598 (step 11598): 1.411962\n",
      "Batch #10\tAverage Generator Loss: 1789.482202\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11599 (step 11599): 1.285835\n",
      "Batch #10\tAverage Generator Loss: 2088.270312\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11600 (step 11600): 1.714433\n",
      "Batch #10\tAverage Generator Loss: 1942.631543\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11601 (step 11601): 1.417510\n",
      "Batch #10\tAverage Generator Loss: 1896.827539\tAverage Discriminator Loss: 0.019171\n",
      "\n",
      "Train time for epoch #11602 (step 11602): 1.534386\n",
      "Batch #10\tAverage Generator Loss: 1749.781097\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11603 (step 11603): 1.658417\n",
      "Batch #10\tAverage Generator Loss: 1961.147656\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11604 (step 11604): 1.310021\n",
      "Batch #10\tAverage Generator Loss: 1795.164398\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11605 (step 11605): 1.735413\n",
      "Batch #10\tAverage Generator Loss: 1929.109863\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11606 (step 11606): 1.282171\n",
      "Batch #10\tAverage Generator Loss: 2012.558014\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11607 (step 11607): 1.293527\n",
      "Batch #10\tAverage Generator Loss: 2105.495624\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11608 (step 11608): 1.776271\n",
      "Batch #10\tAverage Generator Loss: 2033.432043\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11609 (step 11609): 1.358293\n",
      "Batch #10\tAverage Generator Loss: 1858.728473\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11610 (step 11610): 1.866099\n",
      "Batch #10\tAverage Generator Loss: 2061.184509\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11611 (step 11611): 1.321049\n",
      "Batch #10\tAverage Generator Loss: 1998.132678\tAverage Discriminator Loss: 0.000954\n",
      "\n",
      "Train time for epoch #11612 (step 11612): 1.393384\n",
      "Batch #10\tAverage Generator Loss: 1834.210767\tAverage Discriminator Loss: 0.000207\n",
      "\n",
      "Train time for epoch #11613 (step 11613): 1.807374\n",
      "Batch #10\tAverage Generator Loss: 2016.237238\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #11614 (step 11614): 1.296572\n",
      "Batch #10\tAverage Generator Loss: 1623.745685\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11615 (step 11615): 1.392281\n",
      "Batch #10\tAverage Generator Loss: 1970.717029\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11616 (step 11616): 1.734701\n",
      "Batch #10\tAverage Generator Loss: 1813.624512\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11617 (step 11617): 1.333200\n",
      "Batch #10\tAverage Generator Loss: 1963.244702\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11618 (step 11618): 1.697255\n",
      "Batch #10\tAverage Generator Loss: 2051.035400\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11619 (step 11619): 1.340642\n",
      "Batch #10\tAverage Generator Loss: 2004.396680\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11620 (step 11620): 1.290783\n",
      "Batch #10\tAverage Generator Loss: 1782.974792\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11621 (step 11621): 1.639982\n",
      "Batch #10\tAverage Generator Loss: 1875.369543\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11622 (step 11622): 1.440276\n",
      "Batch #10\tAverage Generator Loss: 1610.547992\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11623 (step 11623): 1.258528\n",
      "Batch #10\tAverage Generator Loss: 1787.264655\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11624 (step 11624): 1.694389\n",
      "Batch #10\tAverage Generator Loss: 1865.494739\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11625 (step 11625): 1.430305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 1918.821411\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11626 (step 11626): 1.770763\n",
      "Batch #10\tAverage Generator Loss: 1528.814508\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11627 (step 11627): 1.291982\n",
      "Batch #10\tAverage Generator Loss: 2013.420081\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11628 (step 11628): 1.290616\n",
      "Batch #10\tAverage Generator Loss: 1761.680231\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11629 (step 11629): 1.789907\n",
      "Batch #10\tAverage Generator Loss: 1857.502942\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11630 (step 11630): 1.324540\n",
      "Batch #10\tAverage Generator Loss: 1721.984564\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11631 (step 11631): 1.710712\n",
      "Batch #10\tAverage Generator Loss: 1871.342426\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11632 (step 11632): 1.348883\n",
      "Batch #10\tAverage Generator Loss: 1978.033276\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11633 (step 11633): 1.301837\n",
      "Batch #10\tAverage Generator Loss: 1705.735754\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11634 (step 11634): 1.786931\n",
      "Batch #10\tAverage Generator Loss: 1778.994775\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11635 (step 11635): 1.439348\n",
      "Batch #10\tAverage Generator Loss: 1750.305994\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11636 (step 11636): 1.369629\n",
      "Batch #10\tAverage Generator Loss: 1981.698926\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #11637 (step 11637): 1.742213\n",
      "Batch #10\tAverage Generator Loss: 1974.626135\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #11638 (step 11638): 1.494984\n",
      "Batch #10\tAverage Generator Loss: 1824.277527\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11639 (step 11639): 1.726235\n",
      "Batch #10\tAverage Generator Loss: 1860.720618\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11640 (step 11640): 1.241747\n",
      "Batch #10\tAverage Generator Loss: 1898.215204\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11641 (step 11641): 1.345347\n",
      "Batch #10\tAverage Generator Loss: 1709.487225\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11642 (step 11642): 1.781365\n",
      "Batch #10\tAverage Generator Loss: 1943.967108\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11643 (step 11643): 1.295562\n",
      "Batch #10\tAverage Generator Loss: 1937.039807\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11644 (step 11644): 1.677215\n",
      "Batch #10\tAverage Generator Loss: 2030.533264\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11645 (step 11645): 1.344171\n",
      "Batch #10\tAverage Generator Loss: 2074.608459\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11646 (step 11646): 1.287785\n",
      "Batch #10\tAverage Generator Loss: 1971.491394\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11647 (step 11647): 1.762322\n",
      "Batch #10\tAverage Generator Loss: 1971.352576\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11648 (step 11648): 1.357613\n",
      "Batch #10\tAverage Generator Loss: 1416.258551\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11649 (step 11649): 1.249681\n",
      "Batch #10\tAverage Generator Loss: 2054.798486\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11650 (step 11650): 1.709130\n",
      "Batch #10\tAverage Generator Loss: 1821.459460\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11651 (step 11651): 1.249901\n",
      "Batch #10\tAverage Generator Loss: 1840.709094\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11652 (step 11652): 1.661518\n",
      "Batch #10\tAverage Generator Loss: 1905.898035\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11653 (step 11653): 1.371254\n",
      "Batch #10\tAverage Generator Loss: 1964.861725\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11654 (step 11654): 1.439525\n",
      "Batch #10\tAverage Generator Loss: 1726.220801\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11655 (step 11655): 1.728634\n",
      "Batch #10\tAverage Generator Loss: 1925.822681\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11656 (step 11656): 1.289395\n",
      "Batch #10\tAverage Generator Loss: 2043.091602\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #11657 (step 11657): 1.718326\n",
      "Batch #10\tAverage Generator Loss: 1895.972913\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11658 (step 11658): 1.355437\n",
      "Batch #10\tAverage Generator Loss: 2048.300616\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11659 (step 11659): 1.231333\n",
      "Batch #10\tAverage Generator Loss: 1654.901678\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11660 (step 11660): 1.758957\n",
      "Batch #10\tAverage Generator Loss: 1797.309656\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11661 (step 11661): 1.332432\n",
      "Batch #10\tAverage Generator Loss: 1941.470557\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11662 (step 11662): 1.282704\n",
      "Batch #10\tAverage Generator Loss: 1904.993579\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11663 (step 11663): 1.791495\n",
      "Batch #10\tAverage Generator Loss: 1998.689990\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11664 (step 11664): 1.335980\n",
      "Batch #10\tAverage Generator Loss: 2184.831677\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11665 (step 11665): 1.689768\n",
      "Batch #10\tAverage Generator Loss: 1885.327148\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11666 (step 11666): 1.245258\n",
      "Batch #10\tAverage Generator Loss: 1793.413098\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11667 (step 11667): 1.471135\n",
      "Batch #10\tAverage Generator Loss: 1941.451050\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11668 (step 11668): 1.682875\n",
      "Batch #10\tAverage Generator Loss: 1822.064917\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11669 (step 11669): 1.282102\n",
      "Batch #10\tAverage Generator Loss: 1930.822327\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11670 (step 11670): 1.276846\n",
      "Batch #10\tAverage Generator Loss: 1863.854883\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11671 (step 11671): 1.692296\n",
      "Batch #10\tAverage Generator Loss: 1735.872546\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11672 (step 11672): 1.321949\n",
      "Batch #10\tAverage Generator Loss: 1569.143219\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11673 (step 11673): 1.695646\n",
      "Batch #10\tAverage Generator Loss: 1811.770660\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11674 (step 11674): 1.330141\n",
      "Batch #10\tAverage Generator Loss: 1838.256506\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11675 (step 11675): 1.420387\n",
      "Batch #10\tAverage Generator Loss: 2029.680396\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11676 (step 11676): 1.751739\n",
      "Batch #10\tAverage Generator Loss: 1969.285962\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11677 (step 11677): 1.296109\n",
      "Batch #10\tAverage Generator Loss: 2000.590918\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11678 (step 11678): 1.678461\n",
      "Batch #10\tAverage Generator Loss: 1911.529822\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11679 (step 11679): 1.352583\n",
      "Batch #10\tAverage Generator Loss: 1838.171338\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11680 (step 11680): 1.279326\n",
      "Batch #10\tAverage Generator Loss: 1965.337030\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11681 (step 11681): 1.789239\n",
      "Batch #10\tAverage Generator Loss: 2078.996765\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11682 (step 11682): 1.292368\n",
      "Batch #10\tAverage Generator Loss: 1876.533557\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11683 (step 11683): 1.374903\n",
      "Batch #10\tAverage Generator Loss: 1886.502039\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11684 (step 11684): 1.651186\n",
      "Batch #10\tAverage Generator Loss: 1932.711401\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11685 (step 11685): 1.336781\n",
      "Batch #10\tAverage Generator Loss: 1853.425220\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11686 (step 11686): 1.711388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 1980.410400\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11687 (step 11687): 1.357596\n",
      "Batch #10\tAverage Generator Loss: 1884.240479\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11688 (step 11688): 1.337366\n",
      "Batch #10\tAverage Generator Loss: 1868.301538\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11689 (step 11689): 1.711345\n",
      "Batch #10\tAverage Generator Loss: 1770.582739\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11690 (step 11690): 1.407776\n",
      "Batch #10\tAverage Generator Loss: 2012.464026\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11691 (step 11691): 1.744291\n",
      "Batch #10\tAverage Generator Loss: 1808.637012\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11692 (step 11692): 1.291540\n",
      "Batch #10\tAverage Generator Loss: 1799.254126\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11693 (step 11693): 1.340650\n",
      "Batch #10\tAverage Generator Loss: 1878.273358\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11694 (step 11694): 1.646453\n",
      "Batch #10\tAverage Generator Loss: 2033.542920\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11695 (step 11695): 1.369893\n",
      "Batch #10\tAverage Generator Loss: 2117.546191\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11696 (step 11696): 1.722646\n",
      "Batch #10\tAverage Generator Loss: 1994.356836\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11697 (step 11697): 1.301616\n",
      "Batch #10\tAverage Generator Loss: 1754.642224\tAverage Discriminator Loss: 0.001195\n",
      "\n",
      "Train time for epoch #11698 (step 11698): 1.285447\n",
      "Batch #10\tAverage Generator Loss: 1871.403955\tAverage Discriminator Loss: 0.000040\n",
      "\n",
      "Train time for epoch #11699 (step 11699): 1.659519\n",
      "Batch #10\tAverage Generator Loss: 1652.725067\tAverage Discriminator Loss: 0.000029\n",
      "\n",
      "Train time for epoch #11700 (step 11700): 1.365831\n",
      "Batch #10\tAverage Generator Loss: 1956.776556\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #11701 (step 11701): 1.691891\n",
      "Batch #10\tAverage Generator Loss: 1928.893225\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #11702 (step 11702): 1.279305\n",
      "Batch #10\tAverage Generator Loss: 2004.381702\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #11703 (step 11703): 1.241617\n",
      "Batch #10\tAverage Generator Loss: 1929.368542\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #11704 (step 11704): 1.746715\n",
      "Batch #10\tAverage Generator Loss: 2000.903760\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11705 (step 11705): 1.332181\n",
      "Batch #10\tAverage Generator Loss: 1873.668311\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #11706 (step 11706): 1.694441\n",
      "Batch #10\tAverage Generator Loss: 1884.819324\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11707 (step 11707): 1.332412\n",
      "Batch #10\tAverage Generator Loss: 2047.753503\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11708 (step 11708): 1.291122\n",
      "Batch #10\tAverage Generator Loss: 1619.334229\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11709 (step 11709): 1.740853\n",
      "Batch #10\tAverage Generator Loss: 1923.803821\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11710 (step 11710): 1.255739\n",
      "Batch #10\tAverage Generator Loss: 2074.474170\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11711 (step 11711): 1.464775\n",
      "Batch #10\tAverage Generator Loss: 1969.099707\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11712 (step 11712): 1.734641\n",
      "Batch #10\tAverage Generator Loss: 1863.004126\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11713 (step 11713): 1.296955\n",
      "Batch #10\tAverage Generator Loss: 1863.525525\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11714 (step 11714): 1.695556\n",
      "Batch #10\tAverage Generator Loss: 1922.902942\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11715 (step 11715): 1.296847\n",
      "Batch #10\tAverage Generator Loss: 1880.858136\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11716 (step 11716): 1.314947\n",
      "Batch #10\tAverage Generator Loss: 1918.950122\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11717 (step 11717): 1.784421\n",
      "Batch #10\tAverage Generator Loss: 1751.905145\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11718 (step 11718): 1.290534\n",
      "Batch #10\tAverage Generator Loss: 1886.579602\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11719 (step 11719): 1.251438\n",
      "Batch #10\tAverage Generator Loss: 1858.516351\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11720 (step 11720): 1.663841\n",
      "Batch #10\tAverage Generator Loss: 1882.907495\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11721 (step 11721): 1.422059\n",
      "Batch #10\tAverage Generator Loss: 1755.979059\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11722 (step 11722): 1.671316\n",
      "Batch #10\tAverage Generator Loss: 1983.685437\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11723 (step 11723): 1.321838\n",
      "Batch #10\tAverage Generator Loss: 1745.887292\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11724 (step 11724): 1.411533\n",
      "Batch #10\tAverage Generator Loss: 1839.498889\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11725 (step 11725): 1.706944\n",
      "Batch #10\tAverage Generator Loss: 1986.811023\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11726 (step 11726): 1.330785\n",
      "Batch #10\tAverage Generator Loss: 2107.212744\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11727 (step 11727): 1.346488\n",
      "Batch #10\tAverage Generator Loss: 1925.747473\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11728 (step 11728): 1.752645\n",
      "Batch #10\tAverage Generator Loss: 1661.230182\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11729 (step 11729): 1.399392\n",
      "Batch #10\tAverage Generator Loss: 1843.390430\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11730 (step 11730): 1.672922\n",
      "Batch #10\tAverage Generator Loss: 1778.935919\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11731 (step 11731): 1.349092\n",
      "Batch #10\tAverage Generator Loss: 2065.097156\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11732 (step 11732): 1.376329\n",
      "Batch #10\tAverage Generator Loss: 2012.068811\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11733 (step 11733): 1.620583\n",
      "Batch #10\tAverage Generator Loss: 1729.912378\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11734 (step 11734): 1.353798\n",
      "Batch #10\tAverage Generator Loss: 1680.170239\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11735 (step 11735): 1.756441\n",
      "Batch #10\tAverage Generator Loss: 1671.277295\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11736 (step 11736): 1.296210\n",
      "Batch #10\tAverage Generator Loss: 1864.057898\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11737 (step 11737): 1.286981\n",
      "Batch #10\tAverage Generator Loss: 1675.079550\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11738 (step 11738): 1.725957\n",
      "Batch #10\tAverage Generator Loss: 1740.145306\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11739 (step 11739): 1.405035\n",
      "Batch #10\tAverage Generator Loss: 1943.363098\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11740 (step 11740): 1.280460\n",
      "Batch #10\tAverage Generator Loss: 1800.601697\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11741 (step 11741): 1.710652\n",
      "Batch #10\tAverage Generator Loss: 1798.411505\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11742 (step 11742): 1.293177\n",
      "Batch #10\tAverage Generator Loss: 1859.477783\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11743 (step 11743): 1.730731\n",
      "Batch #10\tAverage Generator Loss: 1942.708826\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11744 (step 11744): 1.281837\n",
      "Batch #10\tAverage Generator Loss: 1937.484955\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11745 (step 11745): 1.498016\n",
      "Batch #10\tAverage Generator Loss: 2074.299707\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11746 (step 11746): 1.703320\n",
      "Batch #10\tAverage Generator Loss: 2131.675378\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11747 (step 11747): 1.337011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 1748.941315\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11748 (step 11748): 1.718489\n",
      "Batch #10\tAverage Generator Loss: 1952.353601\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11749 (step 11749): 1.395696\n",
      "Batch #10\tAverage Generator Loss: 1794.270154\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11750 (step 11750): 1.343499\n",
      "Batch #10\tAverage Generator Loss: 2049.556653\tAverage Discriminator Loss: 0.021386\n",
      "\n",
      "Train time for epoch #11751 (step 11751): 1.756485\n",
      "Batch #10\tAverage Generator Loss: 1865.499725\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11752 (step 11752): 1.246329\n",
      "Batch #10\tAverage Generator Loss: 2165.672571\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11753 (step 11753): 1.441104\n",
      "Batch #10\tAverage Generator Loss: 2040.092450\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11754 (step 11754): 1.701275\n",
      "Batch #10\tAverage Generator Loss: 1818.574213\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11755 (step 11755): 1.428569\n",
      "Batch #10\tAverage Generator Loss: 2159.017139\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11756 (step 11756): 1.737182\n",
      "Batch #10\tAverage Generator Loss: 1972.491785\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11757 (step 11757): 1.279578\n",
      "Batch #10\tAverage Generator Loss: 2066.060785\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11758 (step 11758): 1.345531\n",
      "Batch #10\tAverage Generator Loss: 1998.543140\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11759 (step 11759): 1.658200\n",
      "Batch #10\tAverage Generator Loss: 1843.732556\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11760 (step 11760): 1.347281\n",
      "Batch #10\tAverage Generator Loss: 2023.047266\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11761 (step 11761): 1.760354\n",
      "Batch #10\tAverage Generator Loss: 2169.656238\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11762 (step 11762): 1.388251\n",
      "Batch #10\tAverage Generator Loss: 1964.728918\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11763 (step 11763): 1.345603\n",
      "Batch #10\tAverage Generator Loss: 1824.374976\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11764 (step 11764): 1.705624\n",
      "Batch #10\tAverage Generator Loss: 1894.379657\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11765 (step 11765): 1.302071\n",
      "Batch #10\tAverage Generator Loss: 1776.302673\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11766 (step 11766): 1.299178\n",
      "Batch #10\tAverage Generator Loss: 2128.635400\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11767 (step 11767): 1.694481\n",
      "Batch #10\tAverage Generator Loss: 1882.051132\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11768 (step 11768): 1.301564\n",
      "Batch #10\tAverage Generator Loss: 1840.555176\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11769 (step 11769): 1.685894\n",
      "Batch #10\tAverage Generator Loss: 2051.657617\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11770 (step 11770): 1.326885\n",
      "Batch #10\tAverage Generator Loss: 1886.644019\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11771 (step 11771): 1.472128\n",
      "Batch #10\tAverage Generator Loss: 2136.163586\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11772 (step 11772): 1.660524\n",
      "Batch #10\tAverage Generator Loss: 2317.379150\tAverage Discriminator Loss: 0.020765\n",
      "\n",
      "Train time for epoch #11773 (step 11773): 1.391073\n",
      "Batch #10\tAverage Generator Loss: 2192.710046\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11774 (step 11774): 1.400073\n",
      "Batch #10\tAverage Generator Loss: 2121.909387\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11775 (step 11775): 1.637413\n",
      "Batch #10\tAverage Generator Loss: 1706.086792\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11776 (step 11776): 1.357891\n",
      "Batch #10\tAverage Generator Loss: 2210.060266\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #11777 (step 11777): 1.727351\n",
      "Batch #10\tAverage Generator Loss: 1765.142578\tAverage Discriminator Loss: 0.002274\n",
      "\n",
      "Train time for epoch #11778 (step 11778): 1.295002\n",
      "Batch #10\tAverage Generator Loss: 2090.192371\tAverage Discriminator Loss: 0.000119\n",
      "\n",
      "Train time for epoch #11779 (step 11779): 1.310528\n",
      "Batch #10\tAverage Generator Loss: 1789.321948\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #11780 (step 11780): 1.683586\n",
      "Batch #10\tAverage Generator Loss: 1858.032605\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11781 (step 11781): 1.298178\n",
      "Batch #10\tAverage Generator Loss: 1997.282434\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #11782 (step 11782): 1.272310\n",
      "Batch #10\tAverage Generator Loss: 1953.265869\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #11783 (step 11783): 1.823614\n",
      "Batch #10\tAverage Generator Loss: 1728.581287\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11784 (step 11784): 1.296699\n",
      "Batch #10\tAverage Generator Loss: 1704.582397\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11785 (step 11785): 1.745523\n",
      "Batch #10\tAverage Generator Loss: 1675.222321\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11786 (step 11786): 1.382038\n",
      "Batch #10\tAverage Generator Loss: 1786.379944\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11787 (step 11787): 1.305615\n",
      "Batch #10\tAverage Generator Loss: 1840.183325\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11788 (step 11788): 1.744281\n",
      "Batch #10\tAverage Generator Loss: 1924.483264\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11789 (step 11789): 1.305756\n",
      "Batch #10\tAverage Generator Loss: 1666.352069\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11790 (step 11790): 1.659861\n",
      "Batch #10\tAverage Generator Loss: 2050.909192\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11791 (step 11791): 1.384455\n",
      "Batch #10\tAverage Generator Loss: 1857.233270\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11792 (step 11792): 1.355928\n",
      "Batch #10\tAverage Generator Loss: 1867.261621\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11793 (step 11793): 1.754118\n",
      "Batch #10\tAverage Generator Loss: 2350.849500\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11794 (step 11794): 1.281961\n",
      "Batch #10\tAverage Generator Loss: 1942.354199\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11795 (step 11795): 1.238432\n",
      "Batch #10\tAverage Generator Loss: 2247.405896\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11796 (step 11796): 1.699928\n",
      "Batch #10\tAverage Generator Loss: 1880.624878\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11797 (step 11797): 1.332833\n",
      "Batch #10\tAverage Generator Loss: 1961.280664\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11798 (step 11798): 1.750455\n",
      "Batch #10\tAverage Generator Loss: 1982.941693\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11799 (step 11799): 1.361860\n",
      "Batch #10\tAverage Generator Loss: 2047.718884\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11800 (step 11800): 1.383943\n",
      "Batch #10\tAverage Generator Loss: 1790.620270\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11801 (step 11801): 1.741458\n",
      "Batch #10\tAverage Generator Loss: 1888.399359\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11802 (step 11802): 1.285332\n",
      "Batch #10\tAverage Generator Loss: 1755.730817\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11803 (step 11803): 1.330531\n",
      "Batch #10\tAverage Generator Loss: 1743.225684\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11804 (step 11804): 1.724700\n",
      "Batch #10\tAverage Generator Loss: 1935.884601\tAverage Discriminator Loss: 0.008735\n",
      "\n",
      "Train time for epoch #11805 (step 11805): 1.335010\n",
      "Batch #10\tAverage Generator Loss: 1684.715417\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11806 (step 11806): 1.732450\n",
      "Batch #10\tAverage Generator Loss: 1812.183765\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11807 (step 11807): 1.429163\n",
      "Batch #10\tAverage Generator Loss: 1997.640234\tAverage Discriminator Loss: 0.015930\n",
      "\n",
      "Train time for epoch #11808 (step 11808): 1.404613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 1565.620123\tAverage Discriminator Loss: 0.000393\n",
      "\n",
      "Train time for epoch #11809 (step 11809): 1.658806\n",
      "Batch #10\tAverage Generator Loss: 1702.088702\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11810 (step 11810): 1.361977\n",
      "Batch #10\tAverage Generator Loss: 1724.744379\tAverage Discriminator Loss: 0.006919\n",
      "\n",
      "Train time for epoch #11811 (step 11811): 1.721181\n",
      "Batch #10\tAverage Generator Loss: 1560.201935\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #11812 (step 11812): 1.344256\n",
      "Batch #10\tAverage Generator Loss: 1677.214777\tAverage Discriminator Loss: 0.000025\n",
      "\n",
      "Train time for epoch #11813 (step 11813): 1.291611\n",
      "Batch #10\tAverage Generator Loss: 1914.480981\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #11814 (step 11814): 1.690788\n",
      "Batch #10\tAverage Generator Loss: 1669.416180\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #11815 (step 11815): 1.391394\n",
      "Batch #10\tAverage Generator Loss: 1692.051202\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #11816 (step 11816): 1.773101\n",
      "Batch #10\tAverage Generator Loss: 1755.729645\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #11817 (step 11817): 1.286851\n",
      "Batch #10\tAverage Generator Loss: 1811.636707\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #11818 (step 11818): 1.276845\n",
      "Batch #10\tAverage Generator Loss: 1754.572742\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11819 (step 11819): 1.748698\n",
      "Batch #10\tAverage Generator Loss: 1693.577130\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11820 (step 11820): 1.303981\n",
      "Batch #10\tAverage Generator Loss: 1666.607483\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11821 (step 11821): 1.741708\n",
      "Batch #10\tAverage Generator Loss: 1639.075983\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11822 (step 11822): 1.284834\n",
      "Batch #10\tAverage Generator Loss: 1687.199316\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11823 (step 11823): 1.386863\n",
      "Batch #10\tAverage Generator Loss: 1738.518951\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #11824 (step 11824): 1.863460\n",
      "Batch #10\tAverage Generator Loss: 1818.460297\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11825 (step 11825): 1.336878\n",
      "Batch #10\tAverage Generator Loss: 1519.069846\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11826 (step 11826): 1.413663\n",
      "Batch #10\tAverage Generator Loss: 1541.629095\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11827 (step 11827): 1.715483\n",
      "Batch #10\tAverage Generator Loss: 1690.991455\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11828 (step 11828): 1.480625\n",
      "Batch #10\tAverage Generator Loss: 1892.936694\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11829 (step 11829): 1.760417\n",
      "Batch #10\tAverage Generator Loss: 1735.196149\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11830 (step 11830): 1.281333\n",
      "Batch #10\tAverage Generator Loss: 1401.867313\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11831 (step 11831): 1.438297\n",
      "Batch #10\tAverage Generator Loss: 1881.315723\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #11832 (step 11832): 1.891497\n",
      "Batch #10\tAverage Generator Loss: 1416.539941\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11833 (step 11833): 1.425444\n",
      "Batch #10\tAverage Generator Loss: 1741.204773\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11834 (step 11834): 1.298342\n",
      "Batch #10\tAverage Generator Loss: 1900.721973\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11835 (step 11835): 1.753046\n",
      "Batch #10\tAverage Generator Loss: 1650.233569\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11836 (step 11836): 1.351504\n",
      "Batch #10\tAverage Generator Loss: 1814.596521\tAverage Discriminator Loss: 0.000784\n",
      "\n",
      "Train time for epoch #11837 (step 11837): 1.675821\n",
      "Batch #10\tAverage Generator Loss: 1890.162683\tAverage Discriminator Loss: 0.000050\n",
      "\n",
      "Train time for epoch #11838 (step 11838): 1.367750\n",
      "Batch #10\tAverage Generator Loss: 2441.905029\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11839 (step 11839): 1.287518\n",
      "Batch #10\tAverage Generator Loss: 2167.151215\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11840 (step 11840): 1.794119\n",
      "Batch #10\tAverage Generator Loss: 2380.790866\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11841 (step 11841): 1.292381\n",
      "Batch #10\tAverage Generator Loss: 2462.346118\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11842 (step 11842): 1.342834\n",
      "Batch #10\tAverage Generator Loss: 2533.765210\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11843 (step 11843): 1.671807\n",
      "Batch #10\tAverage Generator Loss: 2357.389893\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11844 (step 11844): 1.340647\n",
      "Batch #10\tAverage Generator Loss: 2306.068188\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11845 (step 11845): 1.783702\n",
      "Batch #10\tAverage Generator Loss: 2349.480823\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11846 (step 11846): 1.291530\n",
      "Batch #10\tAverage Generator Loss: 2263.195782\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11847 (step 11847): 1.295275\n",
      "Batch #10\tAverage Generator Loss: 2411.198120\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11848 (step 11848): 1.786983\n",
      "Batch #10\tAverage Generator Loss: 2294.786707\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11849 (step 11849): 1.407745\n",
      "Batch #10\tAverage Generator Loss: 2492.495728\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11850 (step 11850): 1.829866\n",
      "Batch #10\tAverage Generator Loss: 2401.857776\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11851 (step 11851): 1.294057\n",
      "Batch #10\tAverage Generator Loss: 2602.151318\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11852 (step 11852): 1.292167\n",
      "Batch #10\tAverage Generator Loss: 2223.273218\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11853 (step 11853): 1.646017\n",
      "Batch #10\tAverage Generator Loss: 2454.536780\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11854 (step 11854): 1.331443\n",
      "Batch #10\tAverage Generator Loss: 2114.926001\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11855 (step 11855): 1.388202\n",
      "Batch #10\tAverage Generator Loss: 2370.567383\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11856 (step 11856): 1.800063\n",
      "Batch #10\tAverage Generator Loss: 2416.231311\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11857 (step 11857): 1.366436\n",
      "Batch #10\tAverage Generator Loss: 2311.534583\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11858 (step 11858): 1.687710\n",
      "Batch #10\tAverage Generator Loss: 2497.774170\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11859 (step 11859): 1.297929\n",
      "Batch #10\tAverage Generator Loss: 2465.108691\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11860 (step 11860): 1.252420\n",
      "Batch #10\tAverage Generator Loss: 2289.530310\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11861 (step 11861): 1.724023\n",
      "Batch #10\tAverage Generator Loss: 2289.024365\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11862 (step 11862): 1.333662\n",
      "Batch #10\tAverage Generator Loss: 2252.615051\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11863 (step 11863): 1.228837\n",
      "Batch #10\tAverage Generator Loss: 2238.941345\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11864 (step 11864): 1.812844\n",
      "Batch #10\tAverage Generator Loss: 2363.457666\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11865 (step 11865): 1.247029\n",
      "Batch #10\tAverage Generator Loss: 2322.098718\tAverage Discriminator Loss: 0.001173\n",
      "\n",
      "Train time for epoch #11866 (step 11866): 1.889177\n",
      "Batch #10\tAverage Generator Loss: 2129.723987\tAverage Discriminator Loss: 0.000469\n",
      "\n",
      "Train time for epoch #11867 (step 11867): 1.302277\n",
      "Batch #10\tAverage Generator Loss: 2114.560669\tAverage Discriminator Loss: 0.258904\n",
      "\n",
      "Train time for epoch #11868 (step 11868): 1.386007\n",
      "Batch #10\tAverage Generator Loss: 2767.421326\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11869 (step 11869): 1.858809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2362.294519\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11870 (step 11870): 1.291537\n",
      "Batch #10\tAverage Generator Loss: 3060.256836\tAverage Discriminator Loss: 0.016532\n",
      "\n",
      "Train time for epoch #11871 (step 11871): 1.738000\n",
      "Batch #10\tAverage Generator Loss: 2231.654517\tAverage Discriminator Loss: 0.693238\n",
      "\n",
      "Train time for epoch #11872 (step 11872): 1.431472\n",
      "Batch #10\tAverage Generator Loss: 2200.835278\tAverage Discriminator Loss: 0.042582\n",
      "\n",
      "Train time for epoch #11873 (step 11873): 1.327665\n",
      "Batch #10\tAverage Generator Loss: 2295.558228\tAverage Discriminator Loss: 0.014741\n",
      "\n",
      "Train time for epoch #11874 (step 11874): 1.852536\n",
      "Batch #10\tAverage Generator Loss: 1671.407111\tAverage Discriminator Loss: 0.000123\n",
      "\n",
      "Train time for epoch #11875 (step 11875): 1.340260\n",
      "Batch #10\tAverage Generator Loss: 2082.039600\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11876 (step 11876): 1.280397\n",
      "Batch #10\tAverage Generator Loss: 1899.285291\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11877 (step 11877): 1.827178\n",
      "Batch #10\tAverage Generator Loss: 1820.508838\tAverage Discriminator Loss: 0.008562\n",
      "\n",
      "Train time for epoch #11878 (step 11878): 1.344615\n",
      "Batch #10\tAverage Generator Loss: 1928.880469\tAverage Discriminator Loss: 0.000024\n",
      "\n",
      "Train time for epoch #11879 (step 11879): 1.715942\n",
      "Batch #10\tAverage Generator Loss: 1883.754712\tAverage Discriminator Loss: 0.057255\n",
      "\n",
      "Train time for epoch #11880 (step 11880): 1.360389\n",
      "Batch #10\tAverage Generator Loss: 2009.431152\tAverage Discriminator Loss: 0.001080\n",
      "\n",
      "Train time for epoch #11881 (step 11881): 1.323446\n",
      "Batch #10\tAverage Generator Loss: 1958.897009\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11882 (step 11882): 1.737679\n",
      "Batch #10\tAverage Generator Loss: 1782.670300\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11883 (step 11883): 1.335672\n",
      "Batch #10\tAverage Generator Loss: 2125.061743\tAverage Discriminator Loss: 0.974468\n",
      "\n",
      "Train time for epoch #11884 (step 11884): 1.787853\n",
      "Batch #10\tAverage Generator Loss: 2481.153491\tAverage Discriminator Loss: 0.024757\n",
      "\n",
      "Train time for epoch #11885 (step 11885): 1.292808\n",
      "Batch #10\tAverage Generator Loss: 2198.601218\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11886 (step 11886): 1.259730\n",
      "Batch #10\tAverage Generator Loss: 2909.996570\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11887 (step 11887): 1.681491\n",
      "Batch #10\tAverage Generator Loss: 2814.594263\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11888 (step 11888): 1.306319\n",
      "Batch #10\tAverage Generator Loss: 2612.477344\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11889 (step 11889): 1.335039\n",
      "Batch #10\tAverage Generator Loss: 2475.917822\tAverage Discriminator Loss: 0.102594\n",
      "\n",
      "Train time for epoch #11890 (step 11890): 1.682390\n",
      "Batch #10\tAverage Generator Loss: 3310.701355\tAverage Discriminator Loss: 0.032502\n",
      "\n",
      "Train time for epoch #11891 (step 11891): 1.298711\n",
      "Batch #10\tAverage Generator Loss: 2672.003735\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11892 (step 11892): 1.832685\n",
      "Batch #10\tAverage Generator Loss: 2901.147217\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11893 (step 11893): 1.287500\n",
      "Batch #10\tAverage Generator Loss: 2536.616736\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11894 (step 11894): 1.288425\n",
      "Batch #10\tAverage Generator Loss: 3227.967749\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11895 (step 11895): 1.663085\n",
      "Batch #10\tAverage Generator Loss: 2936.769775\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11896 (step 11896): 1.368580\n",
      "Batch #10\tAverage Generator Loss: 2489.201733\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11897 (step 11897): 1.729610\n",
      "Batch #10\tAverage Generator Loss: 2772.212891\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11898 (step 11898): 1.283534\n",
      "Batch #10\tAverage Generator Loss: 2948.627515\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11899 (step 11899): 1.313743\n",
      "Batch #10\tAverage Generator Loss: 3014.866150\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11900 (step 11900): 1.743142\n",
      "Batch #10\tAverage Generator Loss: 2946.522803\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11901 (step 11901): 1.343889\n",
      "Batch #10\tAverage Generator Loss: 2577.306421\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11902 (step 11902): 1.323013\n",
      "Batch #10\tAverage Generator Loss: 2819.119312\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11903 (step 11903): 1.776109\n",
      "Batch #10\tAverage Generator Loss: 2456.406201\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11904 (step 11904): 1.345557\n",
      "Batch #10\tAverage Generator Loss: 2737.613428\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11905 (step 11905): 1.803510\n",
      "Batch #10\tAverage Generator Loss: 2167.694470\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11906 (step 11906): 1.289223\n",
      "Batch #10\tAverage Generator Loss: 2605.702063\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11907 (step 11907): 1.300689\n",
      "Batch #10\tAverage Generator Loss: 2918.146167\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11908 (step 11908): 1.840364\n",
      "Batch #10\tAverage Generator Loss: 2280.211646\tAverage Discriminator Loss: 0.000171\n",
      "\n",
      "Train time for epoch #11909 (step 11909): 1.295621\n",
      "Batch #10\tAverage Generator Loss: 2597.649927\tAverage Discriminator Loss: 0.012734\n",
      "\n",
      "Train time for epoch #11910 (step 11910): 1.295353\n",
      "Batch #10\tAverage Generator Loss: 2532.553040\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11911 (step 11911): 1.844329\n",
      "Batch #10\tAverage Generator Loss: 2212.068665\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11912 (step 11912): 1.402753\n",
      "Batch #10\tAverage Generator Loss: 2569.842645\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11913 (step 11913): 1.682627\n",
      "Batch #10\tAverage Generator Loss: 2097.735840\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11914 (step 11914): 1.251283\n",
      "Batch #10\tAverage Generator Loss: 2324.394666\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11915 (step 11915): 1.444520\n",
      "Batch #10\tAverage Generator Loss: 2065.766858\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11916 (step 11916): 1.742060\n",
      "Batch #10\tAverage Generator Loss: 2380.484875\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11917 (step 11917): 1.287576\n",
      "Batch #10\tAverage Generator Loss: 2262.022363\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11918 (step 11918): 1.691584\n",
      "Batch #10\tAverage Generator Loss: 2371.608142\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11919 (step 11919): 1.440533\n",
      "Batch #10\tAverage Generator Loss: 2836.089758\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11920 (step 11920): 1.328530\n",
      "Batch #10\tAverage Generator Loss: 2401.852142\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11921 (step 11921): 1.677406\n",
      "Batch #10\tAverage Generator Loss: 2388.800732\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11922 (step 11922): 1.336593\n",
      "Batch #10\tAverage Generator Loss: 2361.835132\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11923 (step 11923): 1.731010\n",
      "Batch #10\tAverage Generator Loss: 2451.405188\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11924 (step 11924): 1.290470\n",
      "Batch #10\tAverage Generator Loss: 2338.874969\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11925 (step 11925): 1.279688\n",
      "Batch #10\tAverage Generator Loss: 2394.124756\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11926 (step 11926): 1.773840\n",
      "Batch #10\tAverage Generator Loss: 2212.730273\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11927 (step 11927): 1.271002\n",
      "Batch #10\tAverage Generator Loss: 2489.853784\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11928 (step 11928): 1.337742\n",
      "Batch #10\tAverage Generator Loss: 2307.920520\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11929 (step 11929): 1.878241\n",
      "Batch #10\tAverage Generator Loss: 2315.501550\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11930 (step 11930): 1.319959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2258.779138\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11931 (step 11931): 1.699211\n",
      "Batch #10\tAverage Generator Loss: 2305.407190\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11932 (step 11932): 1.306919\n",
      "Batch #10\tAverage Generator Loss: 2119.164655\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11933 (step 11933): 1.295751\n",
      "Batch #10\tAverage Generator Loss: 2441.503345\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11934 (step 11934): 1.698228\n",
      "Batch #10\tAverage Generator Loss: 2321.684937\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11935 (step 11935): 1.301370\n",
      "Batch #10\tAverage Generator Loss: 2520.694568\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11936 (step 11936): 1.335058\n",
      "Batch #10\tAverage Generator Loss: 2389.197607\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11937 (step 11937): 1.658441\n",
      "Batch #10\tAverage Generator Loss: 2386.839478\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11938 (step 11938): 1.368654\n",
      "Batch #10\tAverage Generator Loss: 2315.106842\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11939 (step 11939): 1.737529\n",
      "Batch #10\tAverage Generator Loss: 2042.756866\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11940 (step 11940): 1.378630\n",
      "Batch #10\tAverage Generator Loss: 2212.850122\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11941 (step 11941): 1.282675\n",
      "Batch #10\tAverage Generator Loss: 2151.553809\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11942 (step 11942): 1.887630\n",
      "Batch #10\tAverage Generator Loss: 2221.208032\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #11943 (step 11943): 1.250561\n",
      "Batch #10\tAverage Generator Loss: 2658.105981\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11944 (step 11944): 1.401692\n",
      "Batch #10\tAverage Generator Loss: 2336.604736\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11945 (step 11945): 1.705668\n",
      "Batch #10\tAverage Generator Loss: 2669.149963\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11946 (step 11946): 1.328532\n",
      "Batch #10\tAverage Generator Loss: 2292.424390\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11947 (step 11947): 1.759020\n",
      "Batch #10\tAverage Generator Loss: 2430.845593\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11948 (step 11948): 1.413938\n",
      "Batch #10\tAverage Generator Loss: 2374.892542\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11949 (step 11949): 1.359268\n",
      "Batch #10\tAverage Generator Loss: 2205.508252\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11950 (step 11950): 1.793633\n",
      "Batch #10\tAverage Generator Loss: 2573.810754\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11951 (step 11951): 1.296571\n",
      "Batch #10\tAverage Generator Loss: 2396.181714\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11952 (step 11952): 1.721046\n",
      "Batch #10\tAverage Generator Loss: 2471.325629\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11953 (step 11953): 1.320969\n",
      "Batch #10\tAverage Generator Loss: 2274.136841\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11954 (step 11954): 1.355916\n",
      "Batch #10\tAverage Generator Loss: 2253.971082\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11955 (step 11955): 1.687817\n",
      "Batch #10\tAverage Generator Loss: 2604.387585\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11956 (step 11956): 1.375007\n",
      "Batch #10\tAverage Generator Loss: 1873.045435\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11957 (step 11957): 1.417208\n",
      "Batch #10\tAverage Generator Loss: 2647.210547\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11958 (step 11958): 1.671483\n",
      "Batch #10\tAverage Generator Loss: 2256.290674\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11959 (step 11959): 1.374801\n",
      "Batch #10\tAverage Generator Loss: 2239.715900\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11960 (step 11960): 1.282346\n",
      "Batch #10\tAverage Generator Loss: 2428.466705\tAverage Discriminator Loss: 0.276206\n",
      "\n",
      "Train time for epoch #11961 (step 11961): 1.668039\n",
      "Batch #10\tAverage Generator Loss: 2022.438782\tAverage Discriminator Loss: 0.000041\n",
      "\n",
      "Train time for epoch #11962 (step 11962): 1.348606\n",
      "Batch #10\tAverage Generator Loss: 2415.494714\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11963 (step 11963): 1.671969\n",
      "Batch #10\tAverage Generator Loss: 2168.519202\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11964 (step 11964): 1.278373\n",
      "Batch #10\tAverage Generator Loss: 2359.047937\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11965 (step 11965): 1.293616\n",
      "Batch #10\tAverage Generator Loss: 2121.998267\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11966 (step 11966): 1.709975\n",
      "Batch #10\tAverage Generator Loss: 2029.220984\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11967 (step 11967): 1.243327\n",
      "Batch #10\tAverage Generator Loss: 2192.723926\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11968 (step 11968): 1.817825\n",
      "Batch #10\tAverage Generator Loss: 1959.395599\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11969 (step 11969): 1.341390\n",
      "Batch #10\tAverage Generator Loss: 1763.802783\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11970 (step 11970): 1.398909\n",
      "Batch #10\tAverage Generator Loss: 2342.339709\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11971 (step 11971): 1.703058\n",
      "Batch #10\tAverage Generator Loss: 2197.591742\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11972 (step 11972): 1.336215\n",
      "Batch #10\tAverage Generator Loss: 2311.585205\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11973 (step 11973): 1.329526\n",
      "Batch #10\tAverage Generator Loss: 2300.964722\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11974 (step 11974): 1.756953\n",
      "Batch #10\tAverage Generator Loss: 2123.874988\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11975 (step 11975): 1.377235\n",
      "Batch #10\tAverage Generator Loss: 2075.649121\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11976 (step 11976): 1.723759\n",
      "Batch #10\tAverage Generator Loss: 1874.135992\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11977 (step 11977): 1.296288\n",
      "Batch #10\tAverage Generator Loss: 2175.613306\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #11978 (step 11978): 1.339911\n",
      "Batch #10\tAverage Generator Loss: 2353.803998\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11979 (step 11979): 1.643424\n",
      "Batch #10\tAverage Generator Loss: 1914.524365\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11980 (step 11980): 1.302559\n",
      "Batch #10\tAverage Generator Loss: 2306.331799\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11981 (step 11981): 1.436408\n",
      "Batch #10\tAverage Generator Loss: 2313.116663\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11982 (step 11982): 1.702026\n",
      "Batch #10\tAverage Generator Loss: 2292.175183\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11983 (step 11983): 1.249230\n",
      "Batch #10\tAverage Generator Loss: 2429.068990\tAverage Discriminator Loss: 1.553513\n",
      "\n",
      "Train time for epoch #11984 (step 11984): 1.338996\n",
      "Batch #10\tAverage Generator Loss: 2038.563806\tAverage Discriminator Loss: 0.013447\n",
      "\n",
      "Train time for epoch #11985 (step 11985): 1.741068\n",
      "Batch #10\tAverage Generator Loss: 1769.618457\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #11986 (step 11986): 1.287543\n",
      "Batch #10\tAverage Generator Loss: 1663.840070\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #11987 (step 11987): 1.676922\n",
      "Batch #10\tAverage Generator Loss: 1826.488220\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11988 (step 11988): 1.495941\n",
      "Batch #10\tAverage Generator Loss: 1924.961133\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11989 (step 11989): 1.436369\n",
      "Batch #10\tAverage Generator Loss: 1977.288708\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #11990 (step 11990): 1.748444\n",
      "Batch #10\tAverage Generator Loss: 2012.601990\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11991 (step 11991): 1.291768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2045.437500\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #11992 (step 11992): 1.836612\n",
      "Batch #10\tAverage Generator Loss: 1919.962817\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #11993 (step 11993): 1.334922\n",
      "Batch #10\tAverage Generator Loss: 1831.320654\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #11994 (step 11994): 1.373105\n",
      "Batch #10\tAverage Generator Loss: 1706.603510\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #11995 (step 11995): 1.822518\n",
      "Batch #10\tAverage Generator Loss: 1834.530640\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11996 (step 11996): 1.335981\n",
      "Batch #10\tAverage Generator Loss: 1729.020480\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11997 (step 11997): 1.281468\n",
      "Batch #10\tAverage Generator Loss: 1747.214319\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #11998 (step 11998): 1.791227\n",
      "Batch #10\tAverage Generator Loss: 1812.388562\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #11999 (step 11999): 1.357673\n",
      "Batch #10\tAverage Generator Loss: 1590.701294\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #12000 (step 12000): 1.682652\n",
      "Batch #10\tAverage Generator Loss: 2123.775208\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #12001 (step 12001): 1.358915\n",
      "Batch #10\tAverage Generator Loss: 1934.807996\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12002 (step 12002): 1.390361\n",
      "Batch #10\tAverage Generator Loss: 1888.446008\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12003 (step 12003): 1.725459\n",
      "Batch #10\tAverage Generator Loss: 1649.333704\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #12004 (step 12004): 1.402633\n",
      "Batch #10\tAverage Generator Loss: 1920.440088\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12005 (step 12005): 1.654354\n",
      "Batch #10\tAverage Generator Loss: 1848.056995\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #12006 (step 12006): 1.333255\n",
      "Batch #10\tAverage Generator Loss: 1813.873633\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #12007 (step 12007): 1.294266\n",
      "Batch #10\tAverage Generator Loss: 1602.078528\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #12008 (step 12008): 1.672833\n",
      "Batch #10\tAverage Generator Loss: 2023.373682\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #12009 (step 12009): 1.473572\n",
      "Batch #10\tAverage Generator Loss: 1632.216876\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12010 (step 12010): 1.334731\n",
      "Batch #10\tAverage Generator Loss: 1915.820508\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #12011 (step 12011): 1.699767\n",
      "Batch #10\tAverage Generator Loss: 1908.344885\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12012 (step 12012): 1.302375\n",
      "Batch #10\tAverage Generator Loss: 1701.705933\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #12013 (step 12013): 1.687541\n",
      "Batch #10\tAverage Generator Loss: 1920.666699\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #12014 (step 12014): 1.364016\n",
      "Batch #10\tAverage Generator Loss: 1800.883826\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #12015 (step 12015): 1.392793\n",
      "Batch #10\tAverage Generator Loss: 1949.182800\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #12016 (step 12016): 1.771275\n",
      "Batch #10\tAverage Generator Loss: 1993.581165\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #12017 (step 12017): 1.305317\n",
      "Batch #10\tAverage Generator Loss: 1597.691882\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #12018 (step 12018): 1.290163\n",
      "Batch #10\tAverage Generator Loss: 1834.453790\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #12019 (step 12019): 1.717630\n",
      "Batch #10\tAverage Generator Loss: 1600.569482\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #12020 (step 12020): 1.288638\n",
      "Batch #10\tAverage Generator Loss: 1969.882898\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12021 (step 12021): 1.832029\n",
      "Batch #10\tAverage Generator Loss: 1797.930847\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #12022 (step 12022): 1.319859\n",
      "Batch #10\tAverage Generator Loss: 1942.641907\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #12023 (step 12023): 1.336428\n",
      "Batch #10\tAverage Generator Loss: 1727.280865\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #12024 (step 12024): 1.718027\n",
      "Batch #10\tAverage Generator Loss: 1886.217554\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #12025 (step 12025): 1.307627\n",
      "Batch #10\tAverage Generator Loss: 1714.373242\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #12026 (step 12026): 1.846624\n",
      "Batch #10\tAverage Generator Loss: 1907.910754\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #12027 (step 12027): 1.244094\n",
      "Batch #10\tAverage Generator Loss: 1768.232043\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #12028 (step 12028): 1.432521\n",
      "Batch #10\tAverage Generator Loss: 1678.350110\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #12029 (step 12029): 1.813539\n",
      "Batch #10\tAverage Generator Loss: 2014.169775\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #12030 (step 12030): 1.343493\n",
      "Batch #10\tAverage Generator Loss: 1918.451050\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #12031 (step 12031): 2.000942\n",
      "Batch #10\tAverage Generator Loss: 1910.661108\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #12032 (step 12032): 1.282702\n",
      "Batch #10\tAverage Generator Loss: 1681.314673\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12033 (step 12033): 1.445028\n",
      "Batch #10\tAverage Generator Loss: 2020.835852\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12034 (step 12034): 1.744255\n",
      "Batch #10\tAverage Generator Loss: 1839.752429\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #12035 (step 12035): 1.325727\n",
      "Batch #10\tAverage Generator Loss: 1846.817383\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12036 (step 12036): 1.283452\n",
      "Batch #10\tAverage Generator Loss: 2063.600061\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12037 (step 12037): 1.674323\n",
      "Batch #10\tAverage Generator Loss: 2184.676758\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #12038 (step 12038): 1.433440\n",
      "Batch #10\tAverage Generator Loss: 2017.829504\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #12039 (step 12039): 1.786253\n",
      "Batch #10\tAverage Generator Loss: 2108.161169\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #12040 (step 12040): 1.448165\n",
      "Batch #10\tAverage Generator Loss: 1787.510242\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12041 (step 12041): 1.299922\n",
      "Batch #10\tAverage Generator Loss: 1954.347192\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12042 (step 12042): 1.765854\n",
      "Batch #10\tAverage Generator Loss: 1718.618817\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #12043 (step 12043): 1.297712\n",
      "Batch #10\tAverage Generator Loss: 1934.698853\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #12044 (step 12044): 1.240478\n",
      "Batch #10\tAverage Generator Loss: 1813.218091\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #12045 (step 12045): 1.641257\n",
      "Batch #10\tAverage Generator Loss: 1627.444958\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12046 (step 12046): 1.354944\n",
      "Batch #10\tAverage Generator Loss: 1787.421881\tAverage Discriminator Loss: 0.006920\n",
      "\n",
      "Train time for epoch #12047 (step 12047): 1.800188\n",
      "Batch #10\tAverage Generator Loss: 1554.701764\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #12048 (step 12048): 1.374523\n",
      "Batch #10\tAverage Generator Loss: 1684.104761\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #12049 (step 12049): 1.338781\n",
      "Batch #10\tAverage Generator Loss: 1799.781824\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #12050 (step 12050): 1.774859\n",
      "Batch #10\tAverage Generator Loss: 1687.815607\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12051 (step 12051): 1.248966\n",
      "Batch #10\tAverage Generator Loss: 1817.588306\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #12052 (step 12052): 1.353000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 1796.033289\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #12053 (step 12053): 1.702142\n",
      "Batch #10\tAverage Generator Loss: 2003.629114\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12054 (step 12054): 1.394958\n",
      "Batch #10\tAverage Generator Loss: 1861.772821\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #12055 (step 12055): 1.702651\n",
      "Batch #10\tAverage Generator Loss: 2020.775049\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #12056 (step 12056): 1.361255\n",
      "Batch #10\tAverage Generator Loss: 2081.834351\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12057 (step 12057): 1.290917\n",
      "Batch #10\tAverage Generator Loss: 1962.097339\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #12058 (step 12058): 1.745519\n",
      "Batch #10\tAverage Generator Loss: 1850.938342\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12059 (step 12059): 1.257892\n",
      "Batch #10\tAverage Generator Loss: 1739.997443\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #12060 (step 12060): 1.893931\n",
      "Batch #10\tAverage Generator Loss: 2005.377466\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #12061 (step 12061): 1.450816\n",
      "Batch #10\tAverage Generator Loss: 1714.355127\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12062 (step 12062): 1.296427\n",
      "Batch #10\tAverage Generator Loss: 1912.539124\tAverage Discriminator Loss: 0.016609\n",
      "\n",
      "Train time for epoch #12063 (step 12063): 1.747854\n",
      "Batch #10\tAverage Generator Loss: 1825.504309\tAverage Discriminator Loss: 0.001998\n",
      "\n",
      "Train time for epoch #12064 (step 12064): 1.414474\n",
      "Batch #10\tAverage Generator Loss: 1687.549133\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #12065 (step 12065): 1.304639\n",
      "Batch #10\tAverage Generator Loss: 2017.590198\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12066 (step 12066): 1.865842\n",
      "Batch #10\tAverage Generator Loss: 1782.210669\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #12067 (step 12067): 1.331774\n",
      "Batch #10\tAverage Generator Loss: 1949.106213\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #12068 (step 12068): 1.409119\n",
      "Batch #10\tAverage Generator Loss: 1736.692554\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #12069 (step 12069): 1.679172\n",
      "Batch #10\tAverage Generator Loss: 1693.857898\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #12070 (step 12070): 1.245070\n",
      "Batch #10\tAverage Generator Loss: 1812.802563\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12071 (step 12071): 1.730220\n",
      "Batch #10\tAverage Generator Loss: 1918.583813\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12072 (step 12072): 1.241497\n",
      "Batch #10\tAverage Generator Loss: 1981.668054\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12073 (step 12073): 1.299685\n",
      "Batch #10\tAverage Generator Loss: 1892.559543\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12074 (step 12074): 1.850595\n",
      "Batch #10\tAverage Generator Loss: 1703.420526\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12075 (step 12075): 1.299219\n",
      "Batch #10\tAverage Generator Loss: 1832.560083\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12076 (step 12076): 1.388685\n",
      "Batch #10\tAverage Generator Loss: 1987.836548\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12077 (step 12077): 1.679965\n",
      "Batch #10\tAverage Generator Loss: 1629.046478\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12078 (step 12078): 1.347354\n",
      "Batch #10\tAverage Generator Loss: 1825.494812\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12079 (step 12079): 1.736382\n",
      "Batch #10\tAverage Generator Loss: 1835.733789\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12080 (step 12080): 1.454053\n",
      "Batch #10\tAverage Generator Loss: 1729.347546\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12081 (step 12081): 1.277306\n",
      "Batch #10\tAverage Generator Loss: 1860.620044\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12082 (step 12082): 1.683375\n",
      "Batch #10\tAverage Generator Loss: 1978.530603\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12083 (step 12083): 1.299628\n",
      "Batch #10\tAverage Generator Loss: 1878.192957\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12084 (step 12084): 1.288114\n",
      "Batch #10\tAverage Generator Loss: 1977.625500\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12085 (step 12085): 1.718442\n",
      "Batch #10\tAverage Generator Loss: 1765.990906\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12086 (step 12086): 1.451324\n",
      "Batch #10\tAverage Generator Loss: 1872.791785\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12087 (step 12087): 1.700711\n",
      "Batch #10\tAverage Generator Loss: 1876.242346\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12088 (step 12088): 1.406868\n",
      "Batch #10\tAverage Generator Loss: 1813.146533\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12089 (step 12089): 1.359727\n",
      "Batch #10\tAverage Generator Loss: 1972.871899\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12090 (step 12090): 1.694845\n",
      "Batch #10\tAverage Generator Loss: 1974.880273\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12091 (step 12091): 1.345525\n",
      "Batch #10\tAverage Generator Loss: 1892.331238\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12092 (step 12092): 1.394328\n",
      "Batch #10\tAverage Generator Loss: 1594.684601\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12093 (step 12093): 1.861281\n",
      "Batch #10\tAverage Generator Loss: 1975.217615\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12094 (step 12094): 1.414157\n",
      "Batch #10\tAverage Generator Loss: 1786.168762\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12095 (step 12095): 1.343536\n",
      "Batch #10\tAverage Generator Loss: 1657.041614\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12096 (step 12096): 1.652245\n",
      "Batch #10\tAverage Generator Loss: 1868.522546\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12097 (step 12097): 1.395475\n",
      "Batch #10\tAverage Generator Loss: 1781.467029\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12098 (step 12098): 1.322677\n",
      "Batch #10\tAverage Generator Loss: 1710.413733\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12099 (step 12099): 1.782146\n",
      "Batch #10\tAverage Generator Loss: 1725.982727\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12100 (step 12100): 1.279477\n",
      "Batch #10\tAverage Generator Loss: 1658.936407\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12101 (step 12101): 1.669610\n",
      "Batch #10\tAverage Generator Loss: 1678.763425\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12102 (step 12102): 1.297848\n",
      "Batch #10\tAverage Generator Loss: 1724.033411\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12103 (step 12103): 1.360916\n",
      "Batch #10\tAverage Generator Loss: 1840.614258\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12104 (step 12104): 1.792185\n",
      "Batch #10\tAverage Generator Loss: 1660.617285\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12105 (step 12105): 1.288696\n",
      "Batch #10\tAverage Generator Loss: 1946.682080\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12106 (step 12106): 1.286414\n",
      "Batch #10\tAverage Generator Loss: 1951.428918\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12107 (step 12107): 1.766140\n",
      "Batch #10\tAverage Generator Loss: 1787.089673\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12108 (step 12108): 1.424401\n",
      "Batch #10\tAverage Generator Loss: 1581.510626\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12109 (step 12109): 1.738323\n",
      "Batch #10\tAverage Generator Loss: 1863.425415\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12110 (step 12110): 1.391545\n",
      "Batch #10\tAverage Generator Loss: 1913.451453\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12111 (step 12111): 1.388269\n",
      "Batch #10\tAverage Generator Loss: 1768.885803\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12112 (step 12112): 1.747854\n",
      "Batch #10\tAverage Generator Loss: 1741.945020\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12113 (step 12113): 1.289635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 1682.622125\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12114 (step 12114): 1.262577\n",
      "Batch #10\tAverage Generator Loss: 1928.170483\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12115 (step 12115): 1.698440\n",
      "Batch #10\tAverage Generator Loss: 1789.500635\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12116 (step 12116): 1.331126\n",
      "Batch #10\tAverage Generator Loss: 1897.299487\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12117 (step 12117): 1.387343\n",
      "Batch #10\tAverage Generator Loss: 1875.960962\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12118 (step 12118): 1.688850\n",
      "Batch #10\tAverage Generator Loss: 1686.438690\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12119 (step 12119): 1.344012\n",
      "Batch #10\tAverage Generator Loss: 1729.422388\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12120 (step 12120): 1.718897\n",
      "Batch #10\tAverage Generator Loss: 1792.540942\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12121 (step 12121): 1.347784\n",
      "Batch #10\tAverage Generator Loss: 1998.482385\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12122 (step 12122): 1.296953\n",
      "Batch #10\tAverage Generator Loss: 1914.816223\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12123 (step 12123): 1.725687\n",
      "Batch #10\tAverage Generator Loss: 1711.483594\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12124 (step 12124): 1.393628\n",
      "Batch #10\tAverage Generator Loss: 1755.072009\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12125 (step 12125): 1.736288\n",
      "Batch #10\tAverage Generator Loss: 1928.018726\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12126 (step 12126): 1.418042\n",
      "Batch #10\tAverage Generator Loss: 2068.520190\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12127 (step 12127): 1.330900\n",
      "Batch #10\tAverage Generator Loss: 1663.155823\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12128 (step 12128): 1.740050\n",
      "Batch #10\tAverage Generator Loss: 1806.914502\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12129 (step 12129): 1.429381\n",
      "Batch #10\tAverage Generator Loss: 1908.569995\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12130 (step 12130): 1.285856\n",
      "Batch #10\tAverage Generator Loss: 1720.022949\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12131 (step 12131): 1.686507\n",
      "Batch #10\tAverage Generator Loss: 1668.650342\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12132 (step 12132): 1.325196\n",
      "Batch #10\tAverage Generator Loss: 2047.899048\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12133 (step 12133): 1.332238\n",
      "Batch #10\tAverage Generator Loss: 1892.102539\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12134 (step 12134): 1.792804\n",
      "Batch #10\tAverage Generator Loss: 1997.698914\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12135 (step 12135): 1.356796\n",
      "Batch #10\tAverage Generator Loss: 1700.000977\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12136 (step 12136): 1.791387\n",
      "Batch #10\tAverage Generator Loss: 1985.191052\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12137 (step 12137): 1.299814\n",
      "Batch #10\tAverage Generator Loss: 1959.639844\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12138 (step 12138): 1.382645\n",
      "Batch #10\tAverage Generator Loss: 1919.240796\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12139 (step 12139): 1.760561\n",
      "Batch #10\tAverage Generator Loss: 1895.591028\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12140 (step 12140): 1.395459\n",
      "Batch #10\tAverage Generator Loss: 1876.624054\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12141 (step 12141): 1.369035\n",
      "Batch #10\tAverage Generator Loss: 1677.153485\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12142 (step 12142): 1.767415\n",
      "Batch #10\tAverage Generator Loss: 1971.857361\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12143 (step 12143): 1.301360\n",
      "Batch #10\tAverage Generator Loss: 1781.975256\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12144 (step 12144): 1.747681\n",
      "Batch #10\tAverage Generator Loss: 1946.874817\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12145 (step 12145): 1.436846\n",
      "Batch #10\tAverage Generator Loss: 1729.501666\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12146 (step 12146): 1.290240\n",
      "Batch #10\tAverage Generator Loss: 1676.110242\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12147 (step 12147): 1.764988\n",
      "Batch #10\tAverage Generator Loss: 2078.153174\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12148 (step 12148): 1.311653\n",
      "Batch #10\tAverage Generator Loss: 1640.865271\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12149 (step 12149): 1.393002\n",
      "Batch #10\tAverage Generator Loss: 1942.446118\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12150 (step 12150): 1.778363\n",
      "Batch #10\tAverage Generator Loss: 1992.485730\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12151 (step 12151): 1.342958\n",
      "Batch #10\tAverage Generator Loss: 2042.827832\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12152 (step 12152): 1.878083\n",
      "Batch #10\tAverage Generator Loss: 1796.488086\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12153 (step 12153): 1.300107\n",
      "Batch #10\tAverage Generator Loss: 1817.806982\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12154 (step 12154): 1.350162\n",
      "Batch #10\tAverage Generator Loss: 2215.294031\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12155 (step 12155): 1.740152\n",
      "Batch #10\tAverage Generator Loss: 1847.640161\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12156 (step 12156): 1.355017\n",
      "Batch #10\tAverage Generator Loss: 1979.946948\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12157 (step 12157): 1.301603\n",
      "Batch #10\tAverage Generator Loss: 1701.897266\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12158 (step 12158): 1.708995\n",
      "Batch #10\tAverage Generator Loss: 1982.700964\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12159 (step 12159): 1.339873\n",
      "Batch #10\tAverage Generator Loss: 1921.365027\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12160 (step 12160): 1.834956\n",
      "Batch #10\tAverage Generator Loss: 1884.786267\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12161 (step 12161): 1.336128\n",
      "Batch #10\tAverage Generator Loss: 1992.602417\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12162 (step 12162): 1.307527\n",
      "Batch #10\tAverage Generator Loss: 1842.686292\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12163 (step 12163): 1.716541\n",
      "Batch #10\tAverage Generator Loss: 1936.921875\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12164 (step 12164): 1.272860\n",
      "Batch #10\tAverage Generator Loss: 1767.675464\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12165 (step 12165): 1.686506\n",
      "Batch #10\tAverage Generator Loss: 1867.961865\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12166 (step 12166): 1.404940\n",
      "Batch #10\tAverage Generator Loss: 1903.026758\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12167 (step 12167): 1.395253\n",
      "Batch #10\tAverage Generator Loss: 1827.218945\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12168 (step 12168): 1.806020\n",
      "Batch #10\tAverage Generator Loss: 1800.638068\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12169 (step 12169): 1.392499\n",
      "Batch #10\tAverage Generator Loss: 1764.080774\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12170 (step 12170): 1.768001\n",
      "Batch #10\tAverage Generator Loss: 1867.593359\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12171 (step 12171): 1.403606\n",
      "Batch #10\tAverage Generator Loss: 1842.583643\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12172 (step 12172): 1.326682\n",
      "Batch #10\tAverage Generator Loss: 1794.958405\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12173 (step 12173): 1.830267\n",
      "Batch #10\tAverage Generator Loss: 1706.862939\tAverage Discriminator Loss: 0.000120\n",
      "\n",
      "Train time for epoch #12174 (step 12174): 1.299702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 1942.392236\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12175 (step 12175): 1.325546\n",
      "Batch #10\tAverage Generator Loss: 1954.533582\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12176 (step 12176): 1.703899\n",
      "Batch #10\tAverage Generator Loss: 1833.301917\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12177 (step 12177): 1.395847\n",
      "Batch #10\tAverage Generator Loss: 1672.923615\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12178 (step 12178): 1.345113\n",
      "Batch #10\tAverage Generator Loss: 2085.176660\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12179 (step 12179): 1.736718\n",
      "Batch #10\tAverage Generator Loss: 2028.223230\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12180 (step 12180): 1.380452\n",
      "Batch #10\tAverage Generator Loss: 1744.041907\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12181 (step 12181): 1.843167\n",
      "Batch #10\tAverage Generator Loss: 1818.906787\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12182 (step 12182): 1.295936\n",
      "Batch #10\tAverage Generator Loss: 1739.164996\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12183 (step 12183): 1.343009\n",
      "Batch #10\tAverage Generator Loss: 1937.044702\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12184 (step 12184): 1.838910\n",
      "Batch #10\tAverage Generator Loss: 2024.552917\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12185 (step 12185): 1.300214\n",
      "Batch #10\tAverage Generator Loss: 2007.939099\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12186 (step 12186): 1.336982\n",
      "Batch #10\tAverage Generator Loss: 2118.955103\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12187 (step 12187): 1.749715\n",
      "Batch #10\tAverage Generator Loss: 1979.407568\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12188 (step 12188): 1.336242\n",
      "Batch #10\tAverage Generator Loss: 1812.110883\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12189 (step 12189): 1.743670\n",
      "Batch #10\tAverage Generator Loss: 1814.555286\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12190 (step 12190): 1.338466\n",
      "Batch #10\tAverage Generator Loss: 1708.820227\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12191 (step 12191): 1.305442\n",
      "Batch #10\tAverage Generator Loss: 1772.845789\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12192 (step 12192): 1.686031\n",
      "Batch #10\tAverage Generator Loss: 1778.075232\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12193 (step 12193): 1.377080\n",
      "Batch #10\tAverage Generator Loss: 2004.972668\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12194 (step 12194): 1.296875\n",
      "Batch #10\tAverage Generator Loss: 1854.884509\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12195 (step 12195): 1.795038\n",
      "Batch #10\tAverage Generator Loss: 1890.300488\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12196 (step 12196): 1.364744\n",
      "Batch #10\tAverage Generator Loss: 1806.111621\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12197 (step 12197): 1.830307\n",
      "Batch #10\tAverage Generator Loss: 1911.520630\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12198 (step 12198): 1.286864\n",
      "Batch #10\tAverage Generator Loss: 1737.378113\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12199 (step 12199): 1.285054\n",
      "Batch #10\tAverage Generator Loss: 1877.638464\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12200 (step 12200): 1.670965\n",
      "Batch #10\tAverage Generator Loss: 1955.949414\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12201 (step 12201): 1.287475\n",
      "Batch #10\tAverage Generator Loss: 1918.545825\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12202 (step 12202): 1.412296\n",
      "Batch #10\tAverage Generator Loss: 1857.659656\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12203 (step 12203): 1.733893\n",
      "Batch #10\tAverage Generator Loss: 1785.385095\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12204 (step 12204): 1.345696\n",
      "Batch #10\tAverage Generator Loss: 2045.658032\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12205 (step 12205): 1.792124\n",
      "Batch #10\tAverage Generator Loss: 1939.508191\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12206 (step 12206): 1.349761\n",
      "Batch #10\tAverage Generator Loss: 1865.600610\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12207 (step 12207): 1.408153\n",
      "Batch #10\tAverage Generator Loss: 1627.625977\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12208 (step 12208): 1.759938\n",
      "Batch #10\tAverage Generator Loss: 1926.975232\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12209 (step 12209): 1.408892\n",
      "Batch #10\tAverage Generator Loss: 1995.596057\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12210 (step 12210): 1.290684\n",
      "Batch #10\tAverage Generator Loss: 1842.947546\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12211 (step 12211): 1.759923\n",
      "Batch #10\tAverage Generator Loss: 1989.616565\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12212 (step 12212): 1.286661\n",
      "Batch #10\tAverage Generator Loss: 1817.551929\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12213 (step 12213): 1.766958\n",
      "Batch #10\tAverage Generator Loss: 1906.926074\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12214 (step 12214): 1.302266\n",
      "Batch #10\tAverage Generator Loss: 1940.118372\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12215 (step 12215): 1.304784\n",
      "Batch #10\tAverage Generator Loss: 1906.609521\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12216 (step 12216): 1.764801\n",
      "Batch #10\tAverage Generator Loss: 1751.741663\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12217 (step 12217): 1.246606\n",
      "Batch #10\tAverage Generator Loss: 1824.385675\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12218 (step 12218): 1.721007\n",
      "Batch #10\tAverage Generator Loss: 1876.918317\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12219 (step 12219): 1.268718\n",
      "Batch #10\tAverage Generator Loss: 1819.034351\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12220 (step 12220): 1.284154\n",
      "Batch #10\tAverage Generator Loss: 1849.326111\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12221 (step 12221): 1.956199\n",
      "Batch #10\tAverage Generator Loss: 1831.703174\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12222 (step 12222): 1.296288\n",
      "Batch #10\tAverage Generator Loss: 1775.840125\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12223 (step 12223): 1.334293\n",
      "Batch #10\tAverage Generator Loss: 1995.927173\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12224 (step 12224): 1.724873\n",
      "Batch #10\tAverage Generator Loss: 1832.322949\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12225 (step 12225): 1.318634\n",
      "Batch #10\tAverage Generator Loss: 1649.923492\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12226 (step 12226): 1.719536\n",
      "Batch #10\tAverage Generator Loss: 1854.095538\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12227 (step 12227): 1.342382\n",
      "Batch #10\tAverage Generator Loss: 1780.383997\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12228 (step 12228): 1.410374\n",
      "Batch #10\tAverage Generator Loss: 1809.077014\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12229 (step 12229): 1.707663\n",
      "Batch #10\tAverage Generator Loss: 1784.993451\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12230 (step 12230): 1.338626\n",
      "Batch #10\tAverage Generator Loss: 1920.111475\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12231 (step 12231): 1.755817\n",
      "Batch #10\tAverage Generator Loss: 1871.511133\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12232 (step 12232): 1.333732\n",
      "Batch #10\tAverage Generator Loss: 1686.485999\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12233 (step 12233): 1.288950\n",
      "Batch #10\tAverage Generator Loss: 1837.808923\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12234 (step 12234): 1.674041\n",
      "Batch #10\tAverage Generator Loss: 1919.595691\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12235 (step 12235): 1.279710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 1760.802679\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12236 (step 12236): 1.401368\n",
      "Batch #10\tAverage Generator Loss: 1965.152979\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12237 (step 12237): 1.723741\n",
      "Batch #10\tAverage Generator Loss: 1986.693518\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12238 (step 12238): 1.333327\n",
      "Batch #10\tAverage Generator Loss: 2007.981445\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12239 (step 12239): 1.803920\n",
      "Batch #10\tAverage Generator Loss: 1828.174390\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12240 (step 12240): 1.359071\n",
      "Batch #10\tAverage Generator Loss: 2057.635132\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12241 (step 12241): 1.380026\n",
      "Batch #10\tAverage Generator Loss: 2158.084631\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12242 (step 12242): 1.681739\n",
      "Batch #10\tAverage Generator Loss: 2063.194104\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12243 (step 12243): 1.296578\n",
      "Batch #10\tAverage Generator Loss: 1774.963745\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12244 (step 12244): 1.355688\n",
      "Batch #10\tAverage Generator Loss: 2040.910052\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12245 (step 12245): 1.724085\n",
      "Batch #10\tAverage Generator Loss: 2095.719971\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12246 (step 12246): 1.530480\n",
      "Batch #10\tAverage Generator Loss: 1958.923206\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12247 (step 12247): 1.347534\n",
      "Batch #10\tAverage Generator Loss: 1944.752368\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12248 (step 12248): 1.679451\n",
      "Batch #10\tAverage Generator Loss: 1878.865094\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12249 (step 12249): 1.352605\n",
      "Batch #10\tAverage Generator Loss: 1867.898969\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12250 (step 12250): 1.798071\n",
      "Batch #10\tAverage Generator Loss: 1950.685583\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12251 (step 12251): 1.295998\n",
      "Batch #10\tAverage Generator Loss: 1890.465332\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12252 (step 12252): 1.346499\n",
      "Batch #10\tAverage Generator Loss: 1833.514294\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12253 (step 12253): 1.859343\n",
      "Batch #10\tAverage Generator Loss: 1905.834131\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12254 (step 12254): 1.388179\n",
      "Batch #10\tAverage Generator Loss: 1920.555328\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12255 (step 12255): 1.368695\n",
      "Batch #10\tAverage Generator Loss: 1856.987231\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12256 (step 12256): 1.717191\n",
      "Batch #10\tAverage Generator Loss: 1746.668127\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12257 (step 12257): 1.425106\n",
      "Batch #10\tAverage Generator Loss: 2011.459869\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12258 (step 12258): 1.776902\n",
      "Batch #10\tAverage Generator Loss: 1990.476904\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12259 (step 12259): 1.297895\n",
      "Batch #10\tAverage Generator Loss: 1744.522937\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12260 (step 12260): 1.338362\n",
      "Batch #10\tAverage Generator Loss: 1741.852435\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12261 (step 12261): 1.792607\n",
      "Batch #10\tAverage Generator Loss: 2078.774353\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12262 (step 12262): 1.345882\n",
      "Batch #10\tAverage Generator Loss: 1837.993481\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12263 (step 12263): 1.343003\n",
      "Batch #10\tAverage Generator Loss: 1943.047119\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12264 (step 12264): 1.766145\n",
      "Batch #10\tAverage Generator Loss: 1932.492126\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12265 (step 12265): 1.475653\n",
      "Batch #10\tAverage Generator Loss: 1943.615204\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12266 (step 12266): 1.789360\n",
      "Batch #10\tAverage Generator Loss: 1799.341406\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12267 (step 12267): 1.418190\n",
      "Batch #10\tAverage Generator Loss: 1787.398999\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12268 (step 12268): 1.266838\n",
      "Batch #10\tAverage Generator Loss: 2039.479358\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12269 (step 12269): 1.725321\n",
      "Batch #10\tAverage Generator Loss: 1889.286768\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12270 (step 12270): 1.286320\n",
      "Batch #10\tAverage Generator Loss: 1841.345447\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12271 (step 12271): 1.285627\n",
      "Batch #10\tAverage Generator Loss: 1961.502527\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12272 (step 12272): 1.734610\n",
      "Batch #10\tAverage Generator Loss: 1854.768475\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12273 (step 12273): 1.341293\n",
      "Batch #10\tAverage Generator Loss: 1868.538745\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12274 (step 12274): 1.784009\n",
      "Batch #10\tAverage Generator Loss: 1913.846423\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12275 (step 12275): 1.282980\n",
      "Batch #10\tAverage Generator Loss: 1866.342206\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12276 (step 12276): 1.348904\n",
      "Batch #10\tAverage Generator Loss: 2003.280286\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12277 (step 12277): 1.728367\n",
      "Batch #10\tAverage Generator Loss: 2020.581982\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #12278 (step 12278): 1.338463\n",
      "Batch #10\tAverage Generator Loss: 1778.434259\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12279 (step 12279): 1.340494\n",
      "Batch #10\tAverage Generator Loss: 1902.648633\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12280 (step 12280): 1.850370\n",
      "Batch #10\tAverage Generator Loss: 1978.387231\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12281 (step 12281): 1.365793\n",
      "Batch #10\tAverage Generator Loss: 1843.077222\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12282 (step 12282): 1.236887\n",
      "Batch #10\tAverage Generator Loss: 1824.718115\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12283 (step 12283): 1.703490\n",
      "Batch #10\tAverage Generator Loss: 1785.634692\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12284 (step 12284): 1.375539\n",
      "Batch #10\tAverage Generator Loss: 1763.406433\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12285 (step 12285): 1.799461\n",
      "Batch #10\tAverage Generator Loss: 1698.480664\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12286 (step 12286): 1.349767\n",
      "Batch #10\tAverage Generator Loss: 1714.995142\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12287 (step 12287): 1.302016\n",
      "Batch #10\tAverage Generator Loss: 1791.100134\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12288 (step 12288): 1.675397\n",
      "Batch #10\tAverage Generator Loss: 1943.467651\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12289 (step 12289): 1.441518\n",
      "Batch #10\tAverage Generator Loss: 1807.203247\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12290 (step 12290): 1.331999\n",
      "Batch #10\tAverage Generator Loss: 1921.588184\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12291 (step 12291): 1.725258\n",
      "Batch #10\tAverage Generator Loss: 1632.720422\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12292 (step 12292): 1.392138\n",
      "Batch #10\tAverage Generator Loss: 1647.554456\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12293 (step 12293): 1.274893\n",
      "Batch #10\tAverage Generator Loss: 1942.853448\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12294 (step 12294): 1.771314\n",
      "Batch #10\tAverage Generator Loss: 2045.400696\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12295 (step 12295): 1.289597\n",
      "Batch #10\tAverage Generator Loss: 1651.926215\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12296 (step 12296): 1.754205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 1880.837177\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12297 (step 12297): 1.297326\n",
      "Batch #10\tAverage Generator Loss: 1872.475073\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12298 (step 12298): 1.429744\n",
      "Batch #10\tAverage Generator Loss: 1821.110297\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12299 (step 12299): 1.702211\n",
      "Batch #10\tAverage Generator Loss: 1750.835962\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12300 (step 12300): 1.364588\n",
      "Batch #10\tAverage Generator Loss: 2003.334973\tAverage Discriminator Loss: 0.011135\n",
      "\n",
      "Train time for epoch #12301 (step 12301): 1.836090\n",
      "Batch #10\tAverage Generator Loss: 1804.033301\tAverage Discriminator Loss: 0.000954\n",
      "\n",
      "Train time for epoch #12302 (step 12302): 1.255131\n",
      "Batch #10\tAverage Generator Loss: 1623.178357\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #12303 (step 12303): 1.332313\n",
      "Batch #10\tAverage Generator Loss: 1739.960828\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12304 (step 12304): 1.761614\n",
      "Batch #10\tAverage Generator Loss: 1856.065747\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12305 (step 12305): 1.245436\n",
      "Batch #10\tAverage Generator Loss: 1887.645679\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12306 (step 12306): 1.272565\n",
      "Batch #10\tAverage Generator Loss: 1680.973718\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12307 (step 12307): 1.673423\n",
      "Batch #10\tAverage Generator Loss: 1800.750403\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12308 (step 12308): 1.370738\n",
      "Batch #10\tAverage Generator Loss: 1329.269415\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12309 (step 12309): 1.335252\n",
      "Batch #10\tAverage Generator Loss: 1918.525323\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12310 (step 12310): 1.709213\n",
      "Batch #10\tAverage Generator Loss: 2028.946838\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12311 (step 12311): 1.332237\n",
      "Batch #10\tAverage Generator Loss: 1720.192761\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12312 (step 12312): 1.821851\n",
      "Batch #10\tAverage Generator Loss: 1830.863293\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12313 (step 12313): 1.391211\n",
      "Batch #10\tAverage Generator Loss: 1739.842834\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12314 (step 12314): 1.304917\n",
      "Batch #10\tAverage Generator Loss: 1652.194293\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12315 (step 12315): 1.784354\n",
      "Batch #10\tAverage Generator Loss: 1734.729706\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12316 (step 12316): 1.302217\n",
      "Batch #10\tAverage Generator Loss: 1931.682275\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12317 (step 12317): 1.386442\n",
      "Batch #10\tAverage Generator Loss: 1893.834375\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12318 (step 12318): 1.682111\n",
      "Batch #10\tAverage Generator Loss: 1944.824994\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12319 (step 12319): 1.506500\n",
      "Batch #10\tAverage Generator Loss: 1705.289191\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12320 (step 12320): 1.787030\n",
      "Batch #10\tAverage Generator Loss: 1821.948151\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12321 (step 12321): 1.237906\n",
      "Batch #10\tAverage Generator Loss: 1850.505249\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12322 (step 12322): 1.319001\n",
      "Batch #10\tAverage Generator Loss: 1607.908557\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12323 (step 12323): 1.681674\n",
      "Batch #10\tAverage Generator Loss: 1839.764673\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12324 (step 12324): 1.351471\n",
      "Batch #10\tAverage Generator Loss: 1917.672998\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12325 (step 12325): 1.560338\n",
      "Batch #10\tAverage Generator Loss: 1872.481952\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12326 (step 12326): 1.646609\n",
      "Batch #10\tAverage Generator Loss: 1827.017126\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12327 (step 12327): 1.290771\n",
      "Batch #10\tAverage Generator Loss: 1604.604932\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12328 (step 12328): 1.677629\n",
      "Batch #10\tAverage Generator Loss: 1840.566406\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12329 (step 12329): 1.249083\n",
      "Batch #10\tAverage Generator Loss: 1738.776471\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12330 (step 12330): 1.395872\n",
      "Batch #10\tAverage Generator Loss: 1783.566559\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12331 (step 12331): 1.755008\n",
      "Batch #10\tAverage Generator Loss: 1780.498813\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12332 (step 12332): 1.335627\n",
      "Batch #10\tAverage Generator Loss: 1839.741010\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12333 (step 12333): 1.322613\n",
      "Batch #10\tAverage Generator Loss: 1673.312292\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12334 (step 12334): 1.712331\n",
      "Batch #10\tAverage Generator Loss: 1795.520435\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12335 (step 12335): 1.316099\n",
      "Batch #10\tAverage Generator Loss: 1779.196692\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12336 (step 12336): 1.312608\n",
      "Batch #10\tAverage Generator Loss: 1839.869446\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12337 (step 12337): 1.713696\n",
      "Batch #10\tAverage Generator Loss: 1682.898889\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12338 (step 12338): 1.336360\n",
      "Batch #10\tAverage Generator Loss: 1662.493573\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12339 (step 12339): 1.818536\n",
      "Batch #10\tAverage Generator Loss: 1803.834033\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12340 (step 12340): 1.331975\n",
      "Batch #10\tAverage Generator Loss: 1853.135315\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12341 (step 12341): 1.436156\n",
      "Batch #10\tAverage Generator Loss: 1869.390717\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12342 (step 12342): 1.819970\n",
      "Batch #10\tAverage Generator Loss: 1628.180322\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12343 (step 12343): 1.261929\n",
      "Batch #10\tAverage Generator Loss: 1675.172144\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12344 (step 12344): 1.396771\n",
      "Batch #10\tAverage Generator Loss: 1800.222540\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12345 (step 12345): 1.765970\n",
      "Batch #10\tAverage Generator Loss: 1840.917773\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12346 (step 12346): 1.337590\n",
      "Batch #10\tAverage Generator Loss: 1642.521960\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12347 (step 12347): 1.243147\n",
      "Batch #10\tAverage Generator Loss: 2015.330237\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12348 (step 12348): 1.703561\n",
      "Batch #10\tAverage Generator Loss: 1619.661853\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12349 (step 12349): 1.374192\n",
      "Batch #10\tAverage Generator Loss: 1826.490369\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12350 (step 12350): 1.761064\n",
      "Batch #10\tAverage Generator Loss: 1804.012488\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12351 (step 12351): 1.334185\n",
      "Batch #10\tAverage Generator Loss: 1806.917957\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12352 (step 12352): 1.287665\n",
      "Batch #10\tAverage Generator Loss: 1543.392242\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12353 (step 12353): 1.709646\n",
      "Batch #10\tAverage Generator Loss: 1866.523315\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12354 (step 12354): 1.294590\n",
      "Batch #10\tAverage Generator Loss: 1741.108777\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12355 (step 12355): 1.284940\n",
      "Batch #10\tAverage Generator Loss: 1796.244031\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12356 (step 12356): 1.687591\n",
      "Batch #10\tAverage Generator Loss: 1628.388318\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12357 (step 12357): 1.354775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 1819.910242\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12358 (step 12358): 1.733814\n",
      "Batch #10\tAverage Generator Loss: 1965.887451\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12359 (step 12359): 1.340947\n",
      "Batch #10\tAverage Generator Loss: 1547.079565\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12360 (step 12360): 1.351297\n",
      "Batch #10\tAverage Generator Loss: 1629.474109\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12361 (step 12361): 1.722361\n",
      "Batch #10\tAverage Generator Loss: 1566.975488\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12362 (step 12362): 1.454273\n",
      "Batch #10\tAverage Generator Loss: 1935.612500\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12363 (step 12363): 1.281249\n",
      "Batch #10\tAverage Generator Loss: 1710.516309\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12364 (step 12364): 1.732287\n",
      "Batch #10\tAverage Generator Loss: 1671.250494\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12365 (step 12365): 1.345104\n",
      "Batch #10\tAverage Generator Loss: 1788.144934\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12366 (step 12366): 1.276783\n",
      "Batch #10\tAverage Generator Loss: 1385.054065\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12367 (step 12367): 1.682889\n",
      "Batch #10\tAverage Generator Loss: 1769.918860\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12368 (step 12368): 1.342067\n",
      "Batch #10\tAverage Generator Loss: 1824.860297\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12369 (step 12369): 1.689923\n",
      "Batch #10\tAverage Generator Loss: 1591.821875\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12370 (step 12370): 1.327483\n",
      "Batch #10\tAverage Generator Loss: 1785.725708\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12371 (step 12371): 1.298353\n",
      "Batch #10\tAverage Generator Loss: 1783.474988\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12372 (step 12372): 1.768639\n",
      "Batch #10\tAverage Generator Loss: 1539.704471\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12373 (step 12373): 1.338845\n",
      "Batch #10\tAverage Generator Loss: 1497.849377\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12374 (step 12374): 1.346672\n",
      "Batch #10\tAverage Generator Loss: 1866.525037\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12375 (step 12375): 1.719111\n",
      "Batch #10\tAverage Generator Loss: 1719.444763\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12376 (step 12376): 1.300616\n",
      "Batch #10\tAverage Generator Loss: 1554.655981\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12377 (step 12377): 1.437924\n",
      "Batch #10\tAverage Generator Loss: 1769.220398\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12378 (step 12378): 1.720391\n",
      "Batch #10\tAverage Generator Loss: 1867.524817\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12379 (step 12379): 1.361860\n",
      "Batch #10\tAverage Generator Loss: 1883.276489\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12380 (step 12380): 1.811057\n",
      "Batch #10\tAverage Generator Loss: 1673.642249\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12381 (step 12381): 1.420964\n",
      "Batch #10\tAverage Generator Loss: 1856.007556\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12382 (step 12382): 1.323248\n",
      "Batch #10\tAverage Generator Loss: 1702.648767\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12383 (step 12383): 1.851128\n",
      "Batch #10\tAverage Generator Loss: 1818.570605\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12384 (step 12384): 1.332134\n",
      "Batch #10\tAverage Generator Loss: 2191.807483\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12385 (step 12385): 1.494903\n",
      "Batch #10\tAverage Generator Loss: 1754.001349\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12386 (step 12386): 1.821859\n",
      "Batch #10\tAverage Generator Loss: 1747.026184\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12387 (step 12387): 1.364333\n",
      "Batch #10\tAverage Generator Loss: 1858.226715\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12388 (step 12388): 1.323171\n",
      "Batch #10\tAverage Generator Loss: 2510.340442\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12389 (step 12389): 1.763937\n",
      "Batch #10\tAverage Generator Loss: 1930.206653\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12390 (step 12390): 1.343062\n",
      "Batch #10\tAverage Generator Loss: 1962.865833\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12391 (step 12391): 1.699408\n",
      "Batch #10\tAverage Generator Loss: 2037.793884\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12392 (step 12392): 1.398063\n",
      "Batch #10\tAverage Generator Loss: 1778.608527\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12393 (step 12393): 1.430405\n",
      "Batch #10\tAverage Generator Loss: 2049.578833\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12394 (step 12394): 1.700063\n",
      "Batch #10\tAverage Generator Loss: 1829.402301\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12395 (step 12395): 1.408657\n",
      "Batch #10\tAverage Generator Loss: 1894.081494\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12396 (step 12396): 1.722013\n",
      "Batch #10\tAverage Generator Loss: 1937.420764\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12397 (step 12397): 1.289983\n",
      "Batch #10\tAverage Generator Loss: 1975.001208\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12398 (step 12398): 1.293619\n",
      "Batch #10\tAverage Generator Loss: 1860.317548\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12399 (step 12399): 1.742092\n",
      "Batch #10\tAverage Generator Loss: 1880.006848\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12400 (step 12400): 1.465832\n",
      "Batch #10\tAverage Generator Loss: 2018.345630\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12401 (step 12401): 1.330833\n",
      "Batch #10\tAverage Generator Loss: 2055.034192\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12402 (step 12402): 1.846586\n",
      "Batch #10\tAverage Generator Loss: 1966.614807\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12403 (step 12403): 1.336611\n",
      "Batch #10\tAverage Generator Loss: 1905.895593\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12404 (step 12404): 1.551283\n",
      "Batch #10\tAverage Generator Loss: 1945.276221\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12405 (step 12405): 1.730037\n",
      "Batch #10\tAverage Generator Loss: 1820.821033\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12406 (step 12406): 1.356844\n",
      "Batch #10\tAverage Generator Loss: 1837.457916\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12407 (step 12407): 1.337634\n",
      "Batch #10\tAverage Generator Loss: 1899.939038\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12408 (step 12408): 1.710649\n",
      "Batch #10\tAverage Generator Loss: 1605.357806\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12409 (step 12409): 1.353741\n",
      "Batch #10\tAverage Generator Loss: 1649.920422\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12410 (step 12410): 1.803910\n",
      "Batch #10\tAverage Generator Loss: 1823.415759\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12411 (step 12411): 1.314934\n",
      "Batch #10\tAverage Generator Loss: 1779.974756\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12412 (step 12412): 1.392895\n",
      "Batch #10\tAverage Generator Loss: 1626.093298\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12413 (step 12413): 1.777632\n",
      "Batch #10\tAverage Generator Loss: 1824.428442\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12414 (step 12414): 1.379536\n",
      "Batch #10\tAverage Generator Loss: 1713.448096\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12415 (step 12415): 1.333699\n",
      "Batch #10\tAverage Generator Loss: 1569.382437\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12416 (step 12416): 1.728276\n",
      "Batch #10\tAverage Generator Loss: 1747.089807\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12417 (step 12417): 1.250087\n",
      "Batch #10\tAverage Generator Loss: 2014.900842\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12418 (step 12418): 1.725754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 1748.092456\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12419 (step 12419): 1.353250\n",
      "Batch #10\tAverage Generator Loss: 1665.563379\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12420 (step 12420): 1.334796\n",
      "Batch #10\tAverage Generator Loss: 1717.208441\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12421 (step 12421): 1.774396\n",
      "Batch #10\tAverage Generator Loss: 1734.037769\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12422 (step 12422): 1.314949\n",
      "Batch #10\tAverage Generator Loss: 1846.019287\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12423 (step 12423): 1.335224\n",
      "Batch #10\tAverage Generator Loss: 1731.693475\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12424 (step 12424): 1.687045\n",
      "Batch #10\tAverage Generator Loss: 1689.767285\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12425 (step 12425): 1.353093\n",
      "Batch #10\tAverage Generator Loss: 1802.831592\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12426 (step 12426): 1.500776\n",
      "Batch #10\tAverage Generator Loss: 1658.355542\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12427 (step 12427): 1.748178\n",
      "Batch #10\tAverage Generator Loss: 1621.773499\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12428 (step 12428): 1.391907\n",
      "Batch #10\tAverage Generator Loss: 1806.604004\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12429 (step 12429): 1.702442\n",
      "Batch #10\tAverage Generator Loss: 1632.353601\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12430 (step 12430): 1.326141\n",
      "Batch #10\tAverage Generator Loss: 1881.358472\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12431 (step 12431): 1.356895\n",
      "Batch #10\tAverage Generator Loss: 1632.765839\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12432 (step 12432): 1.732170\n",
      "Batch #10\tAverage Generator Loss: 1720.872986\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12433 (step 12433): 1.298044\n",
      "Batch #10\tAverage Generator Loss: 1965.319763\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12434 (step 12434): 1.686593\n",
      "Batch #10\tAverage Generator Loss: 1652.708075\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12435 (step 12435): 1.293277\n",
      "Batch #10\tAverage Generator Loss: 1716.481311\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12436 (step 12436): 1.351154\n",
      "Batch #10\tAverage Generator Loss: 1968.310864\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12437 (step 12437): 1.701536\n",
      "Batch #10\tAverage Generator Loss: 1692.925293\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12438 (step 12438): 1.307205\n",
      "Batch #10\tAverage Generator Loss: 1742.127588\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12439 (step 12439): 1.392467\n",
      "Batch #10\tAverage Generator Loss: 1796.080408\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12440 (step 12440): 1.772438\n",
      "Batch #10\tAverage Generator Loss: 1668.145667\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12441 (step 12441): 1.386279\n",
      "Batch #10\tAverage Generator Loss: 1876.494153\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12442 (step 12442): 1.380421\n",
      "Batch #10\tAverage Generator Loss: 1791.955396\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12443 (step 12443): 1.696761\n",
      "Batch #10\tAverage Generator Loss: 1775.483972\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12444 (step 12444): 1.410151\n",
      "Batch #10\tAverage Generator Loss: 1742.347961\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12445 (step 12445): 1.807343\n",
      "Batch #10\tAverage Generator Loss: 1801.645251\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12446 (step 12446): 1.389008\n",
      "Batch #10\tAverage Generator Loss: 1767.470166\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12447 (step 12447): 1.394287\n",
      "Batch #10\tAverage Generator Loss: 1558.142297\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12448 (step 12448): 1.713883\n",
      "Batch #10\tAverage Generator Loss: 1621.181177\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12449 (step 12449): 1.342331\n",
      "Batch #10\tAverage Generator Loss: 1732.780710\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12450 (step 12450): 1.340359\n",
      "Batch #10\tAverage Generator Loss: 1840.063843\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12451 (step 12451): 1.785706\n",
      "Batch #10\tAverage Generator Loss: 1844.458282\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12452 (step 12452): 1.304877\n",
      "Batch #10\tAverage Generator Loss: 1696.125146\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12453 (step 12453): 1.872737\n",
      "Batch #10\tAverage Generator Loss: 1932.726038\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12454 (step 12454): 1.389809\n",
      "Batch #10\tAverage Generator Loss: 1802.792151\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12455 (step 12455): 1.325241\n",
      "Batch #10\tAverage Generator Loss: 1861.043445\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12456 (step 12456): 1.718596\n",
      "Batch #10\tAverage Generator Loss: 1767.694354\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12457 (step 12457): 1.438730\n",
      "Batch #10\tAverage Generator Loss: 1465.833301\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12458 (step 12458): 1.332612\n",
      "Batch #10\tAverage Generator Loss: 1679.675983\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12459 (step 12459): 1.842504\n",
      "Batch #10\tAverage Generator Loss: 1507.492517\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12460 (step 12460): 1.351263\n",
      "Batch #10\tAverage Generator Loss: 1843.874011\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12461 (step 12461): 1.828691\n",
      "Batch #10\tAverage Generator Loss: 1802.286841\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12462 (step 12462): 1.308646\n",
      "Batch #10\tAverage Generator Loss: 1929.953326\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12463 (step 12463): 1.298776\n",
      "Batch #10\tAverage Generator Loss: 2030.450269\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12464 (step 12464): 1.678299\n",
      "Batch #10\tAverage Generator Loss: 2184.068286\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12465 (step 12465): 1.301070\n",
      "Batch #10\tAverage Generator Loss: 2074.806592\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #12466 (step 12466): 1.806075\n",
      "Batch #10\tAverage Generator Loss: 1969.632977\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #12467 (step 12467): 1.391502\n",
      "Batch #10\tAverage Generator Loss: 2084.056561\tAverage Discriminator Loss: 0.516698\n",
      "\n",
      "Train time for epoch #12468 (step 12468): 1.322871\n",
      "Batch #10\tAverage Generator Loss: 1728.878003\tAverage Discriminator Loss: 0.000047\n",
      "\n",
      "Train time for epoch #12469 (step 12469): 1.778342\n",
      "Batch #10\tAverage Generator Loss: 1351.778058\tAverage Discriminator Loss: 0.005200\n",
      "\n",
      "Train time for epoch #12470 (step 12470): 1.245650\n",
      "Batch #10\tAverage Generator Loss: 1434.507373\tAverage Discriminator Loss: 0.001024\n",
      "\n",
      "Train time for epoch #12471 (step 12471): 1.407088\n",
      "Batch #10\tAverage Generator Loss: 1690.854822\tAverage Discriminator Loss: 0.056777\n",
      "\n",
      "Train time for epoch #12472 (step 12472): 1.828188\n",
      "Batch #10\tAverage Generator Loss: 1690.739288\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12473 (step 12473): 1.342874\n",
      "Batch #10\tAverage Generator Loss: 1830.697748\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12474 (step 12474): 1.748154\n",
      "Batch #10\tAverage Generator Loss: 1664.764709\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12475 (step 12475): 1.252885\n",
      "Batch #10\tAverage Generator Loss: 1835.286621\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12476 (step 12476): 1.401404\n",
      "Batch #10\tAverage Generator Loss: 1514.694067\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12477 (step 12477): 1.801625\n",
      "Batch #10\tAverage Generator Loss: 1913.728583\tAverage Discriminator Loss: 0.628238\n",
      "\n",
      "Train time for epoch #12478 (step 12478): 1.246683\n",
      "Batch #10\tAverage Generator Loss: 2319.069836\tAverage Discriminator Loss: 1.498604\n",
      "\n",
      "Train time for epoch #12479 (step 12479): 1.283516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 1892.143878\tAverage Discriminator Loss: 0.071309\n",
      "\n",
      "Train time for epoch #12480 (step 12480): 1.737688\n",
      "Batch #10\tAverage Generator Loss: 1833.884784\tAverage Discriminator Loss: 0.010739\n",
      "\n",
      "Train time for epoch #12481 (step 12481): 1.403879\n",
      "Batch #10\tAverage Generator Loss: 1866.212140\tAverage Discriminator Loss: 0.005452\n",
      "\n",
      "Train time for epoch #12482 (step 12482): 1.343911\n",
      "Batch #10\tAverage Generator Loss: 1978.486572\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12483 (step 12483): 1.731636\n",
      "Batch #10\tAverage Generator Loss: 2542.791663\tAverage Discriminator Loss: 0.000092\n",
      "\n",
      "Train time for epoch #12484 (step 12484): 1.306577\n",
      "Batch #10\tAverage Generator Loss: 2538.566040\tAverage Discriminator Loss: 0.017581\n",
      "\n",
      "Train time for epoch #12485 (step 12485): 1.696955\n",
      "Batch #10\tAverage Generator Loss: 2242.501923\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12486 (step 12486): 1.284471\n",
      "Batch #10\tAverage Generator Loss: 2383.915942\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12487 (step 12487): 1.301630\n",
      "Batch #10\tAverage Generator Loss: 1798.848767\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12488 (step 12488): 1.749124\n",
      "Batch #10\tAverage Generator Loss: 2307.983484\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12489 (step 12489): 1.254813\n",
      "Batch #10\tAverage Generator Loss: 2170.877124\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12490 (step 12490): 1.293895\n",
      "Batch #10\tAverage Generator Loss: 2067.800537\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12491 (step 12491): 1.711753\n",
      "Batch #10\tAverage Generator Loss: 1845.813641\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12492 (step 12492): 1.335880\n",
      "Batch #10\tAverage Generator Loss: 1937.791162\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12493 (step 12493): 1.338838\n",
      "Batch #10\tAverage Generator Loss: 2146.625891\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12494 (step 12494): 1.793185\n",
      "Batch #10\tAverage Generator Loss: 1977.585168\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12495 (step 12495): 1.431848\n",
      "Batch #10\tAverage Generator Loss: 2084.321997\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12496 (step 12496): 1.753015\n",
      "Batch #10\tAverage Generator Loss: 2362.446680\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12497 (step 12497): 1.399521\n",
      "Batch #10\tAverage Generator Loss: 2377.931946\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12498 (step 12498): 1.353565\n",
      "Batch #10\tAverage Generator Loss: 2186.365320\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12499 (step 12499): 1.865547\n",
      "Batch #10\tAverage Generator Loss: 2083.932227\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12500 (step 12500): 1.428808\n",
      "Batch #10\tAverage Generator Loss: 1695.873108\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12501 (step 12501): 1.309985\n",
      "Batch #10\tAverage Generator Loss: 2087.360345\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12502 (step 12502): 1.800196\n",
      "Batch #10\tAverage Generator Loss: 2113.407629\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12503 (step 12503): 1.316589\n",
      "Batch #10\tAverage Generator Loss: 2216.367603\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12504 (step 12504): 1.422239\n",
      "Batch #10\tAverage Generator Loss: 2127.120703\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12505 (step 12505): 1.727838\n",
      "Batch #10\tAverage Generator Loss: 1903.115442\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12506 (step 12506): 1.335342\n",
      "Batch #10\tAverage Generator Loss: 1870.136951\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12507 (step 12507): 1.722176\n",
      "Batch #10\tAverage Generator Loss: 2036.698352\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12508 (step 12508): 1.365803\n",
      "Batch #10\tAverage Generator Loss: 2205.746521\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12509 (step 12509): 1.399977\n",
      "Batch #10\tAverage Generator Loss: 2015.507129\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12510 (step 12510): 1.772085\n",
      "Batch #10\tAverage Generator Loss: 2132.375354\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12511 (step 12511): 1.311140\n",
      "Batch #10\tAverage Generator Loss: 2484.805139\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12512 (step 12512): 1.332503\n",
      "Batch #10\tAverage Generator Loss: 2171.948657\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12513 (step 12513): 1.689066\n",
      "Batch #10\tAverage Generator Loss: 1885.179767\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12514 (step 12514): 1.298600\n",
      "Batch #10\tAverage Generator Loss: 2025.797437\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12515 (step 12515): 1.290856\n",
      "Batch #10\tAverage Generator Loss: 2056.721790\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12516 (step 12516): 1.830718\n",
      "Batch #10\tAverage Generator Loss: 1815.967249\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12517 (step 12517): 1.282827\n",
      "Batch #10\tAverage Generator Loss: 1855.943579\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12518 (step 12518): 1.752859\n",
      "Batch #10\tAverage Generator Loss: 2017.868811\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12519 (step 12519): 1.289335\n",
      "Batch #10\tAverage Generator Loss: 1788.469238\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12520 (step 12520): 1.291354\n",
      "Batch #10\tAverage Generator Loss: 1844.871161\tAverage Discriminator Loss: 0.001456\n",
      "\n",
      "Train time for epoch #12521 (step 12521): 1.703890\n",
      "Batch #10\tAverage Generator Loss: 1977.700415\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12522 (step 12522): 1.382091\n",
      "Batch #10\tAverage Generator Loss: 1898.058643\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12523 (step 12523): 1.295804\n",
      "Batch #10\tAverage Generator Loss: 2369.105994\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12524 (step 12524): 1.728456\n",
      "Batch #10\tAverage Generator Loss: 1838.437122\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12525 (step 12525): 1.310671\n",
      "Batch #10\tAverage Generator Loss: 1526.908173\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12526 (step 12526): 1.352866\n",
      "Batch #10\tAverage Generator Loss: 1695.791101\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12527 (step 12527): 1.665259\n",
      "Batch #10\tAverage Generator Loss: 2117.895258\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12528 (step 12528): 1.297443\n",
      "Batch #10\tAverage Generator Loss: 2002.123743\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12529 (step 12529): 1.836008\n",
      "Batch #10\tAverage Generator Loss: 1931.767517\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12530 (step 12530): 1.298776\n",
      "Batch #10\tAverage Generator Loss: 1904.907458\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12531 (step 12531): 1.298460\n",
      "Batch #10\tAverage Generator Loss: 1673.998401\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12532 (step 12532): 1.775237\n",
      "Batch #10\tAverage Generator Loss: 2170.402313\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12533 (step 12533): 1.378786\n",
      "Batch #10\tAverage Generator Loss: 2177.898230\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12534 (step 12534): 1.281018\n",
      "Batch #10\tAverage Generator Loss: 2056.286444\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12535 (step 12535): 1.684672\n",
      "Batch #10\tAverage Generator Loss: 2156.038672\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12536 (step 12536): 1.361308\n",
      "Batch #10\tAverage Generator Loss: 2085.821472\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12537 (step 12537): 1.709675\n",
      "Batch #10\tAverage Generator Loss: 2348.311035\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12538 (step 12538): 1.284853\n",
      "Batch #10\tAverage Generator Loss: 2334.836926\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12539 (step 12539): 1.241041\n",
      "Batch #10\tAverage Generator Loss: 1993.069482\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12540 (step 12540): 1.878219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 1941.455682\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12541 (step 12541): 1.284522\n",
      "Batch #10\tAverage Generator Loss: 1969.195020\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12542 (step 12542): 1.288527\n",
      "Batch #10\tAverage Generator Loss: 1919.900702\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12543 (step 12543): 1.771893\n",
      "Batch #10\tAverage Generator Loss: 1984.709540\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12544 (step 12544): 1.358802\n",
      "Batch #10\tAverage Generator Loss: 2000.083093\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12545 (step 12545): 1.292834\n",
      "Batch #10\tAverage Generator Loss: 1765.881171\tAverage Discriminator Loss: 0.093524\n",
      "\n",
      "Train time for epoch #12546 (step 12546): 1.850232\n",
      "Batch #10\tAverage Generator Loss: 1665.715271\tAverage Discriminator Loss: 0.007649\n",
      "\n",
      "Train time for epoch #12547 (step 12547): 1.380743\n",
      "Batch #10\tAverage Generator Loss: 1793.627979\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12548 (step 12548): 1.800543\n",
      "Batch #10\tAverage Generator Loss: 1714.846008\tAverage Discriminator Loss: 0.002769\n",
      "\n",
      "Train time for epoch #12549 (step 12549): 1.336444\n",
      "Batch #10\tAverage Generator Loss: 1963.394507\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #12550 (step 12550): 1.289758\n",
      "Batch #10\tAverage Generator Loss: 1962.833917\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #12551 (step 12551): 1.729071\n",
      "Batch #10\tAverage Generator Loss: 1963.629626\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #12552 (step 12552): 1.336636\n",
      "Batch #10\tAverage Generator Loss: 1844.241040\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12553 (step 12553): 1.294547\n",
      "Batch #10\tAverage Generator Loss: 1830.380463\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12554 (step 12554): 1.680848\n",
      "Batch #10\tAverage Generator Loss: 1744.685529\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #12555 (step 12555): 1.342607\n",
      "Batch #10\tAverage Generator Loss: 2229.852130\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12556 (step 12556): 1.395788\n",
      "Batch #10\tAverage Generator Loss: 2095.779608\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #12557 (step 12557): 1.698008\n",
      "Batch #10\tAverage Generator Loss: 2075.858295\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12558 (step 12558): 1.392498\n",
      "Batch #10\tAverage Generator Loss: 1921.757312\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #12559 (step 12559): 1.835565\n",
      "Batch #10\tAverage Generator Loss: 1976.816431\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #12560 (step 12560): 1.278728\n",
      "Batch #10\tAverage Generator Loss: 2001.043311\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #12561 (step 12561): 1.335053\n",
      "Batch #10\tAverage Generator Loss: 2082.830103\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #12562 (step 12562): 1.768812\n",
      "Batch #10\tAverage Generator Loss: 2143.537427\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #12563 (step 12563): 1.344151\n",
      "Batch #10\tAverage Generator Loss: 1851.231848\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #12564 (step 12564): 1.304998\n",
      "Batch #10\tAverage Generator Loss: 1987.735120\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12565 (step 12565): 1.703934\n",
      "Batch #10\tAverage Generator Loss: 1815.144812\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #12566 (step 12566): 1.338794\n",
      "Batch #10\tAverage Generator Loss: 1856.670154\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #12567 (step 12567): 1.431177\n",
      "Batch #10\tAverage Generator Loss: 2053.838910\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12568 (step 12568): 1.762567\n",
      "Batch #10\tAverage Generator Loss: 1961.858655\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12569 (step 12569): 1.342420\n",
      "Batch #10\tAverage Generator Loss: 1621.427246\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #12570 (step 12570): 1.750564\n",
      "Batch #10\tAverage Generator Loss: 2001.354004\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #12571 (step 12571): 1.418295\n",
      "Batch #10\tAverage Generator Loss: 1631.085510\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #12572 (step 12572): 1.450038\n",
      "Batch #10\tAverage Generator Loss: 1895.575891\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12573 (step 12573): 1.873603\n",
      "Batch #10\tAverage Generator Loss: 1970.151892\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #12574 (step 12574): 1.442133\n",
      "Batch #10\tAverage Generator Loss: 1917.540033\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #12575 (step 12575): 1.384788\n",
      "Batch #10\tAverage Generator Loss: 1903.865552\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #12576 (step 12576): 1.889184\n",
      "Batch #10\tAverage Generator Loss: 2097.150061\tAverage Discriminator Loss: 0.006960\n",
      "\n",
      "Train time for epoch #12577 (step 12577): 1.331522\n",
      "Batch #10\tAverage Generator Loss: 2109.767297\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #12578 (step 12578): 1.277497\n",
      "Batch #10\tAverage Generator Loss: 1860.941272\tAverage Discriminator Loss: 0.000029\n",
      "\n",
      "Train time for epoch #12579 (step 12579): 1.829365\n",
      "Batch #10\tAverage Generator Loss: 1893.228760\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #12580 (step 12580): 1.284317\n",
      "Batch #10\tAverage Generator Loss: 1912.621686\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #12581 (step 12581): 1.842700\n",
      "Batch #10\tAverage Generator Loss: 1848.736707\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #12582 (step 12582): 1.497160\n",
      "Batch #10\tAverage Generator Loss: 2019.369714\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #12583 (step 12583): 1.398605\n",
      "Batch #10\tAverage Generator Loss: 2135.835681\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #12584 (step 12584): 1.759769\n",
      "Batch #10\tAverage Generator Loss: 1717.309326\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #12585 (step 12585): 1.412812\n",
      "Batch #10\tAverage Generator Loss: 1652.087689\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #12586 (step 12586): 1.431617\n",
      "Batch #10\tAverage Generator Loss: 1705.813782\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #12587 (step 12587): 1.739202\n",
      "Batch #10\tAverage Generator Loss: 2018.590265\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #12588 (step 12588): 1.292591\n",
      "Batch #10\tAverage Generator Loss: 1889.483276\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #12589 (step 12589): 1.435474\n",
      "Batch #10\tAverage Generator Loss: 1963.746899\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #12590 (step 12590): 1.815613\n",
      "Batch #10\tAverage Generator Loss: 2042.769470\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #12591 (step 12591): 1.334487\n",
      "Batch #10\tAverage Generator Loss: 1945.758002\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #12592 (step 12592): 1.289941\n",
      "Batch #10\tAverage Generator Loss: 1748.973486\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #12593 (step 12593): 1.638732\n",
      "Batch #10\tAverage Generator Loss: 2413.733484\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #12594 (step 12594): 1.315536\n",
      "Batch #10\tAverage Generator Loss: 2048.723755\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #12595 (step 12595): 1.796450\n",
      "Batch #10\tAverage Generator Loss: 1832.331366\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #12596 (step 12596): 1.289757\n",
      "Batch #10\tAverage Generator Loss: 2111.675537\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #12597 (step 12597): 1.344969\n",
      "Batch #10\tAverage Generator Loss: 2054.856360\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #12598 (step 12598): 1.740133\n",
      "Batch #10\tAverage Generator Loss: 1866.248193\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #12599 (step 12599): 1.336778\n",
      "Batch #10\tAverage Generator Loss: 2040.203351\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #12600 (step 12600): 1.334959\n",
      "Batch #10\tAverage Generator Loss: 1975.391528\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #12601 (step 12601): 1.758518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 1884.570544\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #12602 (step 12602): 1.288638\n",
      "Batch #10\tAverage Generator Loss: 2009.605707\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #12603 (step 12603): 1.413720\n",
      "Batch #10\tAverage Generator Loss: 1816.258356\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #12604 (step 12604): 1.829278\n",
      "Batch #10\tAverage Generator Loss: 1786.543005\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #12605 (step 12605): 1.427910\n",
      "Batch #10\tAverage Generator Loss: 1883.855774\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #12606 (step 12606): 1.787346\n",
      "Batch #10\tAverage Generator Loss: 1935.076245\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #12607 (step 12607): 1.334822\n",
      "Batch #10\tAverage Generator Loss: 1797.955865\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #12608 (step 12608): 1.344265\n",
      "Batch #10\tAverage Generator Loss: 1832.185205\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #12609 (step 12609): 1.765126\n",
      "Batch #10\tAverage Generator Loss: 1807.595813\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #12610 (step 12610): 1.447308\n",
      "Batch #10\tAverage Generator Loss: 1915.761456\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #12611 (step 12611): 1.312170\n",
      "Batch #10\tAverage Generator Loss: 1610.057159\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #12612 (step 12612): 1.724943\n",
      "Batch #10\tAverage Generator Loss: 1997.743268\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #12613 (step 12613): 1.284378\n",
      "Batch #10\tAverage Generator Loss: 2009.249622\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #12614 (step 12614): 1.287581\n",
      "Batch #10\tAverage Generator Loss: 1809.746729\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #12615 (step 12615): 1.663675\n",
      "Batch #10\tAverage Generator Loss: 2081.054187\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #12616 (step 12616): 1.429968\n",
      "Batch #10\tAverage Generator Loss: 1624.306866\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #12617 (step 12617): 1.294731\n",
      "Batch #10\tAverage Generator Loss: 1799.696155\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #12618 (step 12618): 1.759471\n",
      "Batch #10\tAverage Generator Loss: 1816.036768\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #12619 (step 12619): 1.399283\n",
      "Batch #10\tAverage Generator Loss: 1949.372607\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #12620 (step 12620): 1.670097\n",
      "Batch #10\tAverage Generator Loss: 1919.673761\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #12621 (step 12621): 1.349208\n",
      "Batch #10\tAverage Generator Loss: 1692.970605\tAverage Discriminator Loss: 0.000209\n",
      "\n",
      "Train time for epoch #12622 (step 12622): 1.333932\n",
      "Batch #10\tAverage Generator Loss: 2146.546692\tAverage Discriminator Loss: 0.000672\n",
      "\n",
      "Train time for epoch #12623 (step 12623): 1.752810\n",
      "Batch #10\tAverage Generator Loss: 2134.273706\tAverage Discriminator Loss: 0.000022\n",
      "\n",
      "Train time for epoch #12624 (step 12624): 1.449985\n",
      "Batch #10\tAverage Generator Loss: 1945.447162\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #12625 (step 12625): 1.346932\n",
      "Batch #10\tAverage Generator Loss: 1654.345502\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #12626 (step 12626): 1.785506\n",
      "Batch #10\tAverage Generator Loss: 1760.489160\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #12627 (step 12627): 1.295010\n",
      "Batch #10\tAverage Generator Loss: 1843.669348\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #12628 (step 12628): 1.275479\n",
      "Batch #10\tAverage Generator Loss: 2074.475183\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #12629 (step 12629): 1.749303\n",
      "Batch #10\tAverage Generator Loss: 1808.123322\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #12630 (step 12630): 1.280893\n",
      "Batch #10\tAverage Generator Loss: 1833.219690\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #12631 (step 12631): 1.745050\n",
      "Batch #10\tAverage Generator Loss: 1868.264587\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #12632 (step 12632): 1.287201\n",
      "Batch #10\tAverage Generator Loss: 1995.840198\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #12633 (step 12633): 1.296776\n",
      "Batch #10\tAverage Generator Loss: 1848.088257\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #12634 (step 12634): 1.732898\n",
      "Batch #10\tAverage Generator Loss: 1882.872522\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #12635 (step 12635): 1.285860\n",
      "Batch #10\tAverage Generator Loss: 1812.604706\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #12636 (step 12636): 1.348621\n",
      "Batch #10\tAverage Generator Loss: 1882.610803\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #12637 (step 12637): 1.748101\n",
      "Batch #10\tAverage Generator Loss: 1821.450098\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #12638 (step 12638): 1.344020\n",
      "Batch #10\tAverage Generator Loss: 2132.886987\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #12639 (step 12639): 1.339495\n",
      "Batch #10\tAverage Generator Loss: 1917.834094\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #12640 (step 12640): 1.697100\n",
      "Batch #10\tAverage Generator Loss: 1955.136743\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #12641 (step 12641): 1.407309\n",
      "Batch #10\tAverage Generator Loss: 1689.069598\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #12642 (step 12642): 1.320809\n",
      "Batch #10\tAverage Generator Loss: 2163.130225\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #12643 (step 12643): 1.743724\n",
      "Batch #10\tAverage Generator Loss: 1956.157300\tAverage Discriminator Loss: 0.035819\n",
      "\n",
      "Train time for epoch #12644 (step 12644): 1.386512\n",
      "Batch #10\tAverage Generator Loss: 2011.307239\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #12645 (step 12645): 1.375966\n",
      "Batch #10\tAverage Generator Loss: 2200.836951\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12646 (step 12646): 1.700220\n",
      "Batch #10\tAverage Generator Loss: 2069.421814\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12647 (step 12647): 1.328309\n",
      "Batch #10\tAverage Generator Loss: 2159.070911\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12648 (step 12648): 1.289186\n",
      "Batch #10\tAverage Generator Loss: 2467.064755\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12649 (step 12649): 1.773591\n",
      "Batch #10\tAverage Generator Loss: 2383.532910\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12650 (step 12650): 1.288810\n",
      "Batch #10\tAverage Generator Loss: 1758.225397\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12651 (step 12651): 1.735088\n",
      "Batch #10\tAverage Generator Loss: 2196.019226\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12652 (step 12652): 1.295796\n",
      "Batch #10\tAverage Generator Loss: 2016.503772\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12653 (step 12653): 1.337748\n",
      "Batch #10\tAverage Generator Loss: 2181.709955\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12654 (step 12654): 1.775369\n",
      "Batch #10\tAverage Generator Loss: 2097.350183\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12655 (step 12655): 1.335156\n",
      "Batch #10\tAverage Generator Loss: 2097.988525\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12656 (step 12656): 1.393671\n",
      "Batch #10\tAverage Generator Loss: 2087.061206\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12657 (step 12657): 1.735827\n",
      "Batch #10\tAverage Generator Loss: 2164.198242\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12658 (step 12658): 1.295121\n",
      "Batch #10\tAverage Generator Loss: 1940.595898\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12659 (step 12659): 1.286738\n",
      "Batch #10\tAverage Generator Loss: 2278.719849\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12660 (step 12660): 1.722310\n",
      "Batch #10\tAverage Generator Loss: 1946.785901\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12661 (step 12661): 1.392498\n",
      "Batch #10\tAverage Generator Loss: 2213.329309\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12662 (step 12662): 1.277849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 1997.981946\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12663 (step 12663): 1.733405\n",
      "Batch #10\tAverage Generator Loss: 2048.944836\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12664 (step 12664): 1.292883\n",
      "Batch #10\tAverage Generator Loss: 2143.641663\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12665 (step 12665): 1.803972\n",
      "Batch #10\tAverage Generator Loss: 2412.924805\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12666 (step 12666): 1.372674\n",
      "Batch #10\tAverage Generator Loss: 2476.366040\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12667 (step 12667): 1.296801\n",
      "Batch #10\tAverage Generator Loss: 2318.738379\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12668 (step 12668): 1.696639\n",
      "Batch #10\tAverage Generator Loss: 1879.232629\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12669 (step 12669): 1.423869\n",
      "Batch #10\tAverage Generator Loss: 2370.125415\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12670 (step 12670): 1.339588\n",
      "Batch #10\tAverage Generator Loss: 2477.731763\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12671 (step 12671): 1.735499\n",
      "Batch #10\tAverage Generator Loss: 2047.462659\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12672 (step 12672): 1.340675\n",
      "Batch #10\tAverage Generator Loss: 2317.579199\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12673 (step 12673): 1.760145\n",
      "Batch #10\tAverage Generator Loss: 2045.126428\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12674 (step 12674): 1.289433\n",
      "Batch #10\tAverage Generator Loss: 2274.747620\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12675 (step 12675): 1.295271\n",
      "Batch #10\tAverage Generator Loss: 1862.886633\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12676 (step 12676): 1.798779\n",
      "Batch #10\tAverage Generator Loss: 2103.040967\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12677 (step 12677): 1.437999\n",
      "Batch #10\tAverage Generator Loss: 2289.740723\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12678 (step 12678): 1.390254\n",
      "Batch #10\tAverage Generator Loss: 1930.597253\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12679 (step 12679): 1.750263\n",
      "Batch #10\tAverage Generator Loss: 1709.258746\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12680 (step 12680): 1.346133\n",
      "Batch #10\tAverage Generator Loss: 2111.003589\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12681 (step 12681): 1.693111\n",
      "Batch #10\tAverage Generator Loss: 2038.529028\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12682 (step 12682): 1.396217\n",
      "Batch #10\tAverage Generator Loss: 2198.966870\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12683 (step 12683): 1.352832\n",
      "Batch #10\tAverage Generator Loss: 1923.405945\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12684 (step 12684): 1.717381\n",
      "Batch #10\tAverage Generator Loss: 2160.827655\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12685 (step 12685): 1.443526\n",
      "Batch #10\tAverage Generator Loss: 2005.030750\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12686 (step 12686): 1.287810\n",
      "Batch #10\tAverage Generator Loss: 1927.563184\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12687 (step 12687): 1.824330\n",
      "Batch #10\tAverage Generator Loss: 2337.329749\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12688 (step 12688): 1.314977\n",
      "Batch #10\tAverage Generator Loss: 2012.320410\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12689 (step 12689): 1.395665\n",
      "Batch #10\tAverage Generator Loss: 2097.783289\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12690 (step 12690): 1.832171\n",
      "Batch #10\tAverage Generator Loss: 2077.594348\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12691 (step 12691): 1.344465\n",
      "Batch #10\tAverage Generator Loss: 2057.228217\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12692 (step 12692): 1.715873\n",
      "Batch #10\tAverage Generator Loss: 1958.642578\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12693 (step 12693): 1.339836\n",
      "Batch #10\tAverage Generator Loss: 2113.124976\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12694 (step 12694): 1.388812\n",
      "Batch #10\tAverage Generator Loss: 2005.935077\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12695 (step 12695): 1.880430\n",
      "Batch #10\tAverage Generator Loss: 2106.735608\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12696 (step 12696): 1.314598\n",
      "Batch #10\tAverage Generator Loss: 1730.898291\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12697 (step 12697): 1.387045\n",
      "Batch #10\tAverage Generator Loss: 2097.399243\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12698 (step 12698): 1.722259\n",
      "Batch #10\tAverage Generator Loss: 2012.838623\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12699 (step 12699): 1.277419\n",
      "Batch #10\tAverage Generator Loss: 1998.370398\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12700 (step 12700): 1.280558\n",
      "Batch #10\tAverage Generator Loss: 2167.220941\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12701 (step 12701): 1.774024\n",
      "Batch #10\tAverage Generator Loss: 2351.742657\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12702 (step 12702): 1.290309\n",
      "Batch #10\tAverage Generator Loss: 1991.497119\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12703 (step 12703): 1.292914\n",
      "Batch #10\tAverage Generator Loss: 2042.675598\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12704 (step 12704): 1.768581\n",
      "Batch #10\tAverage Generator Loss: 1978.506396\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12705 (step 12705): 1.342867\n",
      "Batch #10\tAverage Generator Loss: 2044.464514\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12706 (step 12706): 1.752000\n",
      "Batch #10\tAverage Generator Loss: 1973.136682\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12707 (step 12707): 1.389656\n",
      "Batch #10\tAverage Generator Loss: 1778.549054\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12708 (step 12708): 1.366246\n",
      "Batch #10\tAverage Generator Loss: 2016.596472\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12709 (step 12709): 1.656322\n",
      "Batch #10\tAverage Generator Loss: 2016.307599\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12710 (step 12710): 1.285113\n",
      "Batch #10\tAverage Generator Loss: 2430.282959\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12711 (step 12711): 1.293828\n",
      "Batch #10\tAverage Generator Loss: 2093.714624\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12712 (step 12712): 1.702115\n",
      "Batch #10\tAverage Generator Loss: 2069.183759\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12713 (step 12713): 1.276176\n",
      "Batch #10\tAverage Generator Loss: 1942.810059\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12714 (step 12714): 1.343431\n",
      "Batch #10\tAverage Generator Loss: 2042.560742\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12715 (step 12715): 1.740905\n",
      "Batch #10\tAverage Generator Loss: 2033.601758\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12716 (step 12716): 1.384591\n",
      "Batch #10\tAverage Generator Loss: 1972.097211\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12717 (step 12717): 1.694935\n",
      "Batch #10\tAverage Generator Loss: 2088.252985\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12718 (step 12718): 1.234629\n",
      "Batch #10\tAverage Generator Loss: 1896.887122\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12719 (step 12719): 1.328935\n",
      "Batch #10\tAverage Generator Loss: 1954.081537\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12720 (step 12720): 1.817161\n",
      "Batch #10\tAverage Generator Loss: 2206.791809\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12721 (step 12721): 1.283988\n",
      "Batch #10\tAverage Generator Loss: 2156.285748\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12722 (step 12722): 1.477528\n",
      "Batch #10\tAverage Generator Loss: 1821.245013\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12723 (step 12723): 1.728834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2027.498053\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12724 (step 12724): 1.369850\n",
      "Batch #10\tAverage Generator Loss: 1830.492963\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12725 (step 12725): 1.335452\n",
      "Batch #10\tAverage Generator Loss: 1477.450958\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12726 (step 12726): 1.703043\n",
      "Batch #10\tAverage Generator Loss: 2181.689819\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12727 (step 12727): 1.310997\n",
      "Batch #10\tAverage Generator Loss: 2021.443628\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12728 (step 12728): 1.499733\n",
      "Batch #10\tAverage Generator Loss: 2172.973993\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12729 (step 12729): 1.792060\n",
      "Batch #10\tAverage Generator Loss: 2166.342151\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12730 (step 12730): 1.280868\n",
      "Batch #10\tAverage Generator Loss: 2098.110400\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12731 (step 12731): 1.302563\n",
      "Batch #10\tAverage Generator Loss: 2177.954651\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12732 (step 12732): 1.735289\n",
      "Batch #10\tAverage Generator Loss: 2172.840344\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12733 (step 12733): 1.377204\n",
      "Batch #10\tAverage Generator Loss: 2236.817017\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12734 (step 12734): 1.322921\n",
      "Batch #10\tAverage Generator Loss: 2464.626758\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12735 (step 12735): 1.764890\n",
      "Batch #10\tAverage Generator Loss: 2089.889685\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12736 (step 12736): 1.230537\n",
      "Batch #10\tAverage Generator Loss: 2085.938409\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12737 (step 12737): 1.679287\n",
      "Batch #10\tAverage Generator Loss: 2322.008887\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12738 (step 12738): 1.308565\n",
      "Batch #10\tAverage Generator Loss: 1990.107062\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12739 (step 12739): 1.326112\n",
      "Batch #10\tAverage Generator Loss: 2265.373950\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12740 (step 12740): 1.708786\n",
      "Batch #10\tAverage Generator Loss: 2189.412952\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12741 (step 12741): 1.284494\n",
      "Batch #10\tAverage Generator Loss: 1781.074945\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12742 (step 12742): 1.351522\n",
      "Batch #10\tAverage Generator Loss: 1799.445685\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12743 (step 12743): 1.797037\n",
      "Batch #10\tAverage Generator Loss: 2237.740625\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12744 (step 12744): 1.418080\n",
      "Batch #10\tAverage Generator Loss: 2129.587402\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12745 (step 12745): 1.384611\n",
      "Batch #10\tAverage Generator Loss: 1913.330798\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12746 (step 12746): 1.718796\n",
      "Batch #10\tAverage Generator Loss: 1724.247137\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12747 (step 12747): 1.348167\n",
      "Batch #10\tAverage Generator Loss: 2202.190747\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12748 (step 12748): 1.802574\n",
      "Batch #10\tAverage Generator Loss: 1845.276624\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12749 (step 12749): 1.305686\n",
      "Batch #10\tAverage Generator Loss: 1832.870923\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12750 (step 12750): 1.425928\n",
      "Batch #10\tAverage Generator Loss: 1964.409509\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12751 (step 12751): 1.769571\n",
      "Batch #10\tAverage Generator Loss: 2270.633630\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12752 (step 12752): 1.282920\n",
      "Batch #10\tAverage Generator Loss: 2112.793018\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12753 (step 12753): 1.299265\n",
      "Batch #10\tAverage Generator Loss: 1807.802216\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12754 (step 12754): 1.772614\n",
      "Batch #10\tAverage Generator Loss: 2056.724231\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12755 (step 12755): 1.246492\n",
      "Batch #10\tAverage Generator Loss: 2111.297693\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12756 (step 12756): 1.397506\n",
      "Batch #10\tAverage Generator Loss: 2102.339587\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12757 (step 12757): 1.704754\n",
      "Batch #10\tAverage Generator Loss: 2222.927466\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12758 (step 12758): 1.496186\n",
      "Batch #10\tAverage Generator Loss: 1689.323053\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12759 (step 12759): 1.951472\n",
      "Batch #10\tAverage Generator Loss: 1529.158136\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12760 (step 12760): 1.282092\n",
      "Batch #10\tAverage Generator Loss: 1918.197412\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12761 (step 12761): 1.261363\n",
      "Batch #10\tAverage Generator Loss: 2069.429395\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12762 (step 12762): 1.719431\n",
      "Batch #10\tAverage Generator Loss: 1787.303864\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12763 (step 12763): 1.292026\n",
      "Batch #10\tAverage Generator Loss: 2089.281061\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12764 (step 12764): 1.284342\n",
      "Batch #10\tAverage Generator Loss: 2098.543347\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12765 (step 12765): 1.723782\n",
      "Batch #10\tAverage Generator Loss: 1704.749799\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12766 (step 12766): 1.356656\n",
      "Batch #10\tAverage Generator Loss: 2362.562781\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12767 (step 12767): 1.342587\n",
      "Batch #10\tAverage Generator Loss: 2053.806595\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12768 (step 12768): 1.796827\n",
      "Batch #10\tAverage Generator Loss: 2024.506885\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12769 (step 12769): 1.291738\n",
      "Batch #10\tAverage Generator Loss: 1924.698376\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12770 (step 12770): 1.302314\n",
      "Batch #10\tAverage Generator Loss: 2036.340906\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12771 (step 12771): 1.751168\n",
      "Batch #10\tAverage Generator Loss: 1916.881219\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12772 (step 12772): 1.262220\n",
      "Batch #10\tAverage Generator Loss: 1834.259229\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12773 (step 12773): 1.756773\n",
      "Batch #10\tAverage Generator Loss: 2075.603552\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12774 (step 12774): 1.296845\n",
      "Batch #10\tAverage Generator Loss: 2210.207190\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12775 (step 12775): 1.360702\n",
      "Batch #10\tAverage Generator Loss: 2095.936017\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12776 (step 12776): 1.817293\n",
      "Batch #10\tAverage Generator Loss: 2328.250476\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12777 (step 12777): 1.241304\n",
      "Batch #10\tAverage Generator Loss: 1884.726526\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12778 (step 12778): 1.459949\n",
      "Batch #10\tAverage Generator Loss: 2105.276868\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12779 (step 12779): 1.728607\n",
      "Batch #10\tAverage Generator Loss: 2241.378796\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12780 (step 12780): 1.283212\n",
      "Batch #10\tAverage Generator Loss: 2354.245288\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12781 (step 12781): 1.402399\n",
      "Batch #10\tAverage Generator Loss: 1933.623840\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12782 (step 12782): 1.759807\n",
      "Batch #10\tAverage Generator Loss: 2044.451782\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12783 (step 12783): 1.299479\n",
      "Batch #10\tAverage Generator Loss: 1998.195087\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12784 (step 12784): 1.378780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2110.633716\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12785 (step 12785): 1.818173\n",
      "Batch #10\tAverage Generator Loss: 2187.989050\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12786 (step 12786): 1.291149\n",
      "Batch #10\tAverage Generator Loss: 1977.371570\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12787 (step 12787): 1.692738\n",
      "Batch #10\tAverage Generator Loss: 2248.989624\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12788 (step 12788): 1.307662\n",
      "Batch #10\tAverage Generator Loss: 1893.604694\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12789 (step 12789): 1.387776\n",
      "Batch #10\tAverage Generator Loss: 2051.122083\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12790 (step 12790): 1.792878\n",
      "Batch #10\tAverage Generator Loss: 1938.050781\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12791 (step 12791): 1.285293\n",
      "Batch #10\tAverage Generator Loss: 1762.933856\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12792 (step 12792): 1.326711\n",
      "Batch #10\tAverage Generator Loss: 2434.469629\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #12793 (step 12793): 1.781106\n",
      "Batch #10\tAverage Generator Loss: 2135.496716\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12794 (step 12794): 1.300241\n",
      "Batch #10\tAverage Generator Loss: 2128.534607\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12795 (step 12795): 1.342950\n",
      "Batch #10\tAverage Generator Loss: 1956.960626\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12796 (step 12796): 1.781201\n",
      "Batch #10\tAverage Generator Loss: 2224.070056\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12797 (step 12797): 1.336558\n",
      "Batch #10\tAverage Generator Loss: 2190.146350\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12798 (step 12798): 1.645592\n",
      "Batch #10\tAverage Generator Loss: 1933.966321\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12799 (step 12799): 1.425605\n",
      "Batch #10\tAverage Generator Loss: 2114.879895\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12800 (step 12800): 1.362615\n",
      "Batch #10\tAverage Generator Loss: 2121.803198\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12801 (step 12801): 1.780046\n",
      "Batch #10\tAverage Generator Loss: 2023.590765\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12802 (step 12802): 1.240870\n",
      "Batch #10\tAverage Generator Loss: 2236.125061\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12803 (step 12803): 1.346927\n",
      "Batch #10\tAverage Generator Loss: 1862.974756\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12804 (step 12804): 1.767199\n",
      "Batch #10\tAverage Generator Loss: 2108.065784\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12805 (step 12805): 1.284707\n",
      "Batch #10\tAverage Generator Loss: 2184.710583\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12806 (step 12806): 1.291270\n",
      "Batch #10\tAverage Generator Loss: 2098.243286\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12807 (step 12807): 1.824278\n",
      "Batch #10\tAverage Generator Loss: 1851.748688\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12808 (step 12808): 1.277275\n",
      "Batch #10\tAverage Generator Loss: 2030.582007\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12809 (step 12809): 1.417533\n",
      "Batch #10\tAverage Generator Loss: 2052.378436\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12810 (step 12810): 1.748359\n",
      "Batch #10\tAverage Generator Loss: 1958.915228\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12811 (step 12811): 1.336864\n",
      "Batch #10\tAverage Generator Loss: 1916.265930\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12812 (step 12812): 1.727883\n",
      "Batch #10\tAverage Generator Loss: 2352.578357\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12813 (step 12813): 1.440437\n",
      "Batch #10\tAverage Generator Loss: 2003.210687\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12814 (step 12814): 1.307708\n",
      "Batch #10\tAverage Generator Loss: 2066.921399\tAverage Discriminator Loss: 0.009486\n",
      "\n",
      "Train time for epoch #12815 (step 12815): 1.991501\n",
      "Batch #10\tAverage Generator Loss: 1997.963361\tAverage Discriminator Loss: 0.000526\n",
      "\n",
      "Train time for epoch #12816 (step 12816): 1.292210\n",
      "Batch #10\tAverage Generator Loss: 1813.949298\tAverage Discriminator Loss: 0.000024\n",
      "\n",
      "Train time for epoch #12817 (step 12817): 1.390115\n",
      "Batch #10\tAverage Generator Loss: 1855.697482\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #12818 (step 12818): 1.857823\n",
      "Batch #10\tAverage Generator Loss: 2241.031128\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #12819 (step 12819): 1.335505\n",
      "Batch #10\tAverage Generator Loss: 1851.378363\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #12820 (step 12820): 1.345089\n",
      "Batch #10\tAverage Generator Loss: 2166.688879\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #12821 (step 12821): 1.781519\n",
      "Batch #10\tAverage Generator Loss: 2235.289197\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #12822 (step 12822): 1.485219\n",
      "Batch #10\tAverage Generator Loss: 1965.921600\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #12823 (step 12823): 1.337253\n",
      "Batch #10\tAverage Generator Loss: 1828.169385\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #12824 (step 12824): 1.740217\n",
      "Batch #10\tAverage Generator Loss: 1953.212439\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #12825 (step 12825): 1.299683\n",
      "Batch #10\tAverage Generator Loss: 1687.349982\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #12826 (step 12826): 1.413153\n",
      "Batch #10\tAverage Generator Loss: 2096.797827\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #12827 (step 12827): 1.713603\n",
      "Batch #10\tAverage Generator Loss: 1797.201929\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #12828 (step 12828): 1.289768\n",
      "Batch #10\tAverage Generator Loss: 1947.855396\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #12829 (step 12829): 1.279665\n",
      "Batch #10\tAverage Generator Loss: 2014.751770\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #12830 (step 12830): 1.703580\n",
      "Batch #10\tAverage Generator Loss: 2363.363806\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #12831 (step 12831): 1.335828\n",
      "Batch #10\tAverage Generator Loss: 2060.726062\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #12832 (step 12832): 1.724851\n",
      "Batch #10\tAverage Generator Loss: 1778.427063\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #12833 (step 12833): 1.359358\n",
      "Batch #10\tAverage Generator Loss: 2048.855371\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #12834 (step 12834): 1.291643\n",
      "Batch #10\tAverage Generator Loss: 1958.378455\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #12835 (step 12835): 1.806178\n",
      "Batch #10\tAverage Generator Loss: 2079.188940\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #12836 (step 12836): 1.247254\n",
      "Batch #10\tAverage Generator Loss: 1822.513477\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #12837 (step 12837): 1.270553\n",
      "Batch #10\tAverage Generator Loss: 2150.265479\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #12838 (step 12838): 1.678421\n",
      "Batch #10\tAverage Generator Loss: 2089.565002\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #12839 (step 12839): 1.298405\n",
      "Batch #10\tAverage Generator Loss: 1797.238116\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #12840 (step 12840): 1.344343\n",
      "Batch #10\tAverage Generator Loss: 2193.628674\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #12841 (step 12841): 1.700306\n",
      "Batch #10\tAverage Generator Loss: 2241.416382\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #12842 (step 12842): 1.330564\n",
      "Batch #10\tAverage Generator Loss: 2126.912488\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #12843 (step 12843): 1.814323\n",
      "Batch #10\tAverage Generator Loss: 2099.256995\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #12844 (step 12844): 1.281373\n",
      "Batch #10\tAverage Generator Loss: 1791.899371\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #12845 (step 12845): 1.431687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2001.427734\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #12846 (step 12846): 1.824823\n",
      "Batch #10\tAverage Generator Loss: 1955.595313\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #12847 (step 12847): 1.335732\n",
      "Batch #10\tAverage Generator Loss: 2217.941895\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #12848 (step 12848): 1.277806\n",
      "Batch #10\tAverage Generator Loss: 1841.828571\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #12849 (step 12849): 1.910627\n",
      "Batch #10\tAverage Generator Loss: 2136.506488\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #12850 (step 12850): 1.373014\n",
      "Batch #10\tAverage Generator Loss: 2224.554114\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #12851 (step 12851): 1.336946\n",
      "Batch #10\tAverage Generator Loss: 2118.718567\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #12852 (step 12852): 1.785316\n",
      "Batch #10\tAverage Generator Loss: 1978.175354\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #12853 (step 12853): 1.383953\n",
      "Batch #10\tAverage Generator Loss: 2062.720300\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #12854 (step 12854): 1.297723\n",
      "Batch #10\tAverage Generator Loss: 1985.787173\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #12855 (step 12855): 1.903529\n",
      "Batch #10\tAverage Generator Loss: 1937.893558\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #12856 (step 12856): 1.338345\n",
      "Batch #10\tAverage Generator Loss: 2349.701111\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #12857 (step 12857): 1.743964\n",
      "Batch #10\tAverage Generator Loss: 2142.440149\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #12858 (step 12858): 1.328750\n",
      "Batch #10\tAverage Generator Loss: 1916.018494\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #12859 (step 12859): 1.446661\n",
      "Batch #10\tAverage Generator Loss: 2062.157935\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #12860 (step 12860): 1.775062\n",
      "Batch #10\tAverage Generator Loss: 1785.811823\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #12861 (step 12861): 1.329399\n",
      "Batch #10\tAverage Generator Loss: 1990.681238\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12862 (step 12862): 1.368435\n",
      "Batch #10\tAverage Generator Loss: 1980.215991\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #12863 (step 12863): 1.784133\n",
      "Batch #10\tAverage Generator Loss: 1846.153589\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #12864 (step 12864): 1.388164\n",
      "Batch #10\tAverage Generator Loss: 1913.067285\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #12865 (step 12865): 1.715510\n",
      "Batch #10\tAverage Generator Loss: 1946.424280\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12866 (step 12866): 1.380275\n",
      "Batch #10\tAverage Generator Loss: 1798.498907\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #12867 (step 12867): 1.370106\n",
      "Batch #10\tAverage Generator Loss: 1963.076099\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #12868 (step 12868): 1.701268\n",
      "Batch #10\tAverage Generator Loss: 1997.887939\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #12869 (step 12869): 1.299393\n",
      "Batch #10\tAverage Generator Loss: 1918.600525\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #12870 (step 12870): 1.328113\n",
      "Batch #10\tAverage Generator Loss: 2077.356567\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #12871 (step 12871): 1.664795\n",
      "Batch #10\tAverage Generator Loss: 2022.942883\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12872 (step 12872): 1.369146\n",
      "Batch #10\tAverage Generator Loss: 1846.761206\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #12873 (step 12873): 1.381823\n",
      "Batch #10\tAverage Generator Loss: 1921.908295\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #12874 (step 12874): 1.645862\n",
      "Batch #10\tAverage Generator Loss: 2071.893378\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #12875 (step 12875): 1.295637\n",
      "Batch #10\tAverage Generator Loss: 2282.516589\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #12876 (step 12876): 1.702350\n",
      "Batch #10\tAverage Generator Loss: 1893.526880\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #12877 (step 12877): 1.296052\n",
      "Batch #10\tAverage Generator Loss: 2014.086285\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12878 (step 12878): 1.285198\n",
      "Batch #10\tAverage Generator Loss: 2038.047119\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12879 (step 12879): 1.893525\n",
      "Batch #10\tAverage Generator Loss: 1770.574631\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #12880 (step 12880): 1.330305\n",
      "Batch #10\tAverage Generator Loss: 1568.333575\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #12881 (step 12881): 1.285681\n",
      "Batch #10\tAverage Generator Loss: 2085.379785\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #12882 (step 12882): 1.846860\n",
      "Batch #10\tAverage Generator Loss: 2145.182275\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #12883 (step 12883): 1.345540\n",
      "Batch #10\tAverage Generator Loss: 1785.621375\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #12884 (step 12884): 1.345934\n",
      "Batch #10\tAverage Generator Loss: 2006.904150\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12885 (step 12885): 1.693240\n",
      "Batch #10\tAverage Generator Loss: 2201.391589\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12886 (step 12886): 1.401879\n",
      "Batch #10\tAverage Generator Loss: 1764.551227\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12887 (step 12887): 1.311481\n",
      "Batch #10\tAverage Generator Loss: 2022.678009\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #12888 (step 12888): 1.803977\n",
      "Batch #10\tAverage Generator Loss: 2171.521350\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #12889 (step 12889): 1.231254\n",
      "Batch #10\tAverage Generator Loss: 2098.304340\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12890 (step 12890): 1.726299\n",
      "Batch #10\tAverage Generator Loss: 2138.963495\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12891 (step 12891): 1.338073\n",
      "Batch #10\tAverage Generator Loss: 1954.685138\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #12892 (step 12892): 1.449950\n",
      "Batch #10\tAverage Generator Loss: 2107.833240\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12893 (step 12893): 1.674103\n",
      "Batch #10\tAverage Generator Loss: 2028.568359\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12894 (step 12894): 1.524891\n",
      "Batch #10\tAverage Generator Loss: 1674.043878\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #12895 (step 12895): 1.374203\n",
      "Batch #10\tAverage Generator Loss: 1742.130035\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12896 (step 12896): 1.773685\n",
      "Batch #10\tAverage Generator Loss: 2649.625354\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12897 (step 12897): 1.274757\n",
      "Batch #10\tAverage Generator Loss: 1873.248431\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #12898 (step 12898): 1.338370\n",
      "Batch #10\tAverage Generator Loss: 2008.221191\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12899 (step 12899): 1.790069\n",
      "Batch #10\tAverage Generator Loss: 1877.664014\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12900 (step 12900): 1.296490\n",
      "Batch #10\tAverage Generator Loss: 2086.161658\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #12901 (step 12901): 1.781829\n",
      "Batch #10\tAverage Generator Loss: 2363.928870\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12902 (step 12902): 1.238338\n",
      "Batch #10\tAverage Generator Loss: 1989.977258\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12903 (step 12903): 1.385716\n",
      "Batch #10\tAverage Generator Loss: 1945.316840\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12904 (step 12904): 1.729201\n",
      "Batch #10\tAverage Generator Loss: 2103.671344\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #12905 (step 12905): 1.372747\n",
      "Batch #10\tAverage Generator Loss: 2138.348901\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12906 (step 12906): 1.346213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2081.082117\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12907 (step 12907): 1.749707\n",
      "Batch #10\tAverage Generator Loss: 1921.944244\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12908 (step 12908): 1.294618\n",
      "Batch #10\tAverage Generator Loss: 1892.271387\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12909 (step 12909): 1.374108\n",
      "Batch #10\tAverage Generator Loss: 1968.338696\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12910 (step 12910): 1.677545\n",
      "Batch #10\tAverage Generator Loss: 1829.886414\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12911 (step 12911): 1.347790\n",
      "Batch #10\tAverage Generator Loss: 2167.724658\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12912 (step 12912): 1.286396\n",
      "Batch #10\tAverage Generator Loss: 1941.933673\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12913 (step 12913): 1.743240\n",
      "Batch #10\tAverage Generator Loss: 2133.557312\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12914 (step 12914): 1.349063\n",
      "Batch #10\tAverage Generator Loss: 1924.121301\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12915 (step 12915): 1.388585\n",
      "Batch #10\tAverage Generator Loss: 2079.302551\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12916 (step 12916): 1.745785\n",
      "Batch #10\tAverage Generator Loss: 2149.142346\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12917 (step 12917): 1.354377\n",
      "Batch #10\tAverage Generator Loss: 1821.830450\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12918 (step 12918): 1.353485\n",
      "Batch #10\tAverage Generator Loss: 1903.000269\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12919 (step 12919): 1.648001\n",
      "Batch #10\tAverage Generator Loss: 2183.545789\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12920 (step 12920): 1.377016\n",
      "Batch #10\tAverage Generator Loss: 1996.678558\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12921 (step 12921): 1.725593\n",
      "Batch #10\tAverage Generator Loss: 1941.377533\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12922 (step 12922): 1.379418\n",
      "Batch #10\tAverage Generator Loss: 2084.417981\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12923 (step 12923): 1.284397\n",
      "Batch #10\tAverage Generator Loss: 1842.119073\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12924 (step 12924): 1.703754\n",
      "Batch #10\tAverage Generator Loss: 2121.626660\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12925 (step 12925): 1.365192\n",
      "Batch #10\tAverage Generator Loss: 2182.729785\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12926 (step 12926): 1.429063\n",
      "Batch #10\tAverage Generator Loss: 1998.822510\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12927 (step 12927): 1.700214\n",
      "Batch #10\tAverage Generator Loss: 2238.192212\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12928 (step 12928): 1.301039\n",
      "Batch #10\tAverage Generator Loss: 2118.517810\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12929 (step 12929): 1.298036\n",
      "Batch #10\tAverage Generator Loss: 2125.922754\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12930 (step 12930): 1.777313\n",
      "Batch #10\tAverage Generator Loss: 2312.282849\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12931 (step 12931): 1.281433\n",
      "Batch #10\tAverage Generator Loss: 1702.519171\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12932 (step 12932): 1.343520\n",
      "Batch #10\tAverage Generator Loss: 2019.762366\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12933 (step 12933): 1.735773\n",
      "Batch #10\tAverage Generator Loss: 2210.771619\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12934 (step 12934): 1.343447\n",
      "Batch #10\tAverage Generator Loss: 1877.734631\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12935 (step 12935): 1.944451\n",
      "Batch #10\tAverage Generator Loss: 1923.109717\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12936 (step 12936): 1.485520\n",
      "Batch #10\tAverage Generator Loss: 1901.304572\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12937 (step 12937): 1.287686\n",
      "Batch #10\tAverage Generator Loss: 1862.262878\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12938 (step 12938): 1.736738\n",
      "Batch #10\tAverage Generator Loss: 2344.657764\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12939 (step 12939): 1.240645\n",
      "Batch #10\tAverage Generator Loss: 1548.963165\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12940 (step 12940): 1.425941\n",
      "Batch #10\tAverage Generator Loss: 1963.118774\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12941 (step 12941): 1.739137\n",
      "Batch #10\tAverage Generator Loss: 2198.172864\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12942 (step 12942): 1.303950\n",
      "Batch #10\tAverage Generator Loss: 2130.835168\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12943 (step 12943): 1.292198\n",
      "Batch #10\tAverage Generator Loss: 2099.058032\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12944 (step 12944): 1.771651\n",
      "Batch #10\tAverage Generator Loss: 1697.230591\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12945 (step 12945): 1.390231\n",
      "Batch #10\tAverage Generator Loss: 2088.456409\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12946 (step 12946): 1.304447\n",
      "Batch #10\tAverage Generator Loss: 1961.212817\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12947 (step 12947): 1.712787\n",
      "Batch #10\tAverage Generator Loss: 1760.430029\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12948 (step 12948): 1.296388\n",
      "Batch #10\tAverage Generator Loss: 2162.089844\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12949 (step 12949): 1.699066\n",
      "Batch #10\tAverage Generator Loss: 1856.129919\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12950 (step 12950): 1.340076\n",
      "Batch #10\tAverage Generator Loss: 2109.255933\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12951 (step 12951): 1.378277\n",
      "Batch #10\tAverage Generator Loss: 2024.764819\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12952 (step 12952): 1.762579\n",
      "Batch #10\tAverage Generator Loss: 1740.134656\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12953 (step 12953): 1.276923\n",
      "Batch #10\tAverage Generator Loss: 1750.824304\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12954 (step 12954): 1.284887\n",
      "Batch #10\tAverage Generator Loss: 1954.271948\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12955 (step 12955): 1.844151\n",
      "Batch #10\tAverage Generator Loss: 1926.471484\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12956 (step 12956): 1.285006\n",
      "Batch #10\tAverage Generator Loss: 2002.861725\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12957 (step 12957): 1.358284\n",
      "Batch #10\tAverage Generator Loss: 1893.345557\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12958 (step 12958): 1.804433\n",
      "Batch #10\tAverage Generator Loss: 1857.116077\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12959 (step 12959): 1.327782\n",
      "Batch #10\tAverage Generator Loss: 1935.543054\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12960 (step 12960): 1.388283\n",
      "Batch #10\tAverage Generator Loss: 2324.444562\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12961 (step 12961): 1.698944\n",
      "Batch #10\tAverage Generator Loss: 2168.526343\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12962 (step 12962): 1.329443\n",
      "Batch #10\tAverage Generator Loss: 1996.285297\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12963 (step 12963): 1.270627\n",
      "Batch #10\tAverage Generator Loss: 1931.950891\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12964 (step 12964): 1.877673\n",
      "Batch #10\tAverage Generator Loss: 2019.740747\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12965 (step 12965): 1.294634\n",
      "Batch #10\tAverage Generator Loss: 1811.302667\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12966 (step 12966): 1.739401\n",
      "Batch #10\tAverage Generator Loss: 1889.862561\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12967 (step 12967): 1.301073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 1869.855688\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12968 (step 12968): 1.429140\n",
      "Batch #10\tAverage Generator Loss: 2003.502576\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12969 (step 12969): 1.755674\n",
      "Batch #10\tAverage Generator Loss: 2154.549023\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12970 (step 12970): 1.383889\n",
      "Batch #10\tAverage Generator Loss: 2145.292554\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12971 (step 12971): 1.355542\n",
      "Batch #10\tAverage Generator Loss: 1962.570349\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12972 (step 12972): 1.739671\n",
      "Batch #10\tAverage Generator Loss: 1948.819812\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12973 (step 12973): 1.244555\n",
      "Batch #10\tAverage Generator Loss: 1975.832019\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12974 (step 12974): 1.378097\n",
      "Batch #10\tAverage Generator Loss: 2096.338232\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12975 (step 12975): 1.708254\n",
      "Batch #10\tAverage Generator Loss: 2631.034900\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12976 (step 12976): 1.338408\n",
      "Batch #10\tAverage Generator Loss: 1903.152295\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12977 (step 12977): 1.737623\n",
      "Batch #10\tAverage Generator Loss: 1808.418170\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12978 (step 12978): 1.389393\n",
      "Batch #10\tAverage Generator Loss: 2229.975427\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12979 (step 12979): 1.403535\n",
      "Batch #10\tAverage Generator Loss: 2100.353467\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12980 (step 12980): 1.755279\n",
      "Batch #10\tAverage Generator Loss: 2109.530920\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12981 (step 12981): 1.346842\n",
      "Batch #10\tAverage Generator Loss: 2150.128027\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12982 (step 12982): 1.286627\n",
      "Batch #10\tAverage Generator Loss: 2000.599719\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12983 (step 12983): 1.737221\n",
      "Batch #10\tAverage Generator Loss: 2247.042761\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12984 (step 12984): 1.389281\n",
      "Batch #10\tAverage Generator Loss: 2083.498639\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12985 (step 12985): 1.341887\n",
      "Batch #10\tAverage Generator Loss: 1942.942676\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12986 (step 12986): 1.695193\n",
      "Batch #10\tAverage Generator Loss: 1992.134338\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12987 (step 12987): 1.382351\n",
      "Batch #10\tAverage Generator Loss: 1983.546667\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12988 (step 12988): 1.743631\n",
      "Batch #10\tAverage Generator Loss: 1775.477100\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12989 (step 12989): 1.348996\n",
      "Batch #10\tAverage Generator Loss: 1898.596747\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12990 (step 12990): 1.262051\n",
      "Batch #10\tAverage Generator Loss: 1923.877673\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12991 (step 12991): 1.712563\n",
      "Batch #10\tAverage Generator Loss: 1944.323035\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12992 (step 12992): 1.382813\n",
      "Batch #10\tAverage Generator Loss: 1944.728558\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12993 (step 12993): 1.286438\n",
      "Batch #10\tAverage Generator Loss: 1940.369495\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12994 (step 12994): 1.834932\n",
      "Batch #10\tAverage Generator Loss: 2086.978748\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12995 (step 12995): 1.429409\n",
      "Batch #10\tAverage Generator Loss: 1964.873340\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12996 (step 12996): 1.445967\n",
      "Batch #10\tAverage Generator Loss: 2160.475793\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #12997 (step 12997): 1.768636\n",
      "Batch #10\tAverage Generator Loss: 1915.458972\tAverage Discriminator Loss: 0.012864\n",
      "\n",
      "Train time for epoch #12998 (step 12998): 1.410598\n",
      "Batch #10\tAverage Generator Loss: 1908.805371\tAverage Discriminator Loss: 0.075749\n",
      "\n",
      "Train time for epoch #12999 (step 12999): 1.295689\n",
      "Batch #10\tAverage Generator Loss: 2003.085535\tAverage Discriminator Loss: 0.002487\n",
      "\n",
      "Train time for epoch #13000 (step 13000): 1.851181\n",
      "Batch #10\tAverage Generator Loss: 1957.825781\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13001 (step 13001): 1.282819\n",
      "Batch #10\tAverage Generator Loss: 1696.734705\tAverage Discriminator Loss: 0.034664\n",
      "\n",
      "Train time for epoch #13002 (step 13002): 1.323372\n",
      "Batch #10\tAverage Generator Loss: 1834.503705\tAverage Discriminator Loss: 0.001349\n",
      "\n",
      "Train time for epoch #13003 (step 13003): 1.765017\n",
      "Batch #10\tAverage Generator Loss: 1734.876532\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13004 (step 13004): 1.288110\n",
      "Batch #10\tAverage Generator Loss: 2225.174292\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13005 (step 13005): 1.782914\n",
      "Batch #10\tAverage Generator Loss: 2056.745480\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13006 (step 13006): 1.270803\n",
      "Batch #10\tAverage Generator Loss: 1807.672711\tAverage Discriminator Loss: 0.273578\n",
      "\n",
      "Train time for epoch #13007 (step 13007): 1.346623\n",
      "Batch #10\tAverage Generator Loss: 1272.638385\tAverage Discriminator Loss: 0.009759\n",
      "\n",
      "Train time for epoch #13008 (step 13008): 1.723984\n",
      "Batch #10\tAverage Generator Loss: 1387.147266\tAverage Discriminator Loss: 0.023741\n",
      "\n",
      "Train time for epoch #13009 (step 13009): 1.344004\n",
      "Batch #10\tAverage Generator Loss: 1623.668494\tAverage Discriminator Loss: 0.014471\n",
      "\n",
      "Train time for epoch #13010 (step 13010): 1.399335\n",
      "Batch #10\tAverage Generator Loss: 2146.519812\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #13011 (step 13011): 1.820718\n",
      "Batch #10\tAverage Generator Loss: 1909.926624\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #13012 (step 13012): 1.383302\n",
      "Batch #10\tAverage Generator Loss: 1668.027173\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #13013 (step 13013): 1.453185\n",
      "Batch #10\tAverage Generator Loss: 2002.960547\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #13014 (step 13014): 1.855784\n",
      "Batch #10\tAverage Generator Loss: 2109.134058\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13015 (step 13015): 1.419469\n",
      "Batch #10\tAverage Generator Loss: 1938.601251\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #13016 (step 13016): 1.768974\n",
      "Batch #10\tAverage Generator Loss: 1596.023050\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #13017 (step 13017): 1.355027\n",
      "Batch #10\tAverage Generator Loss: 2011.824841\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #13018 (step 13018): 1.295274\n",
      "Batch #10\tAverage Generator Loss: 1538.231348\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #13019 (step 13019): 1.744800\n",
      "Batch #10\tAverage Generator Loss: 1866.267664\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #13020 (step 13020): 1.458826\n",
      "Batch #10\tAverage Generator Loss: 1803.254010\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #13021 (step 13021): 1.387813\n",
      "Batch #10\tAverage Generator Loss: 2029.645984\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #13022 (step 13022): 1.777715\n",
      "Batch #10\tAverage Generator Loss: 1687.256665\tAverage Discriminator Loss: 0.005726\n",
      "\n",
      "Train time for epoch #13023 (step 13023): 1.333368\n",
      "Batch #10\tAverage Generator Loss: 1686.630426\tAverage Discriminator Loss: 0.000314\n",
      "\n",
      "Train time for epoch #13024 (step 13024): 1.330535\n",
      "Batch #10\tAverage Generator Loss: 1622.171313\tAverage Discriminator Loss: 0.000038\n",
      "\n",
      "Train time for epoch #13025 (step 13025): 1.788624\n",
      "Batch #10\tAverage Generator Loss: 1774.681409\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #13026 (step 13026): 1.368720\n",
      "Batch #10\tAverage Generator Loss: 1899.175464\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #13027 (step 13027): 1.338041\n",
      "Batch #10\tAverage Generator Loss: 1613.852307\tAverage Discriminator Loss: 0.330616\n",
      "\n",
      "Train time for epoch #13028 (step 13028): 1.857515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 1840.164185\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13029 (step 13029): 1.395350\n",
      "Batch #10\tAverage Generator Loss: 2207.614990\tAverage Discriminator Loss: 0.218382\n",
      "\n",
      "Train time for epoch #13030 (step 13030): 1.292764\n",
      "Batch #10\tAverage Generator Loss: 2944.172351\tAverage Discriminator Loss: 0.012316\n",
      "\n",
      "Train time for epoch #13031 (step 13031): 1.797359\n",
      "Batch #10\tAverage Generator Loss: 2245.876923\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13032 (step 13032): 1.448434\n",
      "Batch #10\tAverage Generator Loss: 2424.525854\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #13033 (step 13033): 1.263673\n",
      "Batch #10\tAverage Generator Loss: 2426.983960\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13034 (step 13034): 1.731508\n",
      "Batch #10\tAverage Generator Loss: 2104.669659\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13035 (step 13035): 1.285981\n",
      "Batch #10\tAverage Generator Loss: 3188.339246\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13036 (step 13036): 1.296070\n",
      "Batch #10\tAverage Generator Loss: 2803.935999\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13037 (step 13037): 1.803501\n",
      "Batch #10\tAverage Generator Loss: 2160.340234\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13038 (step 13038): 1.410341\n",
      "Batch #10\tAverage Generator Loss: 2464.487988\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13039 (step 13039): 1.868921\n",
      "Batch #10\tAverage Generator Loss: 2389.157727\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13040 (step 13040): 1.340021\n",
      "Batch #10\tAverage Generator Loss: 2695.058691\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13041 (step 13041): 1.368395\n",
      "Batch #10\tAverage Generator Loss: 2694.583704\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13042 (step 13042): 1.907755\n",
      "Batch #10\tAverage Generator Loss: 2252.810550\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13043 (step 13043): 1.405244\n",
      "Batch #10\tAverage Generator Loss: 2356.016577\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13044 (step 13044): 1.372087\n",
      "Batch #10\tAverage Generator Loss: 2288.654285\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13045 (step 13045): 1.785572\n",
      "Batch #10\tAverage Generator Loss: 2803.340649\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13046 (step 13046): 1.391344\n",
      "Batch #10\tAverage Generator Loss: 2567.798657\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13047 (step 13047): 1.374598\n",
      "Batch #10\tAverage Generator Loss: 2431.029272\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13048 (step 13048): 1.742859\n",
      "Batch #10\tAverage Generator Loss: 2656.522644\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13049 (step 13049): 1.345930\n",
      "Batch #10\tAverage Generator Loss: 2325.316248\tAverage Discriminator Loss: 0.009250\n",
      "\n",
      "Train time for epoch #13050 (step 13050): 1.287480\n",
      "Batch #10\tAverage Generator Loss: 2375.654846\tAverage Discriminator Loss: 0.005994\n",
      "\n",
      "Train time for epoch #13051 (step 13051): 1.848749\n",
      "Batch #10\tAverage Generator Loss: 2516.530463\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13052 (step 13052): 1.376889\n",
      "Batch #10\tAverage Generator Loss: 2542.078601\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13053 (step 13053): 1.829175\n",
      "Batch #10\tAverage Generator Loss: 2505.069739\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13054 (step 13054): 2.178119\n",
      "Batch #10\tAverage Generator Loss: 2587.026111\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13055 (step 13055): 1.368941\n",
      "Batch #10\tAverage Generator Loss: 2398.593542\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13056 (step 13056): 1.990251\n",
      "Batch #10\tAverage Generator Loss: 2419.264380\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13057 (step 13057): 1.326583\n",
      "Batch #10\tAverage Generator Loss: 2931.213379\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13058 (step 13058): 1.768659\n",
      "Batch #10\tAverage Generator Loss: 2590.234509\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13059 (step 13059): 1.989695\n",
      "Batch #10\tAverage Generator Loss: 2489.381720\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13060 (step 13060): 1.341837\n",
      "Batch #10\tAverage Generator Loss: 2458.899127\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13061 (step 13061): 1.991892\n",
      "Batch #10\tAverage Generator Loss: 2867.036304\tAverage Discriminator Loss: 0.519532\n",
      "\n",
      "Train time for epoch #13062 (step 13062): 2.200497\n",
      "Batch #10\tAverage Generator Loss: 2258.305676\tAverage Discriminator Loss: 0.049571\n",
      "\n",
      "Train time for epoch #13063 (step 13063): 1.441527\n",
      "Batch #10\tAverage Generator Loss: 2299.430591\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13064 (step 13064): 1.238161\n",
      "Batch #10\tAverage Generator Loss: 2088.188916\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13065 (step 13065): 1.880640\n",
      "Batch #10\tAverage Generator Loss: 2133.757690\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13066 (step 13066): 1.370841\n",
      "Batch #10\tAverage Generator Loss: 2124.715015\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13067 (step 13067): 1.329799\n",
      "Batch #10\tAverage Generator Loss: 2276.952930\tAverage Discriminator Loss: 0.280558\n",
      "\n",
      "Train time for epoch #13068 (step 13068): 1.878289\n",
      "Batch #10\tAverage Generator Loss: 2200.099390\tAverage Discriminator Loss: 0.016660\n",
      "\n",
      "Train time for epoch #13069 (step 13069): 1.408047\n",
      "Batch #10\tAverage Generator Loss: 2022.581958\tAverage Discriminator Loss: 0.000100\n",
      "\n",
      "Train time for epoch #13070 (step 13070): 1.913347\n",
      "Batch #10\tAverage Generator Loss: 1897.696381\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #13071 (step 13071): 1.373909\n",
      "Batch #10\tAverage Generator Loss: 2286.484998\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #13072 (step 13072): 1.247113\n",
      "Batch #10\tAverage Generator Loss: 2151.356677\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #13073 (step 13073): 1.723600\n",
      "Batch #10\tAverage Generator Loss: 1963.657159\tAverage Discriminator Loss: 0.000022\n",
      "\n",
      "Train time for epoch #13074 (step 13074): 1.290319\n",
      "Batch #10\tAverage Generator Loss: 1906.732513\tAverage Discriminator Loss: 0.000020\n",
      "\n",
      "Train time for epoch #13075 (step 13075): 1.288589\n",
      "Batch #10\tAverage Generator Loss: 1921.422736\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #13076 (step 13076): 1.836328\n",
      "Batch #10\tAverage Generator Loss: 1817.808289\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #13077 (step 13077): 1.346151\n",
      "Batch #10\tAverage Generator Loss: 1870.427417\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #13078 (step 13078): 1.292983\n",
      "Batch #10\tAverage Generator Loss: 1961.287537\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #13079 (step 13079): 1.753102\n",
      "Batch #10\tAverage Generator Loss: 2058.790002\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #13080 (step 13080): 1.296006\n",
      "Batch #10\tAverage Generator Loss: 2112.132080\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #13081 (step 13081): 1.542496\n",
      "Batch #10\tAverage Generator Loss: 1835.834888\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #13082 (step 13082): 1.827499\n",
      "Batch #10\tAverage Generator Loss: 2019.699011\tAverage Discriminator Loss: 0.000249\n",
      "\n",
      "Train time for epoch #13083 (step 13083): 1.323527\n",
      "Batch #10\tAverage Generator Loss: 1955.204065\tAverage Discriminator Loss: 0.000135\n",
      "\n",
      "Train time for epoch #13084 (step 13084): 1.784989\n",
      "Batch #10\tAverage Generator Loss: 2060.670764\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #13085 (step 13085): 1.339768\n",
      "Batch #10\tAverage Generator Loss: 2106.066223\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #13086 (step 13086): 1.287058\n",
      "Batch #10\tAverage Generator Loss: 1997.786694\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #13087 (step 13087): 1.786617\n",
      "Batch #10\tAverage Generator Loss: 1867.406201\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #13088 (step 13088): 1.351473\n",
      "Batch #10\tAverage Generator Loss: 1796.124536\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #13089 (step 13089): 1.345925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2065.462561\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #13090 (step 13090): 1.782376\n",
      "Batch #10\tAverage Generator Loss: 2009.532678\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #13091 (step 13091): 1.326525\n",
      "Batch #10\tAverage Generator Loss: 1798.227838\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #13092 (step 13092): 1.271849\n",
      "Batch #10\tAverage Generator Loss: 2111.769458\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #13093 (step 13093): 1.786431\n",
      "Batch #10\tAverage Generator Loss: 1831.174591\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #13094 (step 13094): 1.285982\n",
      "Batch #10\tAverage Generator Loss: 2145.636987\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #13095 (step 13095): 1.347686\n",
      "Batch #10\tAverage Generator Loss: 2085.410376\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #13096 (step 13096): 1.846448\n",
      "Batch #10\tAverage Generator Loss: 2080.614557\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #13097 (step 13097): 1.323647\n",
      "Batch #10\tAverage Generator Loss: 2071.624097\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #13098 (step 13098): 1.373362\n",
      "Batch #10\tAverage Generator Loss: 2055.486194\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #13099 (step 13099): 1.830206\n",
      "Batch #10\tAverage Generator Loss: 1878.674518\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #13100 (step 13100): 1.236453\n",
      "Batch #10\tAverage Generator Loss: 1785.893579\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #13101 (step 13101): 1.267401\n",
      "Batch #10\tAverage Generator Loss: 1774.762653\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #13102 (step 13102): 1.855032\n",
      "Batch #10\tAverage Generator Loss: 2060.245642\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #13103 (step 13103): 1.302705\n",
      "Batch #10\tAverage Generator Loss: 1929.595508\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #13104 (step 13104): 1.823125\n",
      "Batch #10\tAverage Generator Loss: 1974.944177\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #13105 (step 13105): 1.388108\n",
      "Batch #10\tAverage Generator Loss: 2371.592542\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #13106 (step 13106): 1.283124\n",
      "Batch #10\tAverage Generator Loss: 1994.205615\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #13107 (step 13107): 1.671455\n",
      "Batch #10\tAverage Generator Loss: 2150.917932\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #13108 (step 13108): 1.281074\n",
      "Batch #10\tAverage Generator Loss: 2050.503345\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #13109 (step 13109): 1.346394\n",
      "Batch #10\tAverage Generator Loss: 1802.430615\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #13110 (step 13110): 1.737260\n",
      "Batch #10\tAverage Generator Loss: 2117.809009\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #13111 (step 13111): 1.404434\n",
      "Batch #10\tAverage Generator Loss: 1993.311633\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #13112 (step 13112): 1.290559\n",
      "Batch #10\tAverage Generator Loss: 1965.850281\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #13113 (step 13113): 1.934185\n",
      "Batch #10\tAverage Generator Loss: 2149.448743\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #13114 (step 13114): 1.343882\n",
      "Batch #10\tAverage Generator Loss: 2150.466003\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #13115 (step 13115): 1.324874\n",
      "Batch #10\tAverage Generator Loss: 1856.613538\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #13116 (step 13116): 1.668889\n",
      "Batch #10\tAverage Generator Loss: 1959.837219\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #13117 (step 13117): 1.343514\n",
      "Batch #10\tAverage Generator Loss: 1759.995972\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #13118 (step 13118): 1.297085\n",
      "Batch #10\tAverage Generator Loss: 2003.094440\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #13119 (step 13119): 1.793311\n",
      "Batch #10\tAverage Generator Loss: 1912.946595\tAverage Discriminator Loss: 1.317788\n",
      "\n",
      "Train time for epoch #13120 (step 13120): 1.309183\n",
      "Batch #10\tAverage Generator Loss: 2551.977026\tAverage Discriminator Loss: 0.000078\n",
      "\n",
      "Train time for epoch #13121 (step 13121): 1.379092\n",
      "Batch #10\tAverage Generator Loss: 2523.950354\tAverage Discriminator Loss: 0.014912\n",
      "\n",
      "Train time for epoch #13122 (step 13122): 1.752256\n",
      "Batch #10\tAverage Generator Loss: 2595.068530\tAverage Discriminator Loss: 0.079997\n",
      "\n",
      "Train time for epoch #13123 (step 13123): 1.338477\n",
      "Batch #10\tAverage Generator Loss: 2614.911639\tAverage Discriminator Loss: 0.000808\n",
      "\n",
      "Train time for epoch #13124 (step 13124): 1.822790\n",
      "Batch #10\tAverage Generator Loss: 1828.650720\tAverage Discriminator Loss: 0.213773\n",
      "\n",
      "Train time for epoch #13125 (step 13125): 1.291192\n",
      "Batch #10\tAverage Generator Loss: 2625.819263\tAverage Discriminator Loss: 0.123541\n",
      "\n",
      "Train time for epoch #13126 (step 13126): 1.373751\n",
      "Batch #10\tAverage Generator Loss: 3067.290979\tAverage Discriminator Loss: 0.062099\n",
      "\n",
      "Train time for epoch #13127 (step 13127): 1.900469\n",
      "Batch #10\tAverage Generator Loss: 3261.637927\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13128 (step 13128): 1.467428\n",
      "Batch #10\tAverage Generator Loss: 2773.025354\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13129 (step 13129): 1.290768\n",
      "Batch #10\tAverage Generator Loss: 2804.124243\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13130 (step 13130): 1.761667\n",
      "Batch #10\tAverage Generator Loss: 2996.730444\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13131 (step 13131): 1.287042\n",
      "Batch #10\tAverage Generator Loss: 3088.052551\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #13132 (step 13132): 1.258328\n",
      "Batch #10\tAverage Generator Loss: 2601.936316\tAverage Discriminator Loss: 0.000024\n",
      "\n",
      "Train time for epoch #13133 (step 13133): 1.794454\n",
      "Batch #10\tAverage Generator Loss: 2919.142236\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13134 (step 13134): 1.285372\n",
      "Batch #10\tAverage Generator Loss: 2557.936694\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13135 (step 13135): 1.880635\n",
      "Batch #10\tAverage Generator Loss: 3682.086829\tAverage Discriminator Loss: 0.007508\n",
      "\n",
      "Train time for epoch #13136 (step 13136): 1.393930\n",
      "Batch #10\tAverage Generator Loss: 2622.323987\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13137 (step 13137): 1.288873\n",
      "Batch #10\tAverage Generator Loss: 2825.658179\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13138 (step 13138): 1.736540\n",
      "Batch #10\tAverage Generator Loss: 3231.035107\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13139 (step 13139): 1.513429\n",
      "Batch #10\tAverage Generator Loss: 2787.958545\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13140 (step 13140): 1.291686\n",
      "Batch #10\tAverage Generator Loss: 2916.678198\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13141 (step 13141): 1.747568\n",
      "Batch #10\tAverage Generator Loss: 2569.627161\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13142 (step 13142): 1.392248\n",
      "Batch #10\tAverage Generator Loss: 2932.262463\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13143 (step 13143): 1.384919\n",
      "Batch #10\tAverage Generator Loss: 3020.290430\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13144 (step 13144): 1.694019\n",
      "Batch #10\tAverage Generator Loss: 2742.959546\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13145 (step 13145): 1.332836\n",
      "Batch #10\tAverage Generator Loss: 2825.492395\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13146 (step 13146): 1.787593\n",
      "Batch #10\tAverage Generator Loss: 2499.552197\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13147 (step 13147): 1.361784\n",
      "Batch #10\tAverage Generator Loss: 2878.067969\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13148 (step 13148): 1.388578\n",
      "Batch #10\tAverage Generator Loss: 2519.224854\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13149 (step 13149): 1.756804\n",
      "Batch #10\tAverage Generator Loss: 2531.653723\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13150 (step 13150): 1.292606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2969.862476\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13151 (step 13151): 1.288757\n",
      "Batch #10\tAverage Generator Loss: 2513.371313\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13152 (step 13152): 1.710021\n",
      "Batch #10\tAverage Generator Loss: 2806.189514\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13153 (step 13153): 1.313559\n",
      "Batch #10\tAverage Generator Loss: 2609.275830\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13154 (step 13154): 1.301225\n",
      "Batch #10\tAverage Generator Loss: 2577.516223\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13155 (step 13155): 1.706034\n",
      "Batch #10\tAverage Generator Loss: 3073.684875\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13156 (step 13156): 1.328679\n",
      "Batch #10\tAverage Generator Loss: 2816.038843\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13157 (step 13157): 1.285087\n",
      "Batch #10\tAverage Generator Loss: 2696.740857\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13158 (step 13158): 1.690669\n",
      "Batch #10\tAverage Generator Loss: 2332.763782\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13159 (step 13159): 1.420166\n",
      "Batch #10\tAverage Generator Loss: 3048.919690\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13160 (step 13160): 1.744732\n",
      "Batch #10\tAverage Generator Loss: 2843.074377\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13161 (step 13161): 1.285143\n",
      "Batch #10\tAverage Generator Loss: 2324.398474\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13162 (step 13162): 1.399636\n",
      "Batch #10\tAverage Generator Loss: 2683.924261\tAverage Discriminator Loss: 0.000030\n",
      "\n",
      "Train time for epoch #13163 (step 13163): 1.826154\n",
      "Batch #10\tAverage Generator Loss: 2732.587158\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13164 (step 13164): 1.306443\n",
      "Batch #10\tAverage Generator Loss: 2227.154211\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13165 (step 13165): 1.294430\n",
      "Batch #10\tAverage Generator Loss: 2295.530273\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13166 (step 13166): 1.789519\n",
      "Batch #10\tAverage Generator Loss: 2930.068835\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13167 (step 13167): 1.352718\n",
      "Batch #10\tAverage Generator Loss: 2250.774994\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13168 (step 13168): 1.292536\n",
      "Batch #10\tAverage Generator Loss: 2746.360925\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13169 (step 13169): 1.752257\n",
      "Batch #10\tAverage Generator Loss: 2689.282495\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13170 (step 13170): 1.373859\n",
      "Batch #10\tAverage Generator Loss: 2260.437842\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13171 (step 13171): 1.309979\n",
      "Batch #10\tAverage Generator Loss: 2641.155676\tAverage Discriminator Loss: 0.039821\n",
      "\n",
      "Train time for epoch #13172 (step 13172): 1.793528\n",
      "Batch #10\tAverage Generator Loss: 2910.523511\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13173 (step 13173): 1.346232\n",
      "Batch #10\tAverage Generator Loss: 2684.762097\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13174 (step 13174): 1.406754\n",
      "Batch #10\tAverage Generator Loss: 3025.773840\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13175 (step 13175): 1.810308\n",
      "Batch #10\tAverage Generator Loss: 2335.208908\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13176 (step 13176): 1.379915\n",
      "Batch #10\tAverage Generator Loss: 2679.926355\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13177 (step 13177): 1.307576\n",
      "Batch #10\tAverage Generator Loss: 2813.691882\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13178 (step 13178): 1.687507\n",
      "Batch #10\tAverage Generator Loss: 2795.242188\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13179 (step 13179): 1.330882\n",
      "Batch #10\tAverage Generator Loss: 2536.151929\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13180 (step 13180): 1.791509\n",
      "Batch #10\tAverage Generator Loss: 2635.845703\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13181 (step 13181): 1.463025\n",
      "Batch #10\tAverage Generator Loss: 2413.514355\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13182 (step 13182): 1.534183\n",
      "Batch #10\tAverage Generator Loss: 2581.888953\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13183 (step 13183): 1.707191\n",
      "Batch #10\tAverage Generator Loss: 2624.688135\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13184 (step 13184): 1.344242\n",
      "Batch #10\tAverage Generator Loss: 2686.085980\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13185 (step 13185): 1.438601\n",
      "Batch #10\tAverage Generator Loss: 2790.422729\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13186 (step 13186): 1.749783\n",
      "Batch #10\tAverage Generator Loss: 2940.013464\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13187 (step 13187): 1.341170\n",
      "Batch #10\tAverage Generator Loss: 2992.045422\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13188 (step 13188): 1.599254\n",
      "Batch #10\tAverage Generator Loss: 2747.926660\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13189 (step 13189): 1.701288\n",
      "Batch #10\tAverage Generator Loss: 2595.716199\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13190 (step 13190): 1.301203\n",
      "Batch #10\tAverage Generator Loss: 2699.735693\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13191 (step 13191): 1.346672\n",
      "Batch #10\tAverage Generator Loss: 3047.729517\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13192 (step 13192): 1.792371\n",
      "Batch #10\tAverage Generator Loss: 3077.955200\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13193 (step 13193): 1.240563\n",
      "Batch #10\tAverage Generator Loss: 2752.665027\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13194 (step 13194): 1.281948\n",
      "Batch #10\tAverage Generator Loss: 2840.233667\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13195 (step 13195): 1.673985\n",
      "Batch #10\tAverage Generator Loss: 3163.440796\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13196 (step 13196): 1.281861\n",
      "Batch #10\tAverage Generator Loss: 2629.307446\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13197 (step 13197): 1.475475\n",
      "Batch #10\tAverage Generator Loss: 2661.404816\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13198 (step 13198): 1.814744\n",
      "Batch #10\tAverage Generator Loss: 2975.963196\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13199 (step 13199): 1.295853\n",
      "Batch #10\tAverage Generator Loss: 3058.319067\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13200 (step 13200): 1.788710\n",
      "Batch #10\tAverage Generator Loss: 2939.534998\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13201 (step 13201): 1.390424\n",
      "Batch #10\tAverage Generator Loss: 2471.170142\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13202 (step 13202): 1.348756\n",
      "Batch #10\tAverage Generator Loss: 3483.160913\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13203 (step 13203): 1.826242\n",
      "Batch #10\tAverage Generator Loss: 2917.657849\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13204 (step 13204): 1.383910\n",
      "Batch #10\tAverage Generator Loss: 2969.587842\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13205 (step 13205): 1.331716\n",
      "Batch #10\tAverage Generator Loss: 2749.065601\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13206 (step 13206): 1.273019\n",
      "Batch #10\tAverage Generator Loss: 2246.264642\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13207 (step 13207): 1.875052\n",
      "Batch #10\tAverage Generator Loss: 2528.618054\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13208 (step 13208): 1.390854\n",
      "Batch #10\tAverage Generator Loss: 2789.155164\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13209 (step 13209): 1.724471\n",
      "Batch #10\tAverage Generator Loss: 2745.463635\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13210 (step 13210): 1.369307\n",
      "Batch #10\tAverage Generator Loss: 2935.979614\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13211 (step 13211): 1.328259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 3049.204553\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13212 (step 13212): 1.806584\n",
      "Batch #10\tAverage Generator Loss: 3409.750989\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13213 (step 13213): 1.282091\n",
      "Batch #10\tAverage Generator Loss: 2949.372095\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13214 (step 13214): 1.259941\n",
      "Batch #10\tAverage Generator Loss: 2971.443408\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13215 (step 13215): 1.749543\n",
      "Batch #10\tAverage Generator Loss: 2576.062061\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13216 (step 13216): 1.333572\n",
      "Batch #10\tAverage Generator Loss: 2626.784436\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13217 (step 13217): 1.828257\n",
      "Batch #10\tAverage Generator Loss: 3031.967603\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13218 (step 13218): 1.292235\n",
      "Batch #10\tAverage Generator Loss: 2921.318237\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13219 (step 13219): 1.329481\n",
      "Batch #10\tAverage Generator Loss: 2949.299524\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13220 (step 13220): 1.765990\n",
      "Batch #10\tAverage Generator Loss: 2966.464124\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13221 (step 13221): 1.357004\n",
      "Batch #10\tAverage Generator Loss: 2493.617517\tAverage Discriminator Loss: 0.000077\n",
      "\n",
      "Train time for epoch #13222 (step 13222): 1.334343\n",
      "Batch #10\tAverage Generator Loss: 2984.451489\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13223 (step 13223): 1.769915\n",
      "Batch #10\tAverage Generator Loss: 2824.143274\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13224 (step 13224): 1.320554\n",
      "Batch #10\tAverage Generator Loss: 2698.029211\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13225 (step 13225): 1.350701\n",
      "Batch #10\tAverage Generator Loss: 3147.464636\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13226 (step 13226): 1.754450\n",
      "Batch #10\tAverage Generator Loss: 2660.527271\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13227 (step 13227): 1.338612\n",
      "Batch #10\tAverage Generator Loss: 2611.000256\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13228 (step 13228): 1.350619\n",
      "Batch #10\tAverage Generator Loss: 2722.979907\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13229 (step 13229): 1.828526\n",
      "Batch #10\tAverage Generator Loss: 3265.807373\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13230 (step 13230): 1.446075\n",
      "Batch #10\tAverage Generator Loss: 2597.707874\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13231 (step 13231): 1.388173\n",
      "Batch #10\tAverage Generator Loss: 2769.349628\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13232 (step 13232): 1.867078\n",
      "Batch #10\tAverage Generator Loss: 3351.385059\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13233 (step 13233): 1.376658\n",
      "Batch #10\tAverage Generator Loss: 2543.999121\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13234 (step 13234): 1.385174\n",
      "Batch #10\tAverage Generator Loss: 2980.278882\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13235 (step 13235): 1.765481\n",
      "Batch #10\tAverage Generator Loss: 2670.599756\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13236 (step 13236): 1.295986\n",
      "Batch #10\tAverage Generator Loss: 2537.698767\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13237 (step 13237): 1.781411\n",
      "Batch #10\tAverage Generator Loss: 2632.403650\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13238 (step 13238): 1.339464\n",
      "Batch #10\tAverage Generator Loss: 2983.182849\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13239 (step 13239): 1.351089\n",
      "Batch #10\tAverage Generator Loss: 2808.855264\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13240 (step 13240): 1.755071\n",
      "Batch #10\tAverage Generator Loss: 2991.554724\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13241 (step 13241): 1.348294\n",
      "Batch #10\tAverage Generator Loss: 2777.439746\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13242 (step 13242): 1.288524\n",
      "Batch #10\tAverage Generator Loss: 2430.907489\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13243 (step 13243): 1.793699\n",
      "Batch #10\tAverage Generator Loss: 2871.956152\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13244 (step 13244): 1.302040\n",
      "Batch #10\tAverage Generator Loss: 3290.091089\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13245 (step 13245): 1.437407\n",
      "Batch #10\tAverage Generator Loss: 2716.711182\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13246 (step 13246): 1.747440\n",
      "Batch #10\tAverage Generator Loss: 2655.612292\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13247 (step 13247): 1.402108\n",
      "Batch #10\tAverage Generator Loss: 3003.569092\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13248 (step 13248): 1.281127\n",
      "Batch #10\tAverage Generator Loss: 3029.940454\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13249 (step 13249): 1.799331\n",
      "Batch #10\tAverage Generator Loss: 2921.155664\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13250 (step 13250): 1.282365\n",
      "Batch #10\tAverage Generator Loss: 2553.062134\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13251 (step 13251): 1.447326\n",
      "Batch #10\tAverage Generator Loss: 3007.774463\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13252 (step 13252): 1.751223\n",
      "Batch #10\tAverage Generator Loss: 2954.233325\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13253 (step 13253): 1.291874\n",
      "Batch #10\tAverage Generator Loss: 2762.723120\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13254 (step 13254): 1.483493\n",
      "Batch #10\tAverage Generator Loss: 2316.630865\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13255 (step 13255): 1.787906\n",
      "Batch #10\tAverage Generator Loss: 2925.757483\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13256 (step 13256): 1.280860\n",
      "Batch #10\tAverage Generator Loss: 2538.697095\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13257 (step 13257): 1.285173\n",
      "Batch #10\tAverage Generator Loss: 2833.918542\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13258 (step 13258): 1.796316\n",
      "Batch #10\tAverage Generator Loss: 2436.786945\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13259 (step 13259): 1.302479\n",
      "Batch #10\tAverage Generator Loss: 2788.290369\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13260 (step 13260): 1.806080\n",
      "Batch #10\tAverage Generator Loss: 2876.964844\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13261 (step 13261): 1.293585\n",
      "Batch #10\tAverage Generator Loss: 2775.115454\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13262 (step 13262): 1.343582\n",
      "Batch #10\tAverage Generator Loss: 2788.454529\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13263 (step 13263): 1.787975\n",
      "Batch #10\tAverage Generator Loss: 2750.029602\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13264 (step 13264): 1.280916\n",
      "Batch #10\tAverage Generator Loss: 2933.038440\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13265 (step 13265): 1.375361\n",
      "Batch #10\tAverage Generator Loss: 2918.887219\tAverage Discriminator Loss: 0.030269\n",
      "\n",
      "Train time for epoch #13266 (step 13266): 1.709295\n",
      "Batch #10\tAverage Generator Loss: 2160.154498\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13267 (step 13267): 1.412915\n",
      "Batch #10\tAverage Generator Loss: 2511.744849\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13268 (step 13268): 1.334863\n",
      "Batch #10\tAverage Generator Loss: 2551.121057\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13269 (step 13269): 1.937495\n",
      "Batch #10\tAverage Generator Loss: 2673.554797\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13270 (step 13270): 1.363168\n",
      "Batch #10\tAverage Generator Loss: 2419.917279\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13271 (step 13271): 1.388836\n",
      "Batch #10\tAverage Generator Loss: 2702.728418\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13272 (step 13272): 1.811052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2283.693091\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13273 (step 13273): 1.282648\n",
      "Batch #10\tAverage Generator Loss: 2984.461914\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13274 (step 13274): 1.692042\n",
      "Batch #10\tAverage Generator Loss: 2835.740686\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13275 (step 13275): 1.348719\n",
      "Batch #10\tAverage Generator Loss: 2699.998285\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13276 (step 13276): 1.280746\n",
      "Batch #10\tAverage Generator Loss: 2544.447107\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13277 (step 13277): 1.776805\n",
      "Batch #10\tAverage Generator Loss: 2863.222888\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13278 (step 13278): 1.346476\n",
      "Batch #10\tAverage Generator Loss: 2840.817322\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13279 (step 13279): 1.277606\n",
      "Batch #10\tAverage Generator Loss: 2406.257043\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13280 (step 13280): 1.758720\n",
      "Batch #10\tAverage Generator Loss: 2656.754602\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13281 (step 13281): 1.246133\n",
      "Batch #10\tAverage Generator Loss: 3027.176392\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13282 (step 13282): 1.285021\n",
      "Batch #10\tAverage Generator Loss: 2685.431274\tAverage Discriminator Loss: 0.000129\n",
      "\n",
      "Train time for epoch #13283 (step 13283): 1.743562\n",
      "Batch #10\tAverage Generator Loss: 2488.834851\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13284 (step 13284): 1.450053\n",
      "Batch #10\tAverage Generator Loss: 2767.760681\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13285 (step 13285): 1.285436\n",
      "Batch #10\tAverage Generator Loss: 2847.593774\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13286 (step 13286): 1.874650\n",
      "Batch #10\tAverage Generator Loss: 2455.544305\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13287 (step 13287): 1.420788\n",
      "Batch #10\tAverage Generator Loss: 2827.429993\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13288 (step 13288): 1.351856\n",
      "Batch #10\tAverage Generator Loss: 2638.960291\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13289 (step 13289): 1.742283\n",
      "Batch #10\tAverage Generator Loss: 2488.779462\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13290 (step 13290): 1.289580\n",
      "Batch #10\tAverage Generator Loss: 2395.185156\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13291 (step 13291): 1.386621\n",
      "Batch #10\tAverage Generator Loss: 2306.166431\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13292 (step 13292): 1.866414\n",
      "Batch #10\tAverage Generator Loss: 2645.919922\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13293 (step 13293): 1.336761\n",
      "Batch #10\tAverage Generator Loss: 2834.056396\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13294 (step 13294): 1.388004\n",
      "Batch #10\tAverage Generator Loss: 2735.960986\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13295 (step 13295): 1.763653\n",
      "Batch #10\tAverage Generator Loss: 2849.707910\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13296 (step 13296): 1.319173\n",
      "Batch #10\tAverage Generator Loss: 2878.100891\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13297 (step 13297): 1.381488\n",
      "Batch #10\tAverage Generator Loss: 2482.473431\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13298 (step 13298): 1.736656\n",
      "Batch #10\tAverage Generator Loss: 2307.352263\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13299 (step 13299): 1.371744\n",
      "Batch #10\tAverage Generator Loss: 2638.760779\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13300 (step 13300): 1.788918\n",
      "Batch #10\tAverage Generator Loss: 2675.434607\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13301 (step 13301): 1.337287\n",
      "Batch #10\tAverage Generator Loss: 2563.341138\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13302 (step 13302): 1.345874\n",
      "Batch #10\tAverage Generator Loss: 2670.686560\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13303 (step 13303): 1.810024\n",
      "Batch #10\tAverage Generator Loss: 2446.897839\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13304 (step 13304): 1.241101\n",
      "Batch #10\tAverage Generator Loss: 2611.549890\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13305 (step 13305): 1.338554\n",
      "Batch #10\tAverage Generator Loss: 2695.905817\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13306 (step 13306): 1.714790\n",
      "Batch #10\tAverage Generator Loss: 2856.439172\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13307 (step 13307): 1.318384\n",
      "Batch #10\tAverage Generator Loss: 2890.744690\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13308 (step 13308): 1.289083\n",
      "Batch #10\tAverage Generator Loss: 2552.541431\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13309 (step 13309): 1.849505\n",
      "Batch #10\tAverage Generator Loss: 2726.652002\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13310 (step 13310): 1.400905\n",
      "Batch #10\tAverage Generator Loss: 2755.831592\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13311 (step 13311): 1.773920\n",
      "Batch #10\tAverage Generator Loss: 2923.405273\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13312 (step 13312): 1.334708\n",
      "Batch #10\tAverage Generator Loss: 2724.633997\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13313 (step 13313): 1.351629\n",
      "Batch #10\tAverage Generator Loss: 2437.534344\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13314 (step 13314): 1.777595\n",
      "Batch #10\tAverage Generator Loss: 2974.775598\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13315 (step 13315): 1.322663\n",
      "Batch #10\tAverage Generator Loss: 2838.491724\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13316 (step 13316): 1.373274\n",
      "Batch #10\tAverage Generator Loss: 2687.998352\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13317 (step 13317): 1.734474\n",
      "Batch #10\tAverage Generator Loss: 3096.202454\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13318 (step 13318): 1.231558\n",
      "Batch #10\tAverage Generator Loss: 2338.804089\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13319 (step 13319): 1.301641\n",
      "Batch #10\tAverage Generator Loss: 2401.142053\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13320 (step 13320): 1.746766\n",
      "Batch #10\tAverage Generator Loss: 2571.016565\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13321 (step 13321): 1.335907\n",
      "Batch #10\tAverage Generator Loss: 2204.978540\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13322 (step 13322): 1.454872\n",
      "Batch #10\tAverage Generator Loss: 2588.966870\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13323 (step 13323): 1.945182\n",
      "Batch #10\tAverage Generator Loss: 1918.664270\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13324 (step 13324): 1.348957\n",
      "Batch #10\tAverage Generator Loss: 2796.008093\tAverage Discriminator Loss: 0.001006\n",
      "\n",
      "Train time for epoch #13325 (step 13325): 1.290852\n",
      "Batch #10\tAverage Generator Loss: 2508.106329\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13326 (step 13326): 1.746505\n",
      "Batch #10\tAverage Generator Loss: 2544.266211\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13327 (step 13327): 1.287403\n",
      "Batch #10\tAverage Generator Loss: 2748.122864\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13328 (step 13328): 1.335317\n",
      "Batch #10\tAverage Generator Loss: 3173.861475\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13329 (step 13329): 1.811420\n",
      "Batch #10\tAverage Generator Loss: 2418.459052\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13330 (step 13330): 1.364806\n",
      "Batch #10\tAverage Generator Loss: 3047.462646\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13331 (step 13331): 1.490762\n",
      "Batch #10\tAverage Generator Loss: 2937.520398\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13332 (step 13332): 1.746436\n",
      "Batch #10\tAverage Generator Loss: 2842.209424\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13333 (step 13333): 1.324912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 3015.249353\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13334 (step 13334): 1.413945\n",
      "Batch #10\tAverage Generator Loss: 2994.729419\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13335 (step 13335): 1.845399\n",
      "Batch #10\tAverage Generator Loss: 3129.472595\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13336 (step 13336): 1.336918\n",
      "Batch #10\tAverage Generator Loss: 2980.708081\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13337 (step 13337): 1.770985\n",
      "Batch #10\tAverage Generator Loss: 2291.104004\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13338 (step 13338): 1.348534\n",
      "Batch #10\tAverage Generator Loss: 2712.729956\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13339 (step 13339): 1.249934\n",
      "Batch #10\tAverage Generator Loss: 3092.110486\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13340 (step 13340): 1.774499\n",
      "Batch #10\tAverage Generator Loss: 2650.220483\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13341 (step 13341): 1.295580\n",
      "Batch #10\tAverage Generator Loss: 3140.759277\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13342 (step 13342): 1.295459\n",
      "Batch #10\tAverage Generator Loss: 2520.901776\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13343 (step 13343): 1.707882\n",
      "Batch #10\tAverage Generator Loss: 2816.695654\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13344 (step 13344): 1.299906\n",
      "Batch #10\tAverage Generator Loss: 2775.296606\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13345 (step 13345): 1.348102\n",
      "Batch #10\tAverage Generator Loss: 2167.388080\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13346 (step 13346): 1.764004\n",
      "Batch #10\tAverage Generator Loss: 3055.639734\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13347 (step 13347): 1.384796\n",
      "Batch #10\tAverage Generator Loss: 2653.885559\tAverage Discriminator Loss: 0.027796\n",
      "\n",
      "Train time for epoch #13348 (step 13348): 1.469439\n",
      "Batch #10\tAverage Generator Loss: 2782.862109\tAverage Discriminator Loss: 0.005472\n",
      "\n",
      "Train time for epoch #13349 (step 13349): 1.727859\n",
      "Batch #10\tAverage Generator Loss: 2572.527966\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13350 (step 13350): 1.399176\n",
      "Batch #10\tAverage Generator Loss: 2749.589899\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13351 (step 13351): 1.728438\n",
      "Batch #10\tAverage Generator Loss: 3052.836389\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13352 (step 13352): 1.289426\n",
      "Batch #10\tAverage Generator Loss: 2966.626636\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13353 (step 13353): 1.377346\n",
      "Batch #10\tAverage Generator Loss: 2726.496082\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13354 (step 13354): 1.753153\n",
      "Batch #10\tAverage Generator Loss: 2957.054333\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13355 (step 13355): 1.336252\n",
      "Batch #10\tAverage Generator Loss: 2923.512109\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13356 (step 13356): 1.371037\n",
      "Batch #10\tAverage Generator Loss: 2930.293018\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13357 (step 13357): 1.726889\n",
      "Batch #10\tAverage Generator Loss: 2535.955640\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13358 (step 13358): 1.345937\n",
      "Batch #10\tAverage Generator Loss: 3043.706458\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13359 (step 13359): 1.338713\n",
      "Batch #10\tAverage Generator Loss: 3145.744788\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13360 (step 13360): 1.841974\n",
      "Batch #10\tAverage Generator Loss: 2462.916675\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #13361 (step 13361): 1.378785\n",
      "Batch #10\tAverage Generator Loss: 2649.923572\tAverage Discriminator Loss: 0.002732\n",
      "\n",
      "Train time for epoch #13362 (step 13362): 1.389009\n",
      "Batch #10\tAverage Generator Loss: 2315.871625\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13363 (step 13363): 1.865176\n",
      "Batch #10\tAverage Generator Loss: 2536.627637\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13364 (step 13364): 1.310569\n",
      "Batch #10\tAverage Generator Loss: 3237.033130\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13365 (step 13365): 1.493523\n",
      "Batch #10\tAverage Generator Loss: 2593.239624\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13366 (step 13366): 1.741666\n",
      "Batch #10\tAverage Generator Loss: 2699.283447\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13367 (step 13367): 1.286219\n",
      "Batch #10\tAverage Generator Loss: 2706.331970\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13368 (step 13368): 1.423713\n",
      "Batch #10\tAverage Generator Loss: 2670.429034\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13369 (step 13369): 1.838800\n",
      "Batch #10\tAverage Generator Loss: 2871.740002\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13370 (step 13370): 1.353574\n",
      "Batch #10\tAverage Generator Loss: 2895.602197\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13371 (step 13371): 1.879726\n",
      "Batch #10\tAverage Generator Loss: 2952.634570\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13372 (step 13372): 1.445686\n",
      "Batch #10\tAverage Generator Loss: 2457.145923\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13373 (step 13373): 1.346249\n",
      "Batch #10\tAverage Generator Loss: 2350.600867\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13374 (step 13374): 1.844063\n",
      "Batch #10\tAverage Generator Loss: 2624.162817\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13375 (step 13375): 1.377739\n",
      "Batch #10\tAverage Generator Loss: 2929.093042\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13376 (step 13376): 1.270682\n",
      "Batch #10\tAverage Generator Loss: 2920.142639\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13377 (step 13377): 1.762529\n",
      "Batch #10\tAverage Generator Loss: 2827.486523\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13378 (step 13378): 1.444126\n",
      "Batch #10\tAverage Generator Loss: 2937.066711\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13379 (step 13379): 1.325140\n",
      "Batch #10\tAverage Generator Loss: 2723.315729\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13380 (step 13380): 1.781009\n",
      "Batch #10\tAverage Generator Loss: 2965.531873\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13381 (step 13381): 1.326312\n",
      "Batch #10\tAverage Generator Loss: 2745.627722\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13382 (step 13382): 1.283952\n",
      "Batch #10\tAverage Generator Loss: 2627.242786\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13383 (step 13383): 1.755499\n",
      "Batch #10\tAverage Generator Loss: 2936.172510\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13384 (step 13384): 1.406450\n",
      "Batch #10\tAverage Generator Loss: 2601.323895\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13385 (step 13385): 1.370947\n",
      "Batch #10\tAverage Generator Loss: 2903.936536\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13386 (step 13386): 1.868352\n",
      "Batch #10\tAverage Generator Loss: 3029.689856\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13387 (step 13387): 1.392070\n",
      "Batch #10\tAverage Generator Loss: 2709.356189\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13388 (step 13388): 1.694997\n",
      "Batch #10\tAverage Generator Loss: 2624.643750\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13389 (step 13389): 1.295598\n",
      "Batch #10\tAverage Generator Loss: 2933.248779\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13390 (step 13390): 1.291316\n",
      "Batch #10\tAverage Generator Loss: 2641.579321\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13391 (step 13391): 1.753350\n",
      "Batch #10\tAverage Generator Loss: 2733.805957\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13392 (step 13392): 1.379780\n",
      "Batch #10\tAverage Generator Loss: 3083.378168\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13393 (step 13393): 1.433083\n",
      "Batch #10\tAverage Generator Loss: 2490.671411\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13394 (step 13394): 1.799044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2547.907764\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13395 (step 13395): 1.284130\n",
      "Batch #10\tAverage Generator Loss: 2439.995435\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13396 (step 13396): 1.340636\n",
      "Batch #10\tAverage Generator Loss: 2891.172546\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13397 (step 13397): 1.732134\n",
      "Batch #10\tAverage Generator Loss: 2680.335095\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13398 (step 13398): 1.348800\n",
      "Batch #10\tAverage Generator Loss: 2487.382446\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13399 (step 13399): 1.421647\n",
      "Batch #10\tAverage Generator Loss: 2367.377167\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13400 (step 13400): 1.808122\n",
      "Batch #10\tAverage Generator Loss: 2921.275208\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13401 (step 13401): 1.292504\n",
      "Batch #10\tAverage Generator Loss: 2804.689966\tAverage Discriminator Loss: 0.208546\n",
      "\n",
      "Train time for epoch #13402 (step 13402): 1.346916\n",
      "Batch #10\tAverage Generator Loss: 2046.660547\tAverage Discriminator Loss: 0.244593\n",
      "\n",
      "Train time for epoch #13403 (step 13403): 1.983135\n",
      "Batch #10\tAverage Generator Loss: 2173.972864\tAverage Discriminator Loss: 0.000034\n",
      "\n",
      "Train time for epoch #13404 (step 13404): 1.497680\n",
      "Batch #10\tAverage Generator Loss: 1724.618781\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13405 (step 13405): 1.748983\n",
      "Batch #10\tAverage Generator Loss: 2143.710132\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13406 (step 13406): 1.292188\n",
      "Batch #10\tAverage Generator Loss: 1783.365723\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13407 (step 13407): 1.350768\n",
      "Batch #10\tAverage Generator Loss: 2142.357019\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13408 (step 13408): 1.754095\n",
      "Batch #10\tAverage Generator Loss: 2394.958789\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13409 (step 13409): 1.369128\n",
      "Batch #10\tAverage Generator Loss: 2173.353247\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13410 (step 13410): 1.382218\n",
      "Batch #10\tAverage Generator Loss: 2190.414001\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13411 (step 13411): 1.863256\n",
      "Batch #10\tAverage Generator Loss: 1564.797708\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13412 (step 13412): 1.353388\n",
      "Batch #10\tAverage Generator Loss: 2132.812234\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13413 (step 13413): 1.291842\n",
      "Batch #10\tAverage Generator Loss: 2620.110693\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13414 (step 13414): 1.791536\n",
      "Batch #10\tAverage Generator Loss: 2677.957947\tAverage Discriminator Loss: 0.040351\n",
      "\n",
      "Train time for epoch #13415 (step 13415): 1.298750\n",
      "Batch #10\tAverage Generator Loss: 2788.237256\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13416 (step 13416): 1.328506\n",
      "Batch #10\tAverage Generator Loss: 2388.481805\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13417 (step 13417): 1.784909\n",
      "Batch #10\tAverage Generator Loss: 2379.113983\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13418 (step 13418): 1.287299\n",
      "Batch #10\tAverage Generator Loss: 2891.124707\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13419 (step 13419): 1.399224\n",
      "Batch #10\tAverage Generator Loss: 2749.853113\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13420 (step 13420): 1.731303\n",
      "Batch #10\tAverage Generator Loss: 1897.325909\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13421 (step 13421): 1.500715\n",
      "Batch #10\tAverage Generator Loss: 2766.848578\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13422 (step 13422): 1.669826\n",
      "Batch #10\tAverage Generator Loss: 2834.921057\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13423 (step 13423): 1.291043\n",
      "Batch #10\tAverage Generator Loss: 2458.002173\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13424 (step 13424): 1.363823\n",
      "Batch #10\tAverage Generator Loss: 2267.720239\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13425 (step 13425): 1.709363\n",
      "Batch #10\tAverage Generator Loss: 2357.062476\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13426 (step 13426): 1.430276\n",
      "Batch #10\tAverage Generator Loss: 2944.656628\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13427 (step 13427): 1.337947\n",
      "Batch #10\tAverage Generator Loss: 2429.436011\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13428 (step 13428): 1.923633\n",
      "Batch #10\tAverage Generator Loss: 2499.044971\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13429 (step 13429): 1.392438\n",
      "Batch #10\tAverage Generator Loss: 1963.931891\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13430 (step 13430): 1.339152\n",
      "Batch #10\tAverage Generator Loss: 2707.174060\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13431 (step 13431): 1.966162\n",
      "Batch #10\tAverage Generator Loss: 2281.693921\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13432 (step 13432): 1.381416\n",
      "Batch #10\tAverage Generator Loss: 2824.555066\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13433 (step 13433): 1.292645\n",
      "Batch #10\tAverage Generator Loss: 2067.621045\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13434 (step 13434): 1.823321\n",
      "Batch #10\tAverage Generator Loss: 2343.399805\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13435 (step 13435): 1.282971\n",
      "Batch #10\tAverage Generator Loss: 2218.808789\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13436 (step 13436): 1.331470\n",
      "Batch #10\tAverage Generator Loss: 2056.454584\tAverage Discriminator Loss: 0.006868\n",
      "\n",
      "Train time for epoch #13437 (step 13437): 1.736282\n",
      "Batch #10\tAverage Generator Loss: 1978.460138\tAverage Discriminator Loss: 0.000376\n",
      "\n",
      "Train time for epoch #13438 (step 13438): 1.349367\n",
      "Batch #10\tAverage Generator Loss: 2070.270361\tAverage Discriminator Loss: 0.001506\n",
      "\n",
      "Train time for epoch #13439 (step 13439): 1.288472\n",
      "Batch #10\tAverage Generator Loss: 1754.108984\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #13440 (step 13440): 1.763736\n",
      "Batch #10\tAverage Generator Loss: 2006.170163\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #13441 (step 13441): 1.436285\n",
      "Batch #10\tAverage Generator Loss: 2232.777853\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #13442 (step 13442): 1.351474\n",
      "Batch #10\tAverage Generator Loss: 1685.838116\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13443 (step 13443): 1.950149\n",
      "Batch #10\tAverage Generator Loss: 2284.716254\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13444 (step 13444): 1.385819\n",
      "Batch #10\tAverage Generator Loss: 1883.726843\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13445 (step 13445): 1.918354\n",
      "Batch #10\tAverage Generator Loss: 2102.549493\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13446 (step 13446): 1.341436\n",
      "Batch #10\tAverage Generator Loss: 2019.820154\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13447 (step 13447): 1.268854\n",
      "Batch #10\tAverage Generator Loss: 1988.901190\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13448 (step 13448): 1.283319\n",
      "Batch #10\tAverage Generator Loss: 2444.442230\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13449 (step 13449): 1.841446\n",
      "Batch #10\tAverage Generator Loss: 1679.010553\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13450 (step 13450): 1.357047\n",
      "Batch #10\tAverage Generator Loss: 2383.362360\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13451 (step 13451): 1.786061\n",
      "Batch #10\tAverage Generator Loss: 2013.134207\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13452 (step 13452): 1.343585\n",
      "Batch #10\tAverage Generator Loss: 2177.774451\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13453 (step 13453): 1.292548\n",
      "Batch #10\tAverage Generator Loss: 2158.108478\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13454 (step 13454): 1.760664\n",
      "Batch #10\tAverage Generator Loss: 2406.178857\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13455 (step 13455): 1.326439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2167.605896\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13456 (step 13456): 1.340446\n",
      "Batch #10\tAverage Generator Loss: 2027.569458\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13457 (step 13457): 1.734902\n",
      "Batch #10\tAverage Generator Loss: 2357.339624\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13458 (step 13458): 1.432296\n",
      "Batch #10\tAverage Generator Loss: 2282.051129\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13459 (step 13459): 1.443453\n",
      "Batch #10\tAverage Generator Loss: 2530.989746\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13460 (step 13460): 1.777470\n",
      "Batch #10\tAverage Generator Loss: 2302.086243\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13461 (step 13461): 1.324781\n",
      "Batch #10\tAverage Generator Loss: 2086.288379\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13462 (step 13462): 1.382475\n",
      "Batch #10\tAverage Generator Loss: 2273.256689\tAverage Discriminator Loss: 0.132112\n",
      "\n",
      "Train time for epoch #13463 (step 13463): 1.646789\n",
      "Batch #10\tAverage Generator Loss: 2583.055554\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13464 (step 13464): 1.302089\n",
      "Batch #10\tAverage Generator Loss: 2704.433130\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13465 (step 13465): 1.290935\n",
      "Batch #10\tAverage Generator Loss: 2375.716443\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13466 (step 13466): 1.719155\n",
      "Batch #10\tAverage Generator Loss: 2259.629419\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13467 (step 13467): 1.326303\n",
      "Batch #10\tAverage Generator Loss: 2185.490442\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13468 (step 13468): 1.269984\n",
      "Batch #10\tAverage Generator Loss: 2363.498730\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13469 (step 13469): 1.848033\n",
      "Batch #10\tAverage Generator Loss: 2498.000500\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13470 (step 13470): 1.435916\n",
      "Batch #10\tAverage Generator Loss: 2383.962183\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13471 (step 13471): 1.336306\n",
      "Batch #10\tAverage Generator Loss: 2447.325366\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13472 (step 13472): 1.718006\n",
      "Batch #10\tAverage Generator Loss: 2445.112537\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13473 (step 13473): 1.350346\n",
      "Batch #10\tAverage Generator Loss: 2364.567639\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13474 (step 13474): 1.280676\n",
      "Batch #10\tAverage Generator Loss: 2813.235913\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13475 (step 13475): 1.727775\n",
      "Batch #10\tAverage Generator Loss: 2401.918030\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13476 (step 13476): 1.436291\n",
      "Batch #10\tAverage Generator Loss: 2487.487317\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13477 (step 13477): 1.359990\n",
      "Batch #10\tAverage Generator Loss: 2238.611554\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13478 (step 13478): 1.703681\n",
      "Batch #10\tAverage Generator Loss: 2199.645312\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13479 (step 13479): 1.391301\n",
      "Batch #10\tAverage Generator Loss: 2370.579645\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13480 (step 13480): 1.743133\n",
      "Batch #10\tAverage Generator Loss: 2247.911877\tAverage Discriminator Loss: 0.014811\n",
      "\n",
      "Train time for epoch #13481 (step 13481): 1.298105\n",
      "Batch #10\tAverage Generator Loss: 2278.564563\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #13482 (step 13482): 1.415990\n",
      "Batch #10\tAverage Generator Loss: 2496.465552\tAverage Discriminator Loss: 0.000033\n",
      "\n",
      "Train time for epoch #13483 (step 13483): 1.745159\n",
      "Batch #10\tAverage Generator Loss: 2731.497253\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #13484 (step 13484): 1.371715\n",
      "Batch #10\tAverage Generator Loss: 2603.255518\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #13485 (step 13485): 1.248483\n",
      "Batch #10\tAverage Generator Loss: 2169.191785\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #13486 (step 13486): 1.853677\n",
      "Batch #10\tAverage Generator Loss: 2155.573767\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #13487 (step 13487): 1.280254\n",
      "Batch #10\tAverage Generator Loss: 2062.178479\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #13488 (step 13488): 1.337109\n",
      "Batch #10\tAverage Generator Loss: 2351.716772\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #13489 (step 13489): 1.855042\n",
      "Batch #10\tAverage Generator Loss: 2445.241870\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #13490 (step 13490): 1.359165\n",
      "Batch #10\tAverage Generator Loss: 2235.186536\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #13491 (step 13491): 1.279150\n",
      "Batch #10\tAverage Generator Loss: 2262.569080\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #13492 (step 13492): 1.787532\n",
      "Batch #10\tAverage Generator Loss: 2396.080627\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #13493 (step 13493): 1.283383\n",
      "Batch #10\tAverage Generator Loss: 1941.718860\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #13494 (step 13494): 1.296370\n",
      "Batch #10\tAverage Generator Loss: 2029.003394\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #13495 (step 13495): 1.899426\n",
      "Batch #10\tAverage Generator Loss: 2234.237537\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #13496 (step 13496): 1.286312\n",
      "Batch #10\tAverage Generator Loss: 2529.944299\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #13497 (step 13497): 1.821368\n",
      "Batch #10\tAverage Generator Loss: 2252.697009\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #13498 (step 13498): 1.300165\n",
      "Batch #10\tAverage Generator Loss: 2165.102271\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #13499 (step 13499): 1.426347\n",
      "Batch #10\tAverage Generator Loss: 2304.312488\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #13500 (step 13500): 1.715710\n",
      "Batch #10\tAverage Generator Loss: 2325.310773\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #13501 (step 13501): 1.294329\n",
      "Batch #10\tAverage Generator Loss: 2648.402722\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #13502 (step 13502): 1.303268\n",
      "Batch #10\tAverage Generator Loss: 2186.542926\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #13503 (step 13503): 1.731446\n",
      "Batch #10\tAverage Generator Loss: 2279.965540\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #13504 (step 13504): 1.350300\n",
      "Batch #10\tAverage Generator Loss: 2049.673969\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #13505 (step 13505): 1.433702\n",
      "Batch #10\tAverage Generator Loss: 2247.033069\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #13506 (step 13506): 1.792589\n",
      "Batch #10\tAverage Generator Loss: 2342.388428\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #13507 (step 13507): 1.340249\n",
      "Batch #10\tAverage Generator Loss: 2461.066919\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #13508 (step 13508): 1.281891\n",
      "Batch #10\tAverage Generator Loss: 2443.717053\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #13509 (step 13509): 1.332515\n",
      "Batch #10\tAverage Generator Loss: 2784.934851\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #13510 (step 13510): 1.825995\n",
      "Batch #10\tAverage Generator Loss: 2441.966272\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #13511 (step 13511): 1.371078\n",
      "Batch #10\tAverage Generator Loss: 2188.480688\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #13512 (step 13512): 1.809147\n",
      "Batch #10\tAverage Generator Loss: 2353.446643\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13513 (step 13513): 1.291188\n",
      "Batch #10\tAverage Generator Loss: 2539.547412\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #13514 (step 13514): 1.410001\n",
      "Batch #10\tAverage Generator Loss: 2488.635754\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #13515 (step 13515): 1.805731\n",
      "Batch #10\tAverage Generator Loss: 2310.556384\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #13516 (step 13516): 1.378358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2282.608655\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #13517 (step 13517): 1.332880\n",
      "Batch #10\tAverage Generator Loss: 2878.826086\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #13518 (step 13518): 1.740588\n",
      "Batch #10\tAverage Generator Loss: 2404.366174\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #13519 (step 13519): 1.445925\n",
      "Batch #10\tAverage Generator Loss: 2460.754474\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #13520 (step 13520): 1.394539\n",
      "Batch #10\tAverage Generator Loss: 2254.452502\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #13521 (step 13521): 1.853271\n",
      "Batch #10\tAverage Generator Loss: 2103.693494\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #13522 (step 13522): 1.319065\n",
      "Batch #10\tAverage Generator Loss: 2772.723157\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #13523 (step 13523): 1.335354\n",
      "Batch #10\tAverage Generator Loss: 2647.325586\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #13524 (step 13524): 1.814483\n",
      "Batch #10\tAverage Generator Loss: 2765.898901\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #13525 (step 13525): 1.331099\n",
      "Batch #10\tAverage Generator Loss: 2416.627637\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #13526 (step 13526): 1.287692\n",
      "Batch #10\tAverage Generator Loss: 2364.855066\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13527 (step 13527): 1.730714\n",
      "Batch #10\tAverage Generator Loss: 2306.461127\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #13528 (step 13528): 1.354185\n",
      "Batch #10\tAverage Generator Loss: 2455.861084\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #13529 (step 13529): 1.303583\n",
      "Batch #10\tAverage Generator Loss: 2450.812036\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13530 (step 13530): 1.749171\n",
      "Batch #10\tAverage Generator Loss: 2195.500671\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #13531 (step 13531): 1.330873\n",
      "Batch #10\tAverage Generator Loss: 2568.272028\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13532 (step 13532): 1.289760\n",
      "Batch #10\tAverage Generator Loss: 2020.904172\tAverage Discriminator Loss: 0.005869\n",
      "\n",
      "Train time for epoch #13533 (step 13533): 1.752494\n",
      "Batch #10\tAverage Generator Loss: 2176.928833\tAverage Discriminator Loss: 0.019579\n",
      "\n",
      "Train time for epoch #13534 (step 13534): 1.338503\n",
      "Batch #10\tAverage Generator Loss: 2170.226678\tAverage Discriminator Loss: 0.054746\n",
      "\n",
      "Train time for epoch #13535 (step 13535): 1.413532\n",
      "Batch #10\tAverage Generator Loss: 2508.126660\tAverage Discriminator Loss: 0.006503\n",
      "\n",
      "Train time for epoch #13536 (step 13536): 1.846142\n",
      "Batch #10\tAverage Generator Loss: 2513.030017\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13537 (step 13537): 1.306315\n",
      "Batch #10\tAverage Generator Loss: 2462.521204\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13538 (step 13538): 1.300363\n",
      "Batch #10\tAverage Generator Loss: 2551.286853\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13539 (step 13539): 1.780803\n",
      "Batch #10\tAverage Generator Loss: 2530.824060\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13540 (step 13540): 1.307704\n",
      "Batch #10\tAverage Generator Loss: 1768.684521\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13541 (step 13541): 1.288688\n",
      "Batch #10\tAverage Generator Loss: 2487.724988\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13542 (step 13542): 1.744438\n",
      "Batch #10\tAverage Generator Loss: 2238.586584\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13543 (step 13543): 1.404670\n",
      "Batch #10\tAverage Generator Loss: 2287.302197\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13544 (step 13544): 1.765238\n",
      "Batch #10\tAverage Generator Loss: 2156.088416\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13545 (step 13545): 1.324328\n",
      "Batch #10\tAverage Generator Loss: 1918.255969\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13546 (step 13546): 1.299521\n",
      "Batch #10\tAverage Generator Loss: 2263.295642\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13547 (step 13547): 1.734031\n",
      "Batch #10\tAverage Generator Loss: 2539.247107\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13548 (step 13548): 1.281155\n",
      "Batch #10\tAverage Generator Loss: 2765.098804\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13549 (step 13549): 1.416088\n",
      "Batch #10\tAverage Generator Loss: 2282.369592\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13550 (step 13550): 1.771728\n",
      "Batch #10\tAverage Generator Loss: 2387.445728\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13551 (step 13551): 1.295909\n",
      "Batch #10\tAverage Generator Loss: 2240.279919\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13552 (step 13552): 1.399077\n",
      "Batch #10\tAverage Generator Loss: 1953.054449\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13553 (step 13553): 1.785076\n",
      "Batch #10\tAverage Generator Loss: 2555.802063\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13554 (step 13554): 1.280670\n",
      "Batch #10\tAverage Generator Loss: 2334.988708\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13555 (step 13555): 1.390345\n",
      "Batch #10\tAverage Generator Loss: 2304.005408\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13556 (step 13556): 1.766776\n",
      "Batch #10\tAverage Generator Loss: 2405.395447\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13557 (step 13557): 1.296399\n",
      "Batch #10\tAverage Generator Loss: 2382.510071\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13558 (step 13558): 1.314218\n",
      "Batch #10\tAverage Generator Loss: 2529.539490\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13559 (step 13559): 1.784674\n",
      "Batch #10\tAverage Generator Loss: 2414.899658\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13560 (step 13560): 1.286088\n",
      "Batch #10\tAverage Generator Loss: 2207.813879\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13561 (step 13561): 1.352480\n",
      "Batch #10\tAverage Generator Loss: 2577.648718\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13562 (step 13562): 1.907189\n",
      "Batch #10\tAverage Generator Loss: 2633.909253\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13563 (step 13563): 1.301845\n",
      "Batch #10\tAverage Generator Loss: 2433.033313\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13564 (step 13564): 1.333739\n",
      "Batch #10\tAverage Generator Loss: 2374.990320\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13565 (step 13565): 1.719021\n",
      "Batch #10\tAverage Generator Loss: 2430.075989\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13566 (step 13566): 1.294067\n",
      "Batch #10\tAverage Generator Loss: 2338.923755\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13567 (step 13567): 1.893468\n",
      "Batch #10\tAverage Generator Loss: 2507.034448\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13568 (step 13568): 1.418599\n",
      "Batch #10\tAverage Generator Loss: 2310.525269\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13569 (step 13569): 1.295297\n",
      "Batch #10\tAverage Generator Loss: 2431.912476\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13570 (step 13570): 1.288421\n",
      "Batch #10\tAverage Generator Loss: 2171.566406\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13571 (step 13571): 1.764886\n",
      "Batch #10\tAverage Generator Loss: 2213.102258\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13572 (step 13572): 1.336095\n",
      "Batch #10\tAverage Generator Loss: 2312.574908\tAverage Discriminator Loss: 0.025922\n",
      "\n",
      "Train time for epoch #13573 (step 13573): 1.738103\n",
      "Batch #10\tAverage Generator Loss: 2073.160376\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13574 (step 13574): 1.357408\n",
      "Batch #10\tAverage Generator Loss: 2220.021423\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #13575 (step 13575): 1.402072\n",
      "Batch #10\tAverage Generator Loss: 2261.303967\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #13576 (step 13576): 1.330468\n",
      "Batch #10\tAverage Generator Loss: 2245.038196\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #13577 (step 13577): 1.804946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 1974.993762\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #13578 (step 13578): 1.340534\n",
      "Batch #10\tAverage Generator Loss: 2124.139001\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #13579 (step 13579): 1.730306\n",
      "Batch #10\tAverage Generator Loss: 1981.065918\tAverage Discriminator Loss: 0.000077\n",
      "\n",
      "Train time for epoch #13580 (step 13580): 1.378599\n",
      "Batch #10\tAverage Generator Loss: 2235.351050\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #13581 (step 13581): 1.388240\n",
      "Batch #10\tAverage Generator Loss: 2241.319434\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13582 (step 13582): 1.724956\n",
      "Batch #10\tAverage Generator Loss: 2046.032898\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13583 (step 13583): 1.282814\n",
      "Batch #10\tAverage Generator Loss: 1798.291266\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13584 (step 13584): 1.294956\n",
      "Batch #10\tAverage Generator Loss: 2118.452515\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13585 (step 13585): 1.680136\n",
      "Batch #10\tAverage Generator Loss: 2326.333783\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13586 (step 13586): 1.574713\n",
      "Batch #10\tAverage Generator Loss: 2199.048254\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13587 (step 13587): 1.351603\n",
      "Batch #10\tAverage Generator Loss: 1768.968982\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13588 (step 13588): 1.720450\n",
      "Batch #10\tAverage Generator Loss: 2064.583502\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13589 (step 13589): 1.298730\n",
      "Batch #10\tAverage Generator Loss: 2187.261877\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13590 (step 13590): 1.444142\n",
      "Batch #10\tAverage Generator Loss: 2494.528882\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13591 (step 13591): 1.764267\n",
      "Batch #10\tAverage Generator Loss: 1951.412726\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13592 (step 13592): 1.290657\n",
      "Batch #10\tAverage Generator Loss: 1972.721851\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13593 (step 13593): 1.297427\n",
      "Batch #10\tAverage Generator Loss: 2201.310315\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13594 (step 13594): 1.706081\n",
      "Batch #10\tAverage Generator Loss: 2074.453357\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13595 (step 13595): 1.468488\n",
      "Batch #10\tAverage Generator Loss: 1896.476721\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13596 (step 13596): 1.307353\n",
      "Batch #10\tAverage Generator Loss: 2071.679810\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13597 (step 13597): 1.689111\n",
      "Batch #10\tAverage Generator Loss: 2167.218884\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13598 (step 13598): 1.375764\n",
      "Batch #10\tAverage Generator Loss: 2124.791663\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13599 (step 13599): 1.444248\n",
      "Batch #10\tAverage Generator Loss: 2017.633374\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13600 (step 13600): 1.846760\n",
      "Batch #10\tAverage Generator Loss: 2125.076392\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13601 (step 13601): 1.319565\n",
      "Batch #10\tAverage Generator Loss: 1810.327130\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13602 (step 13602): 1.338838\n",
      "Batch #10\tAverage Generator Loss: 2029.830371\tAverage Discriminator Loss: 0.009051\n",
      "\n",
      "Train time for epoch #13603 (step 13603): 1.845235\n",
      "Batch #10\tAverage Generator Loss: 2248.681091\tAverage Discriminator Loss: 0.015539\n",
      "\n",
      "Train time for epoch #13604 (step 13604): 1.357919\n",
      "Batch #10\tAverage Generator Loss: 2432.283386\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13605 (step 13605): 1.289234\n",
      "Batch #10\tAverage Generator Loss: 1673.260312\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13606 (step 13606): 1.802174\n",
      "Batch #10\tAverage Generator Loss: 2031.352493\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13607 (step 13607): 1.408464\n",
      "Batch #10\tAverage Generator Loss: 1862.503992\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13608 (step 13608): 1.330670\n",
      "Batch #10\tAverage Generator Loss: 1911.532019\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13609 (step 13609): 1.836672\n",
      "Batch #10\tAverage Generator Loss: 2173.272339\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13610 (step 13610): 1.465896\n",
      "Batch #10\tAverage Generator Loss: 1994.520093\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13611 (step 13611): 1.334197\n",
      "Batch #10\tAverage Generator Loss: 2231.084387\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13612 (step 13612): 1.820917\n",
      "Batch #10\tAverage Generator Loss: 1957.338953\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13613 (step 13613): 1.359598\n",
      "Batch #10\tAverage Generator Loss: 2135.072766\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13614 (step 13614): 1.305976\n",
      "Batch #10\tAverage Generator Loss: 2194.621008\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13615 (step 13615): 1.857652\n",
      "Batch #10\tAverage Generator Loss: 2371.685864\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13616 (step 13616): 1.296613\n",
      "Batch #10\tAverage Generator Loss: 2138.806995\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13617 (step 13617): 1.377447\n",
      "Batch #10\tAverage Generator Loss: 2141.757605\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13618 (step 13618): 1.807038\n",
      "Batch #10\tAverage Generator Loss: 1922.987958\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13619 (step 13619): 1.288621\n",
      "Batch #10\tAverage Generator Loss: 2349.590869\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13620 (step 13620): 1.272926\n",
      "Batch #10\tAverage Generator Loss: 1994.167712\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13621 (step 13621): 1.833851\n",
      "Batch #10\tAverage Generator Loss: 2088.655078\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13622 (step 13622): 1.314788\n",
      "Batch #10\tAverage Generator Loss: 1968.934302\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13623 (step 13623): 1.352466\n",
      "Batch #10\tAverage Generator Loss: 2073.702307\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13624 (step 13624): 1.708313\n",
      "Batch #10\tAverage Generator Loss: 2055.465527\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13625 (step 13625): 1.303774\n",
      "Batch #10\tAverage Generator Loss: 2271.667334\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13626 (step 13626): 1.245868\n",
      "Batch #10\tAverage Generator Loss: 2175.064923\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13627 (step 13627): 1.773996\n",
      "Batch #10\tAverage Generator Loss: 2355.702649\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13628 (step 13628): 1.328068\n",
      "Batch #10\tAverage Generator Loss: 2290.912415\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13629 (step 13629): 1.295022\n",
      "Batch #10\tAverage Generator Loss: 1787.507068\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13630 (step 13630): 1.695369\n",
      "Batch #10\tAverage Generator Loss: 2190.937939\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13631 (step 13631): 1.394215\n",
      "Batch #10\tAverage Generator Loss: 2153.220068\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13632 (step 13632): 1.681995\n",
      "Batch #10\tAverage Generator Loss: 2150.668219\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13633 (step 13633): 1.571805\n",
      "Batch #10\tAverage Generator Loss: 2194.530566\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13634 (step 13634): 1.273332\n",
      "Batch #10\tAverage Generator Loss: 2144.618329\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13635 (step 13635): 1.846626\n",
      "Batch #10\tAverage Generator Loss: 2189.563232\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13636 (step 13636): 1.288008\n",
      "Batch #10\tAverage Generator Loss: 2498.287854\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13637 (step 13637): 1.292941\n",
      "Batch #10\tAverage Generator Loss: 2209.636169\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13638 (step 13638): 1.770216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2220.875977\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13639 (step 13639): 1.299000\n",
      "Batch #10\tAverage Generator Loss: 2500.453931\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13640 (step 13640): 1.334665\n",
      "Batch #10\tAverage Generator Loss: 2244.550598\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13641 (step 13641): 1.865227\n",
      "Batch #10\tAverage Generator Loss: 1917.935962\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13642 (step 13642): 1.281683\n",
      "Batch #10\tAverage Generator Loss: 2033.892773\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13643 (step 13643): 1.277042\n",
      "Batch #10\tAverage Generator Loss: 2111.714178\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13644 (step 13644): 1.748830\n",
      "Batch #10\tAverage Generator Loss: 2103.046161\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13645 (step 13645): 1.478950\n",
      "Batch #10\tAverage Generator Loss: 2345.373511\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13646 (step 13646): 1.253349\n",
      "Batch #10\tAverage Generator Loss: 2226.212573\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13647 (step 13647): 1.968144\n",
      "Batch #10\tAverage Generator Loss: 2020.662045\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13648 (step 13648): 1.339630\n",
      "Batch #10\tAverage Generator Loss: 2197.909534\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13649 (step 13649): 1.333806\n",
      "Batch #10\tAverage Generator Loss: 1990.372974\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13650 (step 13650): 1.864421\n",
      "Batch #10\tAverage Generator Loss: 1889.450317\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13651 (step 13651): 1.481768\n",
      "Batch #10\tAverage Generator Loss: 2217.358905\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13652 (step 13652): 1.971782\n",
      "Batch #10\tAverage Generator Loss: 1912.076514\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13653 (step 13653): 1.338758\n",
      "Batch #10\tAverage Generator Loss: 2145.353162\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13654 (step 13654): 1.506563\n",
      "Batch #10\tAverage Generator Loss: 2193.038501\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13655 (step 13655): 1.760845\n",
      "Batch #10\tAverage Generator Loss: 2196.477698\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13656 (step 13656): 1.333261\n",
      "Batch #10\tAverage Generator Loss: 2006.122009\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13657 (step 13657): 1.445942\n",
      "Batch #10\tAverage Generator Loss: 1697.484750\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13658 (step 13658): 1.901580\n",
      "Batch #10\tAverage Generator Loss: 2095.915601\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13659 (step 13659): 1.337073\n",
      "Batch #10\tAverage Generator Loss: 2004.514478\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13660 (step 13660): 1.251647\n",
      "Batch #10\tAverage Generator Loss: 2319.313977\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13661 (step 13661): 1.712579\n",
      "Batch #10\tAverage Generator Loss: 2208.550079\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13662 (step 13662): 1.319443\n",
      "Batch #10\tAverage Generator Loss: 2183.514941\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13663 (step 13663): 1.251281\n",
      "Batch #10\tAverage Generator Loss: 1993.639819\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13664 (step 13664): 1.717346\n",
      "Batch #10\tAverage Generator Loss: 2302.804907\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13665 (step 13665): 1.402198\n",
      "Batch #10\tAverage Generator Loss: 1936.460315\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13666 (step 13666): 1.353961\n",
      "Batch #10\tAverage Generator Loss: 2266.528601\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13667 (step 13667): 1.821925\n",
      "Batch #10\tAverage Generator Loss: 2541.912537\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13668 (step 13668): 1.350247\n",
      "Batch #10\tAverage Generator Loss: 2023.291040\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13669 (step 13669): 1.403019\n",
      "Batch #10\tAverage Generator Loss: 2456.253552\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13670 (step 13670): 1.786150\n",
      "Batch #10\tAverage Generator Loss: 1905.276544\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13671 (step 13671): 1.442111\n",
      "Batch #10\tAverage Generator Loss: 1954.847180\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13672 (step 13672): 1.284619\n",
      "Batch #10\tAverage Generator Loss: 2203.111731\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13673 (step 13673): 1.842993\n",
      "Batch #10\tAverage Generator Loss: 1653.549608\tAverage Discriminator Loss: 1.993111\n",
      "\n",
      "Train time for epoch #13674 (step 13674): 1.368896\n",
      "Batch #10\tAverage Generator Loss: 1765.868646\tAverage Discriminator Loss: 0.017281\n",
      "\n",
      "Train time for epoch #13675 (step 13675): 1.244371\n",
      "Batch #10\tAverage Generator Loss: 2201.586389\tAverage Discriminator Loss: 0.142832\n",
      "\n",
      "Train time for epoch #13676 (step 13676): 1.774144\n",
      "Batch #10\tAverage Generator Loss: 1975.926117\tAverage Discriminator Loss: 2.386012\n",
      "\n",
      "Train time for epoch #13677 (step 13677): 1.386349\n",
      "Batch #10\tAverage Generator Loss: 2237.384204\tAverage Discriminator Loss: 0.091917\n",
      "\n",
      "Train time for epoch #13678 (step 13678): 1.301075\n",
      "Batch #10\tAverage Generator Loss: 2344.210510\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13679 (step 13679): 1.803153\n",
      "Batch #10\tAverage Generator Loss: 1784.229468\tAverage Discriminator Loss: 0.003447\n",
      "\n",
      "Train time for epoch #13680 (step 13680): 1.301388\n",
      "Batch #10\tAverage Generator Loss: 1840.284497\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13681 (step 13681): 1.311313\n",
      "Batch #10\tAverage Generator Loss: 2955.765631\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13682 (step 13682): 1.816448\n",
      "Batch #10\tAverage Generator Loss: 1959.555737\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13683 (step 13683): 1.299372\n",
      "Batch #10\tAverage Generator Loss: 1888.054913\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13684 (step 13684): 1.381018\n",
      "Batch #10\tAverage Generator Loss: 1727.042084\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13685 (step 13685): 1.759503\n",
      "Batch #10\tAverage Generator Loss: 2166.218787\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13686 (step 13686): 1.292567\n",
      "Batch #10\tAverage Generator Loss: 1874.689087\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13687 (step 13687): 1.352526\n",
      "Batch #10\tAverage Generator Loss: 2605.143701\tAverage Discriminator Loss: 0.023642\n",
      "\n",
      "Train time for epoch #13688 (step 13688): 1.694870\n",
      "Batch #10\tAverage Generator Loss: 2305.170483\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13689 (step 13689): 1.368039\n",
      "Batch #10\tAverage Generator Loss: 1944.939984\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13690 (step 13690): 1.377628\n",
      "Batch #10\tAverage Generator Loss: 1662.001787\tAverage Discriminator Loss: 4.341037\n",
      "\n",
      "Train time for epoch #13691 (step 13691): 1.824477\n",
      "Batch #10\tAverage Generator Loss: 1534.031415\tAverage Discriminator Loss: 0.801493\n",
      "\n",
      "Train time for epoch #13692 (step 13692): 1.331661\n",
      "Batch #10\tAverage Generator Loss: 1736.966315\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13693 (step 13693): 1.336172\n",
      "Batch #10\tAverage Generator Loss: 1554.245911\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13694 (step 13694): 1.755724\n",
      "Batch #10\tAverage Generator Loss: 1870.470691\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13695 (step 13695): 1.300737\n",
      "Batch #10\tAverage Generator Loss: 1771.508258\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13696 (step 13696): 1.396373\n",
      "Batch #10\tAverage Generator Loss: 1473.640387\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13697 (step 13697): 1.798071\n",
      "Batch #10\tAverage Generator Loss: 1613.429944\tAverage Discriminator Loss: 0.000023\n",
      "\n",
      "Train time for epoch #13698 (step 13698): 1.289421\n",
      "Batch #10\tAverage Generator Loss: 1563.061975\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13699 (step 13699): 1.390435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 1637.514954\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13700 (step 13700): 1.765734\n",
      "Batch #10\tAverage Generator Loss: 1522.225861\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13701 (step 13701): 1.353431\n",
      "Batch #10\tAverage Generator Loss: 1533.662683\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13702 (step 13702): 1.294932\n",
      "Batch #10\tAverage Generator Loss: 1675.447803\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13703 (step 13703): 1.710920\n",
      "Batch #10\tAverage Generator Loss: 1551.904236\tAverage Discriminator Loss: 0.011420\n",
      "\n",
      "Train time for epoch #13704 (step 13704): 1.293358\n",
      "Batch #10\tAverage Generator Loss: 1445.700690\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13705 (step 13705): 1.345818\n",
      "Batch #10\tAverage Generator Loss: 1400.017767\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13706 (step 13706): 1.720412\n",
      "Batch #10\tAverage Generator Loss: 1577.374304\tAverage Discriminator Loss: 0.003299\n",
      "\n",
      "Train time for epoch #13707 (step 13707): 1.310176\n",
      "Batch #10\tAverage Generator Loss: 1763.236304\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13708 (step 13708): 1.346702\n",
      "Batch #10\tAverage Generator Loss: 1490.950018\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13709 (step 13709): 1.717471\n",
      "Batch #10\tAverage Generator Loss: 1765.515454\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13710 (step 13710): 1.313196\n",
      "Batch #10\tAverage Generator Loss: 1862.028430\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13711 (step 13711): 1.427967\n",
      "Batch #10\tAverage Generator Loss: 1587.961499\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13712 (step 13712): 1.768674\n",
      "Batch #10\tAverage Generator Loss: 1562.471399\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13713 (step 13713): 1.340949\n",
      "Batch #10\tAverage Generator Loss: 1607.829108\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13714 (step 13714): 1.734092\n",
      "Batch #10\tAverage Generator Loss: 1796.114868\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13715 (step 13715): 1.387585\n",
      "Batch #10\tAverage Generator Loss: 1632.671649\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13716 (step 13716): 1.398633\n",
      "Batch #10\tAverage Generator Loss: 1861.360443\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13717 (step 13717): 1.251276\n",
      "Batch #10\tAverage Generator Loss: 1887.456641\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13718 (step 13718): 1.818995\n",
      "Batch #10\tAverage Generator Loss: 1753.805176\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13719 (step 13719): 1.345676\n",
      "Batch #10\tAverage Generator Loss: 1741.621991\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13720 (step 13720): 1.754521\n",
      "Batch #10\tAverage Generator Loss: 1802.876196\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13721 (step 13721): 1.351290\n",
      "Batch #10\tAverage Generator Loss: 1806.815564\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13722 (step 13722): 1.281772\n",
      "Batch #10\tAverage Generator Loss: 1819.191266\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13723 (step 13723): 1.303819\n",
      "Batch #10\tAverage Generator Loss: 1659.477905\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13724 (step 13724): 1.723475\n",
      "Batch #10\tAverage Generator Loss: 1651.253625\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13725 (step 13725): 1.247781\n",
      "Batch #10\tAverage Generator Loss: 1802.737097\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13726 (step 13726): 1.794284\n",
      "Batch #10\tAverage Generator Loss: 1704.591849\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13727 (step 13727): 1.294695\n",
      "Batch #10\tAverage Generator Loss: 1865.767908\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13728 (step 13728): 1.314640\n",
      "Batch #10\tAverage Generator Loss: 1818.328674\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13729 (step 13729): 1.852280\n",
      "Batch #10\tAverage Generator Loss: 1546.173914\tAverage Discriminator Loss: 0.051719\n",
      "\n",
      "Train time for epoch #13730 (step 13730): 1.362795\n",
      "Batch #10\tAverage Generator Loss: 1840.879211\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13731 (step 13731): 1.303697\n",
      "Batch #10\tAverage Generator Loss: 1577.270802\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13732 (step 13732): 1.831759\n",
      "Batch #10\tAverage Generator Loss: 1842.059338\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13733 (step 13733): 1.474796\n",
      "Batch #10\tAverage Generator Loss: 1743.969507\tAverage Discriminator Loss: 0.000747\n",
      "\n",
      "Train time for epoch #13734 (step 13734): 1.283493\n",
      "Batch #10\tAverage Generator Loss: 1920.546558\tAverage Discriminator Loss: 0.000462\n",
      "\n",
      "Train time for epoch #13735 (step 13735): 1.726081\n",
      "Batch #10\tAverage Generator Loss: 1791.327863\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #13736 (step 13736): 1.413941\n",
      "Batch #10\tAverage Generator Loss: 1752.620801\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #13737 (step 13737): 1.292826\n",
      "Batch #10\tAverage Generator Loss: 1751.672438\tAverage Discriminator Loss: 0.000027\n",
      "\n",
      "Train time for epoch #13738 (step 13738): 1.793917\n",
      "Batch #10\tAverage Generator Loss: 1777.659784\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #13739 (step 13739): 1.387304\n",
      "Batch #10\tAverage Generator Loss: 1647.881732\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #13740 (step 13740): 1.402163\n",
      "Batch #10\tAverage Generator Loss: 1742.835144\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #13741 (step 13741): 1.796584\n",
      "Batch #10\tAverage Generator Loss: 1542.882532\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #13742 (step 13742): 1.410847\n",
      "Batch #10\tAverage Generator Loss: 1850.318982\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #13743 (step 13743): 1.350703\n",
      "Batch #10\tAverage Generator Loss: 2014.528809\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #13744 (step 13744): 1.903297\n",
      "Batch #10\tAverage Generator Loss: 1807.105420\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #13745 (step 13745): 1.338929\n",
      "Batch #10\tAverage Generator Loss: 1717.296118\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #13746 (step 13746): 1.344414\n",
      "Batch #10\tAverage Generator Loss: 1841.293738\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #13747 (step 13747): 1.711048\n",
      "Batch #10\tAverage Generator Loss: 1818.613525\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #13748 (step 13748): 1.372030\n",
      "Batch #10\tAverage Generator Loss: 1855.819275\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #13749 (step 13749): 1.375867\n",
      "Batch #10\tAverage Generator Loss: 1827.322754\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #13750 (step 13750): 1.670249\n",
      "Batch #10\tAverage Generator Loss: 1870.458954\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #13751 (step 13751): 1.287759\n",
      "Batch #10\tAverage Generator Loss: 1726.903845\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #13752 (step 13752): 1.334399\n",
      "Batch #10\tAverage Generator Loss: 1902.157935\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #13753 (step 13753): 1.770857\n",
      "Batch #10\tAverage Generator Loss: 1668.219910\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #13754 (step 13754): 1.351288\n",
      "Batch #10\tAverage Generator Loss: 1685.462842\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #13755 (step 13755): 1.336113\n",
      "Batch #10\tAverage Generator Loss: 1688.792187\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #13756 (step 13756): 1.890104\n",
      "Batch #10\tAverage Generator Loss: 1799.999854\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #13757 (step 13757): 1.292763\n",
      "Batch #10\tAverage Generator Loss: 1670.656018\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #13758 (step 13758): 1.290700\n",
      "Batch #10\tAverage Generator Loss: 1667.714850\tAverage Discriminator Loss: 0.000632\n",
      "\n",
      "Train time for epoch #13759 (step 13759): 1.823917\n",
      "Batch #10\tAverage Generator Loss: 2009.541418\tAverage Discriminator Loss: 0.000033\n",
      "\n",
      "Train time for epoch #13760 (step 13760): 1.398076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 1900.204480\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #13761 (step 13761): 1.341897\n",
      "Batch #10\tAverage Generator Loss: 1761.142957\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #13762 (step 13762): 1.844815\n",
      "Batch #10\tAverage Generator Loss: 1740.302368\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #13763 (step 13763): 1.349026\n",
      "Batch #10\tAverage Generator Loss: 1742.751569\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #13764 (step 13764): 1.297838\n",
      "Batch #10\tAverage Generator Loss: 1820.747998\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #13765 (step 13765): 1.918627\n",
      "Batch #10\tAverage Generator Loss: 1777.590857\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #13766 (step 13766): 1.294403\n",
      "Batch #10\tAverage Generator Loss: 1924.647998\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #13767 (step 13767): 1.247533\n",
      "Batch #10\tAverage Generator Loss: 1847.128381\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #13768 (step 13768): 1.866813\n",
      "Batch #10\tAverage Generator Loss: 1885.825714\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #13769 (step 13769): 1.374285\n",
      "Batch #10\tAverage Generator Loss: 1957.232507\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #13770 (step 13770): 1.299223\n",
      "Batch #10\tAverage Generator Loss: 1721.586096\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #13771 (step 13771): 1.714042\n",
      "Batch #10\tAverage Generator Loss: 1809.609949\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #13772 (step 13772): 1.294706\n",
      "Batch #10\tAverage Generator Loss: 1821.115454\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #13773 (step 13773): 1.808975\n",
      "Batch #10\tAverage Generator Loss: 1716.440491\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #13774 (step 13774): 1.310302\n",
      "Batch #10\tAverage Generator Loss: 1855.820374\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #13775 (step 13775): 1.278567\n",
      "Batch #10\tAverage Generator Loss: 1872.529089\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #13776 (step 13776): 1.896265\n",
      "Batch #10\tAverage Generator Loss: 1917.470850\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #13777 (step 13777): 1.411885\n",
      "Batch #10\tAverage Generator Loss: 1768.241701\tAverage Discriminator Loss: 0.088576\n",
      "\n",
      "Train time for epoch #13778 (step 13778): 1.553303\n",
      "Batch #10\tAverage Generator Loss: 2134.519983\tAverage Discriminator Loss: 0.011186\n",
      "\n",
      "Train time for epoch #13779 (step 13779): 1.758576\n",
      "Batch #10\tAverage Generator Loss: 1807.785327\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13780 (step 13780): 1.368540\n",
      "Batch #10\tAverage Generator Loss: 1721.725696\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13781 (step 13781): 1.288426\n",
      "Batch #10\tAverage Generator Loss: 1904.901282\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13782 (step 13782): 1.744057\n",
      "Batch #10\tAverage Generator Loss: 1848.173682\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13783 (step 13783): 1.394697\n",
      "Batch #10\tAverage Generator Loss: 1796.300403\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13784 (step 13784): 1.344574\n",
      "Batch #10\tAverage Generator Loss: 1846.385937\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13785 (step 13785): 1.774092\n",
      "Batch #10\tAverage Generator Loss: 1846.981616\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13786 (step 13786): 1.286156\n",
      "Batch #10\tAverage Generator Loss: 1876.075415\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13787 (step 13787): 1.287027\n",
      "Batch #10\tAverage Generator Loss: 1823.965918\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13788 (step 13788): 1.747898\n",
      "Batch #10\tAverage Generator Loss: 1877.088708\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13789 (step 13789): 1.329946\n",
      "Batch #10\tAverage Generator Loss: 1834.885437\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13790 (step 13790): 1.240156\n",
      "Batch #10\tAverage Generator Loss: 1915.317206\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13791 (step 13791): 1.734146\n",
      "Batch #10\tAverage Generator Loss: 1807.203918\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13792 (step 13792): 1.339247\n",
      "Batch #10\tAverage Generator Loss: 1748.001599\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13793 (step 13793): 1.350207\n",
      "Batch #10\tAverage Generator Loss: 1812.536255\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13794 (step 13794): 1.791071\n",
      "Batch #10\tAverage Generator Loss: 1861.117468\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13795 (step 13795): 1.380206\n",
      "Batch #10\tAverage Generator Loss: 1709.147534\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13796 (step 13796): 1.440836\n",
      "Batch #10\tAverage Generator Loss: 1772.789417\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13797 (step 13797): 1.749559\n",
      "Batch #10\tAverage Generator Loss: 1940.231580\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13798 (step 13798): 1.448665\n",
      "Batch #10\tAverage Generator Loss: 1567.782196\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13799 (step 13799): 1.336912\n",
      "Batch #10\tAverage Generator Loss: 1922.356763\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13800 (step 13800): 1.756431\n",
      "Batch #10\tAverage Generator Loss: 1669.597986\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13801 (step 13801): 1.289569\n",
      "Batch #10\tAverage Generator Loss: 1824.054486\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13802 (step 13802): 1.384805\n",
      "Batch #10\tAverage Generator Loss: 1966.493872\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13803 (step 13803): 1.754731\n",
      "Batch #10\tAverage Generator Loss: 1907.054175\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13804 (step 13804): 1.359726\n",
      "Batch #10\tAverage Generator Loss: 1853.917224\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13805 (step 13805): 1.335510\n",
      "Batch #10\tAverage Generator Loss: 1724.294299\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13806 (step 13806): 1.829911\n",
      "Batch #10\tAverage Generator Loss: 1834.833295\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13807 (step 13807): 1.335009\n",
      "Batch #10\tAverage Generator Loss: 1699.277869\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13808 (step 13808): 1.353479\n",
      "Batch #10\tAverage Generator Loss: 1660.447531\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13809 (step 13809): 1.756616\n",
      "Batch #10\tAverage Generator Loss: 1691.096838\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13810 (step 13810): 1.384558\n",
      "Batch #10\tAverage Generator Loss: 1870.468042\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13811 (step 13811): 1.276177\n",
      "Batch #10\tAverage Generator Loss: 1850.802478\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13812 (step 13812): 1.699520\n",
      "Batch #10\tAverage Generator Loss: 1736.385413\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13813 (step 13813): 1.340319\n",
      "Batch #10\tAverage Generator Loss: 1781.813623\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13814 (step 13814): 1.296385\n",
      "Batch #10\tAverage Generator Loss: 2015.713123\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13815 (step 13815): 1.772218\n",
      "Batch #10\tAverage Generator Loss: 1881.287732\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13816 (step 13816): 1.294044\n",
      "Batch #10\tAverage Generator Loss: 1745.258118\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13817 (step 13817): 1.797443\n",
      "Batch #10\tAverage Generator Loss: 1846.560791\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13818 (step 13818): 1.341318\n",
      "Batch #10\tAverage Generator Loss: 1665.709979\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13819 (step 13819): 1.341401\n",
      "Batch #10\tAverage Generator Loss: 1839.288794\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13820 (step 13820): 1.813881\n",
      "Batch #10\tAverage Generator Loss: 1959.109204\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13821 (step 13821): 1.345459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 1991.096521\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13822 (step 13822): 1.296795\n",
      "Batch #10\tAverage Generator Loss: 1926.788513\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13823 (step 13823): 1.826948\n",
      "Batch #10\tAverage Generator Loss: 2038.669714\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13824 (step 13824): 1.340054\n",
      "Batch #10\tAverage Generator Loss: 1737.942395\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13825 (step 13825): 1.327003\n",
      "Batch #10\tAverage Generator Loss: 1809.168726\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13826 (step 13826): 1.772460\n",
      "Batch #10\tAverage Generator Loss: 1880.757776\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13827 (step 13827): 1.411196\n",
      "Batch #10\tAverage Generator Loss: 1916.263806\tAverage Discriminator Loss: 0.000371\n",
      "\n",
      "Train time for epoch #13828 (step 13828): 1.350739\n",
      "Batch #10\tAverage Generator Loss: 1808.955334\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13829 (step 13829): 1.888289\n",
      "Batch #10\tAverage Generator Loss: 1836.656183\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13830 (step 13830): 1.294228\n",
      "Batch #10\tAverage Generator Loss: 1669.909363\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13831 (step 13831): 1.239216\n",
      "Batch #10\tAverage Generator Loss: 1978.674048\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13832 (step 13832): 1.738479\n",
      "Batch #10\tAverage Generator Loss: 1810.013177\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13833 (step 13833): 1.287679\n",
      "Batch #10\tAverage Generator Loss: 1950.390393\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13834 (step 13834): 1.337361\n",
      "Batch #10\tAverage Generator Loss: 2008.423828\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13835 (step 13835): 1.894442\n",
      "Batch #10\tAverage Generator Loss: 1459.186255\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13836 (step 13836): 1.370228\n",
      "Batch #10\tAverage Generator Loss: 1931.884497\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13837 (step 13837): 1.397485\n",
      "Batch #10\tAverage Generator Loss: 2151.581665\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13838 (step 13838): 1.933582\n",
      "Batch #10\tAverage Generator Loss: 1750.352484\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13839 (step 13839): 1.270660\n",
      "Batch #10\tAverage Generator Loss: 1823.719568\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13840 (step 13840): 1.408787\n",
      "Batch #10\tAverage Generator Loss: 1492.777167\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13841 (step 13841): 1.830614\n",
      "Batch #10\tAverage Generator Loss: 1773.670337\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13842 (step 13842): 1.302854\n",
      "Batch #10\tAverage Generator Loss: 1856.621777\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13843 (step 13843): 1.374906\n",
      "Batch #10\tAverage Generator Loss: 1851.305078\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13844 (step 13844): 1.923478\n",
      "Batch #10\tAverage Generator Loss: 1876.849097\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13845 (step 13845): 1.297867\n",
      "Batch #10\tAverage Generator Loss: 1559.373132\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13846 (step 13846): 1.384394\n",
      "Batch #10\tAverage Generator Loss: 1786.286597\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13847 (step 13847): 1.765321\n",
      "Batch #10\tAverage Generator Loss: 1777.096881\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13848 (step 13848): 1.335805\n",
      "Batch #10\tAverage Generator Loss: 1763.274878\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13849 (step 13849): 1.300424\n",
      "Batch #10\tAverage Generator Loss: 1895.032220\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13850 (step 13850): 1.773884\n",
      "Batch #10\tAverage Generator Loss: 1686.169849\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13851 (step 13851): 1.418422\n",
      "Batch #10\tAverage Generator Loss: 1843.717908\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13852 (step 13852): 1.365432\n",
      "Batch #10\tAverage Generator Loss: 1769.051788\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13853 (step 13853): 1.910117\n",
      "Batch #10\tAverage Generator Loss: 1706.689307\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13854 (step 13854): 1.388332\n",
      "Batch #10\tAverage Generator Loss: 1890.542053\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13855 (step 13855): 1.294668\n",
      "Batch #10\tAverage Generator Loss: 1924.019946\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13856 (step 13856): 1.717911\n",
      "Batch #10\tAverage Generator Loss: 1921.220215\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13857 (step 13857): 1.351220\n",
      "Batch #10\tAverage Generator Loss: 1731.978967\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13858 (step 13858): 1.511904\n",
      "Batch #10\tAverage Generator Loss: 1729.868491\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13859 (step 13859): 1.817274\n",
      "Batch #10\tAverage Generator Loss: 1890.395264\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13860 (step 13860): 1.259868\n",
      "Batch #10\tAverage Generator Loss: 1991.012183\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13861 (step 13861): 1.292049\n",
      "Batch #10\tAverage Generator Loss: 1781.539978\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13862 (step 13862): 1.725081\n",
      "Batch #10\tAverage Generator Loss: 1783.367822\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13863 (step 13863): 1.380696\n",
      "Batch #10\tAverage Generator Loss: 1850.844470\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13864 (step 13864): 1.302895\n",
      "Batch #10\tAverage Generator Loss: 1723.792542\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13865 (step 13865): 1.782010\n",
      "Batch #10\tAverage Generator Loss: 1583.057605\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13866 (step 13866): 1.297902\n",
      "Batch #10\tAverage Generator Loss: 1922.962976\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13867 (step 13867): 1.290958\n",
      "Batch #10\tAverage Generator Loss: 1706.626996\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13868 (step 13868): 1.788022\n",
      "Batch #10\tAverage Generator Loss: 1660.025500\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13869 (step 13869): 1.387557\n",
      "Batch #10\tAverage Generator Loss: 1876.640881\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13870 (step 13870): 1.324327\n",
      "Batch #10\tAverage Generator Loss: 1642.178735\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13871 (step 13871): 1.743896\n",
      "Batch #10\tAverage Generator Loss: 1736.646710\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13872 (step 13872): 1.395788\n",
      "Batch #10\tAverage Generator Loss: 1651.700079\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13873 (step 13873): 1.352791\n",
      "Batch #10\tAverage Generator Loss: 1934.044568\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13874 (step 13874): 1.761635\n",
      "Batch #10\tAverage Generator Loss: 2002.885291\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #13875 (step 13875): 1.338702\n",
      "Batch #10\tAverage Generator Loss: 1950.941760\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13876 (step 13876): 1.421890\n",
      "Batch #10\tAverage Generator Loss: 2022.347119\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13877 (step 13877): 1.854190\n",
      "Batch #10\tAverage Generator Loss: 1788.433539\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13878 (step 13878): 1.338298\n",
      "Batch #10\tAverage Generator Loss: 1879.477014\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13879 (step 13879): 1.342716\n",
      "Batch #10\tAverage Generator Loss: 1899.703064\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13880 (step 13880): 1.806332\n",
      "Batch #10\tAverage Generator Loss: 1844.668420\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13881 (step 13881): 1.316630\n",
      "Batch #10\tAverage Generator Loss: 1826.031812\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13882 (step 13882): 1.283189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 1888.166760\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13883 (step 13883): 1.785590\n",
      "Batch #10\tAverage Generator Loss: 1725.692065\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13884 (step 13884): 1.262657\n",
      "Batch #10\tAverage Generator Loss: 1841.894788\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13885 (step 13885): 1.306640\n",
      "Batch #10\tAverage Generator Loss: 1726.885187\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13886 (step 13886): 1.805997\n",
      "Batch #10\tAverage Generator Loss: 1813.912854\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13887 (step 13887): 1.345879\n",
      "Batch #10\tAverage Generator Loss: 1678.691058\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13888 (step 13888): 1.291188\n",
      "Batch #10\tAverage Generator Loss: 1849.581506\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13889 (step 13889): 1.804334\n",
      "Batch #10\tAverage Generator Loss: 1794.056207\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13890 (step 13890): 1.367642\n",
      "Batch #10\tAverage Generator Loss: 1896.430518\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13891 (step 13891): 1.324627\n",
      "Batch #10\tAverage Generator Loss: 1766.581714\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13892 (step 13892): 1.768799\n",
      "Batch #10\tAverage Generator Loss: 1665.371582\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13893 (step 13893): 1.336406\n",
      "Batch #10\tAverage Generator Loss: 2064.196185\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13894 (step 13894): 1.335897\n",
      "Batch #10\tAverage Generator Loss: 1910.089697\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13895 (step 13895): 1.813528\n",
      "Batch #10\tAverage Generator Loss: 1835.353223\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13896 (step 13896): 1.286427\n",
      "Batch #10\tAverage Generator Loss: 1905.013940\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13897 (step 13897): 1.333412\n",
      "Batch #10\tAverage Generator Loss: 1861.663947\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13898 (step 13898): 1.824435\n",
      "Batch #10\tAverage Generator Loss: 2049.047308\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13899 (step 13899): 1.413221\n",
      "Batch #10\tAverage Generator Loss: 1559.255017\tAverage Discriminator Loss: 0.046770\n",
      "\n",
      "Train time for epoch #13900 (step 13900): 1.383303\n",
      "Batch #10\tAverage Generator Loss: 1723.689166\tAverage Discriminator Loss: 0.001888\n",
      "\n",
      "Train time for epoch #13901 (step 13901): 1.880378\n",
      "Batch #10\tAverage Generator Loss: 1595.810706\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13902 (step 13902): 1.448192\n",
      "Batch #10\tAverage Generator Loss: 1864.539893\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13903 (step 13903): 1.342926\n",
      "Batch #10\tAverage Generator Loss: 1989.224268\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13904 (step 13904): 1.783157\n",
      "Batch #10\tAverage Generator Loss: 1790.592365\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13905 (step 13905): 1.278871\n",
      "Batch #10\tAverage Generator Loss: 1589.993219\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13906 (step 13906): 1.359609\n",
      "Batch #10\tAverage Generator Loss: 1726.157861\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13907 (step 13907): 1.724930\n",
      "Batch #10\tAverage Generator Loss: 1944.890982\tAverage Discriminator Loss: 0.500260\n",
      "\n",
      "Train time for epoch #13908 (step 13908): 1.334547\n",
      "Batch #10\tAverage Generator Loss: 2289.812872\tAverage Discriminator Loss: 0.101002\n",
      "\n",
      "Train time for epoch #13909 (step 13909): 1.325370\n",
      "Batch #10\tAverage Generator Loss: 2299.493140\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13910 (step 13910): 1.770754\n",
      "Batch #10\tAverage Generator Loss: 2367.383679\tAverage Discriminator Loss: 0.010677\n",
      "\n",
      "Train time for epoch #13911 (step 13911): 1.394982\n",
      "Batch #10\tAverage Generator Loss: 2405.832996\tAverage Discriminator Loss: 0.012655\n",
      "\n",
      "Train time for epoch #13912 (step 13912): 1.290334\n",
      "Batch #10\tAverage Generator Loss: 1879.907916\tAverage Discriminator Loss: 0.067427\n",
      "\n",
      "Train time for epoch #13913 (step 13913): 1.774695\n",
      "Batch #10\tAverage Generator Loss: 2316.630347\tAverage Discriminator Loss: 0.011315\n",
      "\n",
      "Train time for epoch #13914 (step 13914): 1.328428\n",
      "Batch #10\tAverage Generator Loss: 2502.213953\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13915 (step 13915): 1.301472\n",
      "Batch #10\tAverage Generator Loss: 2445.696045\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13916 (step 13916): 1.763237\n",
      "Batch #10\tAverage Generator Loss: 2214.953748\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13917 (step 13917): 1.283962\n",
      "Batch #10\tAverage Generator Loss: 2646.425037\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13918 (step 13918): 1.297519\n",
      "Batch #10\tAverage Generator Loss: 2252.152600\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13919 (step 13919): 1.808967\n",
      "Batch #10\tAverage Generator Loss: 2223.335168\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13920 (step 13920): 1.386942\n",
      "Batch #10\tAverage Generator Loss: 2483.806323\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13921 (step 13921): 1.345030\n",
      "Batch #10\tAverage Generator Loss: 2437.773047\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13922 (step 13922): 1.775573\n",
      "Batch #10\tAverage Generator Loss: 2373.826245\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13923 (step 13923): 1.387022\n",
      "Batch #10\tAverage Generator Loss: 2407.762109\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13924 (step 13924): 1.242844\n",
      "Batch #10\tAverage Generator Loss: 2588.715527\tAverage Discriminator Loss: 0.142619\n",
      "\n",
      "Train time for epoch #13925 (step 13925): 1.758994\n",
      "Batch #10\tAverage Generator Loss: 2197.354724\tAverage Discriminator Loss: 0.000312\n",
      "\n",
      "Train time for epoch #13926 (step 13926): 1.494326\n",
      "Batch #10\tAverage Generator Loss: 2180.233154\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13927 (step 13927): 1.368634\n",
      "Batch #10\tAverage Generator Loss: 2151.806601\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13928 (step 13928): 1.725696\n",
      "Batch #10\tAverage Generator Loss: 2241.836768\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13929 (step 13929): 1.348504\n",
      "Batch #10\tAverage Generator Loss: 2156.182715\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13930 (step 13930): 1.298268\n",
      "Batch #10\tAverage Generator Loss: 2006.618665\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13931 (step 13931): 1.808476\n",
      "Batch #10\tAverage Generator Loss: 2002.913062\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13932 (step 13932): 1.241085\n",
      "Batch #10\tAverage Generator Loss: 2037.246759\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13933 (step 13933): 1.338099\n",
      "Batch #10\tAverage Generator Loss: 1923.566498\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13934 (step 13934): 1.897977\n",
      "Batch #10\tAverage Generator Loss: 2123.406555\tAverage Discriminator Loss: 0.085256\n",
      "\n",
      "Train time for epoch #13935 (step 13935): 1.324462\n",
      "Batch #10\tAverage Generator Loss: 1844.292590\tAverage Discriminator Loss: 0.000060\n",
      "\n",
      "Train time for epoch #13936 (step 13936): 1.773181\n",
      "Batch #10\tAverage Generator Loss: 1733.544104\tAverage Discriminator Loss: 0.000115\n",
      "\n",
      "Train time for epoch #13937 (step 13937): 1.299665\n",
      "Batch #10\tAverage Generator Loss: 1597.854291\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #13938 (step 13938): 1.383610\n",
      "Batch #10\tAverage Generator Loss: 1877.056763\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #13939 (step 13939): 1.727371\n",
      "Batch #10\tAverage Generator Loss: 1774.949207\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #13940 (step 13940): 1.406732\n",
      "Batch #10\tAverage Generator Loss: 1650.040015\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #13941 (step 13941): 1.410450\n",
      "Batch #10\tAverage Generator Loss: 1851.551575\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #13942 (step 13942): 1.771883\n",
      "Batch #10\tAverage Generator Loss: 1611.401422\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #13943 (step 13943): 1.371964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 1753.178369\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #13944 (step 13944): 1.239164\n",
      "Batch #10\tAverage Generator Loss: 1503.779022\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #13945 (step 13945): 1.835461\n",
      "Batch #10\tAverage Generator Loss: 1700.091321\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #13946 (step 13946): 1.396762\n",
      "Batch #10\tAverage Generator Loss: 1736.849438\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #13947 (step 13947): 1.304399\n",
      "Batch #10\tAverage Generator Loss: 1837.803064\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #13948 (step 13948): 1.794362\n",
      "Batch #10\tAverage Generator Loss: 1682.105542\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #13949 (step 13949): 1.289175\n",
      "Batch #10\tAverage Generator Loss: 1842.464917\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #13950 (step 13950): 1.349252\n",
      "Batch #10\tAverage Generator Loss: 1691.465503\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #13951 (step 13951): 1.745473\n",
      "Batch #10\tAverage Generator Loss: 1962.640002\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #13952 (step 13952): 1.416412\n",
      "Batch #10\tAverage Generator Loss: 1779.669812\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #13953 (step 13953): 1.343540\n",
      "Batch #10\tAverage Generator Loss: 1637.600488\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #13954 (step 13954): 1.817167\n",
      "Batch #10\tAverage Generator Loss: 1899.699048\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #13955 (step 13955): 1.342200\n",
      "Batch #10\tAverage Generator Loss: 1541.847034\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #13956 (step 13956): 1.337744\n",
      "Batch #10\tAverage Generator Loss: 1618.910211\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #13957 (step 13957): 1.868320\n",
      "Batch #10\tAverage Generator Loss: 1631.534064\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #13958 (step 13958): 1.309615\n",
      "Batch #10\tAverage Generator Loss: 1549.461823\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #13959 (step 13959): 1.342011\n",
      "Batch #10\tAverage Generator Loss: 1562.455426\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #13960 (step 13960): 1.753124\n",
      "Batch #10\tAverage Generator Loss: 1616.186902\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #13961 (step 13961): 1.336607\n",
      "Batch #10\tAverage Generator Loss: 1661.317542\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #13962 (step 13962): 1.444220\n",
      "Batch #10\tAverage Generator Loss: 1525.280853\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #13963 (step 13963): 1.776269\n",
      "Batch #10\tAverage Generator Loss: 1975.011493\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #13964 (step 13964): 1.304949\n",
      "Batch #10\tAverage Generator Loss: 1636.377075\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #13965 (step 13965): 1.303614\n",
      "Batch #10\tAverage Generator Loss: 1619.203003\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #13966 (step 13966): 1.917619\n",
      "Batch #10\tAverage Generator Loss: 1605.582867\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #13967 (step 13967): 1.298964\n",
      "Batch #10\tAverage Generator Loss: 1726.182361\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #13968 (step 13968): 1.307554\n",
      "Batch #10\tAverage Generator Loss: 1729.668237\tAverage Discriminator Loss: 0.001144\n",
      "\n",
      "Train time for epoch #13969 (step 13969): 1.757223\n",
      "Batch #10\tAverage Generator Loss: 1794.672412\tAverage Discriminator Loss: 0.012712\n",
      "\n",
      "Train time for epoch #13970 (step 13970): 1.330507\n",
      "Batch #10\tAverage Generator Loss: 1819.264722\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #13971 (step 13971): 1.363084\n",
      "Batch #10\tAverage Generator Loss: 1793.689063\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #13972 (step 13972): 1.875231\n",
      "Batch #10\tAverage Generator Loss: 1760.121448\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #13973 (step 13973): 1.341472\n",
      "Batch #10\tAverage Generator Loss: 1717.595056\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #13974 (step 13974): 1.346833\n",
      "Batch #10\tAverage Generator Loss: 2056.543359\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #13975 (step 13975): 1.696695\n",
      "Batch #10\tAverage Generator Loss: 2160.145654\tAverage Discriminator Loss: 0.000209\n",
      "\n",
      "Train time for epoch #13976 (step 13976): 1.339879\n",
      "Batch #10\tAverage Generator Loss: 1733.356360\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #13977 (step 13977): 1.310588\n",
      "Batch #10\tAverage Generator Loss: 1872.034192\tAverage Discriminator Loss: 0.000031\n",
      "\n",
      "Train time for epoch #13978 (step 13978): 1.729053\n",
      "Batch #10\tAverage Generator Loss: 1835.303961\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #13979 (step 13979): 1.337247\n",
      "Batch #10\tAverage Generator Loss: 1785.377425\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #13980 (step 13980): 1.340424\n",
      "Batch #10\tAverage Generator Loss: 1654.469556\tAverage Discriminator Loss: 0.075972\n",
      "\n",
      "Train time for epoch #13981 (step 13981): 1.896220\n",
      "Batch #10\tAverage Generator Loss: 1822.838660\tAverage Discriminator Loss: 0.020351\n",
      "\n",
      "Train time for epoch #13982 (step 13982): 1.284209\n",
      "Batch #10\tAverage Generator Loss: 1918.412732\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13983 (step 13983): 1.337017\n",
      "Batch #10\tAverage Generator Loss: 2067.431152\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13984 (step 13984): 1.744621\n",
      "Batch #10\tAverage Generator Loss: 2040.102942\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13985 (step 13985): 1.455317\n",
      "Batch #10\tAverage Generator Loss: 2260.665015\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13986 (step 13986): 1.245189\n",
      "Batch #10\tAverage Generator Loss: 2187.594189\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13987 (step 13987): 1.765495\n",
      "Batch #10\tAverage Generator Loss: 2109.368579\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13988 (step 13988): 1.381329\n",
      "Batch #10\tAverage Generator Loss: 2154.681567\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13989 (step 13989): 1.384254\n",
      "Batch #10\tAverage Generator Loss: 2005.866968\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #13990 (step 13990): 1.896195\n",
      "Batch #10\tAverage Generator Loss: 2241.861731\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13991 (step 13991): 1.283354\n",
      "Batch #10\tAverage Generator Loss: 2043.453320\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13992 (step 13992): 1.334920\n",
      "Batch #10\tAverage Generator Loss: 2183.661377\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13993 (step 13993): 1.794315\n",
      "Batch #10\tAverage Generator Loss: 2263.001758\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13994 (step 13994): 1.293672\n",
      "Batch #10\tAverage Generator Loss: 2227.461157\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13995 (step 13995): 1.292438\n",
      "Batch #10\tAverage Generator Loss: 2322.926691\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13996 (step 13996): 2.016457\n",
      "Batch #10\tAverage Generator Loss: 2042.636334\tAverage Discriminator Loss: 0.265645\n",
      "\n",
      "Train time for epoch #13997 (step 13997): 1.285302\n",
      "Batch #10\tAverage Generator Loss: 2110.228394\tAverage Discriminator Loss: 0.004026\n",
      "\n",
      "Train time for epoch #13998 (step 13998): 1.290876\n",
      "Batch #10\tAverage Generator Loss: 2180.590015\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #13999 (step 13999): 1.836481\n",
      "Batch #10\tAverage Generator Loss: 1871.208765\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14000 (step 14000): 1.287701\n",
      "Batch #10\tAverage Generator Loss: 2176.149329\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14001 (step 14001): 1.333906\n",
      "Batch #10\tAverage Generator Loss: 1909.039563\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14002 (step 14002): 1.969477\n",
      "Batch #10\tAverage Generator Loss: 2036.986194\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14003 (step 14003): 1.536268\n",
      "Batch #10\tAverage Generator Loss: 2184.150830\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14004 (step 14004): 1.323193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2063.597278\tAverage Discriminator Loss: 0.012009\n",
      "\n",
      "Train time for epoch #14005 (step 14005): 1.826400\n",
      "Batch #10\tAverage Generator Loss: 2341.350452\tAverage Discriminator Loss: 0.007893\n",
      "\n",
      "Train time for epoch #14006 (step 14006): 1.300672\n",
      "Batch #10\tAverage Generator Loss: 1916.976263\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14007 (step 14007): 1.290878\n",
      "Batch #10\tAverage Generator Loss: 1779.213898\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14008 (step 14008): 1.784320\n",
      "Batch #10\tAverage Generator Loss: 2238.334265\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14009 (step 14009): 1.398651\n",
      "Batch #10\tAverage Generator Loss: 1997.036572\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14010 (step 14010): 1.300603\n",
      "Batch #10\tAverage Generator Loss: 1936.706494\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14011 (step 14011): 1.748134\n",
      "Batch #10\tAverage Generator Loss: 2108.447461\tAverage Discriminator Loss: 0.000135\n",
      "\n",
      "Train time for epoch #14012 (step 14012): 1.302966\n",
      "Batch #10\tAverage Generator Loss: 1733.677930\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14013 (step 14013): 1.358904\n",
      "Batch #10\tAverage Generator Loss: 2043.180212\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14014 (step 14014): 1.847837\n",
      "Batch #10\tAverage Generator Loss: 2056.489819\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14015 (step 14015): 1.389569\n",
      "Batch #10\tAverage Generator Loss: 2084.063788\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14016 (step 14016): 1.286708\n",
      "Batch #10\tAverage Generator Loss: 1775.952856\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14017 (step 14017): 1.735342\n",
      "Batch #10\tAverage Generator Loss: 1926.494849\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14018 (step 14018): 1.339467\n",
      "Batch #10\tAverage Generator Loss: 2106.798413\tAverage Discriminator Loss: 0.007225\n",
      "\n",
      "Train time for epoch #14019 (step 14019): 1.359293\n",
      "Batch #10\tAverage Generator Loss: 2096.611584\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14020 (step 14020): 1.782596\n",
      "Batch #10\tAverage Generator Loss: 2038.381421\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14021 (step 14021): 1.493674\n",
      "Batch #10\tAverage Generator Loss: 2141.869470\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14022 (step 14022): 1.286565\n",
      "Batch #10\tAverage Generator Loss: 1834.051544\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14023 (step 14023): 1.778026\n",
      "Batch #10\tAverage Generator Loss: 2131.018347\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14024 (step 14024): 1.300047\n",
      "Batch #10\tAverage Generator Loss: 1956.887704\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14025 (step 14025): 1.398143\n",
      "Batch #10\tAverage Generator Loss: 2133.883630\tAverage Discriminator Loss: 0.000314\n",
      "\n",
      "Train time for epoch #14026 (step 14026): 1.676030\n",
      "Batch #10\tAverage Generator Loss: 1746.641333\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14027 (step 14027): 1.394277\n",
      "Batch #10\tAverage Generator Loss: 1897.390033\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14028 (step 14028): 1.319577\n",
      "Batch #10\tAverage Generator Loss: 2165.824451\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14029 (step 14029): 1.862207\n",
      "Batch #10\tAverage Generator Loss: 2275.670178\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14030 (step 14030): 1.442533\n",
      "Batch #10\tAverage Generator Loss: 2065.671082\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14031 (step 14031): 1.299143\n",
      "Batch #10\tAverage Generator Loss: 1902.304260\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14032 (step 14032): 1.805016\n",
      "Batch #10\tAverage Generator Loss: 2230.498816\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14033 (step 14033): 1.329527\n",
      "Batch #10\tAverage Generator Loss: 1935.259204\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14034 (step 14034): 1.343132\n",
      "Batch #10\tAverage Generator Loss: 2090.059937\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14035 (step 14035): 1.770707\n",
      "Batch #10\tAverage Generator Loss: 1968.422229\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14036 (step 14036): 1.423649\n",
      "Batch #10\tAverage Generator Loss: 1922.401074\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14037 (step 14037): 1.296375\n",
      "Batch #10\tAverage Generator Loss: 1970.937653\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14038 (step 14038): 1.821740\n",
      "Batch #10\tAverage Generator Loss: 1930.993982\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14039 (step 14039): 1.454950\n",
      "Batch #10\tAverage Generator Loss: 2132.576086\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14040 (step 14040): 1.283710\n",
      "Batch #10\tAverage Generator Loss: 2115.898230\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14041 (step 14041): 1.799971\n",
      "Batch #10\tAverage Generator Loss: 2113.902698\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14042 (step 14042): 1.293038\n",
      "Batch #10\tAverage Generator Loss: 2115.616760\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14043 (step 14043): 1.283158\n",
      "Batch #10\tAverage Generator Loss: 1894.383966\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14044 (step 14044): 1.953941\n",
      "Batch #10\tAverage Generator Loss: 2029.302136\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14045 (step 14045): 1.358564\n",
      "Batch #10\tAverage Generator Loss: 1978.781055\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14046 (step 14046): 1.287457\n",
      "Batch #10\tAverage Generator Loss: 2141.604626\tAverage Discriminator Loss: 0.001661\n",
      "\n",
      "Train time for epoch #14047 (step 14047): 1.815151\n",
      "Batch #10\tAverage Generator Loss: 2170.897815\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14048 (step 14048): 1.409440\n",
      "Batch #10\tAverage Generator Loss: 2036.183813\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14049 (step 14049): 1.454192\n",
      "Batch #10\tAverage Generator Loss: 1951.547504\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14050 (step 14050): 1.824667\n",
      "Batch #10\tAverage Generator Loss: 1956.980774\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14051 (step 14051): 1.322612\n",
      "Batch #10\tAverage Generator Loss: 1929.158008\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14052 (step 14052): 1.276686\n",
      "Batch #10\tAverage Generator Loss: 2157.656726\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14053 (step 14053): 1.742326\n",
      "Batch #10\tAverage Generator Loss: 1782.942651\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14054 (step 14054): 1.377761\n",
      "Batch #10\tAverage Generator Loss: 2177.946240\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14055 (step 14055): 1.380176\n",
      "Batch #10\tAverage Generator Loss: 1981.556500\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14056 (step 14056): 1.877693\n",
      "Batch #10\tAverage Generator Loss: 2623.668457\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14057 (step 14057): 1.341376\n",
      "Batch #10\tAverage Generator Loss: 2046.205573\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14058 (step 14058): 1.383771\n",
      "Batch #10\tAverage Generator Loss: 2012.137665\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14059 (step 14059): 1.741792\n",
      "Batch #10\tAverage Generator Loss: 1919.845105\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14060 (step 14060): 1.382564\n",
      "Batch #10\tAverage Generator Loss: 2302.271069\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14061 (step 14061): 1.299136\n",
      "Batch #10\tAverage Generator Loss: 2183.421960\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14062 (step 14062): 1.815886\n",
      "Batch #10\tAverage Generator Loss: 2117.701086\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14063 (step 14063): 1.368302\n",
      "Batch #10\tAverage Generator Loss: 2343.270105\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14064 (step 14064): 1.471924\n",
      "Batch #10\tAverage Generator Loss: 2001.126111\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14065 (step 14065): 1.834757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2128.918030\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14066 (step 14066): 1.277970\n",
      "Batch #10\tAverage Generator Loss: 2115.237012\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14067 (step 14067): 1.291980\n",
      "Batch #10\tAverage Generator Loss: 1872.403705\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14068 (step 14068): 1.803462\n",
      "Batch #10\tAverage Generator Loss: 2314.718567\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14069 (step 14069): 1.444571\n",
      "Batch #10\tAverage Generator Loss: 1989.734363\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14070 (step 14070): 1.278711\n",
      "Batch #10\tAverage Generator Loss: 2357.938892\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14071 (step 14071): 1.850258\n",
      "Batch #10\tAverage Generator Loss: 2219.549194\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14072 (step 14072): 1.379013\n",
      "Batch #10\tAverage Generator Loss: 2021.897742\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14073 (step 14073): 1.390718\n",
      "Batch #10\tAverage Generator Loss: 2252.286316\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14074 (step 14074): 1.809078\n",
      "Batch #10\tAverage Generator Loss: 2117.413196\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14075 (step 14075): 1.491178\n",
      "Batch #10\tAverage Generator Loss: 2094.292078\tAverage Discriminator Loss: 0.000040\n",
      "\n",
      "Train time for epoch #14076 (step 14076): 1.345494\n",
      "Batch #10\tAverage Generator Loss: 2302.472571\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14077 (step 14077): 1.919554\n",
      "Batch #10\tAverage Generator Loss: 2365.952637\tAverage Discriminator Loss: 0.000218\n",
      "\n",
      "Train time for epoch #14078 (step 14078): 1.371515\n",
      "Batch #10\tAverage Generator Loss: 2260.764319\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14079 (step 14079): 1.449389\n",
      "Batch #10\tAverage Generator Loss: 2521.703833\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14080 (step 14080): 1.821185\n",
      "Batch #10\tAverage Generator Loss: 2128.515308\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14081 (step 14081): 1.246034\n",
      "Batch #10\tAverage Generator Loss: 2270.637677\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14082 (step 14082): 1.301379\n",
      "Batch #10\tAverage Generator Loss: 2166.964880\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14083 (step 14083): 1.785427\n",
      "Batch #10\tAverage Generator Loss: 2373.171948\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14084 (step 14084): 1.346255\n",
      "Batch #10\tAverage Generator Loss: 2245.277258\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14085 (step 14085): 1.384294\n",
      "Batch #10\tAverage Generator Loss: 2245.175537\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14086 (step 14086): 1.826688\n",
      "Batch #10\tAverage Generator Loss: 2156.809802\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14087 (step 14087): 1.291935\n",
      "Batch #10\tAverage Generator Loss: 2059.375293\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14088 (step 14088): 1.392127\n",
      "Batch #10\tAverage Generator Loss: 2371.049768\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14089 (step 14089): 1.930457\n",
      "Batch #10\tAverage Generator Loss: 2388.046606\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14090 (step 14090): 1.305634\n",
      "Batch #10\tAverage Generator Loss: 2432.118469\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14091 (step 14091): 1.286052\n",
      "Batch #10\tAverage Generator Loss: 2052.765607\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14092 (step 14092): 1.800232\n",
      "Batch #10\tAverage Generator Loss: 2225.346631\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14093 (step 14093): 1.295099\n",
      "Batch #10\tAverage Generator Loss: 2307.240332\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14094 (step 14094): 1.330918\n",
      "Batch #10\tAverage Generator Loss: 2054.218713\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14095 (step 14095): 1.834471\n",
      "Batch #10\tAverage Generator Loss: 2220.748828\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14096 (step 14096): 1.437734\n",
      "Batch #10\tAverage Generator Loss: 2116.145898\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14097 (step 14097): 1.291025\n",
      "Batch #10\tAverage Generator Loss: 1956.903873\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #14098 (step 14098): 1.820441\n",
      "Batch #10\tAverage Generator Loss: 2119.574316\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14099 (step 14099): 1.386653\n",
      "Batch #10\tAverage Generator Loss: 2281.716919\tAverage Discriminator Loss: 0.000335\n",
      "\n",
      "Train time for epoch #14100 (step 14100): 1.278600\n",
      "Batch #10\tAverage Generator Loss: 2428.805432\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14101 (step 14101): 1.937994\n",
      "Batch #10\tAverage Generator Loss: 1997.127539\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14102 (step 14102): 1.358886\n",
      "Batch #10\tAverage Generator Loss: 2364.328491\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14103 (step 14103): 1.342188\n",
      "Batch #10\tAverage Generator Loss: 2453.367676\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14104 (step 14104): 1.667340\n",
      "Batch #10\tAverage Generator Loss: 2176.176245\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14105 (step 14105): 1.333658\n",
      "Batch #10\tAverage Generator Loss: 2291.552161\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14106 (step 14106): 1.359437\n",
      "Batch #10\tAverage Generator Loss: 2017.305865\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14107 (step 14107): 1.777479\n",
      "Batch #10\tAverage Generator Loss: 2509.814697\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14108 (step 14108): 1.251870\n",
      "Batch #10\tAverage Generator Loss: 2459.116675\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14109 (step 14109): 1.309309\n",
      "Batch #10\tAverage Generator Loss: 2419.100525\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14110 (step 14110): 1.845957\n",
      "Batch #10\tAverage Generator Loss: 2196.749475\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14111 (step 14111): 1.346081\n",
      "Batch #10\tAverage Generator Loss: 2143.776416\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14112 (step 14112): 1.326685\n",
      "Batch #10\tAverage Generator Loss: 2147.760840\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14113 (step 14113): 1.768966\n",
      "Batch #10\tAverage Generator Loss: 2341.092871\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14114 (step 14114): 1.540972\n",
      "Batch #10\tAverage Generator Loss: 2473.878308\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14115 (step 14115): 1.335356\n",
      "Batch #10\tAverage Generator Loss: 2429.042383\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14116 (step 14116): 1.829081\n",
      "Batch #10\tAverage Generator Loss: 2236.015369\tAverage Discriminator Loss: 0.011046\n",
      "\n",
      "Train time for epoch #14117 (step 14117): 1.344177\n",
      "Batch #10\tAverage Generator Loss: 2233.381384\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14118 (step 14118): 1.294921\n",
      "Batch #10\tAverage Generator Loss: 2452.296814\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14119 (step 14119): 1.818312\n",
      "Batch #10\tAverage Generator Loss: 2420.897937\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14120 (step 14120): 1.311603\n",
      "Batch #10\tAverage Generator Loss: 2227.889429\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14121 (step 14121): 1.888967\n",
      "Batch #10\tAverage Generator Loss: 2079.357385\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14122 (step 14122): 1.383194\n",
      "Batch #10\tAverage Generator Loss: 2192.760693\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14123 (step 14123): 1.255520\n",
      "Batch #10\tAverage Generator Loss: 2330.049597\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14124 (step 14124): 1.818003\n",
      "Batch #10\tAverage Generator Loss: 2152.109204\tAverage Discriminator Loss: 0.311886\n",
      "\n",
      "Train time for epoch #14125 (step 14125): 1.339783\n",
      "Batch #10\tAverage Generator Loss: 2187.879584\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14126 (step 14126): 1.291575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2221.242896\tAverage Discriminator Loss: 0.002179\n",
      "\n",
      "Train time for epoch #14127 (step 14127): 1.848231\n",
      "Batch #10\tAverage Generator Loss: 2171.025415\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14128 (step 14128): 1.241488\n",
      "Batch #10\tAverage Generator Loss: 2125.165295\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14129 (step 14129): 1.385888\n",
      "Batch #10\tAverage Generator Loss: 2379.557043\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14130 (step 14130): 1.767601\n",
      "Batch #10\tAverage Generator Loss: 2268.674634\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14131 (step 14131): 1.333684\n",
      "Batch #10\tAverage Generator Loss: 2003.242493\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14132 (step 14132): 1.388456\n",
      "Batch #10\tAverage Generator Loss: 2112.178967\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14133 (step 14133): 1.735648\n",
      "Batch #10\tAverage Generator Loss: 2357.332507\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14134 (step 14134): 1.331301\n",
      "Batch #10\tAverage Generator Loss: 2335.229272\tAverage Discriminator Loss: 0.060693\n",
      "\n",
      "Train time for epoch #14135 (step 14135): 1.335697\n",
      "Batch #10\tAverage Generator Loss: 2447.083203\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14136 (step 14136): 1.790214\n",
      "Batch #10\tAverage Generator Loss: 2089.315942\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14137 (step 14137): 1.270966\n",
      "Batch #10\tAverage Generator Loss: 2166.994385\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14138 (step 14138): 1.473243\n",
      "Batch #10\tAverage Generator Loss: 2045.909387\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14139 (step 14139): 1.759370\n",
      "Batch #10\tAverage Generator Loss: 1991.845169\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14140 (step 14140): 1.289354\n",
      "Batch #10\tAverage Generator Loss: 2444.088428\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14141 (step 14141): 1.383358\n",
      "Batch #10\tAverage Generator Loss: 2276.083911\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14142 (step 14142): 1.734730\n",
      "Batch #10\tAverage Generator Loss: 2259.665198\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14143 (step 14143): 1.301808\n",
      "Batch #10\tAverage Generator Loss: 2178.489844\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14144 (step 14144): 1.267943\n",
      "Batch #10\tAverage Generator Loss: 2094.698309\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14145 (step 14145): 1.360052\n",
      "Batch #10\tAverage Generator Loss: 2293.679163\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14146 (step 14146): 1.770952\n",
      "Batch #10\tAverage Generator Loss: 2116.411365\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14147 (step 14147): 1.276352\n",
      "Batch #10\tAverage Generator Loss: 2234.974841\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14148 (step 14148): 1.289657\n",
      "Batch #10\tAverage Generator Loss: 1930.923849\tAverage Discriminator Loss: 0.000158\n",
      "\n",
      "Train time for epoch #14149 (step 14149): 1.792188\n",
      "Batch #10\tAverage Generator Loss: 1936.139453\tAverage Discriminator Loss: 0.153509\n",
      "\n",
      "Train time for epoch #14150 (step 14150): 1.335330\n",
      "Batch #10\tAverage Generator Loss: 2458.023132\tAverage Discriminator Loss: 0.001231\n",
      "\n",
      "Train time for epoch #14151 (step 14151): 1.340275\n",
      "Batch #10\tAverage Generator Loss: 2283.347595\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14152 (step 14152): 1.873746\n",
      "Batch #10\tAverage Generator Loss: 2340.305078\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14153 (step 14153): 1.326767\n",
      "Batch #10\tAverage Generator Loss: 2346.635278\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14154 (step 14154): 1.444129\n",
      "Batch #10\tAverage Generator Loss: 2275.468713\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14155 (step 14155): 1.801414\n",
      "Batch #10\tAverage Generator Loss: 2331.430688\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14156 (step 14156): 1.342056\n",
      "Batch #10\tAverage Generator Loss: 2494.770477\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14157 (step 14157): 1.244525\n",
      "Batch #10\tAverage Generator Loss: 2476.618018\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14158 (step 14158): 1.775740\n",
      "Batch #10\tAverage Generator Loss: 2598.265143\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14159 (step 14159): 1.338697\n",
      "Batch #10\tAverage Generator Loss: 1979.056726\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14160 (step 14160): 1.340708\n",
      "Batch #10\tAverage Generator Loss: 2179.539600\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14161 (step 14161): 1.924278\n",
      "Batch #10\tAverage Generator Loss: 2424.510706\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14162 (step 14162): 1.292892\n",
      "Batch #10\tAverage Generator Loss: 2618.107654\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14163 (step 14163): 1.389949\n",
      "Batch #10\tAverage Generator Loss: 2432.941528\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14164 (step 14164): 1.904431\n",
      "Batch #10\tAverage Generator Loss: 2264.434253\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14165 (step 14165): 1.293438\n",
      "Batch #10\tAverage Generator Loss: 2700.498755\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14166 (step 14166): 1.287625\n",
      "Batch #10\tAverage Generator Loss: 2283.257520\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14167 (step 14167): 1.879066\n",
      "Batch #10\tAverage Generator Loss: 2218.466949\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14168 (step 14168): 1.277910\n",
      "Batch #10\tAverage Generator Loss: 2108.119421\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14169 (step 14169): 1.283633\n",
      "Batch #10\tAverage Generator Loss: 2396.496875\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14170 (step 14170): 1.766680\n",
      "Batch #10\tAverage Generator Loss: 2162.325674\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14171 (step 14171): 1.309135\n",
      "Batch #10\tAverage Generator Loss: 2388.934790\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14172 (step 14172): 1.381391\n",
      "Batch #10\tAverage Generator Loss: 2273.907788\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14173 (step 14173): 1.814379\n",
      "Batch #10\tAverage Generator Loss: 2627.556995\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14174 (step 14174): 1.366703\n",
      "Batch #10\tAverage Generator Loss: 2330.942371\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14175 (step 14175): 1.283296\n",
      "Batch #10\tAverage Generator Loss: 2550.436841\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14176 (step 14176): 1.822971\n",
      "Batch #10\tAverage Generator Loss: 2126.543359\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14177 (step 14177): 1.280566\n",
      "Batch #10\tAverage Generator Loss: 2341.954761\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14178 (step 14178): 1.299308\n",
      "Batch #10\tAverage Generator Loss: 2215.184424\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14179 (step 14179): 1.794260\n",
      "Batch #10\tAverage Generator Loss: 2389.455762\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14180 (step 14180): 1.353420\n",
      "Batch #10\tAverage Generator Loss: 2360.616290\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14181 (step 14181): 1.317891\n",
      "Batch #10\tAverage Generator Loss: 2571.442163\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14182 (step 14182): 1.719241\n",
      "Batch #10\tAverage Generator Loss: 2132.046521\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14183 (step 14183): 1.363620\n",
      "Batch #10\tAverage Generator Loss: 2468.364954\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14184 (step 14184): 1.330172\n",
      "Batch #10\tAverage Generator Loss: 2108.882336\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14185 (step 14185): 1.747015\n",
      "Batch #10\tAverage Generator Loss: 2135.022375\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14186 (step 14186): 1.355523\n",
      "Batch #10\tAverage Generator Loss: 2059.863861\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14187 (step 14187): 1.294823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2456.521875\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14188 (step 14188): 1.794195\n",
      "Batch #10\tAverage Generator Loss: 2341.292273\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14189 (step 14189): 1.281438\n",
      "Batch #10\tAverage Generator Loss: 2412.653931\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14190 (step 14190): 1.376549\n",
      "Batch #10\tAverage Generator Loss: 2440.621838\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14191 (step 14191): 1.876895\n",
      "Batch #10\tAverage Generator Loss: 2149.702051\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14192 (step 14192): 1.465268\n",
      "Batch #10\tAverage Generator Loss: 2383.747876\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14193 (step 14193): 1.447491\n",
      "Batch #10\tAverage Generator Loss: 2377.370691\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14194 (step 14194): 1.850029\n",
      "Batch #10\tAverage Generator Loss: 2358.703613\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14195 (step 14195): 1.350005\n",
      "Batch #10\tAverage Generator Loss: 2151.993695\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14196 (step 14196): 1.395326\n",
      "Batch #10\tAverage Generator Loss: 2560.646692\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14197 (step 14197): 1.774671\n",
      "Batch #10\tAverage Generator Loss: 1990.774890\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14198 (step 14198): 1.302962\n",
      "Batch #10\tAverage Generator Loss: 2510.515808\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14199 (step 14199): 1.346207\n",
      "Batch #10\tAverage Generator Loss: 2392.266687\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14200 (step 14200): 1.896908\n",
      "Batch #10\tAverage Generator Loss: 2328.396381\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14201 (step 14201): 1.304180\n",
      "Batch #10\tAverage Generator Loss: 2204.220276\tAverage Discriminator Loss: 0.018677\n",
      "\n",
      "Train time for epoch #14202 (step 14202): 1.400995\n",
      "Batch #10\tAverage Generator Loss: 2261.713904\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14203 (step 14203): 1.824060\n",
      "Batch #10\tAverage Generator Loss: 2488.933081\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14204 (step 14204): 1.299871\n",
      "Batch #10\tAverage Generator Loss: 2414.381250\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14205 (step 14205): 1.296192\n",
      "Batch #10\tAverage Generator Loss: 2017.248523\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14206 (step 14206): 1.768734\n",
      "Batch #10\tAverage Generator Loss: 1847.568823\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #14207 (step 14207): 1.331062\n",
      "Batch #10\tAverage Generator Loss: 1931.632526\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14208 (step 14208): 1.287256\n",
      "Batch #10\tAverage Generator Loss: 2475.551538\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14209 (step 14209): 1.921461\n",
      "Batch #10\tAverage Generator Loss: 2431.640198\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14210 (step 14210): 1.331652\n",
      "Batch #10\tAverage Generator Loss: 2025.050580\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14211 (step 14211): 1.370975\n",
      "Batch #10\tAverage Generator Loss: 2295.299976\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14212 (step 14212): 1.860874\n",
      "Batch #10\tAverage Generator Loss: 1995.310437\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14213 (step 14213): 1.350259\n",
      "Batch #10\tAverage Generator Loss: 2313.829443\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14214 (step 14214): 1.384074\n",
      "Batch #10\tAverage Generator Loss: 2195.820947\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14215 (step 14215): 1.796585\n",
      "Batch #10\tAverage Generator Loss: 2229.508899\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14216 (step 14216): 1.344654\n",
      "Batch #10\tAverage Generator Loss: 2291.250854\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14217 (step 14217): 1.294679\n",
      "Batch #10\tAverage Generator Loss: 2127.277039\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14218 (step 14218): 1.801774\n",
      "Batch #10\tAverage Generator Loss: 2184.299036\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14219 (step 14219): 1.268698\n",
      "Batch #10\tAverage Generator Loss: 2475.619910\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14220 (step 14220): 1.288320\n",
      "Batch #10\tAverage Generator Loss: 2101.391986\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14221 (step 14221): 1.731545\n",
      "Batch #10\tAverage Generator Loss: 2406.402173\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14222 (step 14222): 1.337685\n",
      "Batch #10\tAverage Generator Loss: 2315.948297\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14223 (step 14223): 1.408478\n",
      "Batch #10\tAverage Generator Loss: 2463.684961\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14224 (step 14224): 1.784635\n",
      "Batch #10\tAverage Generator Loss: 2119.679248\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14225 (step 14225): 1.292881\n",
      "Batch #10\tAverage Generator Loss: 2177.929449\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14226 (step 14226): 1.345016\n",
      "Batch #10\tAverage Generator Loss: 2157.242053\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14227 (step 14227): 1.745650\n",
      "Batch #10\tAverage Generator Loss: 1980.617914\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14228 (step 14228): 1.292521\n",
      "Batch #10\tAverage Generator Loss: 2219.274646\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14229 (step 14229): 1.335852\n",
      "Batch #10\tAverage Generator Loss: 2131.940393\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14230 (step 14230): 1.792214\n",
      "Batch #10\tAverage Generator Loss: 2435.079248\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14231 (step 14231): 1.393499\n",
      "Batch #10\tAverage Generator Loss: 2250.731885\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14232 (step 14232): 1.299409\n",
      "Batch #10\tAverage Generator Loss: 2392.614539\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14233 (step 14233): 1.828944\n",
      "Batch #10\tAverage Generator Loss: 2138.802222\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14234 (step 14234): 1.374485\n",
      "Batch #10\tAverage Generator Loss: 2351.972571\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14235 (step 14235): 1.302234\n",
      "Batch #10\tAverage Generator Loss: 2235.889880\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14236 (step 14236): 1.884888\n",
      "Batch #10\tAverage Generator Loss: 2078.588531\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14237 (step 14237): 1.291540\n",
      "Batch #10\tAverage Generator Loss: 2205.328516\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14238 (step 14238): 1.303344\n",
      "Batch #10\tAverage Generator Loss: 2123.752063\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14239 (step 14239): 1.823360\n",
      "Batch #10\tAverage Generator Loss: 2192.533716\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14240 (step 14240): 1.331113\n",
      "Batch #10\tAverage Generator Loss: 2444.446936\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14241 (step 14241): 1.437596\n",
      "Batch #10\tAverage Generator Loss: 2525.626038\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14242 (step 14242): 1.813355\n",
      "Batch #10\tAverage Generator Loss: 2176.014380\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14243 (step 14243): 1.421151\n",
      "Batch #10\tAverage Generator Loss: 2688.962207\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14244 (step 14244): 1.345458\n",
      "Batch #10\tAverage Generator Loss: 2383.082898\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14245 (step 14245): 1.870626\n",
      "Batch #10\tAverage Generator Loss: 2039.762280\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14246 (step 14246): 1.245665\n",
      "Batch #10\tAverage Generator Loss: 2231.397119\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14247 (step 14247): 1.391467\n",
      "Batch #10\tAverage Generator Loss: 2379.145618\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14248 (step 14248): 1.808868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2174.048163\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14249 (step 14249): 1.296858\n",
      "Batch #10\tAverage Generator Loss: 2557.071094\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14250 (step 14250): 1.301588\n",
      "Batch #10\tAverage Generator Loss: 2313.263367\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14251 (step 14251): 1.714557\n",
      "Batch #10\tAverage Generator Loss: 2155.920197\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14252 (step 14252): 1.349505\n",
      "Batch #10\tAverage Generator Loss: 2353.421191\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14253 (step 14253): 1.281873\n",
      "Batch #10\tAverage Generator Loss: 2143.204028\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14254 (step 14254): 1.756259\n",
      "Batch #10\tAverage Generator Loss: 2319.747473\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14255 (step 14255): 1.349564\n",
      "Batch #10\tAverage Generator Loss: 2046.066388\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14256 (step 14256): 1.486683\n",
      "Batch #10\tAverage Generator Loss: 2533.876990\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14257 (step 14257): 1.732168\n",
      "Batch #10\tAverage Generator Loss: 2142.197729\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14258 (step 14258): 1.372404\n",
      "Batch #10\tAverage Generator Loss: 1856.018298\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14259 (step 14259): 1.385458\n",
      "Batch #10\tAverage Generator Loss: 1813.585834\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14260 (step 14260): 1.729483\n",
      "Batch #10\tAverage Generator Loss: 2512.067896\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14261 (step 14261): 1.295326\n",
      "Batch #10\tAverage Generator Loss: 2105.494342\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14262 (step 14262): 1.349014\n",
      "Batch #10\tAverage Generator Loss: 2123.449048\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14263 (step 14263): 1.777338\n",
      "Batch #10\tAverage Generator Loss: 2181.774536\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14264 (step 14264): 1.334125\n",
      "Batch #10\tAverage Generator Loss: 2167.977405\tAverage Discriminator Loss: 0.008589\n",
      "\n",
      "Train time for epoch #14265 (step 14265): 1.291876\n",
      "Batch #10\tAverage Generator Loss: 2192.394336\tAverage Discriminator Loss: 0.003058\n",
      "\n",
      "Train time for epoch #14266 (step 14266): 1.807375\n",
      "Batch #10\tAverage Generator Loss: 2317.585669\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14267 (step 14267): 1.339444\n",
      "Batch #10\tAverage Generator Loss: 2173.952527\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14268 (step 14268): 1.289443\n",
      "Batch #10\tAverage Generator Loss: 2381.036804\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14269 (step 14269): 1.831378\n",
      "Batch #10\tAverage Generator Loss: 2351.164612\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14270 (step 14270): 1.300056\n",
      "Batch #10\tAverage Generator Loss: 2493.659790\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14271 (step 14271): 1.286216\n",
      "Batch #10\tAverage Generator Loss: 2094.139154\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14272 (step 14272): 1.859157\n",
      "Batch #10\tAverage Generator Loss: 2424.424744\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14273 (step 14273): 1.350747\n",
      "Batch #10\tAverage Generator Loss: 2287.281116\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14274 (step 14274): 1.293947\n",
      "Batch #10\tAverage Generator Loss: 2117.287415\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14275 (step 14275): 1.821845\n",
      "Batch #10\tAverage Generator Loss: 2388.954907\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14276 (step 14276): 1.329410\n",
      "Batch #10\tAverage Generator Loss: 2246.260950\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14277 (step 14277): 1.278195\n",
      "Batch #10\tAverage Generator Loss: 2483.685632\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14278 (step 14278): 1.779977\n",
      "Batch #10\tAverage Generator Loss: 2490.178381\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14279 (step 14279): 1.328520\n",
      "Batch #10\tAverage Generator Loss: 2300.571301\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14280 (step 14280): 1.284882\n",
      "Batch #10\tAverage Generator Loss: 2171.939722\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14281 (step 14281): 1.917909\n",
      "Batch #10\tAverage Generator Loss: 2232.026746\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14282 (step 14282): 1.291724\n",
      "Batch #10\tAverage Generator Loss: 2235.974103\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14283 (step 14283): 1.343463\n",
      "Batch #10\tAverage Generator Loss: 2628.190869\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14284 (step 14284): 1.815975\n",
      "Batch #10\tAverage Generator Loss: 2500.411530\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14285 (step 14285): 1.296616\n",
      "Batch #10\tAverage Generator Loss: 2391.184631\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14286 (step 14286): 1.355880\n",
      "Batch #10\tAverage Generator Loss: 2302.486060\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14287 (step 14287): 1.948244\n",
      "Batch #10\tAverage Generator Loss: 2543.127185\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14288 (step 14288): 1.456645\n",
      "Batch #10\tAverage Generator Loss: 2507.281470\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14289 (step 14289): 1.295043\n",
      "Batch #10\tAverage Generator Loss: 2279.788977\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14290 (step 14290): 1.867216\n",
      "Batch #10\tAverage Generator Loss: 2281.967383\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14291 (step 14291): 1.290166\n",
      "Batch #10\tAverage Generator Loss: 2223.609204\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14292 (step 14292): 1.393881\n",
      "Batch #10\tAverage Generator Loss: 1979.812976\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14293 (step 14293): 1.830240\n",
      "Batch #10\tAverage Generator Loss: 2223.335974\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14294 (step 14294): 1.248882\n",
      "Batch #10\tAverage Generator Loss: 2199.641956\tAverage Discriminator Loss: 0.187728\n",
      "\n",
      "Train time for epoch #14295 (step 14295): 1.349931\n",
      "Batch #10\tAverage Generator Loss: 2510.946924\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #14296 (step 14296): 1.769937\n",
      "Batch #10\tAverage Generator Loss: 2945.627454\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #14297 (step 14297): 1.418840\n",
      "Batch #10\tAverage Generator Loss: 2491.355908\tAverage Discriminator Loss: 0.202263\n",
      "\n",
      "Train time for epoch #14298 (step 14298): 1.343603\n",
      "Batch #10\tAverage Generator Loss: 2527.933374\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14299 (step 14299): 1.835172\n",
      "Batch #10\tAverage Generator Loss: 2076.811603\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14300 (step 14300): 1.392367\n",
      "Batch #10\tAverage Generator Loss: 2589.164734\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14301 (step 14301): 1.243766\n",
      "Batch #10\tAverage Generator Loss: 2579.838153\tAverage Discriminator Loss: 0.108869\n",
      "\n",
      "Train time for epoch #14302 (step 14302): 1.838583\n",
      "Batch #10\tAverage Generator Loss: 2637.870630\tAverage Discriminator Loss: 0.000534\n",
      "\n",
      "Train time for epoch #14303 (step 14303): 1.300148\n",
      "Batch #10\tAverage Generator Loss: 2496.749463\tAverage Discriminator Loss: 0.000485\n",
      "\n",
      "Train time for epoch #14304 (step 14304): 1.340976\n",
      "Batch #10\tAverage Generator Loss: 2415.246021\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14305 (step 14305): 1.740900\n",
      "Batch #10\tAverage Generator Loss: 2480.442688\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14306 (step 14306): 1.294877\n",
      "Batch #10\tAverage Generator Loss: 2708.657642\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14307 (step 14307): 1.415962\n",
      "Batch #10\tAverage Generator Loss: 2085.841418\tAverage Discriminator Loss: 0.401247\n",
      "\n",
      "Train time for epoch #14308 (step 14308): 1.745003\n",
      "Batch #10\tAverage Generator Loss: 2125.507190\tAverage Discriminator Loss: 0.000731\n",
      "\n",
      "Train time for epoch #14309 (step 14309): 1.355429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2503.650623\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14310 (step 14310): 1.341501\n",
      "Batch #10\tAverage Generator Loss: 2234.126563\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14311 (step 14311): 1.782067\n",
      "Batch #10\tAverage Generator Loss: 2227.844287\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14312 (step 14312): 1.386142\n",
      "Batch #10\tAverage Generator Loss: 1970.266833\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14313 (step 14313): 1.299721\n",
      "Batch #10\tAverage Generator Loss: 2520.733813\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14314 (step 14314): 1.916575\n",
      "Batch #10\tAverage Generator Loss: 2289.823315\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14315 (step 14315): 1.419638\n",
      "Batch #10\tAverage Generator Loss: 2155.846716\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14316 (step 14316): 1.364739\n",
      "Batch #10\tAverage Generator Loss: 2152.429773\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14317 (step 14317): 1.830311\n",
      "Batch #10\tAverage Generator Loss: 2150.756799\tAverage Discriminator Loss: 0.062712\n",
      "\n",
      "Train time for epoch #14318 (step 14318): 1.314030\n",
      "Batch #10\tAverage Generator Loss: 1974.225598\tAverage Discriminator Loss: 0.007361\n",
      "\n",
      "Train time for epoch #14319 (step 14319): 1.349449\n",
      "Batch #10\tAverage Generator Loss: 2230.826831\tAverage Discriminator Loss: 0.000059\n",
      "\n",
      "Train time for epoch #14320 (step 14320): 1.871836\n",
      "Batch #10\tAverage Generator Loss: 2280.397034\tAverage Discriminator Loss: 0.000048\n",
      "\n",
      "Train time for epoch #14321 (step 14321): 1.285438\n",
      "Batch #10\tAverage Generator Loss: 2046.823944\tAverage Discriminator Loss: 0.000022\n",
      "\n",
      "Train time for epoch #14322 (step 14322): 1.449121\n",
      "Batch #10\tAverage Generator Loss: 1972.742969\tAverage Discriminator Loss: 0.028464\n",
      "\n",
      "Train time for epoch #14323 (step 14323): 1.784092\n",
      "Batch #10\tAverage Generator Loss: 2200.590137\tAverage Discriminator Loss: 0.002797\n",
      "\n",
      "Train time for epoch #14324 (step 14324): 1.343610\n",
      "Batch #10\tAverage Generator Loss: 2259.930811\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #14325 (step 14325): 1.441468\n",
      "Batch #10\tAverage Generator Loss: 1802.702393\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #14326 (step 14326): 1.820359\n",
      "Batch #10\tAverage Generator Loss: 2002.116724\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #14327 (step 14327): 1.360663\n",
      "Batch #10\tAverage Generator Loss: 2008.270227\tAverage Discriminator Loss: 0.000037\n",
      "\n",
      "Train time for epoch #14328 (step 14328): 1.290125\n",
      "Batch #10\tAverage Generator Loss: 2167.947217\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #14329 (step 14329): 1.771454\n",
      "Batch #10\tAverage Generator Loss: 1952.004144\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #14330 (step 14330): 1.336636\n",
      "Batch #10\tAverage Generator Loss: 2072.372363\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #14331 (step 14331): 1.344990\n",
      "Batch #10\tAverage Generator Loss: 2085.660718\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #14332 (step 14332): 1.760948\n",
      "Batch #10\tAverage Generator Loss: 2107.400049\tAverage Discriminator Loss: 0.004122\n",
      "\n",
      "Train time for epoch #14333 (step 14333): 1.426242\n",
      "Batch #10\tAverage Generator Loss: 2088.176953\tAverage Discriminator Loss: 0.000053\n",
      "\n",
      "Train time for epoch #14334 (step 14334): 1.291970\n",
      "Batch #10\tAverage Generator Loss: 2073.263110\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #14335 (step 14335): 1.733252\n",
      "Batch #10\tAverage Generator Loss: 2302.214380\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #14336 (step 14336): 1.308855\n",
      "Batch #10\tAverage Generator Loss: 2301.538074\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #14337 (step 14337): 1.360257\n",
      "Batch #10\tAverage Generator Loss: 1981.898511\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #14338 (step 14338): 1.740763\n",
      "Batch #10\tAverage Generator Loss: 2123.012537\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #14339 (step 14339): 1.284182\n",
      "Batch #10\tAverage Generator Loss: 2089.584558\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #14340 (step 14340): 1.325193\n",
      "Batch #10\tAverage Generator Loss: 2190.089404\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #14341 (step 14341): 1.763340\n",
      "Batch #10\tAverage Generator Loss: 2005.265942\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #14342 (step 14342): 1.350912\n",
      "Batch #10\tAverage Generator Loss: 2326.675732\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #14343 (step 14343): 1.326480\n",
      "Batch #10\tAverage Generator Loss: 2307.877197\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #14344 (step 14344): 1.749340\n",
      "Batch #10\tAverage Generator Loss: 2304.116382\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #14345 (step 14345): 1.398236\n",
      "Batch #10\tAverage Generator Loss: 1897.268378\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #14346 (step 14346): 1.349485\n",
      "Batch #10\tAverage Generator Loss: 1918.128119\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #14347 (step 14347): 1.759397\n",
      "Batch #10\tAverage Generator Loss: 2159.959375\tAverage Discriminator Loss: 0.000108\n",
      "\n",
      "Train time for epoch #14348 (step 14348): 1.302212\n",
      "Batch #10\tAverage Generator Loss: 2193.657123\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #14349 (step 14349): 1.299735\n",
      "Batch #10\tAverage Generator Loss: 2205.410669\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #14350 (step 14350): 1.774873\n",
      "Batch #10\tAverage Generator Loss: 1936.685242\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #14351 (step 14351): 1.286970\n",
      "Batch #10\tAverage Generator Loss: 1925.896021\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #14352 (step 14352): 1.502049\n",
      "Batch #10\tAverage Generator Loss: 2324.741858\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #14353 (step 14353): 1.817320\n",
      "Batch #10\tAverage Generator Loss: 2001.231708\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #14354 (step 14354): 1.289208\n",
      "Batch #10\tAverage Generator Loss: 2136.604089\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #14355 (step 14355): 1.322241\n",
      "Batch #10\tAverage Generator Loss: 2252.005432\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #14356 (step 14356): 1.881088\n",
      "Batch #10\tAverage Generator Loss: 1738.118066\tAverage Discriminator Loss: 0.000850\n",
      "\n",
      "Train time for epoch #14357 (step 14357): 1.303060\n",
      "Batch #10\tAverage Generator Loss: 2090.691574\tAverage Discriminator Loss: 0.020035\n",
      "\n",
      "Train time for epoch #14358 (step 14358): 1.364127\n",
      "Batch #10\tAverage Generator Loss: 2197.337158\tAverage Discriminator Loss: 0.000034\n",
      "\n",
      "Train time for epoch #14359 (step 14359): 1.825876\n",
      "Batch #10\tAverage Generator Loss: 2034.411713\tAverage Discriminator Loss: 0.000032\n",
      "\n",
      "Train time for epoch #14360 (step 14360): 1.292009\n",
      "Batch #10\tAverage Generator Loss: 2006.156506\tAverage Discriminator Loss: 0.099892\n",
      "\n",
      "Train time for epoch #14361 (step 14361): 1.374615\n",
      "Batch #10\tAverage Generator Loss: 1773.315930\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #14362 (step 14362): 1.790064\n",
      "Batch #10\tAverage Generator Loss: 1853.969525\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14363 (step 14363): 1.346107\n",
      "Batch #10\tAverage Generator Loss: 2084.132861\tAverage Discriminator Loss: 0.008603\n",
      "\n",
      "Train time for epoch #14364 (step 14364): 1.349455\n",
      "Batch #10\tAverage Generator Loss: 1635.639438\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #14365 (step 14365): 1.809191\n",
      "Batch #10\tAverage Generator Loss: 1787.859546\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #14366 (step 14366): 1.297189\n",
      "Batch #10\tAverage Generator Loss: 1932.781958\tAverage Discriminator Loss: 0.000795\n",
      "\n",
      "Train time for epoch #14367 (step 14367): 1.255477\n",
      "Batch #10\tAverage Generator Loss: 1727.665063\tAverage Discriminator Loss: 0.431146\n",
      "\n",
      "Train time for epoch #14368 (step 14368): 1.848041\n",
      "Batch #10\tAverage Generator Loss: 2151.305634\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14369 (step 14369): 1.302139\n",
      "Batch #10\tAverage Generator Loss: 2492.916882\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14370 (step 14370): 1.301351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2519.958716\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14371 (step 14371): 1.928867\n",
      "Batch #10\tAverage Generator Loss: 2840.755469\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14372 (step 14372): 1.381006\n",
      "Batch #10\tAverage Generator Loss: 2452.568616\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14373 (step 14373): 1.287188\n",
      "Batch #10\tAverage Generator Loss: 2780.751025\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14374 (step 14374): 1.734069\n",
      "Batch #10\tAverage Generator Loss: 2405.264227\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14375 (step 14375): 1.380316\n",
      "Batch #10\tAverage Generator Loss: 2229.388000\tAverage Discriminator Loss: 0.120880\n",
      "\n",
      "Train time for epoch #14376 (step 14376): 1.458539\n",
      "Batch #10\tAverage Generator Loss: 2554.589233\tAverage Discriminator Loss: 0.000140\n",
      "\n",
      "Train time for epoch #14377 (step 14377): 1.798664\n",
      "Batch #10\tAverage Generator Loss: 2825.403235\tAverage Discriminator Loss: 0.000066\n",
      "\n",
      "Train time for epoch #14378 (step 14378): 1.290401\n",
      "Batch #10\tAverage Generator Loss: 2396.706604\tAverage Discriminator Loss: 0.000026\n",
      "\n",
      "Train time for epoch #14379 (step 14379): 1.283890\n",
      "Batch #10\tAverage Generator Loss: 2686.738562\tAverage Discriminator Loss: 0.000019\n",
      "\n",
      "Train time for epoch #14380 (step 14380): 1.840530\n",
      "Batch #10\tAverage Generator Loss: 2375.518561\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #14381 (step 14381): 1.336131\n",
      "Batch #10\tAverage Generator Loss: 2482.780701\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #14382 (step 14382): 1.283566\n",
      "Batch #10\tAverage Generator Loss: 2934.693591\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #14383 (step 14383): 1.333262\n",
      "Batch #10\tAverage Generator Loss: 2950.451208\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #14384 (step 14384): 1.764656\n",
      "Batch #10\tAverage Generator Loss: 2944.552563\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #14385 (step 14385): 1.350827\n",
      "Batch #10\tAverage Generator Loss: 2434.500537\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #14386 (step 14386): 1.358167\n",
      "Batch #10\tAverage Generator Loss: 2596.352588\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #14387 (step 14387): 1.853659\n",
      "Batch #10\tAverage Generator Loss: 2639.641687\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #14388 (step 14388): 1.375044\n",
      "Batch #10\tAverage Generator Loss: 2660.342975\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #14389 (step 14389): 1.388952\n",
      "Batch #10\tAverage Generator Loss: 2310.646838\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #14390 (step 14390): 1.836281\n",
      "Batch #10\tAverage Generator Loss: 2641.748792\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #14391 (step 14391): 1.302532\n",
      "Batch #10\tAverage Generator Loss: 2326.346350\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #14392 (step 14392): 1.372099\n",
      "Batch #10\tAverage Generator Loss: 2484.074426\tAverage Discriminator Loss: 1.355882\n",
      "\n",
      "Train time for epoch #14393 (step 14393): 1.910537\n",
      "Batch #10\tAverage Generator Loss: 2326.819495\tAverage Discriminator Loss: 0.061572\n",
      "\n",
      "Train time for epoch #14394 (step 14394): 1.343196\n",
      "Batch #10\tAverage Generator Loss: 2010.176843\tAverage Discriminator Loss: 0.002189\n",
      "\n",
      "Train time for epoch #14395 (step 14395): 1.298506\n",
      "Batch #10\tAverage Generator Loss: 1790.631641\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #14396 (step 14396): 1.741210\n",
      "Batch #10\tAverage Generator Loss: 2090.883203\tAverage Discriminator Loss: 0.000173\n",
      "\n",
      "Train time for epoch #14397 (step 14397): 1.301449\n",
      "Batch #10\tAverage Generator Loss: 1782.489276\tAverage Discriminator Loss: 0.000097\n",
      "\n",
      "Train time for epoch #14398 (step 14398): 1.380775\n",
      "Batch #10\tAverage Generator Loss: 1864.435950\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #14399 (step 14399): 1.733861\n",
      "Batch #10\tAverage Generator Loss: 1906.152344\tAverage Discriminator Loss: 0.000058\n",
      "\n",
      "Train time for epoch #14400 (step 14400): 1.339302\n",
      "Batch #10\tAverage Generator Loss: 2034.470105\tAverage Discriminator Loss: 0.000052\n",
      "\n",
      "Train time for epoch #14401 (step 14401): 1.481021\n",
      "Batch #10\tAverage Generator Loss: 1853.495837\tAverage Discriminator Loss: 0.000042\n",
      "\n",
      "Train time for epoch #14402 (step 14402): 1.804734\n",
      "Batch #10\tAverage Generator Loss: 1876.597937\tAverage Discriminator Loss: 0.000038\n",
      "\n",
      "Train time for epoch #14403 (step 14403): 1.337984\n",
      "Batch #10\tAverage Generator Loss: 1900.376599\tAverage Discriminator Loss: 0.000033\n",
      "\n",
      "Train time for epoch #14404 (step 14404): 1.334824\n",
      "Batch #10\tAverage Generator Loss: 2032.937073\tAverage Discriminator Loss: 0.000031\n",
      "\n",
      "Train time for epoch #14405 (step 14405): 1.819817\n",
      "Batch #10\tAverage Generator Loss: 2118.805151\tAverage Discriminator Loss: 0.000028\n",
      "\n",
      "Train time for epoch #14406 (step 14406): 1.286774\n",
      "Batch #10\tAverage Generator Loss: 2050.696777\tAverage Discriminator Loss: 0.000026\n",
      "\n",
      "Train time for epoch #14407 (step 14407): 1.329885\n",
      "Batch #10\tAverage Generator Loss: 2078.177850\tAverage Discriminator Loss: 0.000024\n",
      "\n",
      "Train time for epoch #14408 (step 14408): 1.777675\n",
      "Batch #10\tAverage Generator Loss: 1813.734180\tAverage Discriminator Loss: 0.000023\n",
      "\n",
      "Train time for epoch #14409 (step 14409): 1.425850\n",
      "Batch #10\tAverage Generator Loss: 1950.291895\tAverage Discriminator Loss: 0.000021\n",
      "\n",
      "Train time for epoch #14410 (step 14410): 1.336902\n",
      "Batch #10\tAverage Generator Loss: 2016.657507\tAverage Discriminator Loss: 0.000020\n",
      "\n",
      "Train time for epoch #14411 (step 14411): 1.799763\n",
      "Batch #10\tAverage Generator Loss: 1886.038269\tAverage Discriminator Loss: 0.000019\n",
      "\n",
      "Train time for epoch #14412 (step 14412): 1.288450\n",
      "Batch #10\tAverage Generator Loss: 1917.553223\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #14413 (step 14413): 1.352236\n",
      "Batch #10\tAverage Generator Loss: 1783.792242\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #14414 (step 14414): 1.801231\n",
      "Batch #10\tAverage Generator Loss: 1889.164484\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #14415 (step 14415): 1.390363\n",
      "Batch #10\tAverage Generator Loss: 2006.684778\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #14416 (step 14416): 1.399022\n",
      "Batch #10\tAverage Generator Loss: 1873.130139\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #14417 (step 14417): 1.781271\n",
      "Batch #10\tAverage Generator Loss: 1971.070520\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #14418 (step 14418): 1.277988\n",
      "Batch #10\tAverage Generator Loss: 1790.221387\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #14419 (step 14419): 1.439468\n",
      "Batch #10\tAverage Generator Loss: 1663.433301\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #14420 (step 14420): 1.888022\n",
      "Batch #10\tAverage Generator Loss: 1661.379053\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #14421 (step 14421): 1.353971\n",
      "Batch #10\tAverage Generator Loss: 1705.715729\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #14422 (step 14422): 1.290137\n",
      "Batch #10\tAverage Generator Loss: 1647.360425\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #14423 (step 14423): 1.729398\n",
      "Batch #10\tAverage Generator Loss: 1894.301697\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #14424 (step 14424): 1.299059\n",
      "Batch #10\tAverage Generator Loss: 1963.572247\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #14425 (step 14425): 1.321494\n",
      "Batch #10\tAverage Generator Loss: 2013.140674\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #14426 (step 14426): 1.739577\n",
      "Batch #10\tAverage Generator Loss: 1857.316858\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #14427 (step 14427): 1.355016\n",
      "Batch #10\tAverage Generator Loss: 2146.342029\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #14428 (step 14428): 1.445173\n",
      "Batch #10\tAverage Generator Loss: 1911.951929\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #14429 (step 14429): 1.718712\n",
      "Batch #10\tAverage Generator Loss: 1709.488812\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #14430 (step 14430): 1.393671\n",
      "Batch #10\tAverage Generator Loss: 1889.659753\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #14431 (step 14431): 1.374226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2124.931348\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #14432 (step 14432): 1.849002\n",
      "Batch #10\tAverage Generator Loss: 2302.991284\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #14433 (step 14433): 1.278817\n",
      "Batch #10\tAverage Generator Loss: 2137.609717\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #14434 (step 14434): 1.369491\n",
      "Batch #10\tAverage Generator Loss: 2344.115674\tAverage Discriminator Loss: 0.000022\n",
      "\n",
      "Train time for epoch #14435 (step 14435): 1.909086\n",
      "Batch #10\tAverage Generator Loss: 2201.069836\tAverage Discriminator Loss: 0.000022\n",
      "\n",
      "Train time for epoch #14436 (step 14436): 1.288733\n",
      "Batch #10\tAverage Generator Loss: 2121.624109\tAverage Discriminator Loss: 0.000024\n",
      "\n",
      "Train time for epoch #14437 (step 14437): 1.453846\n",
      "Batch #10\tAverage Generator Loss: 2033.618103\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #14438 (step 14438): 1.946949\n",
      "Batch #10\tAverage Generator Loss: 1954.120685\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #14439 (step 14439): 1.311267\n",
      "Batch #10\tAverage Generator Loss: 2145.406396\tAverage Discriminator Loss: 0.000020\n",
      "\n",
      "Train time for epoch #14440 (step 14440): 1.346874\n",
      "Batch #10\tAverage Generator Loss: 2223.223511\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #14441 (step 14441): 1.853215\n",
      "Batch #10\tAverage Generator Loss: 2112.374957\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #14442 (step 14442): 1.332630\n",
      "Batch #10\tAverage Generator Loss: 2337.516650\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #14443 (step 14443): 1.293877\n",
      "Batch #10\tAverage Generator Loss: 2096.392871\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #14444 (step 14444): 1.822306\n",
      "Batch #10\tAverage Generator Loss: 2175.077701\tAverage Discriminator Loss: 0.040407\n",
      "\n",
      "Train time for epoch #14445 (step 14445): 1.293503\n",
      "Batch #10\tAverage Generator Loss: 2115.933533\tAverage Discriminator Loss: 0.007061\n",
      "\n",
      "Train time for epoch #14446 (step 14446): 1.281008\n",
      "Batch #10\tAverage Generator Loss: 1977.809338\tAverage Discriminator Loss: 0.007267\n",
      "\n",
      "Train time for epoch #14447 (step 14447): 1.375258\n",
      "Batch #10\tAverage Generator Loss: 1896.349561\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14448 (step 14448): 1.851648\n",
      "Batch #10\tAverage Generator Loss: 1998.522327\tAverage Discriminator Loss: 0.000153\n",
      "\n",
      "Train time for epoch #14449 (step 14449): 1.398553\n",
      "Batch #10\tAverage Generator Loss: 2002.173169\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14450 (step 14450): 1.288955\n",
      "Batch #10\tAverage Generator Loss: 2196.301440\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14451 (step 14451): 1.798189\n",
      "Batch #10\tAverage Generator Loss: 1988.968665\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14452 (step 14452): 1.337829\n",
      "Batch #10\tAverage Generator Loss: 2222.467395\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14453 (step 14453): 1.375320\n",
      "Batch #10\tAverage Generator Loss: 2074.352124\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14454 (step 14454): 1.798380\n",
      "Batch #10\tAverage Generator Loss: 1949.785809\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14455 (step 14455): 1.389694\n",
      "Batch #10\tAverage Generator Loss: 2096.682483\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14456 (step 14456): 1.292706\n",
      "Batch #10\tAverage Generator Loss: 1916.931342\tAverage Discriminator Loss: 0.000052\n",
      "\n",
      "Train time for epoch #14457 (step 14457): 1.720198\n",
      "Batch #10\tAverage Generator Loss: 2197.417212\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14458 (step 14458): 1.304116\n",
      "Batch #10\tAverage Generator Loss: 2190.696924\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14459 (step 14459): 1.423264\n",
      "Batch #10\tAverage Generator Loss: 1936.291245\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14460 (step 14460): 1.792738\n",
      "Batch #10\tAverage Generator Loss: 1882.679205\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14461 (step 14461): 1.349298\n",
      "Batch #10\tAverage Generator Loss: 2196.226562\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14462 (step 14462): 1.288730\n",
      "Batch #10\tAverage Generator Loss: 1927.969611\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14463 (step 14463): 1.788996\n",
      "Batch #10\tAverage Generator Loss: 2093.786755\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14464 (step 14464): 1.288910\n",
      "Batch #10\tAverage Generator Loss: 2110.494104\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14465 (step 14465): 1.286077\n",
      "Batch #10\tAverage Generator Loss: 2180.205615\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14466 (step 14466): 1.797405\n",
      "Batch #10\tAverage Generator Loss: 1902.847559\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14467 (step 14467): 1.528748\n",
      "Batch #10\tAverage Generator Loss: 2118.990088\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14468 (step 14468): 1.331798\n",
      "Batch #10\tAverage Generator Loss: 2387.093457\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14469 (step 14469): 1.816187\n",
      "Batch #10\tAverage Generator Loss: 1940.861377\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14470 (step 14470): 1.487506\n",
      "Batch #10\tAverage Generator Loss: 2144.769324\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14471 (step 14471): 1.336760\n",
      "Batch #10\tAverage Generator Loss: 2106.149915\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14472 (step 14472): 1.924588\n",
      "Batch #10\tAverage Generator Loss: 2351.792090\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14473 (step 14473): 1.438970\n",
      "Batch #10\tAverage Generator Loss: 1778.765820\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14474 (step 14474): 1.315032\n",
      "Batch #10\tAverage Generator Loss: 2011.536365\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14475 (step 14475): 1.798174\n",
      "Batch #10\tAverage Generator Loss: 1752.739935\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14476 (step 14476): 1.299201\n",
      "Batch #10\tAverage Generator Loss: 1967.076605\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14477 (step 14477): 1.300812\n",
      "Batch #10\tAverage Generator Loss: 1896.989044\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14478 (step 14478): 1.843428\n",
      "Batch #10\tAverage Generator Loss: 1855.467187\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14479 (step 14479): 1.343513\n",
      "Batch #10\tAverage Generator Loss: 2064.213855\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14480 (step 14480): 1.300839\n",
      "Batch #10\tAverage Generator Loss: 2219.137109\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14481 (step 14481): 1.825523\n",
      "Batch #10\tAverage Generator Loss: 1785.803333\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14482 (step 14482): 1.410507\n",
      "Batch #10\tAverage Generator Loss: 1982.156195\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14483 (step 14483): 1.291407\n",
      "Batch #10\tAverage Generator Loss: 2287.160303\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14484 (step 14484): 1.432645\n",
      "Batch #10\tAverage Generator Loss: 2069.111255\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14485 (step 14485): 1.788883\n",
      "Batch #10\tAverage Generator Loss: 1733.488562\tAverage Discriminator Loss: 0.000086\n",
      "\n",
      "Train time for epoch #14486 (step 14486): 1.423970\n",
      "Batch #10\tAverage Generator Loss: 1890.442999\tAverage Discriminator Loss: 0.001024\n",
      "\n",
      "Train time for epoch #14487 (step 14487): 1.319786\n",
      "Batch #10\tAverage Generator Loss: 2253.343262\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #14488 (step 14488): 1.730724\n",
      "Batch #10\tAverage Generator Loss: 1819.435937\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #14489 (step 14489): 1.331269\n",
      "Batch #10\tAverage Generator Loss: 1950.600879\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #14490 (step 14490): 1.848424\n",
      "Batch #10\tAverage Generator Loss: 2007.389856\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14491 (step 14491): 1.283391\n",
      "Batch #10\tAverage Generator Loss: 1664.834265\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14492 (step 14492): 1.437487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 1841.343262\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #14493 (step 14493): 1.297208\n",
      "Batch #10\tAverage Generator Loss: 1992.036731\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #14494 (step 14494): 1.755178\n",
      "Batch #10\tAverage Generator Loss: 1899.864307\tAverage Discriminator Loss: 0.098032\n",
      "\n",
      "Train time for epoch #14495 (step 14495): 1.373391\n",
      "Batch #10\tAverage Generator Loss: 1816.759290\tAverage Discriminator Loss: 0.000049\n",
      "\n",
      "Train time for epoch #14496 (step 14496): 1.361226\n",
      "Batch #10\tAverage Generator Loss: 2230.739734\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #14497 (step 14497): 1.728372\n",
      "Batch #10\tAverage Generator Loss: 2140.741290\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14498 (step 14498): 1.312580\n",
      "Batch #10\tAverage Generator Loss: 2338.044971\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14499 (step 14499): 1.299755\n",
      "Batch #10\tAverage Generator Loss: 2065.336249\tAverage Discriminator Loss: 0.002502\n",
      "\n",
      "Train time for epoch #14500 (step 14500): 1.721203\n",
      "Batch #10\tAverage Generator Loss: 2074.143683\tAverage Discriminator Loss: 0.000038\n",
      "\n",
      "Train time for epoch #14501 (step 14501): 1.287060\n",
      "Batch #10\tAverage Generator Loss: 2280.148938\tAverage Discriminator Loss: 0.003825\n",
      "\n",
      "Train time for epoch #14502 (step 14502): 1.346361\n",
      "Batch #10\tAverage Generator Loss: 2102.841699\tAverage Discriminator Loss: 0.000038\n",
      "\n",
      "Train time for epoch #14503 (step 14503): 1.745868\n",
      "Batch #10\tAverage Generator Loss: 1779.233826\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #14504 (step 14504): 1.294866\n",
      "Batch #10\tAverage Generator Loss: 2057.535107\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #14505 (step 14505): 1.364836\n",
      "Batch #10\tAverage Generator Loss: 2619.071545\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #14506 (step 14506): 1.859414\n",
      "Batch #10\tAverage Generator Loss: 2148.196204\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #14507 (step 14507): 1.292348\n",
      "Batch #10\tAverage Generator Loss: 2365.157556\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #14508 (step 14508): 1.296672\n",
      "Batch #10\tAverage Generator Loss: 2209.072754\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #14509 (step 14509): 1.852829\n",
      "Batch #10\tAverage Generator Loss: 2309.040295\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #14510 (step 14510): 1.340799\n",
      "Batch #10\tAverage Generator Loss: 2424.188013\tAverage Discriminator Loss: 0.000103\n",
      "\n",
      "Train time for epoch #14511 (step 14511): 1.256430\n",
      "Batch #10\tAverage Generator Loss: 2426.867114\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #14512 (step 14512): 1.913397\n",
      "Batch #10\tAverage Generator Loss: 2258.539258\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #14513 (step 14513): 1.278502\n",
      "Batch #10\tAverage Generator Loss: 2182.871301\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #14514 (step 14514): 1.312846\n",
      "Batch #10\tAverage Generator Loss: 2534.012781\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #14515 (step 14515): 1.777772\n",
      "Batch #10\tAverage Generator Loss: 2247.277148\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #14516 (step 14516): 1.391135\n",
      "Batch #10\tAverage Generator Loss: 2179.059790\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #14517 (step 14517): 1.387671\n",
      "Batch #10\tAverage Generator Loss: 2281.991614\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #14518 (step 14518): 1.795500\n",
      "Batch #10\tAverage Generator Loss: 2390.506934\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #14519 (step 14519): 1.547570\n",
      "Batch #10\tAverage Generator Loss: 2272.054834\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #14520 (step 14520): 1.423355\n",
      "Batch #10\tAverage Generator Loss: 2134.140588\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #14521 (step 14521): 1.796129\n",
      "Batch #10\tAverage Generator Loss: 2204.854468\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #14522 (step 14522): 1.282956\n",
      "Batch #10\tAverage Generator Loss: 2243.676843\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #14523 (step 14523): 1.292985\n",
      "Batch #10\tAverage Generator Loss: 2164.881299\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #14524 (step 14524): 1.376902\n",
      "Batch #10\tAverage Generator Loss: 2296.987146\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #14525 (step 14525): 1.746492\n",
      "Batch #10\tAverage Generator Loss: 2470.924255\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #14526 (step 14526): 1.334932\n",
      "Batch #10\tAverage Generator Loss: 2527.103821\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #14527 (step 14527): 1.336857\n",
      "Batch #10\tAverage Generator Loss: 2197.436108\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #14528 (step 14528): 1.792214\n",
      "Batch #10\tAverage Generator Loss: 2372.616711\tAverage Discriminator Loss: 0.028170\n",
      "\n",
      "Train time for epoch #14529 (step 14529): 1.329330\n",
      "Batch #10\tAverage Generator Loss: 2141.827148\tAverage Discriminator Loss: 0.000021\n",
      "\n",
      "Train time for epoch #14530 (step 14530): 1.438046\n",
      "Batch #10\tAverage Generator Loss: 2156.112317\tAverage Discriminator Loss: 0.000024\n",
      "\n",
      "Train time for epoch #14531 (step 14531): 1.805731\n",
      "Batch #10\tAverage Generator Loss: 2087.981116\tAverage Discriminator Loss: 0.000024\n",
      "\n",
      "Train time for epoch #14532 (step 14532): 1.326332\n",
      "Batch #10\tAverage Generator Loss: 2293.093750\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #14533 (step 14533): 1.384874\n",
      "Batch #10\tAverage Generator Loss: 2317.437463\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #14534 (step 14534): 1.912610\n",
      "Batch #10\tAverage Generator Loss: 2474.345215\tAverage Discriminator Loss: 0.000019\n",
      "\n",
      "Train time for epoch #14535 (step 14535): 1.347133\n",
      "Batch #10\tAverage Generator Loss: 2093.405225\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #14536 (step 14536): 1.290351\n",
      "Batch #10\tAverage Generator Loss: 1996.605334\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #14537 (step 14537): 1.850524\n",
      "Batch #10\tAverage Generator Loss: 1915.160284\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #14538 (step 14538): 1.348572\n",
      "Batch #10\tAverage Generator Loss: 2174.033960\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #14539 (step 14539): 1.337786\n",
      "Batch #10\tAverage Generator Loss: 2173.665308\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #14540 (step 14540): 1.749997\n",
      "Batch #10\tAverage Generator Loss: 2060.969177\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #14541 (step 14541): 1.347064\n",
      "Batch #10\tAverage Generator Loss: 2048.080396\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #14542 (step 14542): 1.293296\n",
      "Batch #10\tAverage Generator Loss: 2198.348206\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #14543 (step 14543): 1.746443\n",
      "Batch #10\tAverage Generator Loss: 2086.457336\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #14544 (step 14544): 1.440212\n",
      "Batch #10\tAverage Generator Loss: 1925.037219\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #14545 (step 14545): 1.287436\n",
      "Batch #10\tAverage Generator Loss: 2031.968915\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #14546 (step 14546): 1.869456\n",
      "Batch #10\tAverage Generator Loss: 2113.070728\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #14547 (step 14547): 1.462235\n",
      "Batch #10\tAverage Generator Loss: 2146.376782\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #14548 (step 14548): 1.318870\n",
      "Batch #10\tAverage Generator Loss: 1957.796619\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #14549 (step 14549): 1.915534\n",
      "Batch #10\tAverage Generator Loss: 2208.566937\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #14550 (step 14550): 1.355527\n",
      "Batch #10\tAverage Generator Loss: 2139.921228\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #14551 (step 14551): 1.420986\n",
      "Batch #10\tAverage Generator Loss: 2308.716052\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #14552 (step 14552): 1.794303\n",
      "Batch #10\tAverage Generator Loss: 1732.884271\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #14553 (step 14553): 1.313474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2104.879211\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #14554 (step 14554): 1.334866\n",
      "Batch #10\tAverage Generator Loss: 1971.776898\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #14555 (step 14555): 1.801585\n",
      "Batch #10\tAverage Generator Loss: 2347.729980\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #14556 (step 14556): 1.362121\n",
      "Batch #10\tAverage Generator Loss: 2339.572766\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #14557 (step 14557): 1.349128\n",
      "Batch #10\tAverage Generator Loss: 2145.130603\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #14558 (step 14558): 1.883669\n",
      "Batch #10\tAverage Generator Loss: 2125.763940\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #14559 (step 14559): 1.310545\n",
      "Batch #10\tAverage Generator Loss: 2275.000433\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #14560 (step 14560): 1.236427\n",
      "Batch #10\tAverage Generator Loss: 1927.548291\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #14561 (step 14561): 1.995463\n",
      "Batch #10\tAverage Generator Loss: 1874.881104\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #14562 (step 14562): 1.388071\n",
      "Batch #10\tAverage Generator Loss: 1946.172485\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #14563 (step 14563): 1.296214\n",
      "Batch #10\tAverage Generator Loss: 2167.448120\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #14564 (step 14564): 1.943400\n",
      "Batch #10\tAverage Generator Loss: 2170.460205\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #14565 (step 14565): 1.293499\n",
      "Batch #10\tAverage Generator Loss: 1977.265918\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #14566 (step 14566): 1.283087\n",
      "Batch #10\tAverage Generator Loss: 2109.029266\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #14567 (step 14567): 1.898738\n",
      "Batch #10\tAverage Generator Loss: 2010.744592\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #14568 (step 14568): 1.450980\n",
      "Batch #10\tAverage Generator Loss: 1922.512048\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #14569 (step 14569): 1.304149\n",
      "Batch #10\tAverage Generator Loss: 2311.211865\tAverage Discriminator Loss: 0.009527\n",
      "\n",
      "Train time for epoch #14570 (step 14570): 1.797825\n",
      "Batch #10\tAverage Generator Loss: 2106.955347\tAverage Discriminator Loss: 0.000297\n",
      "\n",
      "Train time for epoch #14571 (step 14571): 1.419906\n",
      "Batch #10\tAverage Generator Loss: 1912.933502\tAverage Discriminator Loss: 0.000208\n",
      "\n",
      "Train time for epoch #14572 (step 14572): 1.291395\n",
      "Batch #10\tAverage Generator Loss: 2091.870337\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #14573 (step 14573): 1.755870\n",
      "Batch #10\tAverage Generator Loss: 2086.757263\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #14574 (step 14574): 1.359172\n",
      "Batch #10\tAverage Generator Loss: 2209.952124\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #14575 (step 14575): 1.437623\n",
      "Batch #10\tAverage Generator Loss: 2076.604797\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #14576 (step 14576): 1.796037\n",
      "Batch #10\tAverage Generator Loss: 1751.248288\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #14577 (step 14577): 1.335484\n",
      "Batch #10\tAverage Generator Loss: 1968.105347\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #14578 (step 14578): 1.306244\n",
      "Batch #10\tAverage Generator Loss: 2057.190515\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #14579 (step 14579): 1.745165\n",
      "Batch #10\tAverage Generator Loss: 2157.522021\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #14580 (step 14580): 1.495538\n",
      "Batch #10\tAverage Generator Loss: 2172.022437\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #14581 (step 14581): 1.242065\n",
      "Batch #10\tAverage Generator Loss: 1980.338965\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #14582 (step 14582): 1.809601\n",
      "Batch #10\tAverage Generator Loss: 1911.414740\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #14583 (step 14583): 1.390432\n",
      "Batch #10\tAverage Generator Loss: 2128.268054\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #14584 (step 14584): 1.340979\n",
      "Batch #10\tAverage Generator Loss: 2216.893811\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #14585 (step 14585): 1.880859\n",
      "Batch #10\tAverage Generator Loss: 2100.931580\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #14586 (step 14586): 1.339025\n",
      "Batch #10\tAverage Generator Loss: 1900.626782\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #14587 (step 14587): 1.387205\n",
      "Batch #10\tAverage Generator Loss: 1936.614191\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #14588 (step 14588): 1.799688\n",
      "Batch #10\tAverage Generator Loss: 1905.290588\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #14589 (step 14589): 1.287667\n",
      "Batch #10\tAverage Generator Loss: 1893.376379\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #14590 (step 14590): 1.290366\n",
      "Batch #10\tAverage Generator Loss: 2097.421521\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #14591 (step 14591): 1.849676\n",
      "Batch #10\tAverage Generator Loss: 2198.112659\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #14592 (step 14592): 1.399282\n",
      "Batch #10\tAverage Generator Loss: 2097.141351\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #14593 (step 14593): 1.321789\n",
      "Batch #10\tAverage Generator Loss: 1902.738940\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #14594 (step 14594): 1.895927\n",
      "Batch #10\tAverage Generator Loss: 1910.654709\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #14595 (step 14595): 1.395112\n",
      "Batch #10\tAverage Generator Loss: 1707.732104\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #14596 (step 14596): 1.313598\n",
      "Batch #10\tAverage Generator Loss: 2156.929382\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #14597 (step 14597): 1.760626\n",
      "Batch #10\tAverage Generator Loss: 2153.513892\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #14598 (step 14598): 1.289544\n",
      "Batch #10\tAverage Generator Loss: 1798.529321\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #14599 (step 14599): 1.301813\n",
      "Batch #10\tAverage Generator Loss: 2125.614197\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #14600 (step 14600): 1.883727\n",
      "Batch #10\tAverage Generator Loss: 2022.917969\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #14601 (step 14601): 1.352559\n",
      "Batch #10\tAverage Generator Loss: 1815.087115\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #14602 (step 14602): 1.336741\n",
      "Batch #10\tAverage Generator Loss: 2137.459778\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #14603 (step 14603): 1.845026\n",
      "Batch #10\tAverage Generator Loss: 1851.944110\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #14604 (step 14604): 1.289707\n",
      "Batch #10\tAverage Generator Loss: 2111.487720\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #14605 (step 14605): 1.283900\n",
      "Batch #10\tAverage Generator Loss: 1973.855811\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #14606 (step 14606): 1.767658\n",
      "Batch #10\tAverage Generator Loss: 1886.041541\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #14607 (step 14607): 1.305682\n",
      "Batch #10\tAverage Generator Loss: 1970.362787\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #14608 (step 14608): 1.291112\n",
      "Batch #10\tAverage Generator Loss: 1870.262695\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #14609 (step 14609): 1.293758\n",
      "Batch #10\tAverage Generator Loss: 2029.078223\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #14610 (step 14610): 1.788784\n",
      "Batch #10\tAverage Generator Loss: 1795.959048\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #14611 (step 14611): 1.284602\n",
      "Batch #10\tAverage Generator Loss: 1998.819653\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #14612 (step 14612): 1.331144\n",
      "Batch #10\tAverage Generator Loss: 2074.286890\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #14613 (step 14613): 1.751139\n",
      "Batch #10\tAverage Generator Loss: 1979.591296\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #14614 (step 14614): 1.293810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2132.595264\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #14615 (step 14615): 1.294825\n",
      "Batch #10\tAverage Generator Loss: 1894.425964\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #14616 (step 14616): 1.863699\n",
      "Batch #10\tAverage Generator Loss: 1789.007474\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #14617 (step 14617): 1.436050\n",
      "Batch #10\tAverage Generator Loss: 1919.853894\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #14618 (step 14618): 1.349774\n",
      "Batch #10\tAverage Generator Loss: 2201.065930\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #14619 (step 14619): 1.803899\n",
      "Batch #10\tAverage Generator Loss: 1909.990845\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #14620 (step 14620): 1.407555\n",
      "Batch #10\tAverage Generator Loss: 2030.602405\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #14621 (step 14621): 1.289840\n",
      "Batch #10\tAverage Generator Loss: 2038.199683\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #14622 (step 14622): 1.735000\n",
      "Batch #10\tAverage Generator Loss: 2220.532465\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #14623 (step 14623): 1.334063\n",
      "Batch #10\tAverage Generator Loss: 1947.130920\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #14624 (step 14624): 1.296997\n",
      "Batch #10\tAverage Generator Loss: 2189.892297\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #14625 (step 14625): 1.856350\n",
      "Batch #10\tAverage Generator Loss: 2066.757971\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #14626 (step 14626): 1.314790\n",
      "Batch #10\tAverage Generator Loss: 2237.591309\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #14627 (step 14627): 1.350513\n",
      "Batch #10\tAverage Generator Loss: 2429.072180\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #14628 (step 14628): 1.860234\n",
      "Batch #10\tAverage Generator Loss: 2014.492358\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #14629 (step 14629): 1.288655\n",
      "Batch #10\tAverage Generator Loss: 1959.154761\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #14630 (step 14630): 1.288350\n",
      "Batch #10\tAverage Generator Loss: 1864.572168\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #14631 (step 14631): 1.796757\n",
      "Batch #10\tAverage Generator Loss: 2124.837488\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #14632 (step 14632): 1.389909\n",
      "Batch #10\tAverage Generator Loss: 2007.957953\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #14633 (step 14633): 1.395086\n",
      "Batch #10\tAverage Generator Loss: 2094.615234\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #14634 (step 14634): 1.737849\n",
      "Batch #10\tAverage Generator Loss: 2274.700659\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #14635 (step 14635): 1.394963\n",
      "Batch #10\tAverage Generator Loss: 1982.403296\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #14636 (step 14636): 1.328507\n",
      "Batch #10\tAverage Generator Loss: 2082.401489\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #14637 (step 14637): 1.780601\n",
      "Batch #10\tAverage Generator Loss: 2251.067419\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #14638 (step 14638): 1.296626\n",
      "Batch #10\tAverage Generator Loss: 2173.292395\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #14639 (step 14639): 1.345088\n",
      "Batch #10\tAverage Generator Loss: 1941.649768\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #14640 (step 14640): 1.308299\n",
      "Batch #10\tAverage Generator Loss: 2001.315222\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #14641 (step 14641): 1.800345\n",
      "Batch #10\tAverage Generator Loss: 2063.684058\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #14642 (step 14642): 1.331039\n",
      "Batch #10\tAverage Generator Loss: 2101.318494\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #14643 (step 14643): 1.297227\n",
      "Batch #10\tAverage Generator Loss: 2098.054895\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #14644 (step 14644): 1.909803\n",
      "Batch #10\tAverage Generator Loss: 2185.026575\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #14645 (step 14645): 1.294029\n",
      "Batch #10\tAverage Generator Loss: 2309.245020\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #14646 (step 14646): 1.289794\n",
      "Batch #10\tAverage Generator Loss: 2185.389496\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #14647 (step 14647): 1.772073\n",
      "Batch #10\tAverage Generator Loss: 2002.536475\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #14648 (step 14648): 1.347987\n",
      "Batch #10\tAverage Generator Loss: 2147.368848\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #14649 (step 14649): 1.340765\n",
      "Batch #10\tAverage Generator Loss: 2084.789172\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #14650 (step 14650): 1.717061\n",
      "Batch #10\tAverage Generator Loss: 2186.648120\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #14651 (step 14651): 1.384826\n",
      "Batch #10\tAverage Generator Loss: 1980.806445\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #14652 (step 14652): 1.284015\n",
      "Batch #10\tAverage Generator Loss: 1797.024445\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #14653 (step 14653): 1.860956\n",
      "Batch #10\tAverage Generator Loss: 1963.082764\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #14654 (step 14654): 1.343972\n",
      "Batch #10\tAverage Generator Loss: 2003.722864\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #14655 (step 14655): 1.293102\n",
      "Batch #10\tAverage Generator Loss: 2291.738013\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #14656 (step 14656): 1.757682\n",
      "Batch #10\tAverage Generator Loss: 1877.518701\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #14657 (step 14657): 1.303819\n",
      "Batch #10\tAverage Generator Loss: 2022.663269\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #14658 (step 14658): 1.306720\n",
      "Batch #10\tAverage Generator Loss: 1755.401495\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #14659 (step 14659): 1.800489\n",
      "Batch #10\tAverage Generator Loss: 1961.166675\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #14660 (step 14660): 1.344548\n",
      "Batch #10\tAverage Generator Loss: 1965.901587\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #14661 (step 14661): 1.310136\n",
      "Batch #10\tAverage Generator Loss: 1975.529175\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #14662 (step 14662): 1.820966\n",
      "Batch #10\tAverage Generator Loss: 2188.157611\tAverage Discriminator Loss: 0.041183\n",
      "\n",
      "Train time for epoch #14663 (step 14663): 1.310617\n",
      "Batch #10\tAverage Generator Loss: 2016.962317\tAverage Discriminator Loss: 0.000045\n",
      "\n",
      "Train time for epoch #14664 (step 14664): 1.291562\n",
      "Batch #10\tAverage Generator Loss: 2053.470032\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #14665 (step 14665): 1.796088\n",
      "Batch #10\tAverage Generator Loss: 2068.785645\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #14666 (step 14666): 1.357937\n",
      "Batch #10\tAverage Generator Loss: 2272.714258\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14667 (step 14667): 1.607139\n",
      "Batch #10\tAverage Generator Loss: 2000.278821\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14668 (step 14668): 1.811371\n",
      "Batch #10\tAverage Generator Loss: 2141.739001\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14669 (step 14669): 1.297267\n",
      "Batch #10\tAverage Generator Loss: 2037.006299\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #14670 (step 14670): 1.333329\n",
      "Batch #10\tAverage Generator Loss: 1896.993311\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14671 (step 14671): 1.946895\n",
      "Batch #10\tAverage Generator Loss: 1896.773157\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14672 (step 14672): 1.477832\n",
      "Batch #10\tAverage Generator Loss: 2122.647656\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14673 (step 14673): 1.293562\n",
      "Batch #10\tAverage Generator Loss: 1883.177100\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14674 (step 14674): 1.856991\n",
      "Batch #10\tAverage Generator Loss: 2186.289709\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #14675 (step 14675): 1.401330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 1802.676672\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14676 (step 14676): 1.290502\n",
      "Batch #10\tAverage Generator Loss: 1856.405405\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14677 (step 14677): 1.860542\n",
      "Batch #10\tAverage Generator Loss: 1807.003571\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14678 (step 14678): 1.328104\n",
      "Batch #10\tAverage Generator Loss: 1950.203308\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14679 (step 14679): 1.485488\n",
      "Batch #10\tAverage Generator Loss: 2055.354919\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14680 (step 14680): 1.769600\n",
      "Batch #10\tAverage Generator Loss: 1956.846228\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14681 (step 14681): 1.358424\n",
      "Batch #10\tAverage Generator Loss: 2020.289392\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14682 (step 14682): 1.302449\n",
      "Batch #10\tAverage Generator Loss: 1763.198877\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14683 (step 14683): 1.781445\n",
      "Batch #10\tAverage Generator Loss: 1981.506799\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14684 (step 14684): 1.348536\n",
      "Batch #10\tAverage Generator Loss: 1987.235834\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14685 (step 14685): 1.347894\n",
      "Batch #10\tAverage Generator Loss: 2091.631384\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14686 (step 14686): 1.857395\n",
      "Batch #10\tAverage Generator Loss: 1796.285153\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14687 (step 14687): 1.342031\n",
      "Batch #10\tAverage Generator Loss: 1891.395349\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14688 (step 14688): 1.435643\n",
      "Batch #10\tAverage Generator Loss: 1937.208569\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14689 (step 14689): 1.739389\n",
      "Batch #10\tAverage Generator Loss: 1924.284729\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #14690 (step 14690): 1.286675\n",
      "Batch #10\tAverage Generator Loss: 1936.029425\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14691 (step 14691): 1.478824\n",
      "Batch #10\tAverage Generator Loss: 2069.468872\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14692 (step 14692): 1.806427\n",
      "Batch #10\tAverage Generator Loss: 2029.048767\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14693 (step 14693): 1.353259\n",
      "Batch #10\tAverage Generator Loss: 1894.716284\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14694 (step 14694): 1.441607\n",
      "Batch #10\tAverage Generator Loss: 1755.019421\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14695 (step 14695): 1.756229\n",
      "Batch #10\tAverage Generator Loss: 1857.335461\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14696 (step 14696): 1.286025\n",
      "Batch #10\tAverage Generator Loss: 1675.875061\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14697 (step 14697): 1.296475\n",
      "Batch #10\tAverage Generator Loss: 2117.288721\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14698 (step 14698): 1.907226\n",
      "Batch #10\tAverage Generator Loss: 1886.958362\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14699 (step 14699): 1.292800\n",
      "Batch #10\tAverage Generator Loss: 1957.515015\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14700 (step 14700): 1.394061\n",
      "Batch #10\tAverage Generator Loss: 2182.270459\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14701 (step 14701): 1.700559\n",
      "Batch #10\tAverage Generator Loss: 1881.858972\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14702 (step 14702): 1.361207\n",
      "Batch #10\tAverage Generator Loss: 2046.139673\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14703 (step 14703): 1.297542\n",
      "Batch #10\tAverage Generator Loss: 2214.827173\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14704 (step 14704): 1.839411\n",
      "Batch #10\tAverage Generator Loss: 1950.940436\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14705 (step 14705): 1.290726\n",
      "Batch #10\tAverage Generator Loss: 1873.914453\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14706 (step 14706): 1.285639\n",
      "Batch #10\tAverage Generator Loss: 1827.552258\tAverage Discriminator Loss: 0.009495\n",
      "\n",
      "Train time for epoch #14707 (step 14707): 1.339222\n",
      "Batch #10\tAverage Generator Loss: 1735.575549\tAverage Discriminator Loss: 0.021299\n",
      "\n",
      "Train time for epoch #14708 (step 14708): 1.890082\n",
      "Batch #10\tAverage Generator Loss: 1888.160962\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14709 (step 14709): 1.357310\n",
      "Batch #10\tAverage Generator Loss: 2223.075891\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14710 (step 14710): 1.396905\n",
      "Batch #10\tAverage Generator Loss: 2600.747668\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14711 (step 14711): 1.814429\n",
      "Batch #10\tAverage Generator Loss: 2173.080176\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14712 (step 14712): 1.303488\n",
      "Batch #10\tAverage Generator Loss: 1798.445398\tAverage Discriminator Loss: 0.085279\n",
      "\n",
      "Train time for epoch #14713 (step 14713): 1.336078\n",
      "Batch #10\tAverage Generator Loss: 1702.797791\tAverage Discriminator Loss: 0.001707\n",
      "\n",
      "Train time for epoch #14714 (step 14714): 1.779230\n",
      "Batch #10\tAverage Generator Loss: 1593.078247\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14715 (step 14715): 1.378768\n",
      "Batch #10\tAverage Generator Loss: 1784.103711\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14716 (step 14716): 1.281418\n",
      "Batch #10\tAverage Generator Loss: 1965.250220\tAverage Discriminator Loss: 0.002646\n",
      "\n",
      "Train time for epoch #14717 (step 14717): 1.904185\n",
      "Batch #10\tAverage Generator Loss: 1898.384821\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #14718 (step 14718): 1.342717\n",
      "Batch #10\tAverage Generator Loss: 1793.297974\tAverage Discriminator Loss: 0.000362\n",
      "\n",
      "Train time for epoch #14719 (step 14719): 1.293162\n",
      "Batch #10\tAverage Generator Loss: 1812.475592\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14720 (step 14720): 1.778876\n",
      "Batch #10\tAverage Generator Loss: 1897.248828\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14721 (step 14721): 1.334609\n",
      "Batch #10\tAverage Generator Loss: 2094.563318\tAverage Discriminator Loss: 0.008204\n",
      "\n",
      "Train time for epoch #14722 (step 14722): 1.296614\n",
      "Batch #10\tAverage Generator Loss: 2027.767065\tAverage Discriminator Loss: 0.000328\n",
      "\n",
      "Train time for epoch #14723 (step 14723): 1.873273\n",
      "Batch #10\tAverage Generator Loss: 1776.837915\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #14724 (step 14724): 1.282636\n",
      "Batch #10\tAverage Generator Loss: 1980.319604\tAverage Discriminator Loss: 0.033735\n",
      "\n",
      "Train time for epoch #14725 (step 14725): 1.383695\n",
      "Batch #10\tAverage Generator Loss: 1973.195728\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14726 (step 14726): 1.826375\n",
      "Batch #10\tAverage Generator Loss: 1805.184808\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14727 (step 14727): 1.298745\n",
      "Batch #10\tAverage Generator Loss: 2077.158008\tAverage Discriminator Loss: 0.000271\n",
      "\n",
      "Train time for epoch #14728 (step 14728): 1.280053\n",
      "Batch #10\tAverage Generator Loss: 2203.089453\tAverage Discriminator Loss: 0.235472\n",
      "\n",
      "Train time for epoch #14729 (step 14729): 1.737213\n",
      "Batch #10\tAverage Generator Loss: 2150.734546\tAverage Discriminator Loss: 0.010584\n",
      "\n",
      "Train time for epoch #14730 (step 14730): 1.308229\n",
      "Batch #10\tAverage Generator Loss: 2255.139172\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14731 (step 14731): 1.277277\n",
      "Batch #10\tAverage Generator Loss: 1923.480499\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14732 (step 14732): 1.760566\n",
      "Batch #10\tAverage Generator Loss: 2047.075903\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14733 (step 14733): 1.299547\n",
      "Batch #10\tAverage Generator Loss: 1942.668903\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14734 (step 14734): 1.288591\n",
      "Batch #10\tAverage Generator Loss: 2398.129785\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14735 (step 14735): 1.795530\n",
      "Batch #10\tAverage Generator Loss: 2058.285339\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14736 (step 14736): 1.279722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2173.905176\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14737 (step 14737): 1.352418\n",
      "Batch #10\tAverage Generator Loss: 2150.280261\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14738 (step 14738): 1.906744\n",
      "Batch #10\tAverage Generator Loss: 2226.841602\tAverage Discriminator Loss: 0.007903\n",
      "\n",
      "Train time for epoch #14739 (step 14739): 1.410708\n",
      "Batch #10\tAverage Generator Loss: 2811.685315\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14740 (step 14740): 1.288280\n",
      "Batch #10\tAverage Generator Loss: 3237.488721\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14741 (step 14741): 1.786798\n",
      "Batch #10\tAverage Generator Loss: 2801.954944\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14742 (step 14742): 1.300191\n",
      "Batch #10\tAverage Generator Loss: 2805.473901\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14743 (step 14743): 1.293092\n",
      "Batch #10\tAverage Generator Loss: 2934.794397\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14744 (step 14744): 1.291066\n",
      "Batch #10\tAverage Generator Loss: 2303.949536\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14745 (step 14745): 1.778775\n",
      "Batch #10\tAverage Generator Loss: 2399.893164\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14746 (step 14746): 1.337247\n",
      "Batch #10\tAverage Generator Loss: 2269.809021\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14747 (step 14747): 1.330317\n",
      "Batch #10\tAverage Generator Loss: 2003.752917\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14748 (step 14748): 1.795465\n",
      "Batch #10\tAverage Generator Loss: 2109.407251\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14749 (step 14749): 1.283421\n",
      "Batch #10\tAverage Generator Loss: 2090.792725\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14750 (step 14750): 1.300024\n",
      "Batch #10\tAverage Generator Loss: 2047.675861\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14751 (step 14751): 1.885128\n",
      "Batch #10\tAverage Generator Loss: 2264.653381\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14752 (step 14752): 1.250614\n",
      "Batch #10\tAverage Generator Loss: 2196.327246\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14753 (step 14753): 1.262233\n",
      "Batch #10\tAverage Generator Loss: 1793.320947\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14754 (step 14754): 1.933174\n",
      "Batch #10\tAverage Generator Loss: 2045.251831\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14755 (step 14755): 1.324754\n",
      "Batch #10\tAverage Generator Loss: 1998.956433\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14756 (step 14756): 1.295211\n",
      "Batch #10\tAverage Generator Loss: 1824.126917\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14757 (step 14757): 1.779263\n",
      "Batch #10\tAverage Generator Loss: 1937.717444\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14758 (step 14758): 1.359336\n",
      "Batch #10\tAverage Generator Loss: 2051.551080\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14759 (step 14759): 1.399743\n",
      "Batch #10\tAverage Generator Loss: 1824.201501\tAverage Discriminator Loss: 0.010964\n",
      "\n",
      "Train time for epoch #14760 (step 14760): 1.879659\n",
      "Batch #10\tAverage Generator Loss: 2107.842786\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #14761 (step 14761): 1.399518\n",
      "Batch #10\tAverage Generator Loss: 1804.809991\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14762 (step 14762): 1.344207\n",
      "Batch #10\tAverage Generator Loss: 1947.164374\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14763 (step 14763): 1.876197\n",
      "Batch #10\tAverage Generator Loss: 1665.660718\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14764 (step 14764): 1.345797\n",
      "Batch #10\tAverage Generator Loss: 2100.858508\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14765 (step 14765): 1.302881\n",
      "Batch #10\tAverage Generator Loss: 1782.297083\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #14766 (step 14766): 1.914315\n",
      "Batch #10\tAverage Generator Loss: 1824.773401\tAverage Discriminator Loss: 0.007163\n",
      "\n",
      "Train time for epoch #14767 (step 14767): 1.250306\n",
      "Batch #10\tAverage Generator Loss: 1872.932690\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14768 (step 14768): 1.349184\n",
      "Batch #10\tAverage Generator Loss: 1697.739209\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14769 (step 14769): 1.803467\n",
      "Batch #10\tAverage Generator Loss: 1760.477838\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14770 (step 14770): 1.351351\n",
      "Batch #10\tAverage Generator Loss: 1890.270007\tAverage Discriminator Loss: 0.000030\n",
      "\n",
      "Train time for epoch #14771 (step 14771): 1.581242\n",
      "Batch #10\tAverage Generator Loss: 1767.747412\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14772 (step 14772): 1.802485\n",
      "Batch #10\tAverage Generator Loss: 2055.189233\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14773 (step 14773): 1.388473\n",
      "Batch #10\tAverage Generator Loss: 1913.633899\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14774 (step 14774): 1.396318\n",
      "Batch #10\tAverage Generator Loss: 1733.816321\tAverage Discriminator Loss: 0.047863\n",
      "\n",
      "Train time for epoch #14775 (step 14775): 1.815403\n",
      "Batch #10\tAverage Generator Loss: 1981.190320\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14776 (step 14776): 1.346345\n",
      "Batch #10\tAverage Generator Loss: 2023.102502\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14777 (step 14777): 1.470815\n",
      "Batch #10\tAverage Generator Loss: 2019.262311\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14778 (step 14778): 1.759836\n",
      "Batch #10\tAverage Generator Loss: 1836.794312\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14779 (step 14779): 1.342037\n",
      "Batch #10\tAverage Generator Loss: 2001.053491\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14780 (step 14780): 1.279300\n",
      "Batch #10\tAverage Generator Loss: 1951.241071\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14781 (step 14781): 1.815119\n",
      "Batch #10\tAverage Generator Loss: 1944.735919\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14782 (step 14782): 1.346640\n",
      "Batch #10\tAverage Generator Loss: 1912.984399\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14783 (step 14783): 1.287687\n",
      "Batch #10\tAverage Generator Loss: 2086.286047\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14784 (step 14784): 1.788514\n",
      "Batch #10\tAverage Generator Loss: 2238.396277\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14785 (step 14785): 1.384479\n",
      "Batch #10\tAverage Generator Loss: 1720.465527\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14786 (step 14786): 1.479434\n",
      "Batch #10\tAverage Generator Loss: 1979.514655\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14787 (step 14787): 1.850157\n",
      "Batch #10\tAverage Generator Loss: 2033.809595\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14788 (step 14788): 1.373306\n",
      "Batch #10\tAverage Generator Loss: 2363.903003\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14789 (step 14789): 1.441572\n",
      "Batch #10\tAverage Generator Loss: 2089.502356\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14790 (step 14790): 1.421275\n",
      "Batch #10\tAverage Generator Loss: 2354.252234\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14791 (step 14791): 1.795551\n",
      "Batch #10\tAverage Generator Loss: 2064.635962\tAverage Discriminator Loss: 0.169277\n",
      "\n",
      "Train time for epoch #14792 (step 14792): 1.490555\n",
      "Batch #10\tAverage Generator Loss: 2220.596216\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14793 (step 14793): 1.394908\n",
      "Batch #10\tAverage Generator Loss: 2319.037158\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14794 (step 14794): 1.810233\n",
      "Batch #10\tAverage Generator Loss: 2161.439514\tAverage Discriminator Loss: 0.018644\n",
      "\n",
      "Train time for epoch #14795 (step 14795): 1.290775\n",
      "Batch #10\tAverage Generator Loss: 1800.074542\tAverage Discriminator Loss: 0.081132\n",
      "\n",
      "Train time for epoch #14796 (step 14796): 1.335053\n",
      "Batch #10\tAverage Generator Loss: 1833.739233\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14797 (step 14797): 1.872228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 1920.821985\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14798 (step 14798): 1.418464\n",
      "Batch #10\tAverage Generator Loss: 2430.605017\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14799 (step 14799): 1.288779\n",
      "Batch #10\tAverage Generator Loss: 2088.994727\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14800 (step 14800): 1.871031\n",
      "Batch #10\tAverage Generator Loss: 1852.328430\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14801 (step 14801): 1.394000\n",
      "Batch #10\tAverage Generator Loss: 1861.654333\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14802 (step 14802): 1.332304\n",
      "Batch #10\tAverage Generator Loss: 1965.094763\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14803 (step 14803): 1.759336\n",
      "Batch #10\tAverage Generator Loss: 2160.735925\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14804 (step 14804): 1.431883\n",
      "Batch #10\tAverage Generator Loss: 2139.550226\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14805 (step 14805): 1.290175\n",
      "Batch #10\tAverage Generator Loss: 2063.410529\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #14806 (step 14806): 1.796857\n",
      "Batch #10\tAverage Generator Loss: 1969.947913\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14807 (step 14807): 1.442570\n",
      "Batch #10\tAverage Generator Loss: 1776.485242\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14808 (step 14808): 1.343566\n",
      "Batch #10\tAverage Generator Loss: 1968.076685\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14809 (step 14809): 1.909543\n",
      "Batch #10\tAverage Generator Loss: 2124.477161\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14810 (step 14810): 1.289155\n",
      "Batch #10\tAverage Generator Loss: 2213.609619\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14811 (step 14811): 1.276782\n",
      "Batch #10\tAverage Generator Loss: 2060.294763\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14812 (step 14812): 1.299431\n",
      "Batch #10\tAverage Generator Loss: 1744.701721\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14813 (step 14813): 1.801945\n",
      "Batch #10\tAverage Generator Loss: 1941.613434\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14814 (step 14814): 1.370292\n",
      "Batch #10\tAverage Generator Loss: 2071.823108\tAverage Discriminator Loss: 0.000156\n",
      "\n",
      "Train time for epoch #14815 (step 14815): 1.287848\n",
      "Batch #10\tAverage Generator Loss: 1998.537872\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14816 (step 14816): 1.811751\n",
      "Batch #10\tAverage Generator Loss: 2123.846820\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14817 (step 14817): 1.390415\n",
      "Batch #10\tAverage Generator Loss: 1902.377264\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14818 (step 14818): 1.293512\n",
      "Batch #10\tAverage Generator Loss: 2029.418152\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14819 (step 14819): 1.756464\n",
      "Batch #10\tAverage Generator Loss: 1979.262561\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14820 (step 14820): 1.395573\n",
      "Batch #10\tAverage Generator Loss: 1731.521838\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14821 (step 14821): 1.346694\n",
      "Batch #10\tAverage Generator Loss: 1878.817523\tAverage Discriminator Loss: 0.014210\n",
      "\n",
      "Train time for epoch #14822 (step 14822): 1.947496\n",
      "Batch #10\tAverage Generator Loss: 2217.443701\tAverage Discriminator Loss: 0.053522\n",
      "\n",
      "Train time for epoch #14823 (step 14823): 1.343894\n",
      "Batch #10\tAverage Generator Loss: 1906.159863\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14824 (step 14824): 1.290370\n",
      "Batch #10\tAverage Generator Loss: 2158.734216\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14825 (step 14825): 2.000722\n",
      "Batch #10\tAverage Generator Loss: 2118.667065\tAverage Discriminator Loss: 0.044624\n",
      "\n",
      "Train time for epoch #14826 (step 14826): 1.295882\n",
      "Batch #10\tAverage Generator Loss: 2248.944629\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #14827 (step 14827): 1.354144\n",
      "Batch #10\tAverage Generator Loss: 1900.805908\tAverage Discriminator Loss: 0.000581\n",
      "\n",
      "Train time for epoch #14828 (step 14828): 1.794342\n",
      "Batch #10\tAverage Generator Loss: 2261.994324\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14829 (step 14829): 1.284911\n",
      "Batch #10\tAverage Generator Loss: 1803.009064\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14830 (step 14830): 1.350417\n",
      "Batch #10\tAverage Generator Loss: 1970.630072\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14831 (step 14831): 1.725896\n",
      "Batch #10\tAverage Generator Loss: 1741.462683\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14832 (step 14832): 1.286234\n",
      "Batch #10\tAverage Generator Loss: 1763.134027\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14833 (step 14833): 1.314059\n",
      "Batch #10\tAverage Generator Loss: 1839.721271\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14834 (step 14834): 1.853457\n",
      "Batch #10\tAverage Generator Loss: 1704.481458\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14835 (step 14835): 1.237329\n",
      "Batch #10\tAverage Generator Loss: 1832.260364\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14836 (step 14836): 1.333535\n",
      "Batch #10\tAverage Generator Loss: 1621.284344\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14837 (step 14837): 1.912499\n",
      "Batch #10\tAverage Generator Loss: 1759.843103\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #14838 (step 14838): 1.325694\n",
      "Batch #10\tAverage Generator Loss: 1856.600659\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14839 (step 14839): 1.279171\n",
      "Batch #10\tAverage Generator Loss: 1801.542786\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #14840 (step 14840): 1.851376\n",
      "Batch #10\tAverage Generator Loss: 1161.730341\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14841 (step 14841): 1.335294\n",
      "Batch #10\tAverage Generator Loss: 1734.065503\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14842 (step 14842): 1.353454\n",
      "Batch #10\tAverage Generator Loss: 1840.397876\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14843 (step 14843): 1.831019\n",
      "Batch #10\tAverage Generator Loss: 2069.587018\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14844 (step 14844): 1.355396\n",
      "Batch #10\tAverage Generator Loss: 1779.341260\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14845 (step 14845): 1.338701\n",
      "Batch #10\tAverage Generator Loss: 1821.947083\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14846 (step 14846): 1.810157\n",
      "Batch #10\tAverage Generator Loss: 1818.975696\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14847 (step 14847): 1.365675\n",
      "Batch #10\tAverage Generator Loss: 1794.614612\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14848 (step 14848): 1.300743\n",
      "Batch #10\tAverage Generator Loss: 1713.506726\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14849 (step 14849): 1.922566\n",
      "Batch #10\tAverage Generator Loss: 1791.740845\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14850 (step 14850): 1.327425\n",
      "Batch #10\tAverage Generator Loss: 1786.689203\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14851 (step 14851): 1.279072\n",
      "Batch #10\tAverage Generator Loss: 1898.902808\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14852 (step 14852): 1.478139\n",
      "Batch #10\tAverage Generator Loss: 1800.723593\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14853 (step 14853): 1.855352\n",
      "Batch #10\tAverage Generator Loss: 1806.592236\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14854 (step 14854): 1.329496\n",
      "Batch #10\tAverage Generator Loss: 1838.489008\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14855 (step 14855): 1.293823\n",
      "Batch #10\tAverage Generator Loss: 1721.195142\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14856 (step 14856): 1.808851\n",
      "Batch #10\tAverage Generator Loss: 1526.436835\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14857 (step 14857): 1.288174\n",
      "Batch #10\tAverage Generator Loss: 1649.861041\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14858 (step 14858): 1.454531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 1860.366431\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14859 (step 14859): 1.837245\n",
      "Batch #10\tAverage Generator Loss: 1730.565594\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14860 (step 14860): 1.327369\n",
      "Batch #10\tAverage Generator Loss: 1579.092102\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14861 (step 14861): 1.245723\n",
      "Batch #10\tAverage Generator Loss: 1648.970203\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14862 (step 14862): 1.881711\n",
      "Batch #10\tAverage Generator Loss: 1715.235840\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14863 (step 14863): 1.498490\n",
      "Batch #10\tAverage Generator Loss: 1723.386328\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14864 (step 14864): 1.399884\n",
      "Batch #10\tAverage Generator Loss: 1576.531586\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14865 (step 14865): 1.846524\n",
      "Batch #10\tAverage Generator Loss: 1880.220862\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14866 (step 14866): 1.399351\n",
      "Batch #10\tAverage Generator Loss: 1744.024561\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14867 (step 14867): 1.291748\n",
      "Batch #10\tAverage Generator Loss: 1758.431763\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14868 (step 14868): 1.828748\n",
      "Batch #10\tAverage Generator Loss: 1777.364453\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14869 (step 14869): 1.404913\n",
      "Batch #10\tAverage Generator Loss: 1664.697986\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14870 (step 14870): 1.386700\n",
      "Batch #10\tAverage Generator Loss: 1872.182855\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14871 (step 14871): 1.898915\n",
      "Batch #10\tAverage Generator Loss: 1788.659900\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14872 (step 14872): 1.299481\n",
      "Batch #10\tAverage Generator Loss: 1757.387335\tAverage Discriminator Loss: 0.018100\n",
      "\n",
      "Train time for epoch #14873 (step 14873): 1.436333\n",
      "Batch #10\tAverage Generator Loss: 1822.826257\tAverage Discriminator Loss: 0.007457\n",
      "\n",
      "Train time for epoch #14874 (step 14874): 1.805220\n",
      "Batch #10\tAverage Generator Loss: 1720.307355\tAverage Discriminator Loss: 0.002662\n",
      "\n",
      "Train time for epoch #14875 (step 14875): 1.305516\n",
      "Batch #10\tAverage Generator Loss: 1790.665533\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14876 (step 14876): 1.291443\n",
      "Batch #10\tAverage Generator Loss: 1720.459558\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14877 (step 14877): 1.796226\n",
      "Batch #10\tAverage Generator Loss: 1884.891187\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14878 (step 14878): 1.450666\n",
      "Batch #10\tAverage Generator Loss: 1780.483057\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14879 (step 14879): 1.337554\n",
      "Batch #10\tAverage Generator Loss: 1664.750848\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14880 (step 14880): 1.842753\n",
      "Batch #10\tAverage Generator Loss: 1928.627466\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14881 (step 14881): 1.331388\n",
      "Batch #10\tAverage Generator Loss: 1818.393134\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14882 (step 14882): 1.306457\n",
      "Batch #10\tAverage Generator Loss: 1622.107269\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14883 (step 14883): 1.828548\n",
      "Batch #10\tAverage Generator Loss: 1807.833289\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14884 (step 14884): 1.339190\n",
      "Batch #10\tAverage Generator Loss: 1560.007855\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14885 (step 14885): 1.395694\n",
      "Batch #10\tAverage Generator Loss: 1873.117828\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14886 (step 14886): 1.354608\n",
      "Batch #10\tAverage Generator Loss: 1773.311963\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14887 (step 14887): 1.749113\n",
      "Batch #10\tAverage Generator Loss: 1852.544434\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14888 (step 14888): 1.385761\n",
      "Batch #10\tAverage Generator Loss: 1634.321313\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14889 (step 14889): 1.338938\n",
      "Batch #10\tAverage Generator Loss: 1609.366034\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14890 (step 14890): 1.769706\n",
      "Batch #10\tAverage Generator Loss: 1682.672729\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14891 (step 14891): 1.431818\n",
      "Batch #10\tAverage Generator Loss: 1831.855200\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14892 (step 14892): 1.402546\n",
      "Batch #10\tAverage Generator Loss: 1683.912842\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14893 (step 14893): 1.756637\n",
      "Batch #10\tAverage Generator Loss: 1789.945203\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14894 (step 14894): 1.471746\n",
      "Batch #10\tAverage Generator Loss: 1724.179395\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14895 (step 14895): 1.289699\n",
      "Batch #10\tAverage Generator Loss: 1858.623437\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14896 (step 14896): 1.749050\n",
      "Batch #10\tAverage Generator Loss: 1728.410297\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14897 (step 14897): 1.321834\n",
      "Batch #10\tAverage Generator Loss: 1653.326202\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #14898 (step 14898): 1.388601\n",
      "Batch #10\tAverage Generator Loss: 1627.685687\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14899 (step 14899): 1.762244\n",
      "Batch #10\tAverage Generator Loss: 1735.436877\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14900 (step 14900): 1.280970\n",
      "Batch #10\tAverage Generator Loss: 1743.519977\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14901 (step 14901): 1.289116\n",
      "Batch #10\tAverage Generator Loss: 1879.799890\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14902 (step 14902): 1.828487\n",
      "Batch #10\tAverage Generator Loss: 1730.666705\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14903 (step 14903): 1.441296\n",
      "Batch #10\tAverage Generator Loss: 1867.166406\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14904 (step 14904): 1.253387\n",
      "Batch #10\tAverage Generator Loss: 1594.098975\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14905 (step 14905): 1.899338\n",
      "Batch #10\tAverage Generator Loss: 1968.106934\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14906 (step 14906): 1.288993\n",
      "Batch #10\tAverage Generator Loss: 1911.129028\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14907 (step 14907): 1.329998\n",
      "Batch #10\tAverage Generator Loss: 1901.781750\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14908 (step 14908): 1.784350\n",
      "Batch #10\tAverage Generator Loss: 2082.645227\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14909 (step 14909): 1.326086\n",
      "Batch #10\tAverage Generator Loss: 1716.695825\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14910 (step 14910): 1.404342\n",
      "Batch #10\tAverage Generator Loss: 1495.796887\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14911 (step 14911): 1.462212\n",
      "Batch #10\tAverage Generator Loss: 1789.735437\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14912 (step 14912): 1.880518\n",
      "Batch #10\tAverage Generator Loss: 1882.901416\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14913 (step 14913): 1.359693\n",
      "Batch #10\tAverage Generator Loss: 1625.037836\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14914 (step 14914): 1.389931\n",
      "Batch #10\tAverage Generator Loss: 1889.461182\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14915 (step 14915): 1.867048\n",
      "Batch #10\tAverage Generator Loss: 1667.910699\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14916 (step 14916): 1.277321\n",
      "Batch #10\tAverage Generator Loss: 1716.240906\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14917 (step 14917): 1.333661\n",
      "Batch #10\tAverage Generator Loss: 1810.036998\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14918 (step 14918): 1.853096\n",
      "Batch #10\tAverage Generator Loss: 1801.973669\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14919 (step 14919): 1.297658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 1824.401770\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14920 (step 14920): 1.435104\n",
      "Batch #10\tAverage Generator Loss: 1733.642340\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14921 (step 14921): 1.781376\n",
      "Batch #10\tAverage Generator Loss: 1711.227100\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14922 (step 14922): 1.365621\n",
      "Batch #10\tAverage Generator Loss: 1807.088599\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #14923 (step 14923): 1.325977\n",
      "Batch #10\tAverage Generator Loss: 1757.535352\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #14924 (step 14924): 1.901763\n",
      "Batch #10\tAverage Generator Loss: 1775.981296\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14925 (step 14925): 1.378579\n",
      "Batch #10\tAverage Generator Loss: 1577.415717\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14926 (step 14926): 1.379903\n",
      "Batch #10\tAverage Generator Loss: 1865.670190\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14927 (step 14927): 1.904042\n",
      "Batch #10\tAverage Generator Loss: 1637.241315\tAverage Discriminator Loss: 0.003725\n",
      "\n",
      "Train time for epoch #14928 (step 14928): 1.389394\n",
      "Batch #10\tAverage Generator Loss: 1872.229309\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #14929 (step 14929): 1.518986\n",
      "Batch #10\tAverage Generator Loss: 1959.181958\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #14930 (step 14930): 1.841098\n",
      "Batch #10\tAverage Generator Loss: 1513.919476\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #14931 (step 14931): 1.376025\n",
      "Batch #10\tAverage Generator Loss: 1856.974200\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #14932 (step 14932): 1.508385\n",
      "Batch #10\tAverage Generator Loss: 1313.021481\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #14933 (step 14933): 1.743023\n",
      "Batch #10\tAverage Generator Loss: 1658.146912\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #14934 (step 14934): 1.336168\n",
      "Batch #10\tAverage Generator Loss: 1521.516022\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #14935 (step 14935): 1.334270\n",
      "Batch #10\tAverage Generator Loss: 1746.672498\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #14936 (step 14936): 1.814156\n",
      "Batch #10\tAverage Generator Loss: 1735.689478\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #14937 (step 14937): 1.293614\n",
      "Batch #10\tAverage Generator Loss: 1726.400012\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #14938 (step 14938): 1.441320\n",
      "Batch #10\tAverage Generator Loss: 1797.212555\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #14939 (step 14939): 1.791459\n",
      "Batch #10\tAverage Generator Loss: 1733.255969\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #14940 (step 14940): 1.275731\n",
      "Batch #10\tAverage Generator Loss: 1627.439124\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #14941 (step 14941): 1.470058\n",
      "Batch #10\tAverage Generator Loss: 1614.598218\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #14942 (step 14942): 1.384708\n",
      "Batch #10\tAverage Generator Loss: 1552.095013\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #14943 (step 14943): 1.852880\n",
      "Batch #10\tAverage Generator Loss: 1665.133289\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #14944 (step 14944): 1.290945\n",
      "Batch #10\tAverage Generator Loss: 1684.826764\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #14945 (step 14945): 1.343410\n",
      "Batch #10\tAverage Generator Loss: 1888.669824\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #14946 (step 14946): 1.895431\n",
      "Batch #10\tAverage Generator Loss: 1758.981042\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #14947 (step 14947): 1.343265\n",
      "Batch #10\tAverage Generator Loss: 1858.271362\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #14948 (step 14948): 1.302096\n",
      "Batch #10\tAverage Generator Loss: 1703.741220\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #14949 (step 14949): 1.910712\n",
      "Batch #10\tAverage Generator Loss: 1664.379199\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #14950 (step 14950): 1.351170\n",
      "Batch #10\tAverage Generator Loss: 1773.912256\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #14951 (step 14951): 1.340582\n",
      "Batch #10\tAverage Generator Loss: 1797.769604\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #14952 (step 14952): 1.804490\n",
      "Batch #10\tAverage Generator Loss: 1649.470972\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #14953 (step 14953): 1.275743\n",
      "Batch #10\tAverage Generator Loss: 1861.602148\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #14954 (step 14954): 1.286109\n",
      "Batch #10\tAverage Generator Loss: 1844.744519\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #14955 (step 14955): 2.031716\n",
      "Batch #10\tAverage Generator Loss: 1598.800128\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #14956 (step 14956): 1.336603\n",
      "Batch #10\tAverage Generator Loss: 1829.432275\tAverage Discriminator Loss: 0.738602\n",
      "\n",
      "Train time for epoch #14957 (step 14957): 1.291683\n",
      "Batch #10\tAverage Generator Loss: 2583.766187\tAverage Discriminator Loss: 0.074139\n",
      "\n",
      "Train time for epoch #14958 (step 14958): 1.290426\n",
      "Batch #10\tAverage Generator Loss: 1966.692834\tAverage Discriminator Loss: 1.703874\n",
      "\n",
      "Train time for epoch #14959 (step 14959): 1.838511\n",
      "Batch #10\tAverage Generator Loss: 1912.065198\tAverage Discriminator Loss: 0.468192\n",
      "\n",
      "Train time for epoch #14960 (step 14960): 1.300113\n",
      "Batch #10\tAverage Generator Loss: 1759.675128\tAverage Discriminator Loss: 0.031802\n",
      "\n",
      "Train time for epoch #14961 (step 14961): 1.281965\n",
      "Batch #10\tAverage Generator Loss: 2034.294495\tAverage Discriminator Loss: 0.000600\n",
      "\n",
      "Train time for epoch #14962 (step 14962): 1.922276\n",
      "Batch #10\tAverage Generator Loss: 1914.509937\tAverage Discriminator Loss: 0.018067\n",
      "\n",
      "Train time for epoch #14963 (step 14963): 1.387462\n",
      "Batch #10\tAverage Generator Loss: 1730.051697\tAverage Discriminator Loss: 0.000350\n",
      "\n",
      "Train time for epoch #14964 (step 14964): 1.335214\n",
      "Batch #10\tAverage Generator Loss: 2287.588574\tAverage Discriminator Loss: 0.000812\n",
      "\n",
      "Train time for epoch #14965 (step 14965): 1.864686\n",
      "Batch #10\tAverage Generator Loss: 2117.027783\tAverage Discriminator Loss: 0.000019\n",
      "\n",
      "Train time for epoch #14966 (step 14966): 1.323243\n",
      "Batch #10\tAverage Generator Loss: 2310.723437\tAverage Discriminator Loss: 0.000101\n",
      "\n",
      "Train time for epoch #14967 (step 14967): 1.354758\n",
      "Batch #10\tAverage Generator Loss: 1938.331793\tAverage Discriminator Loss: 0.000139\n",
      "\n",
      "Train time for epoch #14968 (step 14968): 1.881423\n",
      "Batch #10\tAverage Generator Loss: 2608.217908\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #14969 (step 14969): 1.356786\n",
      "Batch #10\tAverage Generator Loss: 2189.459949\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #14970 (step 14970): 1.397240\n",
      "Batch #10\tAverage Generator Loss: 2303.573572\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #14971 (step 14971): 1.761440\n",
      "Batch #10\tAverage Generator Loss: 2668.619360\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #14972 (step 14972): 1.392971\n",
      "Batch #10\tAverage Generator Loss: 2297.374475\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #14973 (step 14973): 1.257197\n",
      "Batch #10\tAverage Generator Loss: 2389.131714\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #14974 (step 14974): 1.783759\n",
      "Batch #10\tAverage Generator Loss: 2296.562195\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #14975 (step 14975): 1.375820\n",
      "Batch #10\tAverage Generator Loss: 2174.109290\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #14976 (step 14976): 1.269880\n",
      "Batch #10\tAverage Generator Loss: 2186.429919\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #14977 (step 14977): 1.291240\n",
      "Batch #10\tAverage Generator Loss: 2625.185999\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #14978 (step 14978): 1.739003\n",
      "Batch #10\tAverage Generator Loss: 2251.388049\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #14979 (step 14979): 1.326432\n",
      "Batch #10\tAverage Generator Loss: 2228.180225\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #14980 (step 14980): 1.320293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2178.293237\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #14981 (step 14981): 1.916614\n",
      "Batch #10\tAverage Generator Loss: 2155.501245\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #14982 (step 14982): 1.438136\n",
      "Batch #10\tAverage Generator Loss: 2292.554749\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #14983 (step 14983): 1.393964\n",
      "Batch #10\tAverage Generator Loss: 2046.492072\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #14984 (step 14984): 1.990417\n",
      "Batch #10\tAverage Generator Loss: 2270.858948\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #14985 (step 14985): 1.332782\n",
      "Batch #10\tAverage Generator Loss: 2294.654132\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #14986 (step 14986): 1.341754\n",
      "Batch #10\tAverage Generator Loss: 2092.657019\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #14987 (step 14987): 1.920756\n",
      "Batch #10\tAverage Generator Loss: 1795.123853\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #14988 (step 14988): 1.473463\n",
      "Batch #10\tAverage Generator Loss: 2106.556488\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #14989 (step 14989): 1.333627\n",
      "Batch #10\tAverage Generator Loss: 1957.394519\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #14990 (step 14990): 1.809869\n",
      "Batch #10\tAverage Generator Loss: 2404.570630\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #14991 (step 14991): 1.300740\n",
      "Batch #10\tAverage Generator Loss: 2237.215991\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #14992 (step 14992): 1.339370\n",
      "Batch #10\tAverage Generator Loss: 2454.061646\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #14993 (step 14993): 1.833297\n",
      "Batch #10\tAverage Generator Loss: 2126.556439\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #14994 (step 14994): 1.284996\n",
      "Batch #10\tAverage Generator Loss: 2309.352795\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #14995 (step 14995): 1.306089\n",
      "Batch #10\tAverage Generator Loss: 2415.248120\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #14996 (step 14996): 1.911774\n",
      "Batch #10\tAverage Generator Loss: 2018.596021\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #14997 (step 14997): 1.306393\n",
      "Batch #10\tAverage Generator Loss: 2307.274329\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #14998 (step 14998): 1.353390\n",
      "Batch #10\tAverage Generator Loss: 2297.008191\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #14999 (step 14999): 1.912530\n",
      "Batch #10\tAverage Generator Loss: 2065.812946\tAverage Discriminator Loss: 0.021554\n",
      "\n",
      "Train time for epoch #15000 (step 15000): 1.280249\n",
      "Batch #10\tAverage Generator Loss: 1960.053052\tAverage Discriminator Loss: 0.045986\n",
      "\n",
      "Train time for epoch #15001 (step 15001): 1.283583\n",
      "Batch #10\tAverage Generator Loss: 2465.773193\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15002 (step 15002): 1.385331\n",
      "Batch #10\tAverage Generator Loss: 2305.316541\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #15003 (step 15003): 1.816360\n",
      "Batch #10\tAverage Generator Loss: 2383.396460\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #15004 (step 15004): 1.377285\n",
      "Batch #10\tAverage Generator Loss: 2214.729346\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15005 (step 15005): 1.384926\n",
      "Batch #10\tAverage Generator Loss: 2401.061328\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #15006 (step 15006): 1.929096\n",
      "Batch #10\tAverage Generator Loss: 2556.326355\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #15007 (step 15007): 1.423570\n",
      "Batch #10\tAverage Generator Loss: 2561.645660\tAverage Discriminator Loss: 0.001840\n",
      "\n",
      "Train time for epoch #15008 (step 15008): 1.313704\n",
      "Batch #10\tAverage Generator Loss: 2625.792725\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15009 (step 15009): 1.759242\n",
      "Batch #10\tAverage Generator Loss: 2403.302966\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #15010 (step 15010): 1.421979\n",
      "Batch #10\tAverage Generator Loss: 2266.218750\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #15011 (step 15011): 1.368710\n",
      "Batch #10\tAverage Generator Loss: 2283.738971\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15012 (step 15012): 1.801157\n",
      "Batch #10\tAverage Generator Loss: 2455.838831\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15013 (step 15013): 1.271187\n",
      "Batch #10\tAverage Generator Loss: 2038.112256\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15014 (step 15014): 1.389787\n",
      "Batch #10\tAverage Generator Loss: 2487.702197\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15015 (step 15015): 1.924007\n",
      "Batch #10\tAverage Generator Loss: 2212.351233\tAverage Discriminator Loss: 0.001474\n",
      "\n",
      "Train time for epoch #15016 (step 15016): 1.513240\n",
      "Batch #10\tAverage Generator Loss: 2284.273334\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15017 (step 15017): 1.332338\n",
      "Batch #10\tAverage Generator Loss: 2236.020685\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15018 (step 15018): 1.928015\n",
      "Batch #10\tAverage Generator Loss: 2161.241248\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15019 (step 15019): 1.309305\n",
      "Batch #10\tAverage Generator Loss: 2476.183752\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15020 (step 15020): 1.410414\n",
      "Batch #10\tAverage Generator Loss: 2146.329614\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15021 (step 15021): 2.031701\n",
      "Batch #10\tAverage Generator Loss: 2430.522595\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15022 (step 15022): 1.395924\n",
      "Batch #10\tAverage Generator Loss: 2422.282629\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15023 (step 15023): 1.440725\n",
      "Batch #10\tAverage Generator Loss: 2449.878394\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15024 (step 15024): 1.838935\n",
      "Batch #10\tAverage Generator Loss: 2631.727576\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15025 (step 15025): 1.336030\n",
      "Batch #10\tAverage Generator Loss: 2015.932251\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15026 (step 15026): 1.410880\n",
      "Batch #10\tAverage Generator Loss: 2152.095074\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15027 (step 15027): 1.809923\n",
      "Batch #10\tAverage Generator Loss: 2328.198816\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15028 (step 15028): 1.530040\n",
      "Batch #10\tAverage Generator Loss: 2072.232629\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15029 (step 15029): 1.278632\n",
      "Batch #10\tAverage Generator Loss: 2552.420996\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15030 (step 15030): 1.862642\n",
      "Batch #10\tAverage Generator Loss: 2136.943677\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15031 (step 15031): 1.323875\n",
      "Batch #10\tAverage Generator Loss: 2133.265796\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15032 (step 15032): 1.305884\n",
      "Batch #10\tAverage Generator Loss: 2381.815955\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15033 (step 15033): 1.405657\n",
      "Batch #10\tAverage Generator Loss: 2154.390637\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15034 (step 15034): 1.962641\n",
      "Batch #10\tAverage Generator Loss: 2323.840210\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15035 (step 15035): 1.494888\n",
      "Batch #10\tAverage Generator Loss: 2151.158807\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15036 (step 15036): 1.330929\n",
      "Batch #10\tAverage Generator Loss: 2174.715271\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15037 (step 15037): 1.852836\n",
      "Batch #10\tAverage Generator Loss: 2141.880225\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15038 (step 15038): 1.288852\n",
      "Batch #10\tAverage Generator Loss: 2215.495068\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15039 (step 15039): 1.338289\n",
      "Batch #10\tAverage Generator Loss: 2436.080530\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15040 (step 15040): 1.850363\n",
      "Batch #10\tAverage Generator Loss: 2385.374805\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15041 (step 15041): 1.383944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2399.953101\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15042 (step 15042): 1.440107\n",
      "Batch #10\tAverage Generator Loss: 2409.551855\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15043 (step 15043): 1.736691\n",
      "Batch #10\tAverage Generator Loss: 2396.653406\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15044 (step 15044): 1.233320\n",
      "Batch #10\tAverage Generator Loss: 2159.784216\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15045 (step 15045): 1.350523\n",
      "Batch #10\tAverage Generator Loss: 2346.652197\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15046 (step 15046): 1.766875\n",
      "Batch #10\tAverage Generator Loss: 2252.375696\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15047 (step 15047): 1.353164\n",
      "Batch #10\tAverage Generator Loss: 2500.202258\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15048 (step 15048): 1.354956\n",
      "Batch #10\tAverage Generator Loss: 2190.936255\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15049 (step 15049): 1.392025\n",
      "Batch #10\tAverage Generator Loss: 2225.576428\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15050 (step 15050): 1.851462\n",
      "Batch #10\tAverage Generator Loss: 2157.834619\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15051 (step 15051): 1.231531\n",
      "Batch #10\tAverage Generator Loss: 2603.346759\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15052 (step 15052): 1.285412\n",
      "Batch #10\tAverage Generator Loss: 1882.198853\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15053 (step 15053): 1.836939\n",
      "Batch #10\tAverage Generator Loss: 2447.067700\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15054 (step 15054): 1.298458\n",
      "Batch #10\tAverage Generator Loss: 2195.300299\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15055 (step 15055): 1.386379\n",
      "Batch #10\tAverage Generator Loss: 2093.161584\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15056 (step 15056): 1.874655\n",
      "Batch #10\tAverage Generator Loss: 2239.917053\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15057 (step 15057): 1.388175\n",
      "Batch #10\tAverage Generator Loss: 2109.236813\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15058 (step 15058): 1.395025\n",
      "Batch #10\tAverage Generator Loss: 2138.410730\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15059 (step 15059): 1.958327\n",
      "Batch #10\tAverage Generator Loss: 2230.404614\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15060 (step 15060): 1.347016\n",
      "Batch #10\tAverage Generator Loss: 2145.014392\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15061 (step 15061): 1.297411\n",
      "Batch #10\tAverage Generator Loss: 1981.597797\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15062 (step 15062): 1.868121\n",
      "Batch #10\tAverage Generator Loss: 1989.578418\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15063 (step 15063): 1.297753\n",
      "Batch #10\tAverage Generator Loss: 2557.018860\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15064 (step 15064): 1.284844\n",
      "Batch #10\tAverage Generator Loss: 2292.052661\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15065 (step 15065): 1.827817\n",
      "Batch #10\tAverage Generator Loss: 2351.989832\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15066 (step 15066): 1.443355\n",
      "Batch #10\tAverage Generator Loss: 2235.184729\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15067 (step 15067): 1.341924\n",
      "Batch #10\tAverage Generator Loss: 2287.569727\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15068 (step 15068): 1.444942\n",
      "Batch #10\tAverage Generator Loss: 2148.531543\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15069 (step 15069): 1.846735\n",
      "Batch #10\tAverage Generator Loss: 2525.841223\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15070 (step 15070): 1.277632\n",
      "Batch #10\tAverage Generator Loss: 2207.554456\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15071 (step 15071): 1.388516\n",
      "Batch #10\tAverage Generator Loss: 2309.759216\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15072 (step 15072): 1.835007\n",
      "Batch #10\tAverage Generator Loss: 2156.378406\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15073 (step 15073): 1.381895\n",
      "Batch #10\tAverage Generator Loss: 2347.480908\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15074 (step 15074): 1.343902\n",
      "Batch #10\tAverage Generator Loss: 2312.359888\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15075 (step 15075): 1.816569\n",
      "Batch #10\tAverage Generator Loss: 2027.703210\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15076 (step 15076): 1.289786\n",
      "Batch #10\tAverage Generator Loss: 2425.808362\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15077 (step 15077): 1.388110\n",
      "Batch #10\tAverage Generator Loss: 2501.946472\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15078 (step 15078): 1.811573\n",
      "Batch #10\tAverage Generator Loss: 2684.001550\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15079 (step 15079): 1.352386\n",
      "Batch #10\tAverage Generator Loss: 2512.446265\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15080 (step 15080): 1.322988\n",
      "Batch #10\tAverage Generator Loss: 2341.713550\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15081 (step 15081): 1.811935\n",
      "Batch #10\tAverage Generator Loss: 2389.050568\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15082 (step 15082): 1.357163\n",
      "Batch #10\tAverage Generator Loss: 2210.543066\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15083 (step 15083): 1.271469\n",
      "Batch #10\tAverage Generator Loss: 2571.367285\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15084 (step 15084): 1.946066\n",
      "Batch #10\tAverage Generator Loss: 2535.563977\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15085 (step 15085): 1.332843\n",
      "Batch #10\tAverage Generator Loss: 2423.178271\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15086 (step 15086): 1.366903\n",
      "Batch #10\tAverage Generator Loss: 2121.840192\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15087 (step 15087): 1.347048\n",
      "Batch #10\tAverage Generator Loss: 2283.067389\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15088 (step 15088): 1.819910\n",
      "Batch #10\tAverage Generator Loss: 2386.156750\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15089 (step 15089): 1.385290\n",
      "Batch #10\tAverage Generator Loss: 2533.124792\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15090 (step 15090): 1.430496\n",
      "Batch #10\tAverage Generator Loss: 2217.130957\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15091 (step 15091): 1.812227\n",
      "Batch #10\tAverage Generator Loss: 2284.768536\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15092 (step 15092): 1.382623\n",
      "Batch #10\tAverage Generator Loss: 2283.329749\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15093 (step 15093): 1.286323\n",
      "Batch #10\tAverage Generator Loss: 2369.506531\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15094 (step 15094): 1.827753\n",
      "Batch #10\tAverage Generator Loss: 2478.099390\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15095 (step 15095): 1.335912\n",
      "Batch #10\tAverage Generator Loss: 2486.322534\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15096 (step 15096): 1.405118\n",
      "Batch #10\tAverage Generator Loss: 2427.806470\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #15097 (step 15097): 1.887551\n",
      "Batch #10\tAverage Generator Loss: 2344.947284\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15098 (step 15098): 1.326169\n",
      "Batch #10\tAverage Generator Loss: 2218.431140\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15099 (step 15099): 1.341857\n",
      "Batch #10\tAverage Generator Loss: 2433.131952\tAverage Discriminator Loss: 0.050591\n",
      "\n",
      "Train time for epoch #15100 (step 15100): 1.824871\n",
      "Batch #10\tAverage Generator Loss: 2351.505127\tAverage Discriminator Loss: 0.000389\n",
      "\n",
      "Train time for epoch #15101 (step 15101): 1.287887\n",
      "Batch #10\tAverage Generator Loss: 2517.575098\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #15102 (step 15102): 1.286357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2367.457947\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #15103 (step 15103): 1.809650\n",
      "Batch #10\tAverage Generator Loss: 2253.889224\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15104 (step 15104): 1.367792\n",
      "Batch #10\tAverage Generator Loss: 2332.933459\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15105 (step 15105): 1.455276\n",
      "Batch #10\tAverage Generator Loss: 2473.084924\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15106 (step 15106): 1.824692\n",
      "Batch #10\tAverage Generator Loss: 2188.140430\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15107 (step 15107): 1.345593\n",
      "Batch #10\tAverage Generator Loss: 2615.674915\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15108 (step 15108): 1.382674\n",
      "Batch #10\tAverage Generator Loss: 2413.862500\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15109 (step 15109): 1.778791\n",
      "Batch #10\tAverage Generator Loss: 2343.467834\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15110 (step 15110): 1.296724\n",
      "Batch #10\tAverage Generator Loss: 2347.955090\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15111 (step 15111): 1.356783\n",
      "Batch #10\tAverage Generator Loss: 2340.713007\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15112 (step 15112): 1.297915\n",
      "Batch #10\tAverage Generator Loss: 2290.802942\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15113 (step 15113): 1.836828\n",
      "Batch #10\tAverage Generator Loss: 2826.897595\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15114 (step 15114): 1.247949\n",
      "Batch #10\tAverage Generator Loss: 2412.003052\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15115 (step 15115): 1.314566\n",
      "Batch #10\tAverage Generator Loss: 2454.266602\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15116 (step 15116): 1.800686\n",
      "Batch #10\tAverage Generator Loss: 2317.592468\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15117 (step 15117): 1.297595\n",
      "Batch #10\tAverage Generator Loss: 2407.443652\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15118 (step 15118): 1.291071\n",
      "Batch #10\tAverage Generator Loss: 2384.744495\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15119 (step 15119): 1.913631\n",
      "Batch #10\tAverage Generator Loss: 2329.327142\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15120 (step 15120): 1.356024\n",
      "Batch #10\tAverage Generator Loss: 2780.009180\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15121 (step 15121): 1.335151\n",
      "Batch #10\tAverage Generator Loss: 2202.399170\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15122 (step 15122): 1.810303\n",
      "Batch #10\tAverage Generator Loss: 2366.007849\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15123 (step 15123): 1.291781\n",
      "Batch #10\tAverage Generator Loss: 2477.655835\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15124 (step 15124): 1.355521\n",
      "Batch #10\tAverage Generator Loss: 2484.301086\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15125 (step 15125): 1.853557\n",
      "Batch #10\tAverage Generator Loss: 2650.630066\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15126 (step 15126): 1.352534\n",
      "Batch #10\tAverage Generator Loss: 2307.926447\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15127 (step 15127): 1.280096\n",
      "Batch #10\tAverage Generator Loss: 2441.638794\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15128 (step 15128): 1.724231\n",
      "Batch #10\tAverage Generator Loss: 2531.323022\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15129 (step 15129): 1.342369\n",
      "Batch #10\tAverage Generator Loss: 2564.154553\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15130 (step 15130): 1.376099\n",
      "Batch #10\tAverage Generator Loss: 2106.492896\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15131 (step 15131): 1.852067\n",
      "Batch #10\tAverage Generator Loss: 2466.208655\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15132 (step 15132): 1.356733\n",
      "Batch #10\tAverage Generator Loss: 2568.035767\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15133 (step 15133): 1.383377\n",
      "Batch #10\tAverage Generator Loss: 2659.476758\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15134 (step 15134): 1.296530\n",
      "Batch #10\tAverage Generator Loss: 2516.616479\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15135 (step 15135): 1.875722\n",
      "Batch #10\tAverage Generator Loss: 2236.938110\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15136 (step 15136): 1.305391\n",
      "Batch #10\tAverage Generator Loss: 2491.018201\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15137 (step 15137): 1.304533\n",
      "Batch #10\tAverage Generator Loss: 2395.583337\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15138 (step 15138): 1.831211\n",
      "Batch #10\tAverage Generator Loss: 2407.489380\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15139 (step 15139): 1.456377\n",
      "Batch #10\tAverage Generator Loss: 2461.365918\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15140 (step 15140): 1.337426\n",
      "Batch #10\tAverage Generator Loss: 2227.426868\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15141 (step 15141): 1.924797\n",
      "Batch #10\tAverage Generator Loss: 2538.247424\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15142 (step 15142): 1.328438\n",
      "Batch #10\tAverage Generator Loss: 2580.775964\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15143 (step 15143): 1.394080\n",
      "Batch #10\tAverage Generator Loss: 2600.078113\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15144 (step 15144): 1.842043\n",
      "Batch #10\tAverage Generator Loss: 2463.634961\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15145 (step 15145): 1.344817\n",
      "Batch #10\tAverage Generator Loss: 2313.094897\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15146 (step 15146): 1.289004\n",
      "Batch #10\tAverage Generator Loss: 2480.532983\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15147 (step 15147): 1.850911\n",
      "Batch #10\tAverage Generator Loss: 2410.530933\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15148 (step 15148): 1.332333\n",
      "Batch #10\tAverage Generator Loss: 2421.693811\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15149 (step 15149): 1.334126\n",
      "Batch #10\tAverage Generator Loss: 2428.572205\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15150 (step 15150): 1.811765\n",
      "Batch #10\tAverage Generator Loss: 2240.943323\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15151 (step 15151): 1.341969\n",
      "Batch #10\tAverage Generator Loss: 2276.698743\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15152 (step 15152): 1.303143\n",
      "Batch #10\tAverage Generator Loss: 2254.507019\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15153 (step 15153): 1.332010\n",
      "Batch #10\tAverage Generator Loss: 2415.337073\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15154 (step 15154): 1.887661\n",
      "Batch #10\tAverage Generator Loss: 2360.545007\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15155 (step 15155): 1.429484\n",
      "Batch #10\tAverage Generator Loss: 2279.003351\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15156 (step 15156): 1.339170\n",
      "Batch #10\tAverage Generator Loss: 2260.155408\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15157 (step 15157): 1.801310\n",
      "Batch #10\tAverage Generator Loss: 2436.101788\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15158 (step 15158): 1.470703\n",
      "Batch #10\tAverage Generator Loss: 2163.771265\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15159 (step 15159): 1.339907\n",
      "Batch #10\tAverage Generator Loss: 2426.190125\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15160 (step 15160): 1.998611\n",
      "Batch #10\tAverage Generator Loss: 2551.351782\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15161 (step 15161): 1.373180\n",
      "Batch #10\tAverage Generator Loss: 2543.976282\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15162 (step 15162): 1.524345\n",
      "Batch #10\tAverage Generator Loss: 2257.074353\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15163 (step 15163): 1.845948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2630.320325\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15164 (step 15164): 1.259593\n",
      "Batch #10\tAverage Generator Loss: 2426.707495\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15165 (step 15165): 1.343439\n",
      "Batch #10\tAverage Generator Loss: 2168.501611\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15166 (step 15166): 1.827130\n",
      "Batch #10\tAverage Generator Loss: 2600.015234\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15167 (step 15167): 1.458216\n",
      "Batch #10\tAverage Generator Loss: 2311.199268\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15168 (step 15168): 1.344742\n",
      "Batch #10\tAverage Generator Loss: 2363.081787\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15169 (step 15169): 1.300424\n",
      "Batch #10\tAverage Generator Loss: 2577.579578\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15170 (step 15170): 1.747982\n",
      "Batch #10\tAverage Generator Loss: 2542.608704\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15171 (step 15171): 1.303653\n",
      "Batch #10\tAverage Generator Loss: 2307.058301\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15172 (step 15172): 1.387187\n",
      "Batch #10\tAverage Generator Loss: 2275.674329\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15173 (step 15173): 1.764210\n",
      "Batch #10\tAverage Generator Loss: 2660.219067\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15174 (step 15174): 1.396521\n",
      "Batch #10\tAverage Generator Loss: 2485.461023\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15175 (step 15175): 1.288767\n",
      "Batch #10\tAverage Generator Loss: 2200.825598\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15176 (step 15176): 1.960842\n",
      "Batch #10\tAverage Generator Loss: 2466.170691\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15177 (step 15177): 1.382351\n",
      "Batch #10\tAverage Generator Loss: 2837.878455\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15178 (step 15178): 1.363831\n",
      "Batch #10\tAverage Generator Loss: 2655.670276\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15179 (step 15179): 1.837738\n",
      "Batch #10\tAverage Generator Loss: 2621.585620\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15180 (step 15180): 1.282534\n",
      "Batch #10\tAverage Generator Loss: 2251.963171\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15181 (step 15181): 1.317522\n",
      "Batch #10\tAverage Generator Loss: 2587.125305\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15182 (step 15182): 1.818909\n",
      "Batch #10\tAverage Generator Loss: 2313.266113\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15183 (step 15183): 1.400968\n",
      "Batch #10\tAverage Generator Loss: 2261.157764\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15184 (step 15184): 1.427506\n",
      "Batch #10\tAverage Generator Loss: 2580.733044\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15185 (step 15185): 1.804375\n",
      "Batch #10\tAverage Generator Loss: 2508.676709\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15186 (step 15186): 1.367270\n",
      "Batch #10\tAverage Generator Loss: 2457.320349\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15187 (step 15187): 1.337902\n",
      "Batch #10\tAverage Generator Loss: 2373.399646\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15188 (step 15188): 1.369660\n",
      "Batch #10\tAverage Generator Loss: 2510.792444\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15189 (step 15189): 1.905446\n",
      "Batch #10\tAverage Generator Loss: 2465.439307\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15190 (step 15190): 1.236675\n",
      "Batch #10\tAverage Generator Loss: 2469.407349\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15191 (step 15191): 1.367355\n",
      "Batch #10\tAverage Generator Loss: 2669.278198\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15192 (step 15192): 1.795935\n",
      "Batch #10\tAverage Generator Loss: 2204.826581\tAverage Discriminator Loss: 0.162888\n",
      "\n",
      "Train time for epoch #15193 (step 15193): 1.257269\n",
      "Batch #10\tAverage Generator Loss: 2123.608374\tAverage Discriminator Loss: 0.151827\n",
      "\n",
      "Train time for epoch #15194 (step 15194): 1.420414\n",
      "Batch #10\tAverage Generator Loss: 1546.520473\tAverage Discriminator Loss: 0.635194\n",
      "\n",
      "Train time for epoch #15195 (step 15195): 1.768358\n",
      "Batch #10\tAverage Generator Loss: 1751.016199\tAverage Discriminator Loss: 0.126939\n",
      "\n",
      "Train time for epoch #15196 (step 15196): 1.293929\n",
      "Batch #10\tAverage Generator Loss: 1685.748242\tAverage Discriminator Loss: 0.009265\n",
      "\n",
      "Train time for epoch #15197 (step 15197): 1.301149\n",
      "Batch #10\tAverage Generator Loss: 1656.533673\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15198 (step 15198): 1.815583\n",
      "Batch #10\tAverage Generator Loss: 1734.886786\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15199 (step 15199): 1.400953\n",
      "Batch #10\tAverage Generator Loss: 1608.258466\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15200 (step 15200): 1.349566\n",
      "Batch #10\tAverage Generator Loss: 1522.871558\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15201 (step 15201): 1.814274\n",
      "Batch #10\tAverage Generator Loss: 1605.324115\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15202 (step 15202): 1.389201\n",
      "Batch #10\tAverage Generator Loss: 1679.933496\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15203 (step 15203): 1.399845\n",
      "Batch #10\tAverage Generator Loss: 1601.144171\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15204 (step 15204): 1.762266\n",
      "Batch #10\tAverage Generator Loss: 1728.089197\tAverage Discriminator Loss: 0.047998\n",
      "\n",
      "Train time for epoch #15205 (step 15205): 1.299011\n",
      "Batch #10\tAverage Generator Loss: 1605.028528\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15206 (step 15206): 1.350813\n",
      "Batch #10\tAverage Generator Loss: 1727.378149\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15207 (step 15207): 1.770711\n",
      "Batch #10\tAverage Generator Loss: 1534.277313\tAverage Discriminator Loss: 0.000096\n",
      "\n",
      "Train time for epoch #15208 (step 15208): 1.299612\n",
      "Batch #10\tAverage Generator Loss: 1653.655115\tAverage Discriminator Loss: 0.000090\n",
      "\n",
      "Train time for epoch #15209 (step 15209): 1.300995\n",
      "Batch #10\tAverage Generator Loss: 1536.472723\tAverage Discriminator Loss: 0.000035\n",
      "\n",
      "Train time for epoch #15210 (step 15210): 1.764644\n",
      "Batch #10\tAverage Generator Loss: 1450.462451\tAverage Discriminator Loss: 0.000019\n",
      "\n",
      "Train time for epoch #15211 (step 15211): 1.313811\n",
      "Batch #10\tAverage Generator Loss: 1461.097546\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #15212 (step 15212): 1.300188\n",
      "Batch #10\tAverage Generator Loss: 1621.447668\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #15213 (step 15213): 1.889272\n",
      "Batch #10\tAverage Generator Loss: 1341.128107\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #15214 (step 15214): 1.371410\n",
      "Batch #10\tAverage Generator Loss: 1667.079639\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #15215 (step 15215): 1.328566\n",
      "Batch #10\tAverage Generator Loss: 1614.295740\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #15216 (step 15216): 1.405513\n",
      "Batch #10\tAverage Generator Loss: 1565.849103\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #15217 (step 15217): 1.979145\n",
      "Batch #10\tAverage Generator Loss: 1421.572308\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #15218 (step 15218): 1.353024\n",
      "Batch #10\tAverage Generator Loss: 1425.363507\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #15219 (step 15219): 1.343337\n",
      "Batch #10\tAverage Generator Loss: 1547.132568\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #15220 (step 15220): 1.815787\n",
      "Batch #10\tAverage Generator Loss: 1708.281256\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #15221 (step 15221): 1.260367\n",
      "Batch #10\tAverage Generator Loss: 1562.529102\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #15222 (step 15222): 1.376845\n",
      "Batch #10\tAverage Generator Loss: 1770.452856\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #15223 (step 15223): 1.822222\n",
      "Batch #10\tAverage Generator Loss: 1642.934155\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #15224 (step 15224): 1.434608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 1478.205988\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #15225 (step 15225): 1.298545\n",
      "Batch #10\tAverage Generator Loss: 1709.410583\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #15226 (step 15226): 1.849512\n",
      "Batch #10\tAverage Generator Loss: 1566.465497\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #15227 (step 15227): 1.338756\n",
      "Batch #10\tAverage Generator Loss: 1536.688873\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #15228 (step 15228): 1.338108\n",
      "Batch #10\tAverage Generator Loss: 1704.610406\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #15229 (step 15229): 1.864821\n",
      "Batch #10\tAverage Generator Loss: 1520.289816\tAverage Discriminator Loss: 0.001252\n",
      "\n",
      "Train time for epoch #15230 (step 15230): 1.303111\n",
      "Batch #10\tAverage Generator Loss: 1664.932330\tAverage Discriminator Loss: 0.000539\n",
      "\n",
      "Train time for epoch #15231 (step 15231): 1.350244\n",
      "Batch #10\tAverage Generator Loss: 1690.313416\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #15232 (step 15232): 1.283960\n",
      "Batch #10\tAverage Generator Loss: 1475.062848\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #15233 (step 15233): 1.824290\n",
      "Batch #10\tAverage Generator Loss: 1641.351776\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15234 (step 15234): 1.400747\n",
      "Batch #10\tAverage Generator Loss: 1918.116040\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #15235 (step 15235): 1.247382\n",
      "Batch #10\tAverage Generator Loss: 1717.859314\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15236 (step 15236): 1.918980\n",
      "Batch #10\tAverage Generator Loss: 1566.073108\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15237 (step 15237): 1.401452\n",
      "Batch #10\tAverage Generator Loss: 1902.312695\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15238 (step 15238): 1.318166\n",
      "Batch #10\tAverage Generator Loss: 1561.454773\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15239 (step 15239): 1.991333\n",
      "Batch #10\tAverage Generator Loss: 1749.992676\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15240 (step 15240): 1.276325\n",
      "Batch #10\tAverage Generator Loss: 1613.587146\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15241 (step 15241): 1.509606\n",
      "Batch #10\tAverage Generator Loss: 1729.705762\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15242 (step 15242): 1.817774\n",
      "Batch #10\tAverage Generator Loss: 1635.071387\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15243 (step 15243): 1.239635\n",
      "Batch #10\tAverage Generator Loss: 1570.318335\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15244 (step 15244): 1.295446\n",
      "Batch #10\tAverage Generator Loss: 1559.657446\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15245 (step 15245): 1.439622\n",
      "Batch #10\tAverage Generator Loss: 1534.742047\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15246 (step 15246): 1.749081\n",
      "Batch #10\tAverage Generator Loss: 1499.944611\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15247 (step 15247): 1.287761\n",
      "Batch #10\tAverage Generator Loss: 1580.053839\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15248 (step 15248): 1.395718\n",
      "Batch #10\tAverage Generator Loss: 1708.486224\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15249 (step 15249): 1.774897\n",
      "Batch #10\tAverage Generator Loss: 1700.657050\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15250 (step 15250): 1.332483\n",
      "Batch #10\tAverage Generator Loss: 1519.441003\tAverage Discriminator Loss: 0.008331\n",
      "\n",
      "Train time for epoch #15251 (step 15251): 1.396997\n",
      "Batch #10\tAverage Generator Loss: 1598.330029\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #15252 (step 15252): 1.770486\n",
      "Batch #10\tAverage Generator Loss: 1626.736383\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #15253 (step 15253): 1.373255\n",
      "Batch #10\tAverage Generator Loss: 1532.081561\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #15254 (step 15254): 1.395736\n",
      "Batch #10\tAverage Generator Loss: 1509.263715\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #15255 (step 15255): 1.850771\n",
      "Batch #10\tAverage Generator Loss: 1454.445398\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #15256 (step 15256): 1.317848\n",
      "Batch #10\tAverage Generator Loss: 1592.297134\tAverage Discriminator Loss: 0.006146\n",
      "\n",
      "Train time for epoch #15257 (step 15257): 1.332018\n",
      "Batch #10\tAverage Generator Loss: 1627.283746\tAverage Discriminator Loss: 0.000024\n",
      "\n",
      "Train time for epoch #15258 (step 15258): 1.400396\n",
      "Batch #10\tAverage Generator Loss: 1465.077124\tAverage Discriminator Loss: 0.002271\n",
      "\n",
      "Train time for epoch #15259 (step 15259): 1.871922\n",
      "Batch #10\tAverage Generator Loss: 1537.196811\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #15260 (step 15260): 1.287703\n",
      "Batch #10\tAverage Generator Loss: 1878.706079\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #15261 (step 15261): 1.380959\n",
      "Batch #10\tAverage Generator Loss: 1638.774097\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #15262 (step 15262): 1.816075\n",
      "Batch #10\tAverage Generator Loss: 1790.793188\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #15263 (step 15263): 1.417681\n",
      "Batch #10\tAverage Generator Loss: 1710.487012\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #15264 (step 15264): 1.378846\n",
      "Batch #10\tAverage Generator Loss: 1741.796591\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #15265 (step 15265): 1.796529\n",
      "Batch #10\tAverage Generator Loss: 1545.738568\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15266 (step 15266): 1.349750\n",
      "Batch #10\tAverage Generator Loss: 1814.383813\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #15267 (step 15267): 1.357544\n",
      "Batch #10\tAverage Generator Loss: 1650.962610\tAverage Discriminator Loss: 0.000043\n",
      "\n",
      "Train time for epoch #15268 (step 15268): 1.816750\n",
      "Batch #10\tAverage Generator Loss: 1732.952173\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15269 (step 15269): 1.315402\n",
      "Batch #10\tAverage Generator Loss: 1607.871899\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15270 (step 15270): 1.256627\n",
      "Batch #10\tAverage Generator Loss: 1625.296527\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #15271 (step 15271): 1.856543\n",
      "Batch #10\tAverage Generator Loss: 1343.436102\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #15272 (step 15272): 1.295638\n",
      "Batch #10\tAverage Generator Loss: 1772.272986\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #15273 (step 15273): 1.342505\n",
      "Batch #10\tAverage Generator Loss: 1658.406604\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15274 (step 15274): 1.881089\n",
      "Batch #10\tAverage Generator Loss: 1693.074054\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15275 (step 15275): 1.353157\n",
      "Batch #10\tAverage Generator Loss: 1614.136670\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15276 (step 15276): 1.244927\n",
      "Batch #10\tAverage Generator Loss: 1747.561041\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15277 (step 15277): 1.370037\n",
      "Batch #10\tAverage Generator Loss: 1753.132812\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15278 (step 15278): 1.960718\n",
      "Batch #10\tAverage Generator Loss: 1609.843628\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15279 (step 15279): 1.387338\n",
      "Batch #10\tAverage Generator Loss: 1995.581738\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15280 (step 15280): 1.370530\n",
      "Batch #10\tAverage Generator Loss: 1709.410547\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15281 (step 15281): 1.827904\n",
      "Batch #10\tAverage Generator Loss: 1731.971674\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15282 (step 15282): 1.299865\n",
      "Batch #10\tAverage Generator Loss: 1603.024854\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15283 (step 15283): 1.237585\n",
      "Batch #10\tAverage Generator Loss: 1676.313898\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15284 (step 15284): 1.768506\n",
      "Batch #10\tAverage Generator Loss: 1728.385876\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15285 (step 15285): 1.389916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 1572.486761\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15286 (step 15286): 1.365769\n",
      "Batch #10\tAverage Generator Loss: 1669.215906\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15287 (step 15287): 1.871844\n",
      "Batch #10\tAverage Generator Loss: 1602.844812\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15288 (step 15288): 1.380047\n",
      "Batch #10\tAverage Generator Loss: 1875.199683\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15289 (step 15289): 1.258823\n",
      "Batch #10\tAverage Generator Loss: 1742.336340\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15290 (step 15290): 1.876317\n",
      "Batch #10\tAverage Generator Loss: 1454.450601\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15291 (step 15291): 1.389806\n",
      "Batch #10\tAverage Generator Loss: 1721.126215\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15292 (step 15292): 1.342183\n",
      "Batch #10\tAverage Generator Loss: 1632.955811\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15293 (step 15293): 1.359950\n",
      "Batch #10\tAverage Generator Loss: 1598.614221\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15294 (step 15294): 1.795527\n",
      "Batch #10\tAverage Generator Loss: 1581.198523\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15295 (step 15295): 1.366327\n",
      "Batch #10\tAverage Generator Loss: 1756.891199\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15296 (step 15296): 1.349766\n",
      "Batch #10\tAverage Generator Loss: 1748.544897\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15297 (step 15297): 1.813786\n",
      "Batch #10\tAverage Generator Loss: 1446.866272\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15298 (step 15298): 1.401967\n",
      "Batch #10\tAverage Generator Loss: 1641.954376\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15299 (step 15299): 1.341604\n",
      "Batch #10\tAverage Generator Loss: 1544.567938\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15300 (step 15300): 1.824608\n",
      "Batch #10\tAverage Generator Loss: 1646.833459\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15301 (step 15301): 1.298540\n",
      "Batch #10\tAverage Generator Loss: 1771.372217\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15302 (step 15302): 1.291862\n",
      "Batch #10\tAverage Generator Loss: 1614.618787\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15303 (step 15303): 1.891860\n",
      "Batch #10\tAverage Generator Loss: 1640.529974\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15304 (step 15304): 1.238550\n",
      "Batch #10\tAverage Generator Loss: 1457.805762\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15305 (step 15305): 1.334022\n",
      "Batch #10\tAverage Generator Loss: 1790.653870\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15306 (step 15306): 1.402886\n",
      "Batch #10\tAverage Generator Loss: 1673.718683\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15307 (step 15307): 1.773718\n",
      "Batch #10\tAverage Generator Loss: 1764.293823\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15308 (step 15308): 1.295529\n",
      "Batch #10\tAverage Generator Loss: 1597.613684\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15309 (step 15309): 1.340004\n",
      "Batch #10\tAverage Generator Loss: 1605.957550\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15310 (step 15310): 1.868865\n",
      "Batch #10\tAverage Generator Loss: 1360.253748\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15311 (step 15311): 1.469727\n",
      "Batch #10\tAverage Generator Loss: 1667.235504\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15312 (step 15312): 1.311192\n",
      "Batch #10\tAverage Generator Loss: 1531.687463\tAverage Discriminator Loss: 0.017035\n",
      "\n",
      "Train time for epoch #15313 (step 15313): 1.803170\n",
      "Batch #10\tAverage Generator Loss: 1681.550134\tAverage Discriminator Loss: 0.013611\n",
      "\n",
      "Train time for epoch #15314 (step 15314): 1.399636\n",
      "Batch #10\tAverage Generator Loss: 1764.050061\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #15315 (step 15315): 1.304305\n",
      "Batch #10\tAverage Generator Loss: 1740.434424\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15316 (step 15316): 1.786103\n",
      "Batch #10\tAverage Generator Loss: 1740.152332\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15317 (step 15317): 1.320805\n",
      "Batch #10\tAverage Generator Loss: 1660.023816\tAverage Discriminator Loss: 0.053144\n",
      "\n",
      "Train time for epoch #15318 (step 15318): 1.335078\n",
      "Batch #10\tAverage Generator Loss: 1709.222668\tAverage Discriminator Loss: 0.000029\n",
      "\n",
      "Train time for epoch #15319 (step 15319): 1.806522\n",
      "Batch #10\tAverage Generator Loss: 1883.281470\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #15320 (step 15320): 1.638937\n",
      "Batch #10\tAverage Generator Loss: 1731.763940\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #15321 (step 15321): 1.378615\n",
      "Batch #10\tAverage Generator Loss: 1561.799280\tAverage Discriminator Loss: 0.004084\n",
      "\n",
      "Train time for epoch #15322 (step 15322): 1.840427\n",
      "Batch #10\tAverage Generator Loss: 1708.630414\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15323 (step 15323): 1.333304\n",
      "Batch #10\tAverage Generator Loss: 2006.855579\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15324 (step 15324): 1.337137\n",
      "Batch #10\tAverage Generator Loss: 1663.916046\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15325 (step 15325): 1.301239\n",
      "Batch #10\tAverage Generator Loss: 1541.976318\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15326 (step 15326): 1.808127\n",
      "Batch #10\tAverage Generator Loss: 1781.074072\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15327 (step 15327): 1.344278\n",
      "Batch #10\tAverage Generator Loss: 1837.161511\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15328 (step 15328): 1.332623\n",
      "Batch #10\tAverage Generator Loss: 1848.531067\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15329 (step 15329): 1.899647\n",
      "Batch #10\tAverage Generator Loss: 1756.459406\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15330 (step 15330): 1.296952\n",
      "Batch #10\tAverage Generator Loss: 1842.309680\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15331 (step 15331): 1.345065\n",
      "Batch #10\tAverage Generator Loss: 1593.618549\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15332 (step 15332): 1.786609\n",
      "Batch #10\tAverage Generator Loss: 1764.172418\tAverage Discriminator Loss: 0.009740\n",
      "\n",
      "Train time for epoch #15333 (step 15333): 1.350729\n",
      "Batch #10\tAverage Generator Loss: 1628.893976\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15334 (step 15334): 1.301974\n",
      "Batch #10\tAverage Generator Loss: 1546.263287\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15335 (step 15335): 1.828759\n",
      "Batch #10\tAverage Generator Loss: 1611.561090\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15336 (step 15336): 1.381917\n",
      "Batch #10\tAverage Generator Loss: 1771.251367\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15337 (step 15337): 1.383684\n",
      "Batch #10\tAverage Generator Loss: 1867.964526\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15338 (step 15338): 1.949398\n",
      "Batch #10\tAverage Generator Loss: 1792.893750\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15339 (step 15339): 1.336355\n",
      "Batch #10\tAverage Generator Loss: 1845.114636\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15340 (step 15340): 1.332009\n",
      "Batch #10\tAverage Generator Loss: 1773.900818\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15341 (step 15341): 1.813301\n",
      "Batch #10\tAverage Generator Loss: 1837.896484\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15342 (step 15342): 1.411904\n",
      "Batch #10\tAverage Generator Loss: 1837.325952\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15343 (step 15343): 1.286214\n",
      "Batch #10\tAverage Generator Loss: 1682.609637\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15344 (step 15344): 1.423564\n",
      "Batch #10\tAverage Generator Loss: 1806.302661\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15345 (step 15345): 1.817289\n",
      "Batch #10\tAverage Generator Loss: 1686.813000\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15346 (step 15346): 1.306262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 1940.382776\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15347 (step 15347): 1.255616\n",
      "Batch #10\tAverage Generator Loss: 1650.434357\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15348 (step 15348): 1.922272\n",
      "Batch #10\tAverage Generator Loss: 1768.717328\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15349 (step 15349): 1.419254\n",
      "Batch #10\tAverage Generator Loss: 1761.850378\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15350 (step 15350): 1.291487\n",
      "Batch #10\tAverage Generator Loss: 1650.249994\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15351 (step 15351): 1.817708\n",
      "Batch #10\tAverage Generator Loss: 2051.221448\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15352 (step 15352): 1.412000\n",
      "Batch #10\tAverage Generator Loss: 1418.283374\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15353 (step 15353): 1.371902\n",
      "Batch #10\tAverage Generator Loss: 1517.280573\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15354 (step 15354): 1.877431\n",
      "Batch #10\tAverage Generator Loss: 1503.464520\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15355 (step 15355): 1.275418\n",
      "Batch #10\tAverage Generator Loss: 1724.763593\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15356 (step 15356): 1.297444\n",
      "Batch #10\tAverage Generator Loss: 1843.453662\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15357 (step 15357): 1.844856\n",
      "Batch #10\tAverage Generator Loss: 1765.880383\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15358 (step 15358): 1.335411\n",
      "Batch #10\tAverage Generator Loss: 1703.955005\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15359 (step 15359): 1.364287\n",
      "Batch #10\tAverage Generator Loss: 1738.100873\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15360 (step 15360): 1.246673\n",
      "Batch #10\tAverage Generator Loss: 1307.149506\tAverage Discriminator Loss: 0.329734\n",
      "\n",
      "Train time for epoch #15361 (step 15361): 1.760080\n",
      "Batch #10\tAverage Generator Loss: 1616.004004\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #15362 (step 15362): 1.411121\n",
      "Batch #10\tAverage Generator Loss: 1477.136658\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15363 (step 15363): 1.284805\n",
      "Batch #10\tAverage Generator Loss: 1387.606790\tAverage Discriminator Loss: 0.153785\n",
      "\n",
      "Train time for epoch #15364 (step 15364): 1.764089\n",
      "Batch #10\tAverage Generator Loss: 2434.337793\tAverage Discriminator Loss: 0.023770\n",
      "\n",
      "Train time for epoch #15365 (step 15365): 1.300053\n",
      "Batch #10\tAverage Generator Loss: 2375.885474\tAverage Discriminator Loss: 0.006630\n",
      "\n",
      "Train time for epoch #15366 (step 15366): 1.414397\n",
      "Batch #10\tAverage Generator Loss: 2581.404346\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15367 (step 15367): 1.820353\n",
      "Batch #10\tAverage Generator Loss: 2357.428271\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15368 (step 15368): 1.285820\n",
      "Batch #10\tAverage Generator Loss: 2489.077307\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15369 (step 15369): 1.350731\n",
      "Batch #10\tAverage Generator Loss: 2614.763916\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15370 (step 15370): 1.879567\n",
      "Batch #10\tAverage Generator Loss: 2570.457031\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15371 (step 15371): 1.295581\n",
      "Batch #10\tAverage Generator Loss: 2460.864484\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15372 (step 15372): 1.331197\n",
      "Batch #10\tAverage Generator Loss: 2742.283337\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15373 (step 15373): 1.790644\n",
      "Batch #10\tAverage Generator Loss: 2673.247687\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15374 (step 15374): 1.476024\n",
      "Batch #10\tAverage Generator Loss: 2130.334509\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15375 (step 15375): 1.327704\n",
      "Batch #10\tAverage Generator Loss: 2346.975955\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15376 (step 15376): 1.474048\n",
      "Batch #10\tAverage Generator Loss: 2692.618390\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15377 (step 15377): 1.931839\n",
      "Batch #10\tAverage Generator Loss: 2539.012585\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15378 (step 15378): 1.307178\n",
      "Batch #10\tAverage Generator Loss: 2805.466431\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15379 (step 15379): 1.364683\n",
      "Batch #10\tAverage Generator Loss: 3350.362256\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15380 (step 15380): 1.798318\n",
      "Batch #10\tAverage Generator Loss: 4273.601233\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15381 (step 15381): 1.381197\n",
      "Batch #10\tAverage Generator Loss: 4060.055750\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15382 (step 15382): 1.301537\n",
      "Batch #10\tAverage Generator Loss: 3709.237329\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15383 (step 15383): 1.808318\n",
      "Batch #10\tAverage Generator Loss: 4716.291931\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15384 (step 15384): 1.287554\n",
      "Batch #10\tAverage Generator Loss: 3233.411304\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15385 (step 15385): 1.448146\n",
      "Batch #10\tAverage Generator Loss: 3363.056714\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15386 (step 15386): 1.831263\n",
      "Batch #10\tAverage Generator Loss: 3010.271521\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15387 (step 15387): 1.342590\n",
      "Batch #10\tAverage Generator Loss: 4241.727795\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15388 (step 15388): 1.379759\n",
      "Batch #10\tAverage Generator Loss: 2942.703271\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15389 (step 15389): 1.386346\n",
      "Batch #10\tAverage Generator Loss: 3809.578284\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15390 (step 15390): 1.926127\n",
      "Batch #10\tAverage Generator Loss: 2481.008313\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15391 (step 15391): 1.372589\n",
      "Batch #10\tAverage Generator Loss: 2408.018994\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15392 (step 15392): 1.295237\n",
      "Batch #10\tAverage Generator Loss: 2894.814771\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15393 (step 15393): 1.808345\n",
      "Batch #10\tAverage Generator Loss: 2451.065601\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15394 (step 15394): 1.334007\n",
      "Batch #10\tAverage Generator Loss: 2330.446899\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15395 (step 15395): 1.367988\n",
      "Batch #10\tAverage Generator Loss: 2813.406653\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15396 (step 15396): 1.914536\n",
      "Batch #10\tAverage Generator Loss: 2615.685150\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15397 (step 15397): 1.511613\n",
      "Batch #10\tAverage Generator Loss: 2629.623224\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15398 (step 15398): 1.454812\n",
      "Batch #10\tAverage Generator Loss: 2752.172449\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15399 (step 15399): 1.807096\n",
      "Batch #10\tAverage Generator Loss: 2426.881506\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15400 (step 15400): 1.309944\n",
      "Batch #10\tAverage Generator Loss: 2497.873975\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15401 (step 15401): 1.326742\n",
      "Batch #10\tAverage Generator Loss: 2471.945752\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15402 (step 15402): 1.825016\n",
      "Batch #10\tAverage Generator Loss: 2484.442712\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15403 (step 15403): 1.314837\n",
      "Batch #10\tAverage Generator Loss: 2532.390393\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15404 (step 15404): 1.331291\n",
      "Batch #10\tAverage Generator Loss: 2164.082129\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15405 (step 15405): 1.779061\n",
      "Batch #10\tAverage Generator Loss: 2220.514612\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15406 (step 15406): 1.359633\n",
      "Batch #10\tAverage Generator Loss: 2480.577515\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15407 (step 15407): 1.292974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2132.509607\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15408 (step 15408): 1.397197\n",
      "Batch #10\tAverage Generator Loss: 2394.868372\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15409 (step 15409): 1.717034\n",
      "Batch #10\tAverage Generator Loss: 2425.115430\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15410 (step 15410): 1.352879\n",
      "Batch #10\tAverage Generator Loss: 2753.686633\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15411 (step 15411): 1.328506\n",
      "Batch #10\tAverage Generator Loss: 2476.324353\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15412 (step 15412): 1.860435\n",
      "Batch #10\tAverage Generator Loss: 2377.751929\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15413 (step 15413): 1.354282\n",
      "Batch #10\tAverage Generator Loss: 2702.205981\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15414 (step 15414): 1.422334\n",
      "Batch #10\tAverage Generator Loss: 2323.367749\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15415 (step 15415): 1.828435\n",
      "Batch #10\tAverage Generator Loss: 2478.586353\tAverage Discriminator Loss: 0.111871\n",
      "\n",
      "Train time for epoch #15416 (step 15416): 1.334488\n",
      "Batch #10\tAverage Generator Loss: 2715.061780\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15417 (step 15417): 1.464655\n",
      "Batch #10\tAverage Generator Loss: 3037.015491\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15418 (step 15418): 1.902820\n",
      "Batch #10\tAverage Generator Loss: 2586.086169\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15419 (step 15419): 1.340728\n",
      "Batch #10\tAverage Generator Loss: 2382.646484\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15420 (step 15420): 1.284543\n",
      "Batch #10\tAverage Generator Loss: 2463.800439\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15421 (step 15421): 1.854372\n",
      "Batch #10\tAverage Generator Loss: 2779.362463\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15422 (step 15422): 1.347577\n",
      "Batch #10\tAverage Generator Loss: 2306.715454\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15423 (step 15423): 1.330668\n",
      "Batch #10\tAverage Generator Loss: 2889.705243\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15424 (step 15424): 1.814002\n",
      "Batch #10\tAverage Generator Loss: 2700.842407\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15425 (step 15425): 1.337507\n",
      "Batch #10\tAverage Generator Loss: 2344.618713\tAverage Discriminator Loss: 0.009818\n",
      "\n",
      "Train time for epoch #15426 (step 15426): 1.295390\n",
      "Batch #10\tAverage Generator Loss: 3178.625952\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15427 (step 15427): 1.846631\n",
      "Batch #10\tAverage Generator Loss: 2698.935693\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15428 (step 15428): 1.287694\n",
      "Batch #10\tAverage Generator Loss: 2736.325220\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15429 (step 15429): 1.309409\n",
      "Batch #10\tAverage Generator Loss: 2913.518652\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15430 (step 15430): 1.828954\n",
      "Batch #10\tAverage Generator Loss: 2482.369934\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15431 (step 15431): 1.330005\n",
      "Batch #10\tAverage Generator Loss: 3033.496375\tAverage Discriminator Loss: 0.031154\n",
      "\n",
      "Train time for epoch #15432 (step 15432): 1.339411\n",
      "Batch #10\tAverage Generator Loss: 2236.841315\tAverage Discriminator Loss: 0.058628\n",
      "\n",
      "Train time for epoch #15433 (step 15433): 1.352717\n",
      "Batch #10\tAverage Generator Loss: 2924.224976\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15434 (step 15434): 1.793734\n",
      "Batch #10\tAverage Generator Loss: 2503.328845\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15435 (step 15435): 1.418230\n",
      "Batch #10\tAverage Generator Loss: 2899.723047\tAverage Discriminator Loss: 0.009199\n",
      "\n",
      "Train time for epoch #15436 (step 15436): 1.429740\n",
      "Batch #10\tAverage Generator Loss: 2912.158057\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15437 (step 15437): 1.832527\n",
      "Batch #10\tAverage Generator Loss: 2313.360242\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15438 (step 15438): 1.350546\n",
      "Batch #10\tAverage Generator Loss: 2718.450818\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15439 (step 15439): 1.362599\n",
      "Batch #10\tAverage Generator Loss: 2583.817163\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15440 (step 15440): 1.884969\n",
      "Batch #10\tAverage Generator Loss: 2525.794556\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #15441 (step 15441): 1.291904\n",
      "Batch #10\tAverage Generator Loss: 2495.250806\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15442 (step 15442): 1.396971\n",
      "Batch #10\tAverage Generator Loss: 3041.508191\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15443 (step 15443): 1.294596\n",
      "Batch #10\tAverage Generator Loss: 2821.734607\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15444 (step 15444): 1.812974\n",
      "Batch #10\tAverage Generator Loss: 2767.742554\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15445 (step 15445): 1.336764\n",
      "Batch #10\tAverage Generator Loss: 2700.884583\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15446 (step 15446): 1.383806\n",
      "Batch #10\tAverage Generator Loss: 2318.845020\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15447 (step 15447): 1.760084\n",
      "Batch #10\tAverage Generator Loss: 2472.590430\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15448 (step 15448): 1.293339\n",
      "Batch #10\tAverage Generator Loss: 2710.696838\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15449 (step 15449): 1.318815\n",
      "Batch #10\tAverage Generator Loss: 2345.778467\tAverage Discriminator Loss: 0.072950\n",
      "\n",
      "Train time for epoch #15450 (step 15450): 1.761549\n",
      "Batch #10\tAverage Generator Loss: 2270.005664\tAverage Discriminator Loss: 0.000745\n",
      "\n",
      "Train time for epoch #15451 (step 15451): 1.350314\n",
      "Batch #10\tAverage Generator Loss: 1986.551862\tAverage Discriminator Loss: 0.000524\n",
      "\n",
      "Train time for epoch #15452 (step 15452): 1.432015\n",
      "Batch #10\tAverage Generator Loss: 2293.963635\tAverage Discriminator Loss: 0.000034\n",
      "\n",
      "Train time for epoch #15453 (step 15453): 1.890623\n",
      "Batch #10\tAverage Generator Loss: 2212.199341\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15454 (step 15454): 1.279142\n",
      "Batch #10\tAverage Generator Loss: 2178.183496\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15455 (step 15455): 1.344666\n",
      "Batch #10\tAverage Generator Loss: 2342.566901\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15456 (step 15456): 1.940701\n",
      "Batch #10\tAverage Generator Loss: 2223.864789\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15457 (step 15457): 1.459799\n",
      "Batch #10\tAverage Generator Loss: 2387.582788\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15458 (step 15458): 1.337665\n",
      "Batch #10\tAverage Generator Loss: 2517.517151\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15459 (step 15459): 1.344043\n",
      "Batch #10\tAverage Generator Loss: 1945.707562\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15460 (step 15460): 1.908822\n",
      "Batch #10\tAverage Generator Loss: 2323.218298\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15461 (step 15461): 1.308661\n",
      "Batch #10\tAverage Generator Loss: 2199.588232\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15462 (step 15462): 1.265773\n",
      "Batch #10\tAverage Generator Loss: 1982.499768\tAverage Discriminator Loss: 0.008510\n",
      "\n",
      "Train time for epoch #15463 (step 15463): 1.814549\n",
      "Batch #10\tAverage Generator Loss: 2244.570801\tAverage Discriminator Loss: 0.000054\n",
      "\n",
      "Train time for epoch #15464 (step 15464): 1.292753\n",
      "Batch #10\tAverage Generator Loss: 2061.834460\tAverage Discriminator Loss: 0.000197\n",
      "\n",
      "Train time for epoch #15465 (step 15465): 1.402822\n",
      "Batch #10\tAverage Generator Loss: 2428.421021\tAverage Discriminator Loss: 0.000031\n",
      "\n",
      "Train time for epoch #15466 (step 15466): 1.825322\n",
      "Batch #10\tAverage Generator Loss: 2188.863226\tAverage Discriminator Loss: 0.000019\n",
      "\n",
      "Train time for epoch #15467 (step 15467): 1.343513\n",
      "Batch #10\tAverage Generator Loss: 1958.303809\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #15468 (step 15468): 1.291070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2236.863782\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #15469 (step 15469): 1.913267\n",
      "Batch #10\tAverage Generator Loss: 2408.817944\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #15470 (step 15470): 1.470427\n",
      "Batch #10\tAverage Generator Loss: 2198.293042\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #15471 (step 15471): 1.338884\n",
      "Batch #10\tAverage Generator Loss: 2374.435388\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #15472 (step 15472): 1.341205\n",
      "Batch #10\tAverage Generator Loss: 1962.740234\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #15473 (step 15473): 1.808163\n",
      "Batch #10\tAverage Generator Loss: 2276.920337\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #15474 (step 15474): 1.363393\n",
      "Batch #10\tAverage Generator Loss: 2464.671045\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #15475 (step 15475): 1.331708\n",
      "Batch #10\tAverage Generator Loss: 2489.289819\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #15476 (step 15476): 1.825619\n",
      "Batch #10\tAverage Generator Loss: 2105.469092\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #15477 (step 15477): 1.532066\n",
      "Batch #10\tAverage Generator Loss: 2559.952039\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #15478 (step 15478): 1.280179\n",
      "Batch #10\tAverage Generator Loss: 2086.391742\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #15479 (step 15479): 1.776130\n",
      "Batch #10\tAverage Generator Loss: 2162.741388\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #15480 (step 15480): 1.294636\n",
      "Batch #10\tAverage Generator Loss: 2271.067651\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #15481 (step 15481): 1.335031\n",
      "Batch #10\tAverage Generator Loss: 2147.317236\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #15482 (step 15482): 1.862361\n",
      "Batch #10\tAverage Generator Loss: 2149.455286\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15483 (step 15483): 1.420650\n",
      "Batch #10\tAverage Generator Loss: 2467.948108\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #15484 (step 15484): 1.408288\n",
      "Batch #10\tAverage Generator Loss: 2263.788928\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #15485 (step 15485): 1.770035\n",
      "Batch #10\tAverage Generator Loss: 2110.997745\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #15486 (step 15486): 1.375110\n",
      "Batch #10\tAverage Generator Loss: 1803.557373\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #15487 (step 15487): 1.294996\n",
      "Batch #10\tAverage Generator Loss: 2323.479346\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #15488 (step 15488): 1.778772\n",
      "Batch #10\tAverage Generator Loss: 2433.960217\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #15489 (step 15489): 1.282364\n",
      "Batch #10\tAverage Generator Loss: 1965.264044\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #15490 (step 15490): 1.517223\n",
      "Batch #10\tAverage Generator Loss: 2007.293579\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #15491 (step 15491): 1.840092\n",
      "Batch #10\tAverage Generator Loss: 2226.785339\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15492 (step 15492): 1.288918\n",
      "Batch #10\tAverage Generator Loss: 2407.199927\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15493 (step 15493): 1.330935\n",
      "Batch #10\tAverage Generator Loss: 2298.645825\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15494 (step 15494): 1.279756\n",
      "Batch #10\tAverage Generator Loss: 2231.338074\tAverage Discriminator Loss: 0.034840\n",
      "\n",
      "Train time for epoch #15495 (step 15495): 1.886400\n",
      "Batch #10\tAverage Generator Loss: 2274.131219\tAverage Discriminator Loss: 0.000489\n",
      "\n",
      "Train time for epoch #15496 (step 15496): 1.394984\n",
      "Batch #10\tAverage Generator Loss: 2204.232983\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15497 (step 15497): 1.293209\n",
      "Batch #10\tAverage Generator Loss: 2111.786414\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15498 (step 15498): 1.860729\n",
      "Batch #10\tAverage Generator Loss: 2041.747363\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15499 (step 15499): 1.328318\n",
      "Batch #10\tAverage Generator Loss: 2131.410345\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15500 (step 15500): 1.322040\n",
      "Batch #10\tAverage Generator Loss: 2026.187146\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15501 (step 15501): 1.847609\n",
      "Batch #10\tAverage Generator Loss: 2251.528503\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15502 (step 15502): 1.336754\n",
      "Batch #10\tAverage Generator Loss: 1932.108228\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15503 (step 15503): 1.383560\n",
      "Batch #10\tAverage Generator Loss: 1974.687036\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15504 (step 15504): 1.930120\n",
      "Batch #10\tAverage Generator Loss: 1932.582904\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15505 (step 15505): 1.336877\n",
      "Batch #10\tAverage Generator Loss: 2195.022583\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15506 (step 15506): 1.243018\n",
      "Batch #10\tAverage Generator Loss: 2376.930530\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15507 (step 15507): 1.318402\n",
      "Batch #10\tAverage Generator Loss: 2073.923560\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15508 (step 15508): 1.805572\n",
      "Batch #10\tAverage Generator Loss: 2100.826678\tAverage Discriminator Loss: 0.000578\n",
      "\n",
      "Train time for epoch #15509 (step 15509): 1.297363\n",
      "Batch #10\tAverage Generator Loss: 2085.405664\tAverage Discriminator Loss: 0.000061\n",
      "\n",
      "Train time for epoch #15510 (step 15510): 1.401885\n",
      "Batch #10\tAverage Generator Loss: 2016.502808\tAverage Discriminator Loss: 0.000061\n",
      "\n",
      "Train time for epoch #15511 (step 15511): 1.771492\n",
      "Batch #10\tAverage Generator Loss: 2072.936243\tAverage Discriminator Loss: 0.000021\n",
      "\n",
      "Train time for epoch #15512 (step 15512): 1.391797\n",
      "Batch #10\tAverage Generator Loss: 2010.377136\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15513 (step 15513): 1.346301\n",
      "Batch #10\tAverage Generator Loss: 2240.888159\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #15514 (step 15514): 1.912511\n",
      "Batch #10\tAverage Generator Loss: 2046.116791\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #15515 (step 15515): 1.288423\n",
      "Batch #10\tAverage Generator Loss: 2331.523975\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #15516 (step 15516): 1.291405\n",
      "Batch #10\tAverage Generator Loss: 2047.765088\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #15517 (step 15517): 1.888320\n",
      "Batch #10\tAverage Generator Loss: 1747.889709\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #15518 (step 15518): 1.392257\n",
      "Batch #10\tAverage Generator Loss: 2204.726392\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15519 (step 15519): 1.393204\n",
      "Batch #10\tAverage Generator Loss: 1878.374158\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15520 (step 15520): 1.767932\n",
      "Batch #10\tAverage Generator Loss: 1965.637750\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15521 (step 15521): 1.342994\n",
      "Batch #10\tAverage Generator Loss: 2164.071313\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #15522 (step 15522): 1.294882\n",
      "Batch #10\tAverage Generator Loss: 2223.773389\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #15523 (step 15523): 1.767066\n",
      "Batch #10\tAverage Generator Loss: 1932.196716\tAverage Discriminator Loss: 0.011160\n",
      "\n",
      "Train time for epoch #15524 (step 15524): 1.277576\n",
      "Batch #10\tAverage Generator Loss: 1828.045990\tAverage Discriminator Loss: 0.000315\n",
      "\n",
      "Train time for epoch #15525 (step 15525): 1.290396\n",
      "Batch #10\tAverage Generator Loss: 2159.809888\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15526 (step 15526): 1.333286\n",
      "Batch #10\tAverage Generator Loss: 2081.918896\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15527 (step 15527): 1.766607\n",
      "Batch #10\tAverage Generator Loss: 1812.652585\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15528 (step 15528): 1.360871\n",
      "Batch #10\tAverage Generator Loss: 1914.170062\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15529 (step 15529): 1.392322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 1959.333221\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15530 (step 15530): 1.782454\n",
      "Batch #10\tAverage Generator Loss: 2213.241064\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15531 (step 15531): 1.435357\n",
      "Batch #10\tAverage Generator Loss: 1945.690009\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15532 (step 15532): 1.382493\n",
      "Batch #10\tAverage Generator Loss: 2366.969556\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15533 (step 15533): 1.824139\n",
      "Batch #10\tAverage Generator Loss: 2200.880743\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15534 (step 15534): 1.244008\n",
      "Batch #10\tAverage Generator Loss: 1907.907635\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15535 (step 15535): 1.398012\n",
      "Batch #10\tAverage Generator Loss: 2076.840210\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15536 (step 15536): 1.840225\n",
      "Batch #10\tAverage Generator Loss: 1926.589154\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15537 (step 15537): 1.279190\n",
      "Batch #10\tAverage Generator Loss: 1816.364014\tAverage Discriminator Loss: 0.034857\n",
      "\n",
      "Train time for epoch #15538 (step 15538): 1.359646\n",
      "Batch #10\tAverage Generator Loss: 1811.077777\tAverage Discriminator Loss: 0.000297\n",
      "\n",
      "Train time for epoch #15539 (step 15539): 1.828345\n",
      "Batch #10\tAverage Generator Loss: 1998.425708\tAverage Discriminator Loss: 0.000255\n",
      "\n",
      "Train time for epoch #15540 (step 15540): 1.255547\n",
      "Batch #10\tAverage Generator Loss: 1696.648071\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15541 (step 15541): 1.352540\n",
      "Batch #10\tAverage Generator Loss: 1879.953583\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15542 (step 15542): 1.889297\n",
      "Batch #10\tAverage Generator Loss: 1515.375497\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15543 (step 15543): 1.287053\n",
      "Batch #10\tAverage Generator Loss: 1774.586334\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15544 (step 15544): 1.347165\n",
      "Batch #10\tAverage Generator Loss: 1795.118909\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15545 (step 15545): 1.837024\n",
      "Batch #10\tAverage Generator Loss: 1807.145813\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15546 (step 15546): 1.386566\n",
      "Batch #10\tAverage Generator Loss: 1590.499274\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15547 (step 15547): 1.279352\n",
      "Batch #10\tAverage Generator Loss: 1701.007404\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15548 (step 15548): 1.391607\n",
      "Batch #10\tAverage Generator Loss: 1916.416724\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15549 (step 15549): 1.867200\n",
      "Batch #10\tAverage Generator Loss: 1738.223383\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15550 (step 15550): 1.288640\n",
      "Batch #10\tAverage Generator Loss: 1818.125232\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15551 (step 15551): 1.332820\n",
      "Batch #10\tAverage Generator Loss: 1863.867114\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15552 (step 15552): 1.877460\n",
      "Batch #10\tAverage Generator Loss: 1729.575183\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15553 (step 15553): 1.369579\n",
      "Batch #10\tAverage Generator Loss: 1760.856232\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15554 (step 15554): 1.410627\n",
      "Batch #10\tAverage Generator Loss: 1992.845642\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15555 (step 15555): 1.822686\n",
      "Batch #10\tAverage Generator Loss: 1903.224170\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15556 (step 15556): 1.427057\n",
      "Batch #10\tAverage Generator Loss: 1943.850098\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15557 (step 15557): 1.289857\n",
      "Batch #10\tAverage Generator Loss: 1850.449719\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15558 (step 15558): 1.832962\n",
      "Batch #10\tAverage Generator Loss: 1692.083374\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15559 (step 15559): 1.344002\n",
      "Batch #10\tAverage Generator Loss: 1945.676746\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15560 (step 15560): 1.346232\n",
      "Batch #10\tAverage Generator Loss: 2119.862720\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15561 (step 15561): 1.867209\n",
      "Batch #10\tAverage Generator Loss: 1614.832306\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15562 (step 15562): 1.340135\n",
      "Batch #10\tAverage Generator Loss: 1890.597302\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15563 (step 15563): 1.317823\n",
      "Batch #10\tAverage Generator Loss: 1757.965704\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15564 (step 15564): 1.283724\n",
      "Batch #10\tAverage Generator Loss: 1391.529330\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15565 (step 15565): 1.777234\n",
      "Batch #10\tAverage Generator Loss: 2075.373291\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15566 (step 15566): 1.280879\n",
      "Batch #10\tAverage Generator Loss: 1666.446216\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15567 (step 15567): 1.289929\n",
      "Batch #10\tAverage Generator Loss: 1735.574548\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15568 (step 15568): 1.725191\n",
      "Batch #10\tAverage Generator Loss: 2081.041284\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15569 (step 15569): 1.389424\n",
      "Batch #10\tAverage Generator Loss: 1835.164960\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15570 (step 15570): 1.369167\n",
      "Batch #10\tAverage Generator Loss: 1910.179333\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15571 (step 15571): 1.842530\n",
      "Batch #10\tAverage Generator Loss: 1900.386279\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15572 (step 15572): 1.312671\n",
      "Batch #10\tAverage Generator Loss: 2106.520142\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15573 (step 15573): 1.332392\n",
      "Batch #10\tAverage Generator Loss: 1821.177301\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15574 (step 15574): 1.967765\n",
      "Batch #10\tAverage Generator Loss: 1824.863025\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15575 (step 15575): 1.300194\n",
      "Batch #10\tAverage Generator Loss: 1703.937115\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15576 (step 15576): 1.333543\n",
      "Batch #10\tAverage Generator Loss: 1714.948596\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15577 (step 15577): 1.892625\n",
      "Batch #10\tAverage Generator Loss: 2116.330774\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15578 (step 15578): 1.477552\n",
      "Batch #10\tAverage Generator Loss: 1716.472034\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15579 (step 15579): 1.301284\n",
      "Batch #10\tAverage Generator Loss: 1776.748608\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15580 (step 15580): 1.333922\n",
      "Batch #10\tAverage Generator Loss: 1741.375598\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15581 (step 15581): 1.908105\n",
      "Batch #10\tAverage Generator Loss: 1867.628430\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15582 (step 15582): 1.283538\n",
      "Batch #10\tAverage Generator Loss: 1502.387927\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15583 (step 15583): 1.272765\n",
      "Batch #10\tAverage Generator Loss: 1844.263611\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15584 (step 15584): 1.865447\n",
      "Batch #10\tAverage Generator Loss: 1896.808948\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15585 (step 15585): 1.336173\n",
      "Batch #10\tAverage Generator Loss: 1719.028366\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15586 (step 15586): 1.402022\n",
      "Batch #10\tAverage Generator Loss: 1706.004126\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15587 (step 15587): 1.820760\n",
      "Batch #10\tAverage Generator Loss: 2006.452759\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15588 (step 15588): 1.329470\n",
      "Batch #10\tAverage Generator Loss: 1532.126068\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15589 (step 15589): 1.266003\n",
      "Batch #10\tAverage Generator Loss: 1838.214038\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15590 (step 15590): 1.861843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 1877.646594\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15591 (step 15591): 1.492554\n",
      "Batch #10\tAverage Generator Loss: 1845.354321\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15592 (step 15592): 1.393956\n",
      "Batch #10\tAverage Generator Loss: 1856.709363\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15593 (step 15593): 1.850081\n",
      "Batch #10\tAverage Generator Loss: 1881.759546\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15594 (step 15594): 1.342655\n",
      "Batch #10\tAverage Generator Loss: 2000.068964\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15595 (step 15595): 1.257332\n",
      "Batch #10\tAverage Generator Loss: 1809.241382\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15596 (step 15596): 1.344182\n",
      "Batch #10\tAverage Generator Loss: 1606.661493\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15597 (step 15597): 1.765819\n",
      "Batch #10\tAverage Generator Loss: 1980.190509\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15598 (step 15598): 1.392916\n",
      "Batch #10\tAverage Generator Loss: 2031.493250\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15599 (step 15599): 1.256943\n",
      "Batch #10\tAverage Generator Loss: 1433.099158\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15600 (step 15600): 1.750142\n",
      "Batch #10\tAverage Generator Loss: 1789.782391\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15601 (step 15601): 1.347969\n",
      "Batch #10\tAverage Generator Loss: 1769.570514\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15602 (step 15602): 1.296293\n",
      "Batch #10\tAverage Generator Loss: 1724.428369\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15603 (step 15603): 1.786511\n",
      "Batch #10\tAverage Generator Loss: 1718.893488\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15604 (step 15604): 1.350345\n",
      "Batch #10\tAverage Generator Loss: 1527.985400\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15605 (step 15605): 1.334264\n",
      "Batch #10\tAverage Generator Loss: 1795.992810\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #15606 (step 15606): 1.820529\n",
      "Batch #10\tAverage Generator Loss: 1578.225854\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15607 (step 15607): 1.329384\n",
      "Batch #10\tAverage Generator Loss: 1825.483362\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15608 (step 15608): 1.276349\n",
      "Batch #10\tAverage Generator Loss: 1928.949231\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15609 (step 15609): 1.352153\n",
      "Batch #10\tAverage Generator Loss: 1786.552905\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15610 (step 15610): 1.895390\n",
      "Batch #10\tAverage Generator Loss: 1776.300806\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15611 (step 15611): 1.396703\n",
      "Batch #10\tAverage Generator Loss: 1649.065283\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15612 (step 15612): 1.338825\n",
      "Batch #10\tAverage Generator Loss: 1948.498157\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15613 (step 15613): 2.080939\n",
      "Batch #10\tAverage Generator Loss: 1667.069965\tAverage Discriminator Loss: 0.000172\n",
      "\n",
      "Train time for epoch #15614 (step 15614): 1.868077\n",
      "Batch #10\tAverage Generator Loss: 1880.634265\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15615 (step 15615): 1.239727\n",
      "Batch #10\tAverage Generator Loss: 2014.667468\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15616 (step 15616): 1.900154\n",
      "Batch #10\tAverage Generator Loss: 1701.558563\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15617 (step 15617): 1.335746\n",
      "Batch #10\tAverage Generator Loss: 1914.394983\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15618 (step 15618): 1.332947\n",
      "Batch #10\tAverage Generator Loss: 1819.773999\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15619 (step 15619): 2.000834\n",
      "Batch #10\tAverage Generator Loss: 1837.808936\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15620 (step 15620): 1.289269\n",
      "Batch #10\tAverage Generator Loss: 1862.938013\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15621 (step 15621): 1.610928\n",
      "Batch #10\tAverage Generator Loss: 2029.408954\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15622 (step 15622): 2.000308\n",
      "Batch #10\tAverage Generator Loss: 1981.789490\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15623 (step 15623): 1.393932\n",
      "Batch #10\tAverage Generator Loss: 1883.291455\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15624 (step 15624): 1.278515\n",
      "Batch #10\tAverage Generator Loss: 1781.946722\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15625 (step 15625): 4.544450\n",
      "Batch #10\tAverage Generator Loss: 2058.690521\tAverage Discriminator Loss: 0.346122\n",
      "\n",
      "Train time for epoch #15626 (step 15626): 1.401200\n",
      "Batch #10\tAverage Generator Loss: 1892.325714\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15627 (step 15627): 1.293839\n",
      "Batch #10\tAverage Generator Loss: 2501.307651\tAverage Discriminator Loss: 0.011402\n",
      "\n",
      "Train time for epoch #15628 (step 15628): 1.344015\n",
      "Batch #10\tAverage Generator Loss: 2516.727771\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15629 (step 15629): 2.006528\n",
      "Batch #10\tAverage Generator Loss: 2597.023303\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15630 (step 15630): 1.615915\n",
      "Batch #10\tAverage Generator Loss: 2301.047839\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15631 (step 15631): 1.497845\n",
      "Batch #10\tAverage Generator Loss: 2091.093683\tAverage Discriminator Loss: 0.110541\n",
      "\n",
      "Train time for epoch #15632 (step 15632): 1.891430\n",
      "Batch #10\tAverage Generator Loss: 1829.899438\tAverage Discriminator Loss: 0.024631\n",
      "\n",
      "Train time for epoch #15633 (step 15633): 1.368588\n",
      "Batch #10\tAverage Generator Loss: 2153.159473\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #15634 (step 15634): 1.395310\n",
      "Batch #10\tAverage Generator Loss: 1834.516989\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15635 (step 15635): 1.864730\n",
      "Batch #10\tAverage Generator Loss: 2249.344031\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15636 (step 15636): 1.391454\n",
      "Batch #10\tAverage Generator Loss: 1761.425555\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15637 (step 15637): 1.280334\n",
      "Batch #10\tAverage Generator Loss: 2232.347388\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15638 (step 15638): 1.773084\n",
      "Batch #10\tAverage Generator Loss: 1994.275671\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15639 (step 15639): 1.287319\n",
      "Batch #10\tAverage Generator Loss: 2174.743933\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15640 (step 15640): 1.338601\n",
      "Batch #10\tAverage Generator Loss: 2080.708276\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15641 (step 15641): 1.964887\n",
      "Batch #10\tAverage Generator Loss: 2079.575049\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15642 (step 15642): 1.357545\n",
      "Batch #10\tAverage Generator Loss: 1934.044513\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15643 (step 15643): 1.294809\n",
      "Batch #10\tAverage Generator Loss: 2108.147772\tAverage Discriminator Loss: 0.296731\n",
      "\n",
      "Train time for epoch #15644 (step 15644): 1.285040\n",
      "Batch #10\tAverage Generator Loss: 1947.185736\tAverage Discriminator Loss: 0.029826\n",
      "\n",
      "Train time for epoch #15645 (step 15645): 1.964437\n",
      "Batch #10\tAverage Generator Loss: 2016.724329\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15646 (step 15646): 1.302410\n",
      "Batch #10\tAverage Generator Loss: 1797.517157\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15647 (step 15647): 1.291309\n",
      "Batch #10\tAverage Generator Loss: 2205.606128\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15648 (step 15648): 1.851718\n",
      "Batch #10\tAverage Generator Loss: 2164.956702\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15649 (step 15649): 1.376680\n",
      "Batch #10\tAverage Generator Loss: 2096.888281\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15650 (step 15650): 1.247763\n",
      "Batch #10\tAverage Generator Loss: 1966.118671\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15651 (step 15651): 1.766500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 1924.613904\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15652 (step 15652): 1.479444\n",
      "Batch #10\tAverage Generator Loss: 1789.369995\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15653 (step 15653): 1.290844\n",
      "Batch #10\tAverage Generator Loss: 1661.840649\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15654 (step 15654): 1.849658\n",
      "Batch #10\tAverage Generator Loss: 1680.357516\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15655 (step 15655): 1.364022\n",
      "Batch #10\tAverage Generator Loss: 1721.442010\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15656 (step 15656): 1.375872\n",
      "Batch #10\tAverage Generator Loss: 2017.160400\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15657 (step 15657): 1.330975\n",
      "Batch #10\tAverage Generator Loss: 1801.683630\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15658 (step 15658): 1.888712\n",
      "Batch #10\tAverage Generator Loss: 1857.017773\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15659 (step 15659): 1.294953\n",
      "Batch #10\tAverage Generator Loss: 1972.707153\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15660 (step 15660): 1.290750\n",
      "Batch #10\tAverage Generator Loss: 1968.039514\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15661 (step 15661): 1.853724\n",
      "Batch #10\tAverage Generator Loss: 1994.330066\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15662 (step 15662): 1.328797\n",
      "Batch #10\tAverage Generator Loss: 1956.215808\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15663 (step 15663): 1.426646\n",
      "Batch #10\tAverage Generator Loss: 1955.685107\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15664 (step 15664): 1.864301\n",
      "Batch #10\tAverage Generator Loss: 1798.906018\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15665 (step 15665): 1.438502\n",
      "Batch #10\tAverage Generator Loss: 1775.859326\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15666 (step 15666): 1.384594\n",
      "Batch #10\tAverage Generator Loss: 2034.244458\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15667 (step 15667): 1.834896\n",
      "Batch #10\tAverage Generator Loss: 1636.194968\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15668 (step 15668): 1.386691\n",
      "Batch #10\tAverage Generator Loss: 2039.817859\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #15669 (step 15669): 1.343824\n",
      "Batch #10\tAverage Generator Loss: 1937.597278\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #15670 (step 15670): 1.343423\n",
      "Batch #10\tAverage Generator Loss: 1946.267627\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #15671 (step 15671): 1.883875\n",
      "Batch #10\tAverage Generator Loss: 2000.030762\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #15672 (step 15672): 1.287707\n",
      "Batch #10\tAverage Generator Loss: 2007.811511\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #15673 (step 15673): 1.411853\n",
      "Batch #10\tAverage Generator Loss: 1829.647900\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15674 (step 15674): 1.825217\n",
      "Batch #10\tAverage Generator Loss: 1997.272742\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15675 (step 15675): 1.300511\n",
      "Batch #10\tAverage Generator Loss: 1955.252332\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15676 (step 15676): 1.300117\n",
      "Batch #10\tAverage Generator Loss: 1981.554822\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15677 (step 15677): 1.787385\n",
      "Batch #10\tAverage Generator Loss: 1969.689917\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15678 (step 15678): 1.295643\n",
      "Batch #10\tAverage Generator Loss: 1815.433801\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15679 (step 15679): 1.307597\n",
      "Batch #10\tAverage Generator Loss: 2239.955334\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15680 (step 15680): 1.906526\n",
      "Batch #10\tAverage Generator Loss: 2031.801532\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #15681 (step 15681): 1.348864\n",
      "Batch #10\tAverage Generator Loss: 1669.460342\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15682 (step 15682): 1.308805\n",
      "Batch #10\tAverage Generator Loss: 1800.362012\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15683 (step 15683): 1.905838\n",
      "Batch #10\tAverage Generator Loss: 1694.114999\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15684 (step 15684): 1.366022\n",
      "Batch #10\tAverage Generator Loss: 2000.169336\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #15685 (step 15685): 1.315352\n",
      "Batch #10\tAverage Generator Loss: 1735.969855\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15686 (step 15686): 1.294915\n",
      "Batch #10\tAverage Generator Loss: 1766.053333\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15687 (step 15687): 1.768861\n",
      "Batch #10\tAverage Generator Loss: 1991.252222\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15688 (step 15688): 1.305574\n",
      "Batch #10\tAverage Generator Loss: 1579.293988\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15689 (step 15689): 1.341378\n",
      "Batch #10\tAverage Generator Loss: 2157.909253\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15690 (step 15690): 1.844526\n",
      "Batch #10\tAverage Generator Loss: 1824.637592\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15691 (step 15691): 1.436632\n",
      "Batch #10\tAverage Generator Loss: 1945.152942\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15692 (step 15692): 1.327148\n",
      "Batch #10\tAverage Generator Loss: 1817.089655\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15693 (step 15693): 1.833476\n",
      "Batch #10\tAverage Generator Loss: 1773.748999\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15694 (step 15694): 1.351707\n",
      "Batch #10\tAverage Generator Loss: 1793.705231\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15695 (step 15695): 1.273747\n",
      "Batch #10\tAverage Generator Loss: 1967.260736\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15696 (step 15696): 1.336138\n",
      "Batch #10\tAverage Generator Loss: 1802.355634\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15697 (step 15697): 1.906723\n",
      "Batch #10\tAverage Generator Loss: 1692.947302\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15698 (step 15698): 1.364084\n",
      "Batch #10\tAverage Generator Loss: 1907.728113\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15699 (step 15699): 1.472891\n",
      "Batch #10\tAverage Generator Loss: 2069.908795\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15700 (step 15700): 1.830176\n",
      "Batch #10\tAverage Generator Loss: 1780.221875\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15701 (step 15701): 1.397981\n",
      "Batch #10\tAverage Generator Loss: 1620.855020\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15702 (step 15702): 1.320407\n",
      "Batch #10\tAverage Generator Loss: 1970.980435\tAverage Discriminator Loss: 0.000077\n",
      "\n",
      "Train time for epoch #15703 (step 15703): 1.924423\n",
      "Batch #10\tAverage Generator Loss: 1948.095044\tAverage Discriminator Loss: 0.000054\n",
      "\n",
      "Train time for epoch #15704 (step 15704): 1.294629\n",
      "Batch #10\tAverage Generator Loss: 2055.808496\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15705 (step 15705): 1.355209\n",
      "Batch #10\tAverage Generator Loss: 1379.927383\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15706 (step 15706): 1.859951\n",
      "Batch #10\tAverage Generator Loss: 1765.561243\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15707 (step 15707): 1.291796\n",
      "Batch #10\tAverage Generator Loss: 1710.488507\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15708 (step 15708): 1.289701\n",
      "Batch #10\tAverage Generator Loss: 1594.909772\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15709 (step 15709): 1.871318\n",
      "Batch #10\tAverage Generator Loss: 1855.249969\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15710 (step 15710): 1.322541\n",
      "Batch #10\tAverage Generator Loss: 1864.314319\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15711 (step 15711): 1.481283\n",
      "Batch #10\tAverage Generator Loss: 1850.685681\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15712 (step 15712): 1.335624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 1906.613098\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15713 (step 15713): 1.852281\n",
      "Batch #10\tAverage Generator Loss: 1877.736261\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15714 (step 15714): 1.321022\n",
      "Batch #10\tAverage Generator Loss: 2022.306165\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15715 (step 15715): 1.402833\n",
      "Batch #10\tAverage Generator Loss: 1877.829529\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15716 (step 15716): 1.774603\n",
      "Batch #10\tAverage Generator Loss: 1849.437506\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15717 (step 15717): 1.309657\n",
      "Batch #10\tAverage Generator Loss: 1827.562119\tAverage Discriminator Loss: 0.027300\n",
      "\n",
      "Train time for epoch #15718 (step 15718): 1.399842\n",
      "Batch #10\tAverage Generator Loss: 1699.668683\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #15719 (step 15719): 1.939393\n",
      "Batch #10\tAverage Generator Loss: 1733.592038\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #15720 (step 15720): 1.292266\n",
      "Batch #10\tAverage Generator Loss: 1805.473499\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15721 (step 15721): 1.346375\n",
      "Batch #10\tAverage Generator Loss: 1964.103397\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15722 (step 15722): 1.881983\n",
      "Batch #10\tAverage Generator Loss: 1929.312817\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15723 (step 15723): 1.317245\n",
      "Batch #10\tAverage Generator Loss: 1893.788379\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #15724 (step 15724): 1.291708\n",
      "Batch #10\tAverage Generator Loss: 1621.321924\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #15725 (step 15725): 1.248630\n",
      "Batch #10\tAverage Generator Loss: 2075.100781\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15726 (step 15726): 1.804265\n",
      "Batch #10\tAverage Generator Loss: 2255.190564\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15727 (step 15727): 1.379642\n",
      "Batch #10\tAverage Generator Loss: 2046.825208\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15728 (step 15728): 1.285684\n",
      "Batch #10\tAverage Generator Loss: 1882.959009\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15729 (step 15729): 1.870080\n",
      "Batch #10\tAverage Generator Loss: 1904.810046\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15730 (step 15730): 1.400464\n",
      "Batch #10\tAverage Generator Loss: 1858.196606\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15731 (step 15731): 1.289430\n",
      "Batch #10\tAverage Generator Loss: 2104.560034\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15732 (step 15732): 1.900187\n",
      "Batch #10\tAverage Generator Loss: 1923.527228\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15733 (step 15733): 1.336017\n",
      "Batch #10\tAverage Generator Loss: 2251.767639\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15734 (step 15734): 1.401047\n",
      "Batch #10\tAverage Generator Loss: 1931.091351\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15735 (step 15735): 1.378641\n",
      "Batch #10\tAverage Generator Loss: 1701.590137\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15736 (step 15736): 1.870514\n",
      "Batch #10\tAverage Generator Loss: 1875.802838\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15737 (step 15737): 1.277881\n",
      "Batch #10\tAverage Generator Loss: 1965.257996\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15738 (step 15738): 1.338050\n",
      "Batch #10\tAverage Generator Loss: 1892.484052\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15739 (step 15739): 1.826685\n",
      "Batch #10\tAverage Generator Loss: 1667.640021\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15740 (step 15740): 1.354670\n",
      "Batch #10\tAverage Generator Loss: 2147.039465\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15741 (step 15741): 1.434917\n",
      "Batch #10\tAverage Generator Loss: 2079.392072\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15742 (step 15742): 1.948462\n",
      "Batch #10\tAverage Generator Loss: 1834.877563\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15743 (step 15743): 1.288963\n",
      "Batch #10\tAverage Generator Loss: 1659.617212\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15744 (step 15744): 1.405890\n",
      "Batch #10\tAverage Generator Loss: 1844.810339\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15745 (step 15745): 1.307072\n",
      "Batch #10\tAverage Generator Loss: 1974.940295\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15746 (step 15746): 1.878239\n",
      "Batch #10\tAverage Generator Loss: 1794.224060\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15747 (step 15747): 1.381978\n",
      "Batch #10\tAverage Generator Loss: 1749.634192\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15748 (step 15748): 1.295506\n",
      "Batch #10\tAverage Generator Loss: 1767.178619\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15749 (step 15749): 1.868619\n",
      "Batch #10\tAverage Generator Loss: 1890.386761\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15750 (step 15750): 1.330163\n",
      "Batch #10\tAverage Generator Loss: 2170.841559\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15751 (step 15751): 1.302114\n",
      "Batch #10\tAverage Generator Loss: 1737.168463\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15752 (step 15752): 1.890399\n",
      "Batch #10\tAverage Generator Loss: 1738.630396\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15753 (step 15753): 1.315988\n",
      "Batch #10\tAverage Generator Loss: 1733.855334\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15754 (step 15754): 1.265798\n",
      "Batch #10\tAverage Generator Loss: 1979.434473\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15755 (step 15755): 1.780298\n",
      "Batch #10\tAverage Generator Loss: 2142.449536\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15756 (step 15756): 1.406311\n",
      "Batch #10\tAverage Generator Loss: 1887.938708\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15757 (step 15757): 1.391200\n",
      "Batch #10\tAverage Generator Loss: 1842.497729\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15758 (step 15758): 1.328943\n",
      "Batch #10\tAverage Generator Loss: 1943.241382\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15759 (step 15759): 1.914483\n",
      "Batch #10\tAverage Generator Loss: 1699.594080\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15760 (step 15760): 1.293142\n",
      "Batch #10\tAverage Generator Loss: 1803.099878\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15761 (step 15761): 1.282050\n",
      "Batch #10\tAverage Generator Loss: 2121.720422\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15762 (step 15762): 1.771362\n",
      "Batch #10\tAverage Generator Loss: 1872.750427\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15763 (step 15763): 1.345117\n",
      "Batch #10\tAverage Generator Loss: 2024.747119\tAverage Discriminator Loss: 0.023490\n",
      "\n",
      "Train time for epoch #15764 (step 15764): 1.469949\n",
      "Batch #10\tAverage Generator Loss: 2192.271802\tAverage Discriminator Loss: 0.010546\n",
      "\n",
      "Train time for epoch #15765 (step 15765): 1.768325\n",
      "Batch #10\tAverage Generator Loss: 2035.899261\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #15766 (step 15766): 1.279328\n",
      "Batch #10\tAverage Generator Loss: 2204.474304\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15767 (step 15767): 1.336796\n",
      "Batch #10\tAverage Generator Loss: 2164.914758\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15768 (step 15768): 1.844430\n",
      "Batch #10\tAverage Generator Loss: 2499.735266\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15769 (step 15769): 1.240589\n",
      "Batch #10\tAverage Generator Loss: 2151.651721\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15770 (step 15770): 1.307488\n",
      "Batch #10\tAverage Generator Loss: 2154.056787\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15771 (step 15771): 1.600828\n",
      "Batch #10\tAverage Generator Loss: 2000.424451\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15772 (step 15772): 1.886239\n",
      "Batch #10\tAverage Generator Loss: 2204.743628\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15773 (step 15773): 1.285066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2098.790588\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15774 (step 15774): 1.293555\n",
      "Batch #10\tAverage Generator Loss: 2135.845886\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15775 (step 15775): 1.826129\n",
      "Batch #10\tAverage Generator Loss: 2236.936499\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15776 (step 15776): 1.331116\n",
      "Batch #10\tAverage Generator Loss: 2146.098352\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15777 (step 15777): 1.330858\n",
      "Batch #10\tAverage Generator Loss: 2519.129785\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15778 (step 15778): 1.961689\n",
      "Batch #10\tAverage Generator Loss: 2246.125012\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15779 (step 15779): 1.392061\n",
      "Batch #10\tAverage Generator Loss: 2355.905695\tAverage Discriminator Loss: 0.387672\n",
      "\n",
      "Train time for epoch #15780 (step 15780): 1.343640\n",
      "Batch #10\tAverage Generator Loss: 3219.543652\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15781 (step 15781): 1.327998\n",
      "Batch #10\tAverage Generator Loss: 3276.633899\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15782 (step 15782): 1.876862\n",
      "Batch #10\tAverage Generator Loss: 3107.333545\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15783 (step 15783): 1.295804\n",
      "Batch #10\tAverage Generator Loss: 2898.067700\tAverage Discriminator Loss: 0.030063\n",
      "\n",
      "Train time for epoch #15784 (step 15784): 1.350546\n",
      "Batch #10\tAverage Generator Loss: 3051.591260\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15785 (step 15785): 1.880052\n",
      "Batch #10\tAverage Generator Loss: 2819.924181\tAverage Discriminator Loss: 0.218635\n",
      "\n",
      "Train time for epoch #15786 (step 15786): 1.298056\n",
      "Batch #10\tAverage Generator Loss: 2405.907007\tAverage Discriminator Loss: 0.305200\n",
      "\n",
      "Train time for epoch #15787 (step 15787): 1.289854\n",
      "Batch #10\tAverage Generator Loss: 2180.139978\tAverage Discriminator Loss: 0.000235\n",
      "\n",
      "Train time for epoch #15788 (step 15788): 1.898404\n",
      "Batch #10\tAverage Generator Loss: 2433.639929\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #15789 (step 15789): 1.530073\n",
      "Batch #10\tAverage Generator Loss: 2713.259058\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #15790 (step 15790): 1.327477\n",
      "Batch #10\tAverage Generator Loss: 2323.997131\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #15791 (step 15791): 1.921260\n",
      "Batch #10\tAverage Generator Loss: 2418.470959\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #15792 (step 15792): 1.308600\n",
      "Batch #10\tAverage Generator Loss: 2462.191980\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #15793 (step 15793): 1.293030\n",
      "Batch #10\tAverage Generator Loss: 2063.614600\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #15794 (step 15794): 1.843959\n",
      "Batch #10\tAverage Generator Loss: 2508.450757\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15795 (step 15795): 1.439863\n",
      "Batch #10\tAverage Generator Loss: 2320.183063\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #15796 (step 15796): 1.395756\n",
      "Batch #10\tAverage Generator Loss: 2435.355334\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #15797 (step 15797): 1.289446\n",
      "Batch #10\tAverage Generator Loss: 2410.687573\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #15798 (step 15798): 1.851359\n",
      "Batch #10\tAverage Generator Loss: 2251.913849\tAverage Discriminator Loss: 0.000050\n",
      "\n",
      "Train time for epoch #15799 (step 15799): 1.308956\n",
      "Batch #10\tAverage Generator Loss: 2687.301111\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #15800 (step 15800): 1.275061\n",
      "Batch #10\tAverage Generator Loss: 2469.784631\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #15801 (step 15801): 1.853353\n",
      "Batch #10\tAverage Generator Loss: 2226.066296\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #15802 (step 15802): 1.342185\n",
      "Batch #10\tAverage Generator Loss: 2578.555432\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #15803 (step 15803): 1.295448\n",
      "Batch #10\tAverage Generator Loss: 2165.936804\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #15804 (step 15804): 1.898767\n",
      "Batch #10\tAverage Generator Loss: 2293.449011\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #15805 (step 15805): 1.341847\n",
      "Batch #10\tAverage Generator Loss: 2543.923474\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15806 (step 15806): 1.348012\n",
      "Batch #10\tAverage Generator Loss: 2437.630750\tAverage Discriminator Loss: 0.000443\n",
      "\n",
      "Train time for epoch #15807 (step 15807): 1.896090\n",
      "Batch #10\tAverage Generator Loss: 2196.662537\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #15808 (step 15808): 1.472594\n",
      "Batch #10\tAverage Generator Loss: 2211.021930\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15809 (step 15809): 1.310693\n",
      "Batch #10\tAverage Generator Loss: 2512.885999\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15810 (step 15810): 1.906574\n",
      "Batch #10\tAverage Generator Loss: 2315.390808\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15811 (step 15811): 1.485227\n",
      "Batch #10\tAverage Generator Loss: 2255.912354\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15812 (step 15812): 1.291186\n",
      "Batch #10\tAverage Generator Loss: 2265.261688\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15813 (step 15813): 1.448554\n",
      "Batch #10\tAverage Generator Loss: 2197.692517\tAverage Discriminator Loss: 0.000019\n",
      "\n",
      "Train time for epoch #15814 (step 15814): 1.903853\n",
      "Batch #10\tAverage Generator Loss: 2169.677478\tAverage Discriminator Loss: 0.000066\n",
      "\n",
      "Train time for epoch #15815 (step 15815): 1.302592\n",
      "Batch #10\tAverage Generator Loss: 2331.483777\tAverage Discriminator Loss: 0.000082\n",
      "\n",
      "Train time for epoch #15816 (step 15816): 1.315760\n",
      "Batch #10\tAverage Generator Loss: 2860.640515\tAverage Discriminator Loss: 0.181078\n",
      "\n",
      "Train time for epoch #15817 (step 15817): 1.782164\n",
      "Batch #10\tAverage Generator Loss: 2723.626825\tAverage Discriminator Loss: 0.025141\n",
      "\n",
      "Train time for epoch #15818 (step 15818): 1.333560\n",
      "Batch #10\tAverage Generator Loss: 2736.318158\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15819 (step 15819): 1.374104\n",
      "Batch #10\tAverage Generator Loss: 2937.979492\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15820 (step 15820): 1.952199\n",
      "Batch #10\tAverage Generator Loss: 2739.452881\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15821 (step 15821): 1.299235\n",
      "Batch #10\tAverage Generator Loss: 3012.851208\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15822 (step 15822): 1.343134\n",
      "Batch #10\tAverage Generator Loss: 2762.122961\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15823 (step 15823): 1.398626\n",
      "Batch #10\tAverage Generator Loss: 2418.317096\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15824 (step 15824): 1.774821\n",
      "Batch #10\tAverage Generator Loss: 2961.290613\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15825 (step 15825): 1.298819\n",
      "Batch #10\tAverage Generator Loss: 2631.995427\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15826 (step 15826): 1.309891\n",
      "Batch #10\tAverage Generator Loss: 3197.131763\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15827 (step 15827): 1.833851\n",
      "Batch #10\tAverage Generator Loss: 2843.518091\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15828 (step 15828): 1.286475\n",
      "Batch #10\tAverage Generator Loss: 2575.134839\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15829 (step 15829): 1.380870\n",
      "Batch #10\tAverage Generator Loss: 3145.903040\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15830 (step 15830): 1.855611\n",
      "Batch #10\tAverage Generator Loss: 3056.437073\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15831 (step 15831): 1.241998\n",
      "Batch #10\tAverage Generator Loss: 3041.075000\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15832 (step 15832): 1.287033\n",
      "Batch #10\tAverage Generator Loss: 2768.385693\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15833 (step 15833): 1.338790\n",
      "Batch #10\tAverage Generator Loss: 2746.068896\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15834 (step 15834): 1.789652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2909.535571\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15835 (step 15835): 1.333118\n",
      "Batch #10\tAverage Generator Loss: 2596.847729\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15836 (step 15836): 1.366689\n",
      "Batch #10\tAverage Generator Loss: 2386.177271\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15837 (step 15837): 1.798498\n",
      "Batch #10\tAverage Generator Loss: 3053.439282\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15838 (step 15838): 1.426549\n",
      "Batch #10\tAverage Generator Loss: 2770.135303\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15839 (step 15839): 1.309140\n",
      "Batch #10\tAverage Generator Loss: 2810.930591\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15840 (step 15840): 1.828125\n",
      "Batch #10\tAverage Generator Loss: 2964.176367\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15841 (step 15841): 1.288651\n",
      "Batch #10\tAverage Generator Loss: 2572.554358\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15842 (step 15842): 1.525095\n",
      "Batch #10\tAverage Generator Loss: 2513.486682\tAverage Discriminator Loss: 0.022683\n",
      "\n",
      "Train time for epoch #15843 (step 15843): 1.860099\n",
      "Batch #10\tAverage Generator Loss: 3252.726465\tAverage Discriminator Loss: 0.002026\n",
      "\n",
      "Train time for epoch #15844 (step 15844): 1.333353\n",
      "Batch #10\tAverage Generator Loss: 2927.766089\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #15845 (step 15845): 1.292349\n",
      "Batch #10\tAverage Generator Loss: 3033.174902\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15846 (step 15846): 1.299046\n",
      "Batch #10\tAverage Generator Loss: 2794.701373\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15847 (step 15847): 1.793334\n",
      "Batch #10\tAverage Generator Loss: 2739.524011\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15848 (step 15848): 1.344332\n",
      "Batch #10\tAverage Generator Loss: 2734.885461\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15849 (step 15849): 1.343552\n",
      "Batch #10\tAverage Generator Loss: 2724.802057\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15850 (step 15850): 1.920876\n",
      "Batch #10\tAverage Generator Loss: 2928.219897\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15851 (step 15851): 1.338257\n",
      "Batch #10\tAverage Generator Loss: 2914.168372\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15852 (step 15852): 1.325183\n",
      "Batch #10\tAverage Generator Loss: 2901.025891\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15853 (step 15853): 1.897596\n",
      "Batch #10\tAverage Generator Loss: 2770.712622\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15854 (step 15854): 1.342628\n",
      "Batch #10\tAverage Generator Loss: 2858.320154\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15855 (step 15855): 1.320767\n",
      "Batch #10\tAverage Generator Loss: 2334.615289\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15856 (step 15856): 1.877239\n",
      "Batch #10\tAverage Generator Loss: 2487.906360\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15857 (step 15857): 1.292896\n",
      "Batch #10\tAverage Generator Loss: 2781.443738\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15858 (step 15858): 1.407690\n",
      "Batch #10\tAverage Generator Loss: 2983.247205\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15859 (step 15859): 1.334548\n",
      "Batch #10\tAverage Generator Loss: 2950.530646\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15860 (step 15860): 1.864954\n",
      "Batch #10\tAverage Generator Loss: 2802.679187\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15861 (step 15861): 1.336570\n",
      "Batch #10\tAverage Generator Loss: 2798.599829\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15862 (step 15862): 1.282555\n",
      "Batch #10\tAverage Generator Loss: 2930.683667\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15863 (step 15863): 1.867739\n",
      "Batch #10\tAverage Generator Loss: 2862.521820\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15864 (step 15864): 1.306006\n",
      "Batch #10\tAverage Generator Loss: 3062.043274\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15865 (step 15865): 1.434134\n",
      "Batch #10\tAverage Generator Loss: 3045.098987\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15866 (step 15866): 1.970605\n",
      "Batch #10\tAverage Generator Loss: 2526.217371\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15867 (step 15867): 1.473523\n",
      "Batch #10\tAverage Generator Loss: 2859.769800\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15868 (step 15868): 1.362983\n",
      "Batch #10\tAverage Generator Loss: 2952.648535\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15869 (step 15869): 1.295228\n",
      "Batch #10\tAverage Generator Loss: 2797.900916\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15870 (step 15870): 1.850141\n",
      "Batch #10\tAverage Generator Loss: 2930.987842\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15871 (step 15871): 1.283608\n",
      "Batch #10\tAverage Generator Loss: 2727.871265\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15872 (step 15872): 1.473681\n",
      "Batch #10\tAverage Generator Loss: 3054.781116\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15873 (step 15873): 1.737305\n",
      "Batch #10\tAverage Generator Loss: 2918.552698\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15874 (step 15874): 1.340393\n",
      "Batch #10\tAverage Generator Loss: 2307.886230\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15875 (step 15875): 1.317414\n",
      "Batch #10\tAverage Generator Loss: 2352.789166\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15876 (step 15876): 1.906848\n",
      "Batch #10\tAverage Generator Loss: 2490.199792\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15877 (step 15877): 1.240551\n",
      "Batch #10\tAverage Generator Loss: 2544.619141\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15878 (step 15878): 1.283829\n",
      "Batch #10\tAverage Generator Loss: 2481.558734\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15879 (step 15879): 1.341111\n",
      "Batch #10\tAverage Generator Loss: 3018.008960\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15880 (step 15880): 1.883494\n",
      "Batch #10\tAverage Generator Loss: 2426.111292\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15881 (step 15881): 1.388925\n",
      "Batch #10\tAverage Generator Loss: 2748.270483\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15882 (step 15882): 1.281064\n",
      "Batch #10\tAverage Generator Loss: 2508.152039\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15883 (step 15883): 1.781857\n",
      "Batch #10\tAverage Generator Loss: 2997.290015\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15884 (step 15884): 1.364191\n",
      "Batch #10\tAverage Generator Loss: 2493.187280\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15885 (step 15885): 1.338449\n",
      "Batch #10\tAverage Generator Loss: 2916.288745\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15886 (step 15886): 1.841238\n",
      "Batch #10\tAverage Generator Loss: 2767.423022\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15887 (step 15887): 1.403903\n",
      "Batch #10\tAverage Generator Loss: 2881.028796\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15888 (step 15888): 1.350594\n",
      "Batch #10\tAverage Generator Loss: 3019.788403\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15889 (step 15889): 1.900980\n",
      "Batch #10\tAverage Generator Loss: 2724.766357\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15890 (step 15890): 1.356057\n",
      "Batch #10\tAverage Generator Loss: 2874.018298\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15891 (step 15891): 1.291987\n",
      "Batch #10\tAverage Generator Loss: 2131.783447\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15892 (step 15892): 1.327013\n",
      "Batch #10\tAverage Generator Loss: 2449.884436\tAverage Discriminator Loss: 0.003279\n",
      "\n",
      "Train time for epoch #15893 (step 15893): 1.880253\n",
      "Batch #10\tAverage Generator Loss: 2089.699847\tAverage Discriminator Loss: 0.000185\n",
      "\n",
      "Train time for epoch #15894 (step 15894): 1.330702\n",
      "Batch #10\tAverage Generator Loss: 2360.702930\tAverage Discriminator Loss: 0.000145\n",
      "\n",
      "Train time for epoch #15895 (step 15895): 1.394191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2570.769693\tAverage Discriminator Loss: 0.000032\n",
      "\n",
      "Train time for epoch #15896 (step 15896): 1.831120\n",
      "Batch #10\tAverage Generator Loss: 2621.715588\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #15897 (step 15897): 1.369586\n",
      "Batch #10\tAverage Generator Loss: 2755.185010\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #15898 (step 15898): 1.345560\n",
      "Batch #10\tAverage Generator Loss: 3147.313867\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #15899 (step 15899): 2.002375\n",
      "Batch #10\tAverage Generator Loss: 2881.013184\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #15900 (step 15900): 1.289803\n",
      "Batch #10\tAverage Generator Loss: 2512.544067\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #15901 (step 15901): 1.281589\n",
      "Batch #10\tAverage Generator Loss: 3107.739966\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #15902 (step 15902): 1.375434\n",
      "Batch #10\tAverage Generator Loss: 2367.104327\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #15903 (step 15903): 1.881247\n",
      "Batch #10\tAverage Generator Loss: 2838.583167\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #15904 (step 15904): 1.474022\n",
      "Batch #10\tAverage Generator Loss: 2723.418671\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #15905 (step 15905): 1.419846\n",
      "Batch #10\tAverage Generator Loss: 2850.377637\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #15906 (step 15906): 1.883794\n",
      "Batch #10\tAverage Generator Loss: 2921.437915\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #15907 (step 15907): 1.369476\n",
      "Batch #10\tAverage Generator Loss: 2502.396021\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #15908 (step 15908): 1.282326\n",
      "Batch #10\tAverage Generator Loss: 2907.770935\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #15909 (step 15909): 1.811244\n",
      "Batch #10\tAverage Generator Loss: 2339.729242\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #15910 (step 15910): 1.300947\n",
      "Batch #10\tAverage Generator Loss: 2910.724500\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #15911 (step 15911): 1.291124\n",
      "Batch #10\tAverage Generator Loss: 2301.000562\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #15912 (step 15912): 1.311489\n",
      "Batch #10\tAverage Generator Loss: 2418.574652\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #15913 (step 15913): 1.919929\n",
      "Batch #10\tAverage Generator Loss: 2281.556714\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #15914 (step 15914): 1.462755\n",
      "Batch #10\tAverage Generator Loss: 2567.680713\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #15915 (step 15915): 1.289249\n",
      "Batch #10\tAverage Generator Loss: 3078.741467\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #15916 (step 15916): 1.787853\n",
      "Batch #10\tAverage Generator Loss: 3001.538245\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #15917 (step 15917): 1.301102\n",
      "Batch #10\tAverage Generator Loss: 3009.300085\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15918 (step 15918): 1.293254\n",
      "Batch #10\tAverage Generator Loss: 3042.650122\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #15919 (step 15919): 1.977240\n",
      "Batch #10\tAverage Generator Loss: 2510.387134\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15920 (step 15920): 1.305115\n",
      "Batch #10\tAverage Generator Loss: 3032.363989\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #15921 (step 15921): 1.297543\n",
      "Batch #10\tAverage Generator Loss: 2841.740417\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #15922 (step 15922): 1.954611\n",
      "Batch #10\tAverage Generator Loss: 2450.442157\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #15923 (step 15923): 1.350366\n",
      "Batch #10\tAverage Generator Loss: 2488.010205\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #15924 (step 15924): 1.391593\n",
      "Batch #10\tAverage Generator Loss: 2806.746802\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15925 (step 15925): 1.327455\n",
      "Batch #10\tAverage Generator Loss: 2431.321484\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15926 (step 15926): 1.787102\n",
      "Batch #10\tAverage Generator Loss: 2503.821436\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15927 (step 15927): 1.289349\n",
      "Batch #10\tAverage Generator Loss: 3009.866650\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15928 (step 15928): 1.400389\n",
      "Batch #10\tAverage Generator Loss: 2927.042676\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #15929 (step 15929): 1.836583\n",
      "Batch #10\tAverage Generator Loss: 3197.254736\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #15930 (step 15930): 1.304126\n",
      "Batch #10\tAverage Generator Loss: 2874.171558\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15931 (step 15931): 1.287659\n",
      "Batch #10\tAverage Generator Loss: 3323.097974\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15932 (step 15932): 1.870201\n",
      "Batch #10\tAverage Generator Loss: 3072.749756\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15933 (step 15933): 1.345560\n",
      "Batch #10\tAverage Generator Loss: 2809.904248\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15934 (step 15934): 1.298024\n",
      "Batch #10\tAverage Generator Loss: 2477.409119\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15935 (step 15935): 1.845990\n",
      "Batch #10\tAverage Generator Loss: 2503.429626\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15936 (step 15936): 1.329047\n",
      "Batch #10\tAverage Generator Loss: 2494.564978\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15937 (step 15937): 1.297181\n",
      "Batch #10\tAverage Generator Loss: 2285.251624\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15938 (step 15938): 1.352754\n",
      "Batch #10\tAverage Generator Loss: 2702.204272\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15939 (step 15939): 1.847444\n",
      "Batch #10\tAverage Generator Loss: 2617.351282\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15940 (step 15940): 1.308570\n",
      "Batch #10\tAverage Generator Loss: 2844.337567\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15941 (step 15941): 1.491418\n",
      "Batch #10\tAverage Generator Loss: 2694.062244\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15942 (step 15942): 1.873439\n",
      "Batch #10\tAverage Generator Loss: 2621.668835\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15943 (step 15943): 1.312997\n",
      "Batch #10\tAverage Generator Loss: 2823.168689\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15944 (step 15944): 1.331033\n",
      "Batch #10\tAverage Generator Loss: 2741.166217\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15945 (step 15945): 1.957693\n",
      "Batch #10\tAverage Generator Loss: 2815.636847\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15946 (step 15946): 1.369914\n",
      "Batch #10\tAverage Generator Loss: 2787.186414\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15947 (step 15947): 1.387974\n",
      "Batch #10\tAverage Generator Loss: 2918.091797\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15948 (step 15948): 1.390185\n",
      "Batch #10\tAverage Generator Loss: 2363.364368\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15949 (step 15949): 1.827414\n",
      "Batch #10\tAverage Generator Loss: 2938.401477\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15950 (step 15950): 1.387345\n",
      "Batch #10\tAverage Generator Loss: 2839.469727\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15951 (step 15951): 1.353834\n",
      "Batch #10\tAverage Generator Loss: 3244.863110\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15952 (step 15952): 1.787114\n",
      "Batch #10\tAverage Generator Loss: 2803.140674\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15953 (step 15953): 1.342529\n",
      "Batch #10\tAverage Generator Loss: 2620.342981\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #15954 (step 15954): 1.472593\n",
      "Batch #10\tAverage Generator Loss: 2138.985965\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15955 (step 15955): 1.792476\n",
      "Batch #10\tAverage Generator Loss: 2718.389111\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15956 (step 15956): 1.289224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2646.712561\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15957 (step 15957): 1.292211\n",
      "Batch #10\tAverage Generator Loss: 2827.425110\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15958 (step 15958): 1.805779\n",
      "Batch #10\tAverage Generator Loss: 2368.166962\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15959 (step 15959): 1.296314\n",
      "Batch #10\tAverage Generator Loss: 2746.356158\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15960 (step 15960): 1.389752\n",
      "Batch #10\tAverage Generator Loss: 2613.448340\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15961 (step 15961): 1.387762\n",
      "Batch #10\tAverage Generator Loss: 2449.037549\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15962 (step 15962): 1.819321\n",
      "Batch #10\tAverage Generator Loss: 2910.579675\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15963 (step 15963): 1.409607\n",
      "Batch #10\tAverage Generator Loss: 2858.124341\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15964 (step 15964): 1.391423\n",
      "Batch #10\tAverage Generator Loss: 2701.089148\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15965 (step 15965): 1.759788\n",
      "Batch #10\tAverage Generator Loss: 2791.540198\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15966 (step 15966): 1.287991\n",
      "Batch #10\tAverage Generator Loss: 2828.560364\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15967 (step 15967): 1.382318\n",
      "Batch #10\tAverage Generator Loss: 2536.649561\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15968 (step 15968): 1.840574\n",
      "Batch #10\tAverage Generator Loss: 2497.248865\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15969 (step 15969): 1.284002\n",
      "Batch #10\tAverage Generator Loss: 2883.496375\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15970 (step 15970): 1.293087\n",
      "Batch #10\tAverage Generator Loss: 2977.447693\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15971 (step 15971): 1.874075\n",
      "Batch #10\tAverage Generator Loss: 2572.828442\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15972 (step 15972): 1.402302\n",
      "Batch #10\tAverage Generator Loss: 2560.129150\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15973 (step 15973): 1.392834\n",
      "Batch #10\tAverage Generator Loss: 3017.920166\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15974 (step 15974): 1.829513\n",
      "Batch #10\tAverage Generator Loss: 2343.907965\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15975 (step 15975): 1.242076\n",
      "Batch #10\tAverage Generator Loss: 2714.990674\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15976 (step 15976): 1.351259\n",
      "Batch #10\tAverage Generator Loss: 2477.324933\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15977 (step 15977): 1.478875\n",
      "Batch #10\tAverage Generator Loss: 2242.346820\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15978 (step 15978): 1.815012\n",
      "Batch #10\tAverage Generator Loss: 2678.226007\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15979 (step 15979): 1.343469\n",
      "Batch #10\tAverage Generator Loss: 2569.035730\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15980 (step 15980): 1.345433\n",
      "Batch #10\tAverage Generator Loss: 2985.951733\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15981 (step 15981): 1.934273\n",
      "Batch #10\tAverage Generator Loss: 2898.480762\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15982 (step 15982): 1.283820\n",
      "Batch #10\tAverage Generator Loss: 2737.703235\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15983 (step 15983): 1.327235\n",
      "Batch #10\tAverage Generator Loss: 2951.256055\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15984 (step 15984): 1.829562\n",
      "Batch #10\tAverage Generator Loss: 2454.817859\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15985 (step 15985): 1.347186\n",
      "Batch #10\tAverage Generator Loss: 2488.819226\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15986 (step 15986): 1.406314\n",
      "Batch #10\tAverage Generator Loss: 2780.114478\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15987 (step 15987): 1.394448\n",
      "Batch #10\tAverage Generator Loss: 2532.919214\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15988 (step 15988): 1.865073\n",
      "Batch #10\tAverage Generator Loss: 3006.677356\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15989 (step 15989): 1.325585\n",
      "Batch #10\tAverage Generator Loss: 2900.987671\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15990 (step 15990): 1.358715\n",
      "Batch #10\tAverage Generator Loss: 2852.528381\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15991 (step 15991): 1.791322\n",
      "Batch #10\tAverage Generator Loss: 2701.787561\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15992 (step 15992): 1.384588\n",
      "Batch #10\tAverage Generator Loss: 2478.391138\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15993 (step 15993): 1.389055\n",
      "Batch #10\tAverage Generator Loss: 2417.317126\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15994 (step 15994): 1.885312\n",
      "Batch #10\tAverage Generator Loss: 2908.813312\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15995 (step 15995): 1.304868\n",
      "Batch #10\tAverage Generator Loss: 2743.305212\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15996 (step 15996): 1.337151\n",
      "Batch #10\tAverage Generator Loss: 3053.682214\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15997 (step 15997): 1.814994\n",
      "Batch #10\tAverage Generator Loss: 2988.023853\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #15998 (step 15998): 1.386150\n",
      "Batch #10\tAverage Generator Loss: 2391.628601\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #15999 (step 15999): 1.290335\n",
      "Batch #10\tAverage Generator Loss: 2688.400269\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16000 (step 16000): 1.510269\n",
      "Batch #10\tAverage Generator Loss: 2819.672937\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16001 (step 16001): 1.927386\n",
      "Batch #10\tAverage Generator Loss: 2585.744714\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16002 (step 16002): 1.388704\n",
      "Batch #10\tAverage Generator Loss: 2868.147705\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16003 (step 16003): 1.345946\n",
      "Batch #10\tAverage Generator Loss: 2686.894153\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16004 (step 16004): 1.787661\n",
      "Batch #10\tAverage Generator Loss: 2614.841321\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16005 (step 16005): 1.409414\n",
      "Batch #10\tAverage Generator Loss: 2952.160034\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16006 (step 16006): 1.373704\n",
      "Batch #10\tAverage Generator Loss: 2597.360138\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16007 (step 16007): 2.007270\n",
      "Batch #10\tAverage Generator Loss: 2741.744739\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16008 (step 16008): 1.280315\n",
      "Batch #10\tAverage Generator Loss: 2236.986346\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16009 (step 16009): 1.335366\n",
      "Batch #10\tAverage Generator Loss: 2787.547498\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16010 (step 16010): 1.242140\n",
      "Batch #10\tAverage Generator Loss: 3054.914136\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16011 (step 16011): 1.873848\n",
      "Batch #10\tAverage Generator Loss: 2214.728638\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16012 (step 16012): 1.300571\n",
      "Batch #10\tAverage Generator Loss: 2795.984839\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16013 (step 16013): 1.396310\n",
      "Batch #10\tAverage Generator Loss: 2619.118274\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16014 (step 16014): 1.875918\n",
      "Batch #10\tAverage Generator Loss: 2381.277155\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16015 (step 16015): 1.335458\n",
      "Batch #10\tAverage Generator Loss: 3059.611792\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16016 (step 16016): 1.267401\n",
      "Batch #10\tAverage Generator Loss: 3026.003638\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16017 (step 16017): 1.793969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2775.194885\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16018 (step 16018): 1.300455\n",
      "Batch #10\tAverage Generator Loss: 2587.647107\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16019 (step 16019): 1.288941\n",
      "Batch #10\tAverage Generator Loss: 3126.341931\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16020 (step 16020): 1.347580\n",
      "Batch #10\tAverage Generator Loss: 2500.724829\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16021 (step 16021): 1.831386\n",
      "Batch #10\tAverage Generator Loss: 2583.223035\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16022 (step 16022): 1.330697\n",
      "Batch #10\tAverage Generator Loss: 2594.855432\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16023 (step 16023): 1.463811\n",
      "Batch #10\tAverage Generator Loss: 2892.904443\tAverage Discriminator Loss: 0.013206\n",
      "\n",
      "Train time for epoch #16024 (step 16024): 1.943092\n",
      "Batch #10\tAverage Generator Loss: 2976.422424\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16025 (step 16025): 1.277487\n",
      "Batch #10\tAverage Generator Loss: 2453.055078\tAverage Discriminator Loss: 0.000079\n",
      "\n",
      "Train time for epoch #16026 (step 16026): 1.233607\n",
      "Batch #10\tAverage Generator Loss: 2534.590698\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16027 (step 16027): 1.885111\n",
      "Batch #10\tAverage Generator Loss: 2615.594281\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16028 (step 16028): 1.337511\n",
      "Batch #10\tAverage Generator Loss: 2525.748279\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16029 (step 16029): 1.488918\n",
      "Batch #10\tAverage Generator Loss: 2294.633826\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16030 (step 16030): 1.897579\n",
      "Batch #10\tAverage Generator Loss: 2780.844672\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16031 (step 16031): 1.385915\n",
      "Batch #10\tAverage Generator Loss: 2582.234021\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16032 (step 16032): 1.338383\n",
      "Batch #10\tAverage Generator Loss: 2617.501660\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16033 (step 16033): 1.288165\n",
      "Batch #10\tAverage Generator Loss: 2833.477991\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16034 (step 16034): 1.838672\n",
      "Batch #10\tAverage Generator Loss: 2554.492200\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16035 (step 16035): 1.324108\n",
      "Batch #10\tAverage Generator Loss: 2928.794556\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16036 (step 16036): 1.291009\n",
      "Batch #10\tAverage Generator Loss: 2599.165576\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16037 (step 16037): 1.879591\n",
      "Batch #10\tAverage Generator Loss: 2870.593762\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16038 (step 16038): 1.333359\n",
      "Batch #10\tAverage Generator Loss: 2466.012769\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16039 (step 16039): 1.377240\n",
      "Batch #10\tAverage Generator Loss: 2842.551257\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16040 (step 16040): 1.934079\n",
      "Batch #10\tAverage Generator Loss: 2342.543391\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16041 (step 16041): 1.392405\n",
      "Batch #10\tAverage Generator Loss: 2877.110608\tAverage Discriminator Loss: 0.018418\n",
      "\n",
      "Train time for epoch #16042 (step 16042): 1.300052\n",
      "Batch #10\tAverage Generator Loss: 2104.593494\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16043 (step 16043): 1.946139\n",
      "Batch #10\tAverage Generator Loss: 3047.201440\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16044 (step 16044): 1.288252\n",
      "Batch #10\tAverage Generator Loss: 2838.531543\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16045 (step 16045): 1.282949\n",
      "Batch #10\tAverage Generator Loss: 3020.991919\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16046 (step 16046): 1.333582\n",
      "Batch #10\tAverage Generator Loss: 2982.770447\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16047 (step 16047): 1.830109\n",
      "Batch #10\tAverage Generator Loss: 2541.826257\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16048 (step 16048): 1.374736\n",
      "Batch #10\tAverage Generator Loss: 2639.849744\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16049 (step 16049): 1.390612\n",
      "Batch #10\tAverage Generator Loss: 2875.243420\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16050 (step 16050): 1.888470\n",
      "Batch #10\tAverage Generator Loss: 2614.664832\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16051 (step 16051): 1.289659\n",
      "Batch #10\tAverage Generator Loss: 2745.276196\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16052 (step 16052): 1.280088\n",
      "Batch #10\tAverage Generator Loss: 2564.350952\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16053 (step 16053): 1.864358\n",
      "Batch #10\tAverage Generator Loss: 2131.936127\tAverage Discriminator Loss: 0.556353\n",
      "\n",
      "Train time for epoch #16054 (step 16054): 1.328248\n",
      "Batch #10\tAverage Generator Loss: 2887.356714\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16055 (step 16055): 1.329039\n",
      "Batch #10\tAverage Generator Loss: 2710.166919\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16056 (step 16056): 1.311367\n",
      "Batch #10\tAverage Generator Loss: 2818.558325\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16057 (step 16057): 1.920547\n",
      "Batch #10\tAverage Generator Loss: 2512.304333\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16058 (step 16058): 1.444146\n",
      "Batch #10\tAverage Generator Loss: 2677.826807\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16059 (step 16059): 1.336043\n",
      "Batch #10\tAverage Generator Loss: 2430.509302\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16060 (step 16060): 1.832275\n",
      "Batch #10\tAverage Generator Loss: 2654.967688\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16061 (step 16061): 1.291652\n",
      "Batch #10\tAverage Generator Loss: 2824.956506\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16062 (step 16062): 1.234522\n",
      "Batch #10\tAverage Generator Loss: 2782.478436\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16063 (step 16063): 1.821805\n",
      "Batch #10\tAverage Generator Loss: 2452.835559\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16064 (step 16064): 1.351992\n",
      "Batch #10\tAverage Generator Loss: 2755.899805\tAverage Discriminator Loss: 0.005987\n",
      "\n",
      "Train time for epoch #16065 (step 16065): 1.341791\n",
      "Batch #10\tAverage Generator Loss: 2640.010938\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16066 (step 16066): 1.327274\n",
      "Batch #10\tAverage Generator Loss: 2327.820699\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16067 (step 16067): 1.867080\n",
      "Batch #10\tAverage Generator Loss: 2423.853894\tAverage Discriminator Loss: 0.000642\n",
      "\n",
      "Train time for epoch #16068 (step 16068): 1.336552\n",
      "Batch #10\tAverage Generator Loss: 2770.312354\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16069 (step 16069): 1.279952\n",
      "Batch #10\tAverage Generator Loss: 2423.516956\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16070 (step 16070): 1.835757\n",
      "Batch #10\tAverage Generator Loss: 2664.691797\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16071 (step 16071): 1.416583\n",
      "Batch #10\tAverage Generator Loss: 3097.825366\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16072 (step 16072): 1.337963\n",
      "Batch #10\tAverage Generator Loss: 2569.746246\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16073 (step 16073): 1.793650\n",
      "Batch #10\tAverage Generator Loss: 2576.457629\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16074 (step 16074): 1.289298\n",
      "Batch #10\tAverage Generator Loss: 2575.319873\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16075 (step 16075): 1.317260\n",
      "Batch #10\tAverage Generator Loss: 2912.170410\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16076 (step 16076): 1.797014\n",
      "Batch #10\tAverage Generator Loss: 2326.982153\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16077 (step 16077): 1.302478\n",
      "Batch #10\tAverage Generator Loss: 3035.434790\tAverage Discriminator Loss: 0.001583\n",
      "\n",
      "Train time for epoch #16078 (step 16078): 1.423341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2753.011475\tAverage Discriminator Loss: 0.000752\n",
      "\n",
      "Train time for epoch #16079 (step 16079): 1.788966\n",
      "Batch #10\tAverage Generator Loss: 3098.174646\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16080 (step 16080): 1.339078\n",
      "Batch #10\tAverage Generator Loss: 2422.648462\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16081 (step 16081): 1.306736\n",
      "Batch #10\tAverage Generator Loss: 2285.738275\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16082 (step 16082): 1.326434\n",
      "Batch #10\tAverage Generator Loss: 2670.133948\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16083 (step 16083): 1.761691\n",
      "Batch #10\tAverage Generator Loss: 2656.290186\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16084 (step 16084): 1.303473\n",
      "Batch #10\tAverage Generator Loss: 2654.311157\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16085 (step 16085): 1.384237\n",
      "Batch #10\tAverage Generator Loss: 2451.362390\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16086 (step 16086): 1.834873\n",
      "Batch #10\tAverage Generator Loss: 2670.070966\tAverage Discriminator Loss: 0.006604\n",
      "\n",
      "Train time for epoch #16087 (step 16087): 1.338775\n",
      "Batch #10\tAverage Generator Loss: 2472.209863\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #16088 (step 16088): 1.396121\n",
      "Batch #10\tAverage Generator Loss: 2443.959253\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16089 (step 16089): 1.904581\n",
      "Batch #10\tAverage Generator Loss: 2403.007849\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16090 (step 16090): 1.349339\n",
      "Batch #10\tAverage Generator Loss: 2630.379150\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16091 (step 16091): 1.323877\n",
      "Batch #10\tAverage Generator Loss: 2711.998401\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16092 (step 16092): 1.292846\n",
      "Batch #10\tAverage Generator Loss: 2672.180774\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16093 (step 16093): 1.944702\n",
      "Batch #10\tAverage Generator Loss: 2648.667017\tAverage Discriminator Loss: 0.273874\n",
      "\n",
      "Train time for epoch #16094 (step 16094): 1.393324\n",
      "Batch #10\tAverage Generator Loss: 2487.269873\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #16095 (step 16095): 1.290504\n",
      "Batch #10\tAverage Generator Loss: 2498.766870\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16096 (step 16096): 1.909094\n",
      "Batch #10\tAverage Generator Loss: 1862.428650\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16097 (step 16097): 1.341367\n",
      "Batch #10\tAverage Generator Loss: 2330.539526\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16098 (step 16098): 1.243580\n",
      "Batch #10\tAverage Generator Loss: 2099.768091\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16099 (step 16099): 1.878928\n",
      "Batch #10\tAverage Generator Loss: 2236.055975\tAverage Discriminator Loss: 0.032297\n",
      "\n",
      "Train time for epoch #16100 (step 16100): 1.332815\n",
      "Batch #10\tAverage Generator Loss: 2598.140454\tAverage Discriminator Loss: 0.027503\n",
      "\n",
      "Train time for epoch #16101 (step 16101): 1.305497\n",
      "Batch #10\tAverage Generator Loss: 3051.562085\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16102 (step 16102): 1.858143\n",
      "Batch #10\tAverage Generator Loss: 2742.333740\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16103 (step 16103): 1.459374\n",
      "Batch #10\tAverage Generator Loss: 2687.170178\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16104 (step 16104): 1.381591\n",
      "Batch #10\tAverage Generator Loss: 2441.175256\tAverage Discriminator Loss: 0.000458\n",
      "\n",
      "Train time for epoch #16105 (step 16105): 1.354280\n",
      "Batch #10\tAverage Generator Loss: 2572.966211\tAverage Discriminator Loss: 0.011614\n",
      "\n",
      "Train time for epoch #16106 (step 16106): 1.873599\n",
      "Batch #10\tAverage Generator Loss: 2539.014917\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16107 (step 16107): 1.356494\n",
      "Batch #10\tAverage Generator Loss: 2743.886328\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16108 (step 16108): 1.293875\n",
      "Batch #10\tAverage Generator Loss: 2639.111304\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16109 (step 16109): 1.841251\n",
      "Batch #10\tAverage Generator Loss: 2393.243323\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16110 (step 16110): 1.301523\n",
      "Batch #10\tAverage Generator Loss: 2759.743311\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16111 (step 16111): 1.329620\n",
      "Batch #10\tAverage Generator Loss: 2634.099231\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16112 (step 16112): 1.782287\n",
      "Batch #10\tAverage Generator Loss: 2250.836523\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16113 (step 16113): 1.290445\n",
      "Batch #10\tAverage Generator Loss: 2199.974829\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16114 (step 16114): 1.285311\n",
      "Batch #10\tAverage Generator Loss: 2801.877234\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16115 (step 16115): 1.329952\n",
      "Batch #10\tAverage Generator Loss: 2474.457446\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16116 (step 16116): 1.910870\n",
      "Batch #10\tAverage Generator Loss: 2027.903479\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16117 (step 16117): 1.397091\n",
      "Batch #10\tAverage Generator Loss: 2518.345496\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16118 (step 16118): 1.388323\n",
      "Batch #10\tAverage Generator Loss: 2259.675110\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16119 (step 16119): 1.782336\n",
      "Batch #10\tAverage Generator Loss: 2392.780774\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16120 (step 16120): 1.343950\n",
      "Batch #10\tAverage Generator Loss: 2201.974292\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16121 (step 16121): 1.361555\n",
      "Batch #10\tAverage Generator Loss: 2380.135162\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16122 (step 16122): 1.955882\n",
      "Batch #10\tAverage Generator Loss: 2744.827124\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16123 (step 16123): 1.319916\n",
      "Batch #10\tAverage Generator Loss: 2526.002625\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16124 (step 16124): 1.332046\n",
      "Batch #10\tAverage Generator Loss: 2288.258887\tAverage Discriminator Loss: 0.013911\n",
      "\n",
      "Train time for epoch #16125 (step 16125): 1.363717\n",
      "Batch #10\tAverage Generator Loss: 2372.398120\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16126 (step 16126): 1.852821\n",
      "Batch #10\tAverage Generator Loss: 2278.131799\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #16127 (step 16127): 1.360251\n",
      "Batch #10\tAverage Generator Loss: 2561.040576\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #16128 (step 16128): 1.359836\n",
      "Batch #10\tAverage Generator Loss: 2456.146814\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16129 (step 16129): 1.882941\n",
      "Batch #10\tAverage Generator Loss: 2032.407373\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16130 (step 16130): 1.329625\n",
      "Batch #10\tAverage Generator Loss: 2221.248920\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16131 (step 16131): 1.335795\n",
      "Batch #10\tAverage Generator Loss: 2423.589417\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16132 (step 16132): 1.973814\n",
      "Batch #10\tAverage Generator Loss: 2364.079712\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16133 (step 16133): 1.364420\n",
      "Batch #10\tAverage Generator Loss: 2037.610229\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16134 (step 16134): 1.295745\n",
      "Batch #10\tAverage Generator Loss: 2179.467853\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16135 (step 16135): 1.300849\n",
      "Batch #10\tAverage Generator Loss: 2487.993616\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16136 (step 16136): 1.843979\n",
      "Batch #10\tAverage Generator Loss: 2171.301038\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16137 (step 16137): 1.288262\n",
      "Batch #10\tAverage Generator Loss: 2539.906036\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16138 (step 16138): 1.342895\n",
      "Batch #10\tAverage Generator Loss: 2354.351465\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16139 (step 16139): 1.890303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2288.192297\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16140 (step 16140): 1.413113\n",
      "Batch #10\tAverage Generator Loss: 2528.502844\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16141 (step 16141): 1.319842\n",
      "Batch #10\tAverage Generator Loss: 2433.012634\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16142 (step 16142): 1.924605\n",
      "Batch #10\tAverage Generator Loss: 2247.288940\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16143 (step 16143): 1.331969\n",
      "Batch #10\tAverage Generator Loss: 2192.302759\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16144 (step 16144): 1.352097\n",
      "Batch #10\tAverage Generator Loss: 2297.248511\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16145 (step 16145): 1.289303\n",
      "Batch #10\tAverage Generator Loss: 2478.621863\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16146 (step 16146): 1.859552\n",
      "Batch #10\tAverage Generator Loss: 2266.385840\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16147 (step 16147): 1.370776\n",
      "Batch #10\tAverage Generator Loss: 2197.011304\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16148 (step 16148): 1.296105\n",
      "Batch #10\tAverage Generator Loss: 2505.981067\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16149 (step 16149): 1.846219\n",
      "Batch #10\tAverage Generator Loss: 2643.793933\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16150 (step 16150): 1.282459\n",
      "Batch #10\tAverage Generator Loss: 2044.823334\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16151 (step 16151): 1.311245\n",
      "Batch #10\tAverage Generator Loss: 2055.069760\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16152 (step 16152): 1.851611\n",
      "Batch #10\tAverage Generator Loss: 2002.934827\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16153 (step 16153): 1.291918\n",
      "Batch #10\tAverage Generator Loss: 2206.344177\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16154 (step 16154): 1.467108\n",
      "Batch #10\tAverage Generator Loss: 2567.186267\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16155 (step 16155): 1.320084\n",
      "Batch #10\tAverage Generator Loss: 2076.315845\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16156 (step 16156): 1.903368\n",
      "Batch #10\tAverage Generator Loss: 2029.472528\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16157 (step 16157): 1.398825\n",
      "Batch #10\tAverage Generator Loss: 2374.230286\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16158 (step 16158): 1.286193\n",
      "Batch #10\tAverage Generator Loss: 1918.568011\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16159 (step 16159): 1.868325\n",
      "Batch #10\tAverage Generator Loss: 2254.933380\tAverage Discriminator Loss: 0.010258\n",
      "\n",
      "Train time for epoch #16160 (step 16160): 1.291806\n",
      "Batch #10\tAverage Generator Loss: 2374.392188\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16161 (step 16161): 1.346791\n",
      "Batch #10\tAverage Generator Loss: 2554.714490\tAverage Discriminator Loss: 0.000095\n",
      "\n",
      "Train time for epoch #16162 (step 16162): 1.805830\n",
      "Batch #10\tAverage Generator Loss: 2548.452063\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16163 (step 16163): 1.360662\n",
      "Batch #10\tAverage Generator Loss: 2537.307703\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16164 (step 16164): 1.445856\n",
      "Batch #10\tAverage Generator Loss: 2724.708057\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16165 (step 16165): 1.890173\n",
      "Batch #10\tAverage Generator Loss: 2869.529053\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16166 (step 16166): 1.365350\n",
      "Batch #10\tAverage Generator Loss: 2423.522620\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16167 (step 16167): 1.388250\n",
      "Batch #10\tAverage Generator Loss: 2891.888208\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16168 (step 16168): 1.377624\n",
      "Batch #10\tAverage Generator Loss: 2739.478027\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16169 (step 16169): 1.842810\n",
      "Batch #10\tAverage Generator Loss: 2512.694128\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16170 (step 16170): 1.242690\n",
      "Batch #10\tAverage Generator Loss: 2701.746948\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16171 (step 16171): 1.299909\n",
      "Batch #10\tAverage Generator Loss: 2538.282263\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16172 (step 16172): 1.830086\n",
      "Batch #10\tAverage Generator Loss: 2918.670508\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16173 (step 16173): 1.451642\n",
      "Batch #10\tAverage Generator Loss: 2430.081531\tAverage Discriminator Loss: 0.083217\n",
      "\n",
      "Train time for epoch #16174 (step 16174): 1.343377\n",
      "Batch #10\tAverage Generator Loss: 2253.857434\tAverage Discriminator Loss: 0.003786\n",
      "\n",
      "Train time for epoch #16175 (step 16175): 1.898881\n",
      "Batch #10\tAverage Generator Loss: 2857.751697\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16176 (step 16176): 1.335731\n",
      "Batch #10\tAverage Generator Loss: 2826.928137\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16177 (step 16177): 1.525060\n",
      "Batch #10\tAverage Generator Loss: 2199.852863\tAverage Discriminator Loss: 0.197093\n",
      "\n",
      "Train time for epoch #16178 (step 16178): 1.893482\n",
      "Batch #10\tAverage Generator Loss: 2327.733673\tAverage Discriminator Loss: 0.109160\n",
      "\n",
      "Train time for epoch #16179 (step 16179): 1.279775\n",
      "Batch #10\tAverage Generator Loss: 2350.050116\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16180 (step 16180): 1.407592\n",
      "Batch #10\tAverage Generator Loss: 2125.739285\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16181 (step 16181): 1.287710\n",
      "Batch #10\tAverage Generator Loss: 2470.303833\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16182 (step 16182): 2.114302\n",
      "Batch #10\tAverage Generator Loss: 2386.699353\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16183 (step 16183): 1.296105\n",
      "Batch #10\tAverage Generator Loss: 2185.057324\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16184 (step 16184): 1.277007\n",
      "Batch #10\tAverage Generator Loss: 2044.360254\tAverage Discriminator Loss: 0.193500\n",
      "\n",
      "Train time for epoch #16185 (step 16185): 1.969017\n",
      "Batch #10\tAverage Generator Loss: 2003.461993\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16186 (step 16186): 1.240815\n",
      "Batch #10\tAverage Generator Loss: 2002.143237\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #16187 (step 16187): 1.306045\n",
      "Batch #10\tAverage Generator Loss: 2155.253778\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #16188 (step 16188): 1.892771\n",
      "Batch #10\tAverage Generator Loss: 2149.806195\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #16189 (step 16189): 1.425538\n",
      "Batch #10\tAverage Generator Loss: 2327.349268\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #16190 (step 16190): 1.286385\n",
      "Batch #10\tAverage Generator Loss: 2028.280444\tAverage Discriminator Loss: 0.034353\n",
      "\n",
      "Train time for epoch #16191 (step 16191): 1.895304\n",
      "Batch #10\tAverage Generator Loss: 2172.737451\tAverage Discriminator Loss: 0.000066\n",
      "\n",
      "Train time for epoch #16192 (step 16192): 1.362614\n",
      "Batch #10\tAverage Generator Loss: 2059.513947\tAverage Discriminator Loss: 0.000038\n",
      "\n",
      "Train time for epoch #16193 (step 16193): 1.388153\n",
      "Batch #10\tAverage Generator Loss: 1995.350574\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #16194 (step 16194): 1.287368\n",
      "Batch #10\tAverage Generator Loss: 2388.566736\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #16195 (step 16195): 1.813641\n",
      "Batch #10\tAverage Generator Loss: 2006.403003\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #16196 (step 16196): 1.347080\n",
      "Batch #10\tAverage Generator Loss: 2122.349902\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #16197 (step 16197): 1.340425\n",
      "Batch #10\tAverage Generator Loss: 2003.869849\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #16198 (step 16198): 1.835112\n",
      "Batch #10\tAverage Generator Loss: 2099.939111\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #16199 (step 16199): 1.344121\n",
      "Batch #10\tAverage Generator Loss: 2174.356750\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #16200 (step 16200): 1.340852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 1700.212262\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #16201 (step 16201): 1.983915\n",
      "Batch #10\tAverage Generator Loss: 2077.132068\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #16202 (step 16202): 1.295108\n",
      "Batch #10\tAverage Generator Loss: 1770.373077\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16203 (step 16203): 1.289333\n",
      "Batch #10\tAverage Generator Loss: 1958.703137\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #16204 (step 16204): 1.879296\n",
      "Batch #10\tAverage Generator Loss: 2205.344324\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #16205 (step 16205): 1.288589\n",
      "Batch #10\tAverage Generator Loss: 2002.515430\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #16206 (step 16206): 1.288952\n",
      "Batch #10\tAverage Generator Loss: 1816.497021\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #16207 (step 16207): 1.884799\n",
      "Batch #10\tAverage Generator Loss: 1664.954431\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #16208 (step 16208): 1.305521\n",
      "Batch #10\tAverage Generator Loss: 2178.129529\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #16209 (step 16209): 1.301788\n",
      "Batch #10\tAverage Generator Loss: 1928.980066\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #16210 (step 16210): 1.304695\n",
      "Batch #10\tAverage Generator Loss: 2396.208752\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #16211 (step 16211): 1.842722\n",
      "Batch #10\tAverage Generator Loss: 2460.137549\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #16212 (step 16212): 1.341617\n",
      "Batch #10\tAverage Generator Loss: 2641.098828\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #16213 (step 16213): 1.365907\n",
      "Batch #10\tAverage Generator Loss: 2279.472510\tAverage Discriminator Loss: 0.000036\n",
      "\n",
      "Train time for epoch #16214 (step 16214): 1.907508\n",
      "Batch #10\tAverage Generator Loss: 2267.536963\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #16215 (step 16215): 1.373797\n",
      "Batch #10\tAverage Generator Loss: 2160.761206\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #16216 (step 16216): 1.399415\n",
      "Batch #10\tAverage Generator Loss: 2681.471899\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16217 (step 16217): 1.887105\n",
      "Batch #10\tAverage Generator Loss: 1941.147034\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16218 (step 16218): 1.383050\n",
      "Batch #10\tAverage Generator Loss: 2097.692795\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16219 (step 16219): 1.439464\n",
      "Batch #10\tAverage Generator Loss: 2199.467987\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16220 (step 16220): 1.295019\n",
      "Batch #10\tAverage Generator Loss: 2142.580414\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #16221 (step 16221): 1.815405\n",
      "Batch #10\tAverage Generator Loss: 1956.896851\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #16222 (step 16222): 1.337144\n",
      "Batch #10\tAverage Generator Loss: 2184.585840\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16223 (step 16223): 1.411792\n",
      "Batch #10\tAverage Generator Loss: 2040.861359\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16224 (step 16224): 1.854578\n",
      "Batch #10\tAverage Generator Loss: 1906.263330\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16225 (step 16225): 1.275201\n",
      "Batch #10\tAverage Generator Loss: 2280.041626\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16226 (step 16226): 1.346736\n",
      "Batch #10\tAverage Generator Loss: 2174.214905\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16227 (step 16227): 1.287811\n",
      "Batch #10\tAverage Generator Loss: 2145.850830\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16228 (step 16228): 1.786358\n",
      "Batch #10\tAverage Generator Loss: 2202.475647\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16229 (step 16229): 1.454530\n",
      "Batch #10\tAverage Generator Loss: 2154.863269\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16230 (step 16230): 1.288249\n",
      "Batch #10\tAverage Generator Loss: 2295.970544\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16231 (step 16231): 1.983255\n",
      "Batch #10\tAverage Generator Loss: 2190.075702\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16232 (step 16232): 1.296154\n",
      "Batch #10\tAverage Generator Loss: 1910.693420\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16233 (step 16233): 1.343911\n",
      "Batch #10\tAverage Generator Loss: 2068.689484\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16234 (step 16234): 1.838438\n",
      "Batch #10\tAverage Generator Loss: 2057.960242\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16235 (step 16235): 1.303026\n",
      "Batch #10\tAverage Generator Loss: 2344.348816\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16236 (step 16236): 1.362607\n",
      "Batch #10\tAverage Generator Loss: 2106.360229\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16237 (step 16237): 1.303510\n",
      "Batch #10\tAverage Generator Loss: 2258.093127\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16238 (step 16238): 1.823497\n",
      "Batch #10\tAverage Generator Loss: 2374.638611\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16239 (step 16239): 1.281590\n",
      "Batch #10\tAverage Generator Loss: 2141.446484\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16240 (step 16240): 1.345382\n",
      "Batch #10\tAverage Generator Loss: 2122.626184\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16241 (step 16241): 1.827659\n",
      "Batch #10\tAverage Generator Loss: 2024.153162\tAverage Discriminator Loss: 0.000051\n",
      "\n",
      "Train time for epoch #16242 (step 16242): 1.338094\n",
      "Batch #10\tAverage Generator Loss: 2326.194055\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16243 (step 16243): 1.302431\n",
      "Batch #10\tAverage Generator Loss: 2139.222473\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16244 (step 16244): 1.886292\n",
      "Batch #10\tAverage Generator Loss: 2063.408496\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16245 (step 16245): 1.303063\n",
      "Batch #10\tAverage Generator Loss: 2118.054156\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16246 (step 16246): 1.352150\n",
      "Batch #10\tAverage Generator Loss: 2230.928113\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16247 (step 16247): 1.409552\n",
      "Batch #10\tAverage Generator Loss: 2210.710522\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16248 (step 16248): 1.845750\n",
      "Batch #10\tAverage Generator Loss: 1981.962366\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16249 (step 16249): 1.359367\n",
      "Batch #10\tAverage Generator Loss: 1926.590564\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16250 (step 16250): 1.323184\n",
      "Batch #10\tAverage Generator Loss: 1692.975085\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16251 (step 16251): 1.806910\n",
      "Batch #10\tAverage Generator Loss: 2347.382092\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16252 (step 16252): 1.330838\n",
      "Batch #10\tAverage Generator Loss: 2336.359363\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16253 (step 16253): 1.334800\n",
      "Batch #10\tAverage Generator Loss: 2352.186017\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16254 (step 16254): 1.454446\n",
      "Batch #10\tAverage Generator Loss: 2091.116736\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16255 (step 16255): 1.817795\n",
      "Batch #10\tAverage Generator Loss: 1990.607764\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16256 (step 16256): 1.334862\n",
      "Batch #10\tAverage Generator Loss: 1862.365417\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16257 (step 16257): 1.428606\n",
      "Batch #10\tAverage Generator Loss: 2192.750647\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16258 (step 16258): 2.025915\n",
      "Batch #10\tAverage Generator Loss: 1928.941937\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16259 (step 16259): 1.348280\n",
      "Batch #10\tAverage Generator Loss: 2033.895435\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16260 (step 16260): 1.443647\n",
      "Batch #10\tAverage Generator Loss: 1916.329510\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16261 (step 16261): 1.913348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2034.331897\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16262 (step 16262): 1.392975\n",
      "Batch #10\tAverage Generator Loss: 2020.312524\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16263 (step 16263): 1.381173\n",
      "Batch #10\tAverage Generator Loss: 2051.879285\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #16264 (step 16264): 1.875642\n",
      "Batch #10\tAverage Generator Loss: 2238.702435\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16265 (step 16265): 1.410244\n",
      "Batch #10\tAverage Generator Loss: 2011.867102\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16266 (step 16266): 1.369381\n",
      "Batch #10\tAverage Generator Loss: 1998.085278\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16267 (step 16267): 1.251971\n",
      "Batch #10\tAverage Generator Loss: 1710.784100\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16268 (step 16268): 1.799646\n",
      "Batch #10\tAverage Generator Loss: 2268.012042\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16269 (step 16269): 1.330874\n",
      "Batch #10\tAverage Generator Loss: 2039.411511\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16270 (step 16270): 1.293424\n",
      "Batch #10\tAverage Generator Loss: 2176.061823\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16271 (step 16271): 1.780894\n",
      "Batch #10\tAverage Generator Loss: 2091.979614\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16272 (step 16272): 1.297940\n",
      "Batch #10\tAverage Generator Loss: 2111.965979\tAverage Discriminator Loss: 0.335234\n",
      "\n",
      "Train time for epoch #16273 (step 16273): 1.335675\n",
      "Batch #10\tAverage Generator Loss: 1743.982156\tAverage Discriminator Loss: 0.000082\n",
      "\n",
      "Train time for epoch #16274 (step 16274): 1.786726\n",
      "Batch #10\tAverage Generator Loss: 1870.827728\tAverage Discriminator Loss: 0.000036\n",
      "\n",
      "Train time for epoch #16275 (step 16275): 1.294379\n",
      "Batch #10\tAverage Generator Loss: 2405.632275\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #16276 (step 16276): 1.331255\n",
      "Batch #10\tAverage Generator Loss: 2166.538531\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #16277 (step 16277): 1.349310\n",
      "Batch #10\tAverage Generator Loss: 2125.305701\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #16278 (step 16278): 1.889051\n",
      "Batch #10\tAverage Generator Loss: 2114.572620\tAverage Discriminator Loss: 0.061042\n",
      "\n",
      "Train time for epoch #16279 (step 16279): 1.399850\n",
      "Batch #10\tAverage Generator Loss: 2116.154077\tAverage Discriminator Loss: 0.000208\n",
      "\n",
      "Train time for epoch #16280 (step 16280): 1.346460\n",
      "Batch #10\tAverage Generator Loss: 2103.585107\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16281 (step 16281): 1.881642\n",
      "Batch #10\tAverage Generator Loss: 1842.466028\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16282 (step 16282): 1.344862\n",
      "Batch #10\tAverage Generator Loss: 1865.189368\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16283 (step 16283): 1.326005\n",
      "Batch #10\tAverage Generator Loss: 1748.654434\tAverage Discriminator Loss: 0.132673\n",
      "\n",
      "Train time for epoch #16284 (step 16284): 1.974807\n",
      "Batch #10\tAverage Generator Loss: 1636.652942\tAverage Discriminator Loss: 0.002871\n",
      "\n",
      "Train time for epoch #16285 (step 16285): 1.300827\n",
      "Batch #10\tAverage Generator Loss: 2139.478784\tAverage Discriminator Loss: 0.115010\n",
      "\n",
      "Train time for epoch #16286 (step 16286): 1.429911\n",
      "Batch #10\tAverage Generator Loss: 2208.869983\tAverage Discriminator Loss: 0.000142\n",
      "\n",
      "Train time for epoch #16287 (step 16287): 1.239518\n",
      "Batch #10\tAverage Generator Loss: 2402.652881\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #16288 (step 16288): 1.928482\n",
      "Batch #10\tAverage Generator Loss: 2315.501331\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16289 (step 16289): 1.336569\n",
      "Batch #10\tAverage Generator Loss: 2774.430884\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16290 (step 16290): 1.378697\n",
      "Batch #10\tAverage Generator Loss: 2316.858301\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16291 (step 16291): 1.956747\n",
      "Batch #10\tAverage Generator Loss: 2415.163000\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16292 (step 16292): 1.312830\n",
      "Batch #10\tAverage Generator Loss: 2461.270926\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16293 (step 16293): 1.342377\n",
      "Batch #10\tAverage Generator Loss: 2474.089355\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16294 (step 16294): 1.285822\n",
      "Batch #10\tAverage Generator Loss: 2382.864905\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16295 (step 16295): 2.037185\n",
      "Batch #10\tAverage Generator Loss: 2398.174121\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16296 (step 16296): 1.332633\n",
      "Batch #10\tAverage Generator Loss: 2583.257056\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16297 (step 16297): 1.389048\n",
      "Batch #10\tAverage Generator Loss: 2270.001807\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16298 (step 16298): 1.901233\n",
      "Batch #10\tAverage Generator Loss: 2628.316003\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16299 (step 16299): 1.297268\n",
      "Batch #10\tAverage Generator Loss: 2447.720337\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16300 (step 16300): 1.292741\n",
      "Batch #10\tAverage Generator Loss: 2756.817859\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16301 (step 16301): 1.400007\n",
      "Batch #10\tAverage Generator Loss: 2387.822998\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16302 (step 16302): 1.851577\n",
      "Batch #10\tAverage Generator Loss: 2636.811865\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16303 (step 16303): 1.338744\n",
      "Batch #10\tAverage Generator Loss: 2866.901733\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16304 (step 16304): 1.332646\n",
      "Batch #10\tAverage Generator Loss: 2914.122522\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16305 (step 16305): 1.857955\n",
      "Batch #10\tAverage Generator Loss: 2462.941895\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16306 (step 16306): 1.360433\n",
      "Batch #10\tAverage Generator Loss: 2487.170923\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16307 (step 16307): 1.341046\n",
      "Batch #10\tAverage Generator Loss: 2604.000842\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16308 (step 16308): 1.902255\n",
      "Batch #10\tAverage Generator Loss: 2330.991510\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16309 (step 16309): 1.241616\n",
      "Batch #10\tAverage Generator Loss: 2866.002600\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16310 (step 16310): 1.289513\n",
      "Batch #10\tAverage Generator Loss: 2399.474756\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16311 (step 16311): 1.838000\n",
      "Batch #10\tAverage Generator Loss: 2091.567761\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16312 (step 16312): 1.244882\n",
      "Batch #10\tAverage Generator Loss: 2166.309814\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16313 (step 16313): 1.420937\n",
      "Batch #10\tAverage Generator Loss: 2440.246719\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16314 (step 16314): 1.301162\n",
      "Batch #10\tAverage Generator Loss: 2650.936060\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16315 (step 16315): 1.846340\n",
      "Batch #10\tAverage Generator Loss: 2330.758813\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16316 (step 16316): 1.352726\n",
      "Batch #10\tAverage Generator Loss: 2725.612561\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16317 (step 16317): 1.291212\n",
      "Batch #10\tAverage Generator Loss: 2758.948767\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16318 (step 16318): 1.875677\n",
      "Batch #10\tAverage Generator Loss: 2629.818323\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16319 (step 16319): 1.299101\n",
      "Batch #10\tAverage Generator Loss: 2527.650598\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16320 (step 16320): 1.371257\n",
      "Batch #10\tAverage Generator Loss: 2538.829077\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #16321 (step 16321): 1.852094\n",
      "Batch #10\tAverage Generator Loss: 2669.999463\tAverage Discriminator Loss: 0.000028\n",
      "\n",
      "Train time for epoch #16322 (step 16322): 1.382856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2847.255017\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16323 (step 16323): 1.431307\n",
      "Batch #10\tAverage Generator Loss: 2831.078760\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16324 (step 16324): 1.335912\n",
      "Batch #10\tAverage Generator Loss: 2553.315149\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16325 (step 16325): 1.902242\n",
      "Batch #10\tAverage Generator Loss: 2438.193347\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16326 (step 16326): 1.415205\n",
      "Batch #10\tAverage Generator Loss: 2899.077991\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16327 (step 16327): 1.344174\n",
      "Batch #10\tAverage Generator Loss: 2535.890295\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16328 (step 16328): 1.934816\n",
      "Batch #10\tAverage Generator Loss: 2783.773004\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16329 (step 16329): 1.299970\n",
      "Batch #10\tAverage Generator Loss: 2566.341296\tAverage Discriminator Loss: 0.000019\n",
      "\n",
      "Train time for epoch #16330 (step 16330): 1.288472\n",
      "Batch #10\tAverage Generator Loss: 2614.030341\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16331 (step 16331): 2.018559\n",
      "Batch #10\tAverage Generator Loss: 2530.963220\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16332 (step 16332): 1.372928\n",
      "Batch #10\tAverage Generator Loss: 3122.972205\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16333 (step 16333): 1.334599\n",
      "Batch #10\tAverage Generator Loss: 2781.207935\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16334 (step 16334): 1.456447\n",
      "Batch #10\tAverage Generator Loss: 2717.279712\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16335 (step 16335): 1.833137\n",
      "Batch #10\tAverage Generator Loss: 2667.106104\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16336 (step 16336): 1.440557\n",
      "Batch #10\tAverage Generator Loss: 2523.007861\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16337 (step 16337): 1.290719\n",
      "Batch #10\tAverage Generator Loss: 2545.546899\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #16338 (step 16338): 1.892123\n",
      "Batch #10\tAverage Generator Loss: 2550.325958\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16339 (step 16339): 1.427548\n",
      "Batch #10\tAverage Generator Loss: 2598.019043\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16340 (step 16340): 1.414435\n",
      "Batch #10\tAverage Generator Loss: 2733.750586\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16341 (step 16341): 2.121147\n",
      "Batch #10\tAverage Generator Loss: 2476.101660\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16342 (step 16342): 1.387002\n",
      "Batch #10\tAverage Generator Loss: 2540.203943\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16343 (step 16343): 1.444319\n",
      "Batch #10\tAverage Generator Loss: 2872.041205\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16344 (step 16344): 1.438898\n",
      "Batch #10\tAverage Generator Loss: 3057.294824\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16345 (step 16345): 1.834827\n",
      "Batch #10\tAverage Generator Loss: 2467.782104\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16346 (step 16346): 1.299604\n",
      "Batch #10\tAverage Generator Loss: 2540.312238\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16347 (step 16347): 1.311808\n",
      "Batch #10\tAverage Generator Loss: 2700.706592\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16348 (step 16348): 1.796386\n",
      "Batch #10\tAverage Generator Loss: 2340.102515\tAverage Discriminator Loss: 0.012522\n",
      "\n",
      "Train time for epoch #16349 (step 16349): 1.355062\n",
      "Batch #10\tAverage Generator Loss: 2676.558856\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #16350 (step 16350): 1.330812\n",
      "Batch #10\tAverage Generator Loss: 2463.050879\tAverage Discriminator Loss: 0.000020\n",
      "\n",
      "Train time for epoch #16351 (step 16351): 1.822151\n",
      "Batch #10\tAverage Generator Loss: 2692.413831\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #16352 (step 16352): 1.301965\n",
      "Batch #10\tAverage Generator Loss: 2922.263574\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #16353 (step 16353): 1.350728\n",
      "Batch #10\tAverage Generator Loss: 2547.218689\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #16354 (step 16354): 1.300993\n",
      "Batch #10\tAverage Generator Loss: 2648.013562\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #16355 (step 16355): 1.786845\n",
      "Batch #10\tAverage Generator Loss: 2617.922498\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #16356 (step 16356): 1.277851\n",
      "Batch #10\tAverage Generator Loss: 2581.901990\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #16357 (step 16357): 1.357983\n",
      "Batch #10\tAverage Generator Loss: 2843.140771\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #16358 (step 16358): 1.926844\n",
      "Batch #10\tAverage Generator Loss: 2729.407922\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #16359 (step 16359): 1.425250\n",
      "Batch #10\tAverage Generator Loss: 2434.447638\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16360 (step 16360): 1.467378\n",
      "Batch #10\tAverage Generator Loss: 2369.454462\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #16361 (step 16361): 1.360809\n",
      "Batch #10\tAverage Generator Loss: 2429.250781\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #16362 (step 16362): 1.778183\n",
      "Batch #10\tAverage Generator Loss: 2598.146777\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #16363 (step 16363): 1.334745\n",
      "Batch #10\tAverage Generator Loss: 2761.356177\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16364 (step 16364): 1.336874\n",
      "Batch #10\tAverage Generator Loss: 2541.747217\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16365 (step 16365): 1.944505\n",
      "Batch #10\tAverage Generator Loss: 2518.131714\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16366 (step 16366): 1.264446\n",
      "Batch #10\tAverage Generator Loss: 2410.274988\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16367 (step 16367): 1.291798\n",
      "Batch #10\tAverage Generator Loss: 2806.616833\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #16368 (step 16368): 1.854114\n",
      "Batch #10\tAverage Generator Loss: 2685.973413\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16369 (step 16369): 1.324216\n",
      "Batch #10\tAverage Generator Loss: 3040.968799\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16370 (step 16370): 1.288489\n",
      "Batch #10\tAverage Generator Loss: 2460.912073\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #16371 (step 16371): 1.291884\n",
      "Batch #10\tAverage Generator Loss: 2804.253235\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16372 (step 16372): 1.990649\n",
      "Batch #10\tAverage Generator Loss: 2872.370288\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16373 (step 16373): 1.283617\n",
      "Batch #10\tAverage Generator Loss: 2903.886377\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16374 (step 16374): 1.398318\n",
      "Batch #10\tAverage Generator Loss: 2889.568445\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16375 (step 16375): 1.829261\n",
      "Batch #10\tAverage Generator Loss: 2766.739355\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16376 (step 16376): 1.389501\n",
      "Batch #10\tAverage Generator Loss: 2673.296814\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16377 (step 16377): 1.241522\n",
      "Batch #10\tAverage Generator Loss: 2541.860864\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16378 (step 16378): 1.878711\n",
      "Batch #10\tAverage Generator Loss: 2181.674634\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16379 (step 16379): 1.327726\n",
      "Batch #10\tAverage Generator Loss: 2664.269031\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16380 (step 16380): 1.290550\n",
      "Batch #10\tAverage Generator Loss: 2613.482825\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16381 (step 16381): 1.838332\n",
      "Batch #10\tAverage Generator Loss: 2947.212207\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16382 (step 16382): 1.294559\n",
      "Batch #10\tAverage Generator Loss: 2644.595850\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16383 (step 16383): 1.379532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2623.747729\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16384 (step 16384): 1.334300\n",
      "Batch #10\tAverage Generator Loss: 2702.293396\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16385 (step 16385): 1.873597\n",
      "Batch #10\tAverage Generator Loss: 2871.485217\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16386 (step 16386): 1.233542\n",
      "Batch #10\tAverage Generator Loss: 2526.809839\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16387 (step 16387): 1.284794\n",
      "Batch #10\tAverage Generator Loss: 2398.656934\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16388 (step 16388): 1.778152\n",
      "Batch #10\tAverage Generator Loss: 2604.320032\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16389 (step 16389): 1.303939\n",
      "Batch #10\tAverage Generator Loss: 2802.750134\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16390 (step 16390): 1.357795\n",
      "Batch #10\tAverage Generator Loss: 2562.634387\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16391 (step 16391): 1.388460\n",
      "Batch #10\tAverage Generator Loss: 2435.497620\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16392 (step 16392): 1.750284\n",
      "Batch #10\tAverage Generator Loss: 3120.242261\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16393 (step 16393): 1.275528\n",
      "Batch #10\tAverage Generator Loss: 3082.594592\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16394 (step 16394): 1.488907\n",
      "Batch #10\tAverage Generator Loss: 2805.671606\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16395 (step 16395): 1.923917\n",
      "Batch #10\tAverage Generator Loss: 2456.496057\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #16396 (step 16396): 1.288083\n",
      "Batch #10\tAverage Generator Loss: 2532.033923\tAverage Discriminator Loss: 0.000084\n",
      "\n",
      "Train time for epoch #16397 (step 16397): 1.330098\n",
      "Batch #10\tAverage Generator Loss: 2495.411401\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #16398 (step 16398): 1.847574\n",
      "Batch #10\tAverage Generator Loss: 2655.533655\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #16399 (step 16399): 1.341102\n",
      "Batch #10\tAverage Generator Loss: 2769.332703\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16400 (step 16400): 1.460571\n",
      "Batch #10\tAverage Generator Loss: 2450.879810\tAverage Discriminator Loss: 0.004022\n",
      "\n",
      "Train time for epoch #16401 (step 16401): 1.447396\n",
      "Batch #10\tAverage Generator Loss: 2540.841760\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #16402 (step 16402): 1.837263\n",
      "Batch #10\tAverage Generator Loss: 2154.967981\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #16403 (step 16403): 1.349015\n",
      "Batch #10\tAverage Generator Loss: 2457.822046\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16404 (step 16404): 1.481119\n",
      "Batch #10\tAverage Generator Loss: 2719.695349\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16405 (step 16405): 1.896808\n",
      "Batch #10\tAverage Generator Loss: 2192.365820\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16406 (step 16406): 1.342882\n",
      "Batch #10\tAverage Generator Loss: 2304.304443\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16407 (step 16407): 1.280007\n",
      "Batch #10\tAverage Generator Loss: 2610.078198\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16408 (step 16408): 1.289603\n",
      "Batch #10\tAverage Generator Loss: 2508.507251\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16409 (step 16409): 1.867239\n",
      "Batch #10\tAverage Generator Loss: 2368.079370\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16410 (step 16410): 1.393350\n",
      "Batch #10\tAverage Generator Loss: 2373.298767\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16411 (step 16411): 1.376756\n",
      "Batch #10\tAverage Generator Loss: 2456.264258\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16412 (step 16412): 1.946354\n",
      "Batch #10\tAverage Generator Loss: 2262.657532\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16413 (step 16413): 1.299856\n",
      "Batch #10\tAverage Generator Loss: 2364.900684\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16414 (step 16414): 1.379566\n",
      "Batch #10\tAverage Generator Loss: 2262.341888\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16415 (step 16415): 1.948483\n",
      "Batch #10\tAverage Generator Loss: 2845.820532\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16416 (step 16416): 1.295079\n",
      "Batch #10\tAverage Generator Loss: 2212.995459\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16417 (step 16417): 1.490672\n",
      "Batch #10\tAverage Generator Loss: 2530.992627\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16418 (step 16418): 1.938518\n",
      "Batch #10\tAverage Generator Loss: 2352.956006\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16419 (step 16419): 1.389168\n",
      "Batch #10\tAverage Generator Loss: 2199.408356\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16420 (step 16420): 1.345230\n",
      "Batch #10\tAverage Generator Loss: 2661.049792\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16421 (step 16421): 1.288468\n",
      "Batch #10\tAverage Generator Loss: 2559.342407\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16422 (step 16422): 1.882715\n",
      "Batch #10\tAverage Generator Loss: 2236.038672\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16423 (step 16423): 1.301156\n",
      "Batch #10\tAverage Generator Loss: 2566.387146\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16424 (step 16424): 1.431965\n",
      "Batch #10\tAverage Generator Loss: 2082.206116\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16425 (step 16425): 1.804641\n",
      "Batch #10\tAverage Generator Loss: 2483.667285\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16426 (step 16426): 1.251388\n",
      "Batch #10\tAverage Generator Loss: 2751.218140\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16427 (step 16427): 1.411687\n",
      "Batch #10\tAverage Generator Loss: 2193.511230\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16428 (step 16428): 1.898944\n",
      "Batch #10\tAverage Generator Loss: 2413.865771\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16429 (step 16429): 1.350916\n",
      "Batch #10\tAverage Generator Loss: 2414.912213\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16430 (step 16430): 1.289786\n",
      "Batch #10\tAverage Generator Loss: 2479.014844\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16431 (step 16431): 1.294471\n",
      "Batch #10\tAverage Generator Loss: 2220.632397\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16432 (step 16432): 1.924186\n",
      "Batch #10\tAverage Generator Loss: 2472.324036\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16433 (step 16433): 1.350555\n",
      "Batch #10\tAverage Generator Loss: 2468.963574\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16434 (step 16434): 1.280636\n",
      "Batch #10\tAverage Generator Loss: 2254.919159\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16435 (step 16435): 1.903584\n",
      "Batch #10\tAverage Generator Loss: 2445.540332\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16436 (step 16436): 1.387429\n",
      "Batch #10\tAverage Generator Loss: 2590.637915\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16437 (step 16437): 1.239806\n",
      "Batch #10\tAverage Generator Loss: 2519.760229\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16438 (step 16438): 1.903070\n",
      "Batch #10\tAverage Generator Loss: 2580.956543\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16439 (step 16439): 1.335782\n",
      "Batch #10\tAverage Generator Loss: 2640.852551\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16440 (step 16440): 1.287466\n",
      "Batch #10\tAverage Generator Loss: 2350.434058\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16441 (step 16441): 1.340408\n",
      "Batch #10\tAverage Generator Loss: 2093.257947\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16442 (step 16442): 1.875943\n",
      "Batch #10\tAverage Generator Loss: 2231.265356\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16443 (step 16443): 1.380447\n",
      "Batch #10\tAverage Generator Loss: 2882.585754\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16444 (step 16444): 1.352081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2607.352722\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16445 (step 16445): 1.841712\n",
      "Batch #10\tAverage Generator Loss: 2638.412195\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16446 (step 16446): 1.344161\n",
      "Batch #10\tAverage Generator Loss: 2520.687732\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16447 (step 16447): 1.371841\n",
      "Batch #10\tAverage Generator Loss: 2547.618677\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16448 (step 16448): 1.449570\n",
      "Batch #10\tAverage Generator Loss: 2430.297449\tAverage Discriminator Loss: 0.007087\n",
      "\n",
      "Train time for epoch #16449 (step 16449): 1.910063\n",
      "Batch #10\tAverage Generator Loss: 2842.049683\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16450 (step 16450): 1.364500\n",
      "Batch #10\tAverage Generator Loss: 2571.858093\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16451 (step 16451): 1.300037\n",
      "Batch #10\tAverage Generator Loss: 2409.506665\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16452 (step 16452): 1.943838\n",
      "Batch #10\tAverage Generator Loss: 2676.911804\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16453 (step 16453): 1.333716\n",
      "Batch #10\tAverage Generator Loss: 2428.506616\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16454 (step 16454): 1.404815\n",
      "Batch #10\tAverage Generator Loss: 2894.850452\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16455 (step 16455): 1.856767\n",
      "Batch #10\tAverage Generator Loss: 2531.917249\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16456 (step 16456): 1.385509\n",
      "Batch #10\tAverage Generator Loss: 2646.347632\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16457 (step 16457): 1.257058\n",
      "Batch #10\tAverage Generator Loss: 2350.495532\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16458 (step 16458): 1.346296\n",
      "Batch #10\tAverage Generator Loss: 2341.861597\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16459 (step 16459): 1.886554\n",
      "Batch #10\tAverage Generator Loss: 2485.081232\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16460 (step 16460): 1.383152\n",
      "Batch #10\tAverage Generator Loss: 2494.582617\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16461 (step 16461): 1.300504\n",
      "Batch #10\tAverage Generator Loss: 2403.715405\tAverage Discriminator Loss: 0.028933\n",
      "\n",
      "Train time for epoch #16462 (step 16462): 1.954047\n",
      "Batch #10\tAverage Generator Loss: 2527.711011\tAverage Discriminator Loss: 0.001508\n",
      "\n",
      "Train time for epoch #16463 (step 16463): 1.389142\n",
      "Batch #10\tAverage Generator Loss: 2129.662134\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16464 (step 16464): 1.386089\n",
      "Batch #10\tAverage Generator Loss: 2701.266638\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16465 (step 16465): 1.342235\n",
      "Batch #10\tAverage Generator Loss: 2431.641870\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16466 (step 16466): 1.947364\n",
      "Batch #10\tAverage Generator Loss: 2651.416479\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16467 (step 16467): 1.315826\n",
      "Batch #10\tAverage Generator Loss: 2149.104456\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16468 (step 16468): 1.302739\n",
      "Batch #10\tAverage Generator Loss: 2796.999255\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16469 (step 16469): 1.855635\n",
      "Batch #10\tAverage Generator Loss: 2407.252673\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16470 (step 16470): 1.360329\n",
      "Batch #10\tAverage Generator Loss: 2671.163550\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16471 (step 16471): 1.348514\n",
      "Batch #10\tAverage Generator Loss: 2207.856152\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16472 (step 16472): 1.797393\n",
      "Batch #10\tAverage Generator Loss: 2579.169641\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16473 (step 16473): 1.245921\n",
      "Batch #10\tAverage Generator Loss: 2796.400330\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16474 (step 16474): 1.308665\n",
      "Batch #10\tAverage Generator Loss: 2261.772214\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16475 (step 16475): 1.443873\n",
      "Batch #10\tAverage Generator Loss: 2308.198584\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16476 (step 16476): 1.793367\n",
      "Batch #10\tAverage Generator Loss: 2456.592773\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16477 (step 16477): 1.288281\n",
      "Batch #10\tAverage Generator Loss: 2180.371472\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16478 (step 16478): 1.391887\n",
      "Batch #10\tAverage Generator Loss: 2569.736145\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16479 (step 16479): 1.771301\n",
      "Batch #10\tAverage Generator Loss: 2508.576428\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16480 (step 16480): 1.285826\n",
      "Batch #10\tAverage Generator Loss: 2287.254871\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16481 (step 16481): 1.414767\n",
      "Batch #10\tAverage Generator Loss: 2266.041821\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16482 (step 16482): 1.834856\n",
      "Batch #10\tAverage Generator Loss: 2277.613208\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16483 (step 16483): 1.380742\n",
      "Batch #10\tAverage Generator Loss: 1999.497876\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16484 (step 16484): 1.354560\n",
      "Batch #10\tAverage Generator Loss: 2165.198077\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16485 (step 16485): 1.334962\n",
      "Batch #10\tAverage Generator Loss: 2503.518579\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16486 (step 16486): 1.985768\n",
      "Batch #10\tAverage Generator Loss: 2237.481451\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16487 (step 16487): 1.285979\n",
      "Batch #10\tAverage Generator Loss: 2733.166943\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16488 (step 16488): 1.331458\n",
      "Batch #10\tAverage Generator Loss: 2551.939563\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16489 (step 16489): 1.988054\n",
      "Batch #10\tAverage Generator Loss: 2294.601367\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16490 (step 16490): 1.407389\n",
      "Batch #10\tAverage Generator Loss: 2322.361755\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16491 (step 16491): 1.337080\n",
      "Batch #10\tAverage Generator Loss: 2526.749976\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16492 (step 16492): 1.394412\n",
      "Batch #10\tAverage Generator Loss: 2175.260541\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16493 (step 16493): 1.946454\n",
      "Batch #10\tAverage Generator Loss: 2424.609290\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16494 (step 16494): 1.390492\n",
      "Batch #10\tAverage Generator Loss: 2567.977417\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16495 (step 16495): 1.289636\n",
      "Batch #10\tAverage Generator Loss: 2275.706085\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16496 (step 16496): 2.140348\n",
      "Batch #10\tAverage Generator Loss: 2564.408777\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16497 (step 16497): 1.401189\n",
      "Batch #10\tAverage Generator Loss: 2493.277649\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16498 (step 16498): 1.293460\n",
      "Batch #10\tAverage Generator Loss: 2334.740710\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16499 (step 16499): 1.227275\n",
      "Batch #10\tAverage Generator Loss: 2462.372504\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16500 (step 16500): 1.857414\n",
      "Batch #10\tAverage Generator Loss: 2612.515442\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16501 (step 16501): 1.297358\n",
      "Batch #10\tAverage Generator Loss: 2543.018555\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16502 (step 16502): 1.293529\n",
      "Batch #10\tAverage Generator Loss: 2034.166040\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16503 (step 16503): 1.870548\n",
      "Batch #10\tAverage Generator Loss: 2494.267670\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #16504 (step 16504): 1.413029\n",
      "Batch #10\tAverage Generator Loss: 2536.409631\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16505 (step 16505): 1.359196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2131.840344\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16506 (step 16506): 1.843357\n",
      "Batch #10\tAverage Generator Loss: 2619.728815\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16507 (step 16507): 1.314443\n",
      "Batch #10\tAverage Generator Loss: 2291.530634\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16508 (step 16508): 1.386028\n",
      "Batch #10\tAverage Generator Loss: 2634.293805\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16509 (step 16509): 1.785103\n",
      "Batch #10\tAverage Generator Loss: 2374.094812\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16510 (step 16510): 1.380561\n",
      "Batch #10\tAverage Generator Loss: 2075.208563\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16511 (step 16511): 1.334080\n",
      "Batch #10\tAverage Generator Loss: 2272.820288\tAverage Discriminator Loss: 0.047755\n",
      "\n",
      "Train time for epoch #16512 (step 16512): 1.291947\n",
      "Batch #10\tAverage Generator Loss: 2581.708411\tAverage Discriminator Loss: 0.036628\n",
      "\n",
      "Train time for epoch #16513 (step 16513): 1.805892\n",
      "Batch #10\tAverage Generator Loss: 3266.221436\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16514 (step 16514): 1.250479\n",
      "Batch #10\tAverage Generator Loss: 3443.554089\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16515 (step 16515): 1.434927\n",
      "Batch #10\tAverage Generator Loss: 3413.566345\tAverage Discriminator Loss: 0.035651\n",
      "\n",
      "Train time for epoch #16516 (step 16516): 1.237655\n",
      "Batch #10\tAverage Generator Loss: 2484.192578\tAverage Discriminator Loss: 0.073206\n",
      "\n",
      "Train time for epoch #16517 (step 16517): 1.949257\n",
      "Batch #10\tAverage Generator Loss: 2332.361938\tAverage Discriminator Loss: 0.000087\n",
      "\n",
      "Train time for epoch #16518 (step 16518): 1.295294\n",
      "Batch #10\tAverage Generator Loss: 2372.718005\tAverage Discriminator Loss: 0.048604\n",
      "\n",
      "Train time for epoch #16519 (step 16519): 1.328143\n",
      "Batch #10\tAverage Generator Loss: 2218.361511\tAverage Discriminator Loss: 0.019973\n",
      "\n",
      "Train time for epoch #16520 (step 16520): 1.826173\n",
      "Batch #10\tAverage Generator Loss: 2287.475110\tAverage Discriminator Loss: 0.002071\n",
      "\n",
      "Train time for epoch #16521 (step 16521): 1.335181\n",
      "Batch #10\tAverage Generator Loss: 2212.381116\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16522 (step 16522): 1.300953\n",
      "Batch #10\tAverage Generator Loss: 2212.022668\tAverage Discriminator Loss: 0.024129\n",
      "\n",
      "Train time for epoch #16523 (step 16523): 1.947934\n",
      "Batch #10\tAverage Generator Loss: 2297.387354\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16524 (step 16524): 1.323366\n",
      "Batch #10\tAverage Generator Loss: 2251.869879\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16525 (step 16525): 1.400117\n",
      "Batch #10\tAverage Generator Loss: 2548.831232\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16526 (step 16526): 1.391649\n",
      "Batch #10\tAverage Generator Loss: 1929.444501\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16527 (step 16527): 1.900989\n",
      "Batch #10\tAverage Generator Loss: 2522.641687\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16528 (step 16528): 1.280806\n",
      "Batch #10\tAverage Generator Loss: 2191.092175\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16529 (step 16529): 1.288759\n",
      "Batch #10\tAverage Generator Loss: 2044.915131\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16530 (step 16530): 1.869354\n",
      "Batch #10\tAverage Generator Loss: 2107.714404\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16531 (step 16531): 1.430849\n",
      "Batch #10\tAverage Generator Loss: 2223.867407\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16532 (step 16532): 1.406564\n",
      "Batch #10\tAverage Generator Loss: 2283.161218\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16533 (step 16533): 1.904528\n",
      "Batch #10\tAverage Generator Loss: 2101.506262\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16534 (step 16534): 1.327784\n",
      "Batch #10\tAverage Generator Loss: 2123.047144\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16535 (step 16535): 1.295507\n",
      "Batch #10\tAverage Generator Loss: 2370.460126\tAverage Discriminator Loss: 0.023199\n",
      "\n",
      "Train time for epoch #16536 (step 16536): 1.326541\n",
      "Batch #10\tAverage Generator Loss: 2224.670984\tAverage Discriminator Loss: 0.025566\n",
      "\n",
      "Train time for epoch #16537 (step 16537): 1.904264\n",
      "Batch #10\tAverage Generator Loss: 2286.709290\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16538 (step 16538): 1.283356\n",
      "Batch #10\tAverage Generator Loss: 2263.030835\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16539 (step 16539): 1.287362\n",
      "Batch #10\tAverage Generator Loss: 2063.562439\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16540 (step 16540): 1.840729\n",
      "Batch #10\tAverage Generator Loss: 1922.614581\tAverage Discriminator Loss: 0.131995\n",
      "\n",
      "Train time for epoch #16541 (step 16541): 1.487528\n",
      "Batch #10\tAverage Generator Loss: 2234.893628\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16542 (step 16542): 1.354762\n",
      "Batch #10\tAverage Generator Loss: 2120.299561\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #16543 (step 16543): 2.056667\n",
      "Batch #10\tAverage Generator Loss: 2193.519421\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16544 (step 16544): 1.285247\n",
      "Batch #10\tAverage Generator Loss: 2062.631042\tAverage Discriminator Loss: 0.000779\n",
      "\n",
      "Train time for epoch #16545 (step 16545): 1.292339\n",
      "Batch #10\tAverage Generator Loss: 2269.914142\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16546 (step 16546): 1.747166\n",
      "Batch #10\tAverage Generator Loss: 2238.203162\tAverage Discriminator Loss: 0.052525\n",
      "\n",
      "Train time for epoch #16547 (step 16547): 1.279907\n",
      "Batch #10\tAverage Generator Loss: 2408.807617\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16548 (step 16548): 1.288420\n",
      "Batch #10\tAverage Generator Loss: 2585.408423\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16549 (step 16549): 1.377951\n",
      "Batch #10\tAverage Generator Loss: 2568.751062\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16550 (step 16550): 1.904448\n",
      "Batch #10\tAverage Generator Loss: 2394.480170\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16551 (step 16551): 1.304610\n",
      "Batch #10\tAverage Generator Loss: 2451.932373\tAverage Discriminator Loss: 0.025480\n",
      "\n",
      "Train time for epoch #16552 (step 16552): 1.310788\n",
      "Batch #10\tAverage Generator Loss: 2182.266492\tAverage Discriminator Loss: 0.000042\n",
      "\n",
      "Train time for epoch #16553 (step 16553): 1.817698\n",
      "Batch #10\tAverage Generator Loss: 2149.730884\tAverage Discriminator Loss: 0.001063\n",
      "\n",
      "Train time for epoch #16554 (step 16554): 1.532577\n",
      "Batch #10\tAverage Generator Loss: 1857.041089\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #16555 (step 16555): 1.325243\n",
      "Batch #10\tAverage Generator Loss: 1768.992078\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #16556 (step 16556): 1.813097\n",
      "Batch #10\tAverage Generator Loss: 2005.819202\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #16557 (step 16557): 1.422298\n",
      "Batch #10\tAverage Generator Loss: 2207.227051\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #16558 (step 16558): 1.284235\n",
      "Batch #10\tAverage Generator Loss: 2061.007361\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #16559 (step 16559): 1.390995\n",
      "Batch #10\tAverage Generator Loss: 2122.515356\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #16560 (step 16560): 1.983449\n",
      "Batch #10\tAverage Generator Loss: 1963.462244\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #16561 (step 16561): 1.281870\n",
      "Batch #10\tAverage Generator Loss: 1882.684302\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #16562 (step 16562): 1.311997\n",
      "Batch #10\tAverage Generator Loss: 2180.919513\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #16563 (step 16563): 1.860223\n",
      "Batch #10\tAverage Generator Loss: 2348.799927\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #16564 (step 16564): 1.284566\n",
      "Batch #10\tAverage Generator Loss: 1890.810681\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #16565 (step 16565): 1.333640\n",
      "Batch #10\tAverage Generator Loss: 2017.308875\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #16566 (step 16566): 1.300917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2175.499826\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #16567 (step 16567): 1.907061\n",
      "Batch #10\tAverage Generator Loss: 2346.101831\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #16568 (step 16568): 1.353312\n",
      "Batch #10\tAverage Generator Loss: 2118.823523\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #16569 (step 16569): 1.427736\n",
      "Batch #10\tAverage Generator Loss: 1934.697046\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #16570 (step 16570): 1.866484\n",
      "Batch #10\tAverage Generator Loss: 2123.277759\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #16571 (step 16571): 1.447084\n",
      "Batch #10\tAverage Generator Loss: 2160.700662\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16572 (step 16572): 1.266133\n",
      "Batch #10\tAverage Generator Loss: 1813.696240\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #16573 (step 16573): 1.342202\n",
      "Batch #10\tAverage Generator Loss: 2295.853503\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #16574 (step 16574): 1.905524\n",
      "Batch #10\tAverage Generator Loss: 2039.095508\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #16575 (step 16575): 1.412432\n",
      "Batch #10\tAverage Generator Loss: 2214.211963\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16576 (step 16576): 1.300853\n",
      "Batch #10\tAverage Generator Loss: 2002.220044\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #16577 (step 16577): 1.846325\n",
      "Batch #10\tAverage Generator Loss: 2019.622278\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #16578 (step 16578): 1.304512\n",
      "Batch #10\tAverage Generator Loss: 1953.067114\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #16579 (step 16579): 1.359058\n",
      "Batch #10\tAverage Generator Loss: 2095.314124\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #16580 (step 16580): 1.865232\n",
      "Batch #10\tAverage Generator Loss: 2110.975757\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16581 (step 16581): 1.384142\n",
      "Batch #10\tAverage Generator Loss: 2136.878809\tAverage Discriminator Loss: 0.006317\n",
      "\n",
      "Train time for epoch #16582 (step 16582): 1.253723\n",
      "Batch #10\tAverage Generator Loss: 1959.436780\tAverage Discriminator Loss: 0.002664\n",
      "\n",
      "Train time for epoch #16583 (step 16583): 1.405097\n",
      "Batch #10\tAverage Generator Loss: 1916.868188\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16584 (step 16584): 1.798275\n",
      "Batch #10\tAverage Generator Loss: 2163.236450\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16585 (step 16585): 1.474055\n",
      "Batch #10\tAverage Generator Loss: 2097.609399\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16586 (step 16586): 1.326640\n",
      "Batch #10\tAverage Generator Loss: 2210.198535\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16587 (step 16587): 1.799996\n",
      "Batch #10\tAverage Generator Loss: 2143.782068\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16588 (step 16588): 1.314523\n",
      "Batch #10\tAverage Generator Loss: 1944.804825\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16589 (step 16589): 1.296237\n",
      "Batch #10\tAverage Generator Loss: 2254.504517\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16590 (step 16590): 1.473189\n",
      "Batch #10\tAverage Generator Loss: 1555.788190\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16591 (step 16591): 1.941211\n",
      "Batch #10\tAverage Generator Loss: 1895.726819\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16592 (step 16592): 1.338722\n",
      "Batch #10\tAverage Generator Loss: 2202.021680\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16593 (step 16593): 1.356101\n",
      "Batch #10\tAverage Generator Loss: 2117.277557\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16594 (step 16594): 1.864774\n",
      "Batch #10\tAverage Generator Loss: 2064.720142\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16595 (step 16595): 1.351543\n",
      "Batch #10\tAverage Generator Loss: 1873.310278\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16596 (step 16596): 1.426903\n",
      "Batch #10\tAverage Generator Loss: 2278.075830\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16597 (step 16597): 1.862015\n",
      "Batch #10\tAverage Generator Loss: 2071.466602\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16598 (step 16598): 1.428218\n",
      "Batch #10\tAverage Generator Loss: 2057.707983\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16599 (step 16599): 1.384100\n",
      "Batch #10\tAverage Generator Loss: 2107.117627\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16600 (step 16600): 1.286895\n",
      "Batch #10\tAverage Generator Loss: 1706.058081\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16601 (step 16601): 1.839685\n",
      "Batch #10\tAverage Generator Loss: 2223.643188\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16602 (step 16602): 1.394662\n",
      "Batch #10\tAverage Generator Loss: 2204.183807\tAverage Discriminator Loss: 0.030846\n",
      "\n",
      "Train time for epoch #16603 (step 16603): 1.332640\n",
      "Batch #10\tAverage Generator Loss: 1951.758777\tAverage Discriminator Loss: 0.000989\n",
      "\n",
      "Train time for epoch #16604 (step 16604): 1.896278\n",
      "Batch #10\tAverage Generator Loss: 2308.751904\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16605 (step 16605): 1.297865\n",
      "Batch #10\tAverage Generator Loss: 2098.308337\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16606 (step 16606): 1.338225\n",
      "Batch #10\tAverage Generator Loss: 2115.972778\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16607 (step 16607): 1.445335\n",
      "Batch #10\tAverage Generator Loss: 2039.039081\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16608 (step 16608): 1.865471\n",
      "Batch #10\tAverage Generator Loss: 2038.161578\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16609 (step 16609): 1.342999\n",
      "Batch #10\tAverage Generator Loss: 2467.492603\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16610 (step 16610): 1.338929\n",
      "Batch #10\tAverage Generator Loss: 2024.398755\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16611 (step 16611): 1.869717\n",
      "Batch #10\tAverage Generator Loss: 2031.323669\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16612 (step 16612): 1.417793\n",
      "Batch #10\tAverage Generator Loss: 2044.493481\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16613 (step 16613): 1.345623\n",
      "Batch #10\tAverage Generator Loss: 1850.275269\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16614 (step 16614): 1.906630\n",
      "Batch #10\tAverage Generator Loss: 1721.096619\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16615 (step 16615): 1.510108\n",
      "Batch #10\tAverage Generator Loss: 2124.490649\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16616 (step 16616): 1.286252\n",
      "Batch #10\tAverage Generator Loss: 2060.672754\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16617 (step 16617): 1.280385\n",
      "Batch #10\tAverage Generator Loss: 2019.740656\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16618 (step 16618): 1.987049\n",
      "Batch #10\tAverage Generator Loss: 1955.572397\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16619 (step 16619): 1.491834\n",
      "Batch #10\tAverage Generator Loss: 1946.309076\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16620 (step 16620): 1.395902\n",
      "Batch #10\tAverage Generator Loss: 2203.305530\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16621 (step 16621): 1.965867\n",
      "Batch #10\tAverage Generator Loss: 2024.956799\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16622 (step 16622): 1.274609\n",
      "Batch #10\tAverage Generator Loss: 1713.849860\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16623 (step 16623): 1.439113\n",
      "Batch #10\tAverage Generator Loss: 2289.281616\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16624 (step 16624): 1.334508\n",
      "Batch #10\tAverage Generator Loss: 2037.707300\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16625 (step 16625): 1.992465\n",
      "Batch #10\tAverage Generator Loss: 1891.224243\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16626 (step 16626): 1.363982\n",
      "Batch #10\tAverage Generator Loss: 2390.250146\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16627 (step 16627): 1.282996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2185.208838\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16628 (step 16628): 1.905994\n",
      "Batch #10\tAverage Generator Loss: 2191.724353\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16629 (step 16629): 1.232542\n",
      "Batch #10\tAverage Generator Loss: 2265.602515\tAverage Discriminator Loss: 0.000163\n",
      "\n",
      "Train time for epoch #16630 (step 16630): 1.281971\n",
      "Batch #10\tAverage Generator Loss: 2212.132666\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16631 (step 16631): 1.335122\n",
      "Batch #10\tAverage Generator Loss: 1896.855487\tAverage Discriminator Loss: 0.006665\n",
      "\n",
      "Train time for epoch #16632 (step 16632): 1.796932\n",
      "Batch #10\tAverage Generator Loss: 1961.685815\tAverage Discriminator Loss: 0.037483\n",
      "\n",
      "Train time for epoch #16633 (step 16633): 1.285581\n",
      "Batch #10\tAverage Generator Loss: 1823.901807\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16634 (step 16634): 1.337671\n",
      "Batch #10\tAverage Generator Loss: 2043.306177\tAverage Discriminator Loss: 0.181618\n",
      "\n",
      "Train time for epoch #16635 (step 16635): 1.813622\n",
      "Batch #10\tAverage Generator Loss: 2180.123279\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16636 (step 16636): 1.300521\n",
      "Batch #10\tAverage Generator Loss: 2300.598181\tAverage Discriminator Loss: 0.034962\n",
      "\n",
      "Train time for epoch #16637 (step 16637): 1.342211\n",
      "Batch #10\tAverage Generator Loss: 2015.424011\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16638 (step 16638): 1.971320\n",
      "Batch #10\tAverage Generator Loss: 2366.560364\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16639 (step 16639): 1.361340\n",
      "Batch #10\tAverage Generator Loss: 2076.824451\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16640 (step 16640): 1.305429\n",
      "Batch #10\tAverage Generator Loss: 2145.026135\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16641 (step 16641): 1.350446\n",
      "Batch #10\tAverage Generator Loss: 1919.620032\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16642 (step 16642): 1.867381\n",
      "Batch #10\tAverage Generator Loss: 1914.732849\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16643 (step 16643): 1.399758\n",
      "Batch #10\tAverage Generator Loss: 2100.855688\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16644 (step 16644): 1.297904\n",
      "Batch #10\tAverage Generator Loss: 2151.832892\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16645 (step 16645): 1.855685\n",
      "Batch #10\tAverage Generator Loss: 2065.932422\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16646 (step 16646): 1.342609\n",
      "Batch #10\tAverage Generator Loss: 2038.162695\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16647 (step 16647): 1.241543\n",
      "Batch #10\tAverage Generator Loss: 2100.561856\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16648 (step 16648): 1.391380\n",
      "Batch #10\tAverage Generator Loss: 2147.678528\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16649 (step 16649): 1.962619\n",
      "Batch #10\tAverage Generator Loss: 2050.475293\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16650 (step 16650): 1.301258\n",
      "Batch #10\tAverage Generator Loss: 1937.403149\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16651 (step 16651): 1.341123\n",
      "Batch #10\tAverage Generator Loss: 1982.699231\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16652 (step 16652): 1.970435\n",
      "Batch #10\tAverage Generator Loss: 1720.149072\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16653 (step 16653): 1.581056\n",
      "Batch #10\tAverage Generator Loss: 1745.290747\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16654 (step 16654): 1.303962\n",
      "Batch #10\tAverage Generator Loss: 2214.740796\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16655 (step 16655): 1.864335\n",
      "Batch #10\tAverage Generator Loss: 2246.657678\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16656 (step 16656): 1.332281\n",
      "Batch #10\tAverage Generator Loss: 2084.611511\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16657 (step 16657): 1.303576\n",
      "Batch #10\tAverage Generator Loss: 2101.743439\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16658 (step 16658): 1.892368\n",
      "Batch #10\tAverage Generator Loss: 1819.414899\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16659 (step 16659): 1.393769\n",
      "Batch #10\tAverage Generator Loss: 2155.800342\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16660 (step 16660): 1.368650\n",
      "Batch #10\tAverage Generator Loss: 2146.313831\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16661 (step 16661): 1.422584\n",
      "Batch #10\tAverage Generator Loss: 1979.164844\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16662 (step 16662): 1.823228\n",
      "Batch #10\tAverage Generator Loss: 2324.177997\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16663 (step 16663): 1.373639\n",
      "Batch #10\tAverage Generator Loss: 2011.824896\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16664 (step 16664): 1.303889\n",
      "Batch #10\tAverage Generator Loss: 2015.394543\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16665 (step 16665): 1.867972\n",
      "Batch #10\tAverage Generator Loss: 2127.288367\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16666 (step 16666): 1.337135\n",
      "Batch #10\tAverage Generator Loss: 1921.633301\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16667 (step 16667): 1.390853\n",
      "Batch #10\tAverage Generator Loss: 2256.095483\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16668 (step 16668): 1.429290\n",
      "Batch #10\tAverage Generator Loss: 2020.092383\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16669 (step 16669): 1.803938\n",
      "Batch #10\tAverage Generator Loss: 2134.773926\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16670 (step 16670): 1.346808\n",
      "Batch #10\tAverage Generator Loss: 1930.729297\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16671 (step 16671): 1.287436\n",
      "Batch #10\tAverage Generator Loss: 1894.207562\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16672 (step 16672): 1.770281\n",
      "Batch #10\tAverage Generator Loss: 1933.588464\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16673 (step 16673): 1.484656\n",
      "Batch #10\tAverage Generator Loss: 2172.056854\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16674 (step 16674): 1.424667\n",
      "Batch #10\tAverage Generator Loss: 2016.271802\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16675 (step 16675): 1.787508\n",
      "Batch #10\tAverage Generator Loss: 2042.460986\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16676 (step 16676): 1.293992\n",
      "Batch #10\tAverage Generator Loss: 2193.287476\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16677 (step 16677): 1.380809\n",
      "Batch #10\tAverage Generator Loss: 2128.212500\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16678 (step 16678): 1.834038\n",
      "Batch #10\tAverage Generator Loss: 2222.276709\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16679 (step 16679): 1.350124\n",
      "Batch #10\tAverage Generator Loss: 2374.165759\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16680 (step 16680): 1.295002\n",
      "Batch #10\tAverage Generator Loss: 2193.659399\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16681 (step 16681): 1.287833\n",
      "Batch #10\tAverage Generator Loss: 2111.219751\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16682 (step 16682): 1.961189\n",
      "Batch #10\tAverage Generator Loss: 2074.417365\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16683 (step 16683): 1.294774\n",
      "Batch #10\tAverage Generator Loss: 1829.793292\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16684 (step 16684): 1.279283\n",
      "Batch #10\tAverage Generator Loss: 2102.857227\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16685 (step 16685): 1.965301\n",
      "Batch #10\tAverage Generator Loss: 1889.294974\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16686 (step 16686): 1.343818\n",
      "Batch #10\tAverage Generator Loss: 2251.038623\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16687 (step 16687): 1.301353\n",
      "Batch #10\tAverage Generator Loss: 2014.378174\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16688 (step 16688): 1.249803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2246.715173\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16689 (step 16689): 1.872728\n",
      "Batch #10\tAverage Generator Loss: 2141.402301\tAverage Discriminator Loss: 0.021791\n",
      "\n",
      "Train time for epoch #16690 (step 16690): 1.434042\n",
      "Batch #10\tAverage Generator Loss: 2099.181158\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16691 (step 16691): 1.291791\n",
      "Batch #10\tAverage Generator Loss: 1923.139307\tAverage Discriminator Loss: 0.000464\n",
      "\n",
      "Train time for epoch #16692 (step 16692): 1.855073\n",
      "Batch #10\tAverage Generator Loss: 2634.196545\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16693 (step 16693): 1.303044\n",
      "Batch #10\tAverage Generator Loss: 2044.450220\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16694 (step 16694): 1.328280\n",
      "Batch #10\tAverage Generator Loss: 2017.763159\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16695 (step 16695): 1.852197\n",
      "Batch #10\tAverage Generator Loss: 1823.635840\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16696 (step 16696): 1.305170\n",
      "Batch #10\tAverage Generator Loss: 2221.218433\tAverage Discriminator Loss: 0.008034\n",
      "\n",
      "Train time for epoch #16697 (step 16697): 1.392440\n",
      "Batch #10\tAverage Generator Loss: 2004.378284\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16698 (step 16698): 1.348688\n",
      "Batch #10\tAverage Generator Loss: 1821.373724\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16699 (step 16699): 1.861610\n",
      "Batch #10\tAverage Generator Loss: 2161.853101\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16700 (step 16700): 1.415622\n",
      "Batch #10\tAverage Generator Loss: 2043.093054\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16701 (step 16701): 1.539200\n",
      "Batch #10\tAverage Generator Loss: 2285.990039\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16702 (step 16702): 1.764373\n",
      "Batch #10\tAverage Generator Loss: 2110.797119\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16703 (step 16703): 1.334935\n",
      "Batch #10\tAverage Generator Loss: 2114.815332\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16704 (step 16704): 1.334892\n",
      "Batch #10\tAverage Generator Loss: 1950.622424\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16705 (step 16705): 1.348977\n",
      "Batch #10\tAverage Generator Loss: 2030.219238\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16706 (step 16706): 1.807019\n",
      "Batch #10\tAverage Generator Loss: 2122.822314\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16707 (step 16707): 1.343583\n",
      "Batch #10\tAverage Generator Loss: 2257.064355\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16708 (step 16708): 1.334350\n",
      "Batch #10\tAverage Generator Loss: 2092.905725\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16709 (step 16709): 1.818626\n",
      "Batch #10\tAverage Generator Loss: 2219.781555\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16710 (step 16710): 1.391960\n",
      "Batch #10\tAverage Generator Loss: 2171.095459\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16711 (step 16711): 1.337281\n",
      "Batch #10\tAverage Generator Loss: 1869.201917\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16712 (step 16712): 1.863765\n",
      "Batch #10\tAverage Generator Loss: 1827.264783\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16713 (step 16713): 1.419034\n",
      "Batch #10\tAverage Generator Loss: 1673.966241\tAverage Discriminator Loss: 0.664277\n",
      "\n",
      "Train time for epoch #16714 (step 16714): 1.341506\n",
      "Batch #10\tAverage Generator Loss: 1975.778577\tAverage Discriminator Loss: 0.001391\n",
      "\n",
      "Train time for epoch #16715 (step 16715): 1.325232\n",
      "Batch #10\tAverage Generator Loss: 1722.299866\tAverage Discriminator Loss: 0.000027\n",
      "\n",
      "Train time for epoch #16716 (step 16716): 1.965027\n",
      "Batch #10\tAverage Generator Loss: 1988.258911\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #16717 (step 16717): 1.353468\n",
      "Batch #10\tAverage Generator Loss: 2359.092810\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #16718 (step 16718): 1.429287\n",
      "Batch #10\tAverage Generator Loss: 2051.091699\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #16719 (step 16719): 1.884428\n",
      "Batch #10\tAverage Generator Loss: 2591.401831\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #16720 (step 16720): 1.452022\n",
      "Batch #10\tAverage Generator Loss: 2129.032434\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #16721 (step 16721): 1.453608\n",
      "Batch #10\tAverage Generator Loss: 2047.599060\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #16722 (step 16722): 1.902820\n",
      "Batch #10\tAverage Generator Loss: 2426.224292\tAverage Discriminator Loss: 0.000027\n",
      "\n",
      "Train time for epoch #16723 (step 16723): 1.284997\n",
      "Batch #10\tAverage Generator Loss: 2347.923853\tAverage Discriminator Loss: 0.000140\n",
      "\n",
      "Train time for epoch #16724 (step 16724): 1.356951\n",
      "Batch #10\tAverage Generator Loss: 2161.888733\tAverage Discriminator Loss: 0.000034\n",
      "\n",
      "Train time for epoch #16725 (step 16725): 1.289552\n",
      "Batch #10\tAverage Generator Loss: 1957.478070\tAverage Discriminator Loss: 0.000028\n",
      "\n",
      "Train time for epoch #16726 (step 16726): 1.862153\n",
      "Batch #10\tAverage Generator Loss: 2048.115515\tAverage Discriminator Loss: 0.005437\n",
      "\n",
      "Train time for epoch #16727 (step 16727): 1.415076\n",
      "Batch #10\tAverage Generator Loss: 2674.512122\tAverage Discriminator Loss: 0.195660\n",
      "\n",
      "Train time for epoch #16728 (step 16728): 1.351267\n",
      "Batch #10\tAverage Generator Loss: 2497.739587\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16729 (step 16729): 1.885422\n",
      "Batch #10\tAverage Generator Loss: 2719.392151\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16730 (step 16730): 1.350191\n",
      "Batch #10\tAverage Generator Loss: 2467.041626\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16731 (step 16731): 1.429847\n",
      "Batch #10\tAverage Generator Loss: 2724.920105\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16732 (step 16732): 1.945406\n",
      "Batch #10\tAverage Generator Loss: 2646.209570\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16733 (step 16733): 1.342659\n",
      "Batch #10\tAverage Generator Loss: 2448.081335\tAverage Discriminator Loss: 0.050068\n",
      "\n",
      "Train time for epoch #16734 (step 16734): 1.416065\n",
      "Batch #10\tAverage Generator Loss: 2275.519769\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16735 (step 16735): 1.485040\n",
      "Batch #10\tAverage Generator Loss: 2704.461035\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16736 (step 16736): 1.882107\n",
      "Batch #10\tAverage Generator Loss: 2406.006018\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16737 (step 16737): 1.361821\n",
      "Batch #10\tAverage Generator Loss: 3249.376831\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16738 (step 16738): 1.338001\n",
      "Batch #10\tAverage Generator Loss: 2161.540894\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16739 (step 16739): 1.834066\n",
      "Batch #10\tAverage Generator Loss: 3105.392712\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16740 (step 16740): 1.346764\n",
      "Batch #10\tAverage Generator Loss: 2816.506390\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16741 (step 16741): 1.283921\n",
      "Batch #10\tAverage Generator Loss: 3131.412402\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16742 (step 16742): 1.305412\n",
      "Batch #10\tAverage Generator Loss: 2744.004846\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16743 (step 16743): 1.807235\n",
      "Batch #10\tAverage Generator Loss: 2446.952411\tAverage Discriminator Loss: 0.080985\n",
      "\n",
      "Train time for epoch #16744 (step 16744): 1.357475\n",
      "Batch #10\tAverage Generator Loss: 3263.208423\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16745 (step 16745): 1.369808\n",
      "Batch #10\tAverage Generator Loss: 2933.510181\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16746 (step 16746): 1.904675\n",
      "Batch #10\tAverage Generator Loss: 2666.037524\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16747 (step 16747): 1.346588\n",
      "Batch #10\tAverage Generator Loss: 2869.176892\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16748 (step 16748): 1.324910\n",
      "Batch #10\tAverage Generator Loss: 2369.582129\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16749 (step 16749): 1.830544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2500.201843\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16750 (step 16750): 1.288958\n",
      "Batch #10\tAverage Generator Loss: 2512.214612\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16751 (step 16751): 1.297153\n",
      "Batch #10\tAverage Generator Loss: 2687.672400\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16752 (step 16752): 1.294115\n",
      "Batch #10\tAverage Generator Loss: 2600.738342\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16753 (step 16753): 1.948642\n",
      "Batch #10\tAverage Generator Loss: 2366.941699\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16754 (step 16754): 1.291296\n",
      "Batch #10\tAverage Generator Loss: 2174.318628\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16755 (step 16755): 1.421477\n",
      "Batch #10\tAverage Generator Loss: 2371.698010\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16756 (step 16756): 1.850947\n",
      "Batch #10\tAverage Generator Loss: 2670.928699\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16757 (step 16757): 1.437086\n",
      "Batch #10\tAverage Generator Loss: 2382.241748\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16758 (step 16758): 1.492249\n",
      "Batch #10\tAverage Generator Loss: 2537.840088\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16759 (step 16759): 1.301943\n",
      "Batch #10\tAverage Generator Loss: 2280.074243\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16760 (step 16760): 1.958678\n",
      "Batch #10\tAverage Generator Loss: 2266.601904\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16761 (step 16761): 1.289054\n",
      "Batch #10\tAverage Generator Loss: 2593.521509\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16762 (step 16762): 1.252287\n",
      "Batch #10\tAverage Generator Loss: 2222.003253\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16763 (step 16763): 1.963201\n",
      "Batch #10\tAverage Generator Loss: 2440.687012\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16764 (step 16764): 1.333220\n",
      "Batch #10\tAverage Generator Loss: 2543.314294\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16765 (step 16765): 1.387572\n",
      "Batch #10\tAverage Generator Loss: 2277.280103\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16766 (step 16766): 1.861714\n",
      "Batch #10\tAverage Generator Loss: 2703.344763\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16767 (step 16767): 1.382256\n",
      "Batch #10\tAverage Generator Loss: 2412.693799\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16768 (step 16768): 1.297426\n",
      "Batch #10\tAverage Generator Loss: 2562.865308\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16769 (step 16769): 1.281885\n",
      "Batch #10\tAverage Generator Loss: 2592.302991\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16770 (step 16770): 1.933408\n",
      "Batch #10\tAverage Generator Loss: 2146.463147\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16771 (step 16771): 1.319482\n",
      "Batch #10\tAverage Generator Loss: 2366.741992\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16772 (step 16772): 1.257995\n",
      "Batch #10\tAverage Generator Loss: 2413.706219\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16773 (step 16773): 1.932190\n",
      "Batch #10\tAverage Generator Loss: 2938.098730\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16774 (step 16774): 1.287532\n",
      "Batch #10\tAverage Generator Loss: 2274.979065\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16775 (step 16775): 1.424216\n",
      "Batch #10\tAverage Generator Loss: 2629.839038\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16776 (step 16776): 1.333299\n",
      "Batch #10\tAverage Generator Loss: 2546.429089\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16777 (step 16777): 1.903802\n",
      "Batch #10\tAverage Generator Loss: 2690.265576\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16778 (step 16778): 1.399220\n",
      "Batch #10\tAverage Generator Loss: 2302.237299\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16779 (step 16779): 1.333092\n",
      "Batch #10\tAverage Generator Loss: 2635.198816\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16780 (step 16780): 1.917599\n",
      "Batch #10\tAverage Generator Loss: 2331.624683\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16781 (step 16781): 1.401213\n",
      "Batch #10\tAverage Generator Loss: 2518.579456\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16782 (step 16782): 1.292716\n",
      "Batch #10\tAverage Generator Loss: 2442.008630\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16783 (step 16783): 1.795582\n",
      "Batch #10\tAverage Generator Loss: 2228.734009\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16784 (step 16784): 1.294681\n",
      "Batch #10\tAverage Generator Loss: 1933.589624\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16785 (step 16785): 1.401972\n",
      "Batch #10\tAverage Generator Loss: 2169.855798\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16786 (step 16786): 1.531292\n",
      "Batch #10\tAverage Generator Loss: 2438.194470\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16787 (step 16787): 1.796593\n",
      "Batch #10\tAverage Generator Loss: 2380.251917\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16788 (step 16788): 1.284595\n",
      "Batch #10\tAverage Generator Loss: 2367.458167\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16789 (step 16789): 1.307968\n",
      "Batch #10\tAverage Generator Loss: 2375.006628\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16790 (step 16790): 1.919248\n",
      "Batch #10\tAverage Generator Loss: 2700.899536\tAverage Discriminator Loss: 0.000054\n",
      "\n",
      "Train time for epoch #16791 (step 16791): 1.427797\n",
      "Batch #10\tAverage Generator Loss: 2547.011719\tAverage Discriminator Loss: 0.001950\n",
      "\n",
      "Train time for epoch #16792 (step 16792): 1.257938\n",
      "Batch #10\tAverage Generator Loss: 3007.750256\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16793 (step 16793): 1.404652\n",
      "Batch #10\tAverage Generator Loss: 2878.045361\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16794 (step 16794): 1.799002\n",
      "Batch #10\tAverage Generator Loss: 2304.365509\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16795 (step 16795): 1.440850\n",
      "Batch #10\tAverage Generator Loss: 3045.614966\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16796 (step 16796): 1.406229\n",
      "Batch #10\tAverage Generator Loss: 2731.896265\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16797 (step 16797): 1.871835\n",
      "Batch #10\tAverage Generator Loss: 2682.170837\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16798 (step 16798): 1.301712\n",
      "Batch #10\tAverage Generator Loss: 2504.492249\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16799 (step 16799): 1.317586\n",
      "Batch #10\tAverage Generator Loss: 2832.546094\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16800 (step 16800): 1.364684\n",
      "Batch #10\tAverage Generator Loss: 2556.636963\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16801 (step 16801): 1.822882\n",
      "Batch #10\tAverage Generator Loss: 2679.068103\tAverage Discriminator Loss: 0.025115\n",
      "\n",
      "Train time for epoch #16802 (step 16802): 1.342377\n",
      "Batch #10\tAverage Generator Loss: 2729.634198\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #16803 (step 16803): 1.287125\n",
      "Batch #10\tAverage Generator Loss: 2868.689038\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16804 (step 16804): 1.901435\n",
      "Batch #10\tAverage Generator Loss: 2966.014819\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16805 (step 16805): 1.336351\n",
      "Batch #10\tAverage Generator Loss: 2817.477954\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16806 (step 16806): 1.291832\n",
      "Batch #10\tAverage Generator Loss: 2876.743713\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16807 (step 16807): 1.958185\n",
      "Batch #10\tAverage Generator Loss: 2756.778870\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16808 (step 16808): 1.299396\n",
      "Batch #10\tAverage Generator Loss: 2714.431104\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16809 (step 16809): 1.297505\n",
      "Batch #10\tAverage Generator Loss: 3193.010083\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16810 (step 16810): 1.488795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2556.489209\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16811 (step 16811): 1.867611\n",
      "Batch #10\tAverage Generator Loss: 2897.956079\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16812 (step 16812): 1.286625\n",
      "Batch #10\tAverage Generator Loss: 2757.199866\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16813 (step 16813): 1.291657\n",
      "Batch #10\tAverage Generator Loss: 3170.244653\tAverage Discriminator Loss: 0.000077\n",
      "\n",
      "Train time for epoch #16814 (step 16814): 1.908691\n",
      "Batch #10\tAverage Generator Loss: 2954.323730\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16815 (step 16815): 1.453809\n",
      "Batch #10\tAverage Generator Loss: 2554.236292\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16816 (step 16816): 1.293227\n",
      "Batch #10\tAverage Generator Loss: 2900.637109\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16817 (step 16817): 1.843747\n",
      "Batch #10\tAverage Generator Loss: 2950.714282\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16818 (step 16818): 1.305227\n",
      "Batch #10\tAverage Generator Loss: 2982.386340\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16819 (step 16819): 1.404763\n",
      "Batch #10\tAverage Generator Loss: 2608.155273\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16820 (step 16820): 1.284463\n",
      "Batch #10\tAverage Generator Loss: 2662.604700\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16821 (step 16821): 1.812671\n",
      "Batch #10\tAverage Generator Loss: 2849.707996\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16822 (step 16822): 1.277810\n",
      "Batch #10\tAverage Generator Loss: 2715.897058\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16823 (step 16823): 1.292792\n",
      "Batch #10\tAverage Generator Loss: 2543.194141\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16824 (step 16824): 1.961283\n",
      "Batch #10\tAverage Generator Loss: 2890.417664\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16825 (step 16825): 1.280513\n",
      "Batch #10\tAverage Generator Loss: 2712.957275\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16826 (step 16826): 1.295604\n",
      "Batch #10\tAverage Generator Loss: 2910.707812\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16827 (step 16827): 1.377770\n",
      "Batch #10\tAverage Generator Loss: 2808.457446\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16828 (step 16828): 1.827723\n",
      "Batch #10\tAverage Generator Loss: 2716.288965\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16829 (step 16829): 1.404173\n",
      "Batch #10\tAverage Generator Loss: 2706.484668\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16830 (step 16830): 1.405678\n",
      "Batch #10\tAverage Generator Loss: 3114.749976\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16831 (step 16831): 1.825107\n",
      "Batch #10\tAverage Generator Loss: 2386.225647\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16832 (step 16832): 1.337219\n",
      "Batch #10\tAverage Generator Loss: 2708.270154\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16833 (step 16833): 1.405566\n",
      "Batch #10\tAverage Generator Loss: 2547.607068\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16834 (step 16834): 1.367730\n",
      "Batch #10\tAverage Generator Loss: 2358.290503\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16835 (step 16835): 1.877782\n",
      "Batch #10\tAverage Generator Loss: 2802.413965\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16836 (step 16836): 1.357613\n",
      "Batch #10\tAverage Generator Loss: 2613.289014\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16837 (step 16837): 1.291817\n",
      "Batch #10\tAverage Generator Loss: 2751.410095\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16838 (step 16838): 1.956913\n",
      "Batch #10\tAverage Generator Loss: 2891.660742\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16839 (step 16839): 1.373657\n",
      "Batch #10\tAverage Generator Loss: 2950.301562\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16840 (step 16840): 1.293544\n",
      "Batch #10\tAverage Generator Loss: 2390.980377\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16841 (step 16841): 1.928465\n",
      "Batch #10\tAverage Generator Loss: 2844.906140\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16842 (step 16842): 1.291556\n",
      "Batch #10\tAverage Generator Loss: 2641.355115\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16843 (step 16843): 1.396755\n",
      "Batch #10\tAverage Generator Loss: 2651.471460\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16844 (step 16844): 1.314228\n",
      "Batch #10\tAverage Generator Loss: 2667.726892\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16845 (step 16845): 1.871112\n",
      "Batch #10\tAverage Generator Loss: 3046.620325\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16846 (step 16846): 1.338999\n",
      "Batch #10\tAverage Generator Loss: 2835.311145\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16847 (step 16847): 1.297259\n",
      "Batch #10\tAverage Generator Loss: 3215.433728\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16848 (step 16848): 1.903914\n",
      "Batch #10\tAverage Generator Loss: 2548.590250\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16849 (step 16849): 1.293457\n",
      "Batch #10\tAverage Generator Loss: 2764.192810\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16850 (step 16850): 1.361651\n",
      "Batch #10\tAverage Generator Loss: 2577.877466\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16851 (step 16851): 1.341254\n",
      "Batch #10\tAverage Generator Loss: 2881.151196\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16852 (step 16852): 1.911278\n",
      "Batch #10\tAverage Generator Loss: 2850.475134\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16853 (step 16853): 1.282799\n",
      "Batch #10\tAverage Generator Loss: 2654.838367\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16854 (step 16854): 1.509151\n",
      "Batch #10\tAverage Generator Loss: 2533.327173\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16855 (step 16855): 1.814429\n",
      "Batch #10\tAverage Generator Loss: 2914.771484\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16856 (step 16856): 1.311144\n",
      "Batch #10\tAverage Generator Loss: 2845.712292\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16857 (step 16857): 1.288368\n",
      "Batch #10\tAverage Generator Loss: 2430.208435\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16858 (step 16858): 1.293365\n",
      "Batch #10\tAverage Generator Loss: 3246.339624\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16859 (step 16859): 1.805310\n",
      "Batch #10\tAverage Generator Loss: 2914.237280\tAverage Discriminator Loss: 0.011161\n",
      "\n",
      "Train time for epoch #16860 (step 16860): 1.344193\n",
      "Batch #10\tAverage Generator Loss: 2830.752173\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16861 (step 16861): 1.397902\n",
      "Batch #10\tAverage Generator Loss: 2839.471021\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16862 (step 16862): 1.852720\n",
      "Batch #10\tAverage Generator Loss: 3072.073730\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16863 (step 16863): 1.284666\n",
      "Batch #10\tAverage Generator Loss: 2863.947766\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16864 (step 16864): 1.247516\n",
      "Batch #10\tAverage Generator Loss: 2732.927209\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16865 (step 16865): 1.297438\n",
      "Batch #10\tAverage Generator Loss: 2677.777917\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16866 (step 16866): 1.852310\n",
      "Batch #10\tAverage Generator Loss: 2502.401563\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16867 (step 16867): 1.495613\n",
      "Batch #10\tAverage Generator Loss: 2521.093030\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16868 (step 16868): 1.318531\n",
      "Batch #10\tAverage Generator Loss: 3140.151306\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16869 (step 16869): 2.026134\n",
      "Batch #10\tAverage Generator Loss: 3361.314624\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16870 (step 16870): 1.382994\n",
      "Batch #10\tAverage Generator Loss: 2795.023572\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16871 (step 16871): 1.257305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2530.471069\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16872 (step 16872): 1.301077\n",
      "Batch #10\tAverage Generator Loss: 3027.706018\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16873 (step 16873): 1.850555\n",
      "Batch #10\tAverage Generator Loss: 2553.301233\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16874 (step 16874): 1.308677\n",
      "Batch #10\tAverage Generator Loss: 2726.984631\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16875 (step 16875): 1.284857\n",
      "Batch #10\tAverage Generator Loss: 2520.402576\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16876 (step 16876): 2.015772\n",
      "Batch #10\tAverage Generator Loss: 2498.754968\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #16877 (step 16877): 1.344611\n",
      "Batch #10\tAverage Generator Loss: 2914.800562\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16878 (step 16878): 1.296887\n",
      "Batch #10\tAverage Generator Loss: 2415.124988\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16879 (step 16879): 1.976475\n",
      "Batch #10\tAverage Generator Loss: 2293.767126\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16880 (step 16880): 1.279410\n",
      "Batch #10\tAverage Generator Loss: 2746.073743\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16881 (step 16881): 1.303110\n",
      "Batch #10\tAverage Generator Loss: 2732.373706\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16882 (step 16882): 1.298726\n",
      "Batch #10\tAverage Generator Loss: 3081.536829\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16883 (step 16883): 1.872520\n",
      "Batch #10\tAverage Generator Loss: 2523.070898\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16884 (step 16884): 1.293739\n",
      "Batch #10\tAverage Generator Loss: 2658.269275\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16885 (step 16885): 1.334772\n",
      "Batch #10\tAverage Generator Loss: 2934.104822\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16886 (step 16886): 1.293504\n",
      "Batch #10\tAverage Generator Loss: 2451.919324\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16887 (step 16887): 1.904475\n",
      "Batch #10\tAverage Generator Loss: 2652.017029\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16888 (step 16888): 1.378891\n",
      "Batch #10\tAverage Generator Loss: 2727.741589\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16889 (step 16889): 1.531147\n",
      "Batch #10\tAverage Generator Loss: 2254.606110\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16890 (step 16890): 1.968754\n",
      "Batch #10\tAverage Generator Loss: 2732.480701\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16891 (step 16891): 1.345940\n",
      "Batch #10\tAverage Generator Loss: 2503.037634\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16892 (step 16892): 1.384468\n",
      "Batch #10\tAverage Generator Loss: 2560.679059\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16893 (step 16893): 1.938009\n",
      "Batch #10\tAverage Generator Loss: 2738.695471\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16894 (step 16894): 1.273545\n",
      "Batch #10\tAverage Generator Loss: 2849.786926\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16895 (step 16895): 1.447918\n",
      "Batch #10\tAverage Generator Loss: 1799.819174\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16896 (step 16896): 1.308109\n",
      "Batch #10\tAverage Generator Loss: 2558.561426\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16897 (step 16897): 1.942904\n",
      "Batch #10\tAverage Generator Loss: 2755.053186\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16898 (step 16898): 1.334327\n",
      "Batch #10\tAverage Generator Loss: 3044.251471\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16899 (step 16899): 1.340508\n",
      "Batch #10\tAverage Generator Loss: 2433.175482\tAverage Discriminator Loss: 0.558061\n",
      "\n",
      "Train time for epoch #16900 (step 16900): 1.811131\n",
      "Batch #10\tAverage Generator Loss: 1979.724487\tAverage Discriminator Loss: 0.019043\n",
      "\n",
      "Train time for epoch #16901 (step 16901): 1.307670\n",
      "Batch #10\tAverage Generator Loss: 2138.524701\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16902 (step 16902): 1.397865\n",
      "Batch #10\tAverage Generator Loss: 1679.676709\tAverage Discriminator Loss: 0.042742\n",
      "\n",
      "Train time for epoch #16903 (step 16903): 1.976229\n",
      "Batch #10\tAverage Generator Loss: 1693.274072\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16904 (step 16904): 1.246524\n",
      "Batch #10\tAverage Generator Loss: 1961.274658\tAverage Discriminator Loss: 0.082809\n",
      "\n",
      "Train time for epoch #16905 (step 16905): 1.333137\n",
      "Batch #10\tAverage Generator Loss: 2429.896143\tAverage Discriminator Loss: 0.009334\n",
      "\n",
      "Train time for epoch #16906 (step 16906): 1.328965\n",
      "Batch #10\tAverage Generator Loss: 2498.894116\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16907 (step 16907): 1.825753\n",
      "Batch #10\tAverage Generator Loss: 2462.434656\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16908 (step 16908): 1.347290\n",
      "Batch #10\tAverage Generator Loss: 2415.229077\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16909 (step 16909): 1.287260\n",
      "Batch #10\tAverage Generator Loss: 2568.754614\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16910 (step 16910): 1.418661\n",
      "Batch #10\tAverage Generator Loss: 2583.447131\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16911 (step 16911): 1.865725\n",
      "Batch #10\tAverage Generator Loss: 2387.140784\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16912 (step 16912): 1.337331\n",
      "Batch #10\tAverage Generator Loss: 2502.276746\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16913 (step 16913): 1.410869\n",
      "Batch #10\tAverage Generator Loss: 2831.265222\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16914 (step 16914): 1.840755\n",
      "Batch #10\tAverage Generator Loss: 2303.738074\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16915 (step 16915): 1.294892\n",
      "Batch #10\tAverage Generator Loss: 2304.886780\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16916 (step 16916): 1.290582\n",
      "Batch #10\tAverage Generator Loss: 2253.444849\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16917 (step 16917): 2.035513\n",
      "Batch #10\tAverage Generator Loss: 2127.702881\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16918 (step 16918): 1.337914\n",
      "Batch #10\tAverage Generator Loss: 2265.360016\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16919 (step 16919): 1.444034\n",
      "Batch #10\tAverage Generator Loss: 2076.878760\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16920 (step 16920): 1.295990\n",
      "Batch #10\tAverage Generator Loss: 2464.017957\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16921 (step 16921): 1.861313\n",
      "Batch #10\tAverage Generator Loss: 2487.954102\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16922 (step 16922): 1.345681\n",
      "Batch #10\tAverage Generator Loss: 2629.710352\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16923 (step 16923): 1.397671\n",
      "Batch #10\tAverage Generator Loss: 2621.710156\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16924 (step 16924): 1.884808\n",
      "Batch #10\tAverage Generator Loss: 2216.544745\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16925 (step 16925): 1.277680\n",
      "Batch #10\tAverage Generator Loss: 2064.336438\tAverage Discriminator Loss: 0.000117\n",
      "\n",
      "Train time for epoch #16926 (step 16926): 1.393062\n",
      "Batch #10\tAverage Generator Loss: 2488.419263\tAverage Discriminator Loss: 0.008344\n",
      "\n",
      "Train time for epoch #16927 (step 16927): 1.338497\n",
      "Batch #10\tAverage Generator Loss: 2709.786487\tAverage Discriminator Loss: 0.029147\n",
      "\n",
      "Train time for epoch #16928 (step 16928): 1.858823\n",
      "Batch #10\tAverage Generator Loss: 3059.821582\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16929 (step 16929): 1.459589\n",
      "Batch #10\tAverage Generator Loss: 3174.831897\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16930 (step 16930): 1.285920\n",
      "Batch #10\tAverage Generator Loss: 3387.484033\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16931 (step 16931): 1.913385\n",
      "Batch #10\tAverage Generator Loss: 2986.152332\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16932 (step 16932): 1.328938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2728.994128\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16933 (step 16933): 1.336136\n",
      "Batch #10\tAverage Generator Loss: 2969.425732\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16934 (step 16934): 1.382791\n",
      "Batch #10\tAverage Generator Loss: 3478.445569\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16935 (step 16935): 1.799501\n",
      "Batch #10\tAverage Generator Loss: 3903.443823\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16936 (step 16936): 1.313842\n",
      "Batch #10\tAverage Generator Loss: 3688.362451\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16937 (step 16937): 1.449171\n",
      "Batch #10\tAverage Generator Loss: 3579.094751\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16938 (step 16938): 1.910783\n",
      "Batch #10\tAverage Generator Loss: 3130.996790\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16939 (step 16939): 1.301791\n",
      "Batch #10\tAverage Generator Loss: 3177.507349\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16940 (step 16940): 1.294945\n",
      "Batch #10\tAverage Generator Loss: 2995.996838\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16941 (step 16941): 1.825263\n",
      "Batch #10\tAverage Generator Loss: 2903.264038\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16942 (step 16942): 1.422075\n",
      "Batch #10\tAverage Generator Loss: 3230.002991\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16943 (step 16943): 1.283092\n",
      "Batch #10\tAverage Generator Loss: 3576.661670\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16944 (step 16944): 1.303839\n",
      "Batch #10\tAverage Generator Loss: 3424.357227\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16945 (step 16945): 1.869194\n",
      "Batch #10\tAverage Generator Loss: 3382.904529\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16946 (step 16946): 1.387246\n",
      "Batch #10\tAverage Generator Loss: 3304.975635\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16947 (step 16947): 1.329456\n",
      "Batch #10\tAverage Generator Loss: 2824.699927\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16948 (step 16948): 1.970439\n",
      "Batch #10\tAverage Generator Loss: 2730.349365\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16949 (step 16949): 1.292847\n",
      "Batch #10\tAverage Generator Loss: 2916.878650\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16950 (step 16950): 1.361216\n",
      "Batch #10\tAverage Generator Loss: 2990.907849\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16951 (step 16951): 1.286510\n",
      "Batch #10\tAverage Generator Loss: 2920.538782\tAverage Discriminator Loss: 0.001035\n",
      "\n",
      "Train time for epoch #16952 (step 16952): 1.926570\n",
      "Batch #10\tAverage Generator Loss: 2817.974377\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16953 (step 16953): 1.237746\n",
      "Batch #10\tAverage Generator Loss: 3039.937292\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16954 (step 16954): 1.287280\n",
      "Batch #10\tAverage Generator Loss: 2897.834814\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16955 (step 16955): 1.858660\n",
      "Batch #10\tAverage Generator Loss: 3307.454089\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16956 (step 16956): 1.337369\n",
      "Batch #10\tAverage Generator Loss: 3070.937305\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16957 (step 16957): 1.372900\n",
      "Batch #10\tAverage Generator Loss: 3286.240869\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16958 (step 16958): 1.307208\n",
      "Batch #10\tAverage Generator Loss: 3074.828821\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16959 (step 16959): 1.982781\n",
      "Batch #10\tAverage Generator Loss: 3169.511145\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16960 (step 16960): 1.292090\n",
      "Batch #10\tAverage Generator Loss: 2860.776355\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16961 (step 16961): 1.301846\n",
      "Batch #10\tAverage Generator Loss: 3432.712952\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16962 (step 16962): 1.972414\n",
      "Batch #10\tAverage Generator Loss: 3354.116919\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16963 (step 16963): 1.360854\n",
      "Batch #10\tAverage Generator Loss: 2719.181824\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16964 (step 16964): 1.279650\n",
      "Batch #10\tAverage Generator Loss: 3015.780981\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16965 (step 16965): 1.400640\n",
      "Batch #10\tAverage Generator Loss: 2944.840344\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16966 (step 16966): 1.918681\n",
      "Batch #10\tAverage Generator Loss: 3325.703271\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16967 (step 16967): 1.388668\n",
      "Batch #10\tAverage Generator Loss: 3055.399731\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16968 (step 16968): 1.501205\n",
      "Batch #10\tAverage Generator Loss: 2727.290796\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16969 (step 16969): 1.861430\n",
      "Batch #10\tAverage Generator Loss: 3308.982617\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16970 (step 16970): 1.451846\n",
      "Batch #10\tAverage Generator Loss: 2773.603223\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16971 (step 16971): 1.338189\n",
      "Batch #10\tAverage Generator Loss: 2443.814990\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16972 (step 16972): 1.396635\n",
      "Batch #10\tAverage Generator Loss: 2876.773462\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16973 (step 16973): 1.921899\n",
      "Batch #10\tAverage Generator Loss: 3049.220569\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16974 (step 16974): 1.287597\n",
      "Batch #10\tAverage Generator Loss: 3055.042871\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16975 (step 16975): 1.433560\n",
      "Batch #10\tAverage Generator Loss: 2870.191455\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16976 (step 16976): 1.860716\n",
      "Batch #10\tAverage Generator Loss: 2886.256836\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16977 (step 16977): 1.392224\n",
      "Batch #10\tAverage Generator Loss: 2696.265234\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16978 (step 16978): 1.391330\n",
      "Batch #10\tAverage Generator Loss: 2980.608325\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16979 (step 16979): 1.330296\n",
      "Batch #10\tAverage Generator Loss: 2690.854810\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16980 (step 16980): 1.848281\n",
      "Batch #10\tAverage Generator Loss: 3025.906616\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16981 (step 16981): 1.288169\n",
      "Batch #10\tAverage Generator Loss: 2803.717242\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16982 (step 16982): 1.434074\n",
      "Batch #10\tAverage Generator Loss: 2975.928528\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16983 (step 16983): 1.803554\n",
      "Batch #10\tAverage Generator Loss: 2724.380591\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16984 (step 16984): 1.277414\n",
      "Batch #10\tAverage Generator Loss: 2605.972180\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16985 (step 16985): 1.376343\n",
      "Batch #10\tAverage Generator Loss: 2771.672986\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16986 (step 16986): 1.341902\n",
      "Batch #10\tAverage Generator Loss: 2400.651013\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16987 (step 16987): 1.873899\n",
      "Batch #10\tAverage Generator Loss: 3353.494336\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #16988 (step 16988): 1.463995\n",
      "Batch #10\tAverage Generator Loss: 3077.350342\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16989 (step 16989): 1.424918\n",
      "Batch #10\tAverage Generator Loss: 3128.617932\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16990 (step 16990): 1.879715\n",
      "Batch #10\tAverage Generator Loss: 3046.680261\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16991 (step 16991): 1.373433\n",
      "Batch #10\tAverage Generator Loss: 3050.662463\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16992 (step 16992): 1.395451\n",
      "Batch #10\tAverage Generator Loss: 3033.145648\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #16993 (step 16993): 1.838644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2808.064087\tAverage Discriminator Loss: 0.006613\n",
      "\n",
      "Train time for epoch #16994 (step 16994): 1.337554\n",
      "Batch #10\tAverage Generator Loss: 2976.473950\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #16995 (step 16995): 1.255762\n",
      "Batch #10\tAverage Generator Loss: 3130.903784\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #16996 (step 16996): 1.321981\n",
      "Batch #10\tAverage Generator Loss: 2824.666248\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #16997 (step 16997): 1.921938\n",
      "Batch #10\tAverage Generator Loss: 2405.117810\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #16998 (step 16998): 1.300409\n",
      "Batch #10\tAverage Generator Loss: 3100.730688\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #16999 (step 16999): 1.279884\n",
      "Batch #10\tAverage Generator Loss: 2893.874109\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #17000 (step 17000): 1.959242\n",
      "Batch #10\tAverage Generator Loss: 2652.570642\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #17001 (step 17001): 1.438950\n",
      "Batch #10\tAverage Generator Loss: 2708.366620\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #17002 (step 17002): 1.391207\n",
      "Batch #10\tAverage Generator Loss: 2738.856995\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #17003 (step 17003): 1.231931\n",
      "Batch #10\tAverage Generator Loss: 2969.073560\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17004 (step 17004): 1.884231\n",
      "Batch #10\tAverage Generator Loss: 3013.519360\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17005 (step 17005): 1.400887\n",
      "Batch #10\tAverage Generator Loss: 2946.621631\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #17006 (step 17006): 1.315491\n",
      "Batch #10\tAverage Generator Loss: 3194.239258\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17007 (step 17007): 1.867879\n",
      "Batch #10\tAverage Generator Loss: 3409.064917\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17008 (step 17008): 1.285949\n",
      "Batch #10\tAverage Generator Loss: 2640.505786\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17009 (step 17009): 1.320272\n",
      "Batch #10\tAverage Generator Loss: 2662.102185\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17010 (step 17010): 1.390513\n",
      "Batch #10\tAverage Generator Loss: 3031.722546\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17011 (step 17011): 1.860135\n",
      "Batch #10\tAverage Generator Loss: 3266.388684\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17012 (step 17012): 1.340227\n",
      "Batch #10\tAverage Generator Loss: 2694.271631\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17013 (step 17013): 1.342229\n",
      "Batch #10\tAverage Generator Loss: 2597.377271\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17014 (step 17014): 1.855653\n",
      "Batch #10\tAverage Generator Loss: 2782.849670\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17015 (step 17015): 1.373676\n",
      "Batch #10\tAverage Generator Loss: 3209.411938\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17016 (step 17016): 1.475436\n",
      "Batch #10\tAverage Generator Loss: 3143.133105\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17017 (step 17017): 1.332685\n",
      "Batch #10\tAverage Generator Loss: 2976.833777\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17018 (step 17018): 1.884196\n",
      "Batch #10\tAverage Generator Loss: 2590.324445\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17019 (step 17019): 1.247265\n",
      "Batch #10\tAverage Generator Loss: 2694.878186\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17020 (step 17020): 1.234106\n",
      "Batch #10\tAverage Generator Loss: 2785.317456\tAverage Discriminator Loss: 0.055941\n",
      "\n",
      "Train time for epoch #17021 (step 17021): 1.875727\n",
      "Batch #10\tAverage Generator Loss: 2863.407471\tAverage Discriminator Loss: 0.000237\n",
      "\n",
      "Train time for epoch #17022 (step 17022): 1.342629\n",
      "Batch #10\tAverage Generator Loss: 2345.881213\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17023 (step 17023): 1.332297\n",
      "Batch #10\tAverage Generator Loss: 3362.197266\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17024 (step 17024): 1.340931\n",
      "Batch #10\tAverage Generator Loss: 2545.868164\tAverage Discriminator Loss: 0.233396\n",
      "\n",
      "Train time for epoch #17025 (step 17025): 1.804255\n",
      "Batch #10\tAverage Generator Loss: 2576.583020\tAverage Discriminator Loss: 0.003926\n",
      "\n",
      "Train time for epoch #17026 (step 17026): 1.371769\n",
      "Batch #10\tAverage Generator Loss: 2390.761804\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17027 (step 17027): 1.342754\n",
      "Batch #10\tAverage Generator Loss: 2346.549878\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17028 (step 17028): 1.868509\n",
      "Batch #10\tAverage Generator Loss: 2436.070911\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17029 (step 17029): 1.339143\n",
      "Batch #10\tAverage Generator Loss: 2065.072498\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17030 (step 17030): 1.456461\n",
      "Batch #10\tAverage Generator Loss: 2471.616687\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17031 (step 17031): 1.286477\n",
      "Batch #10\tAverage Generator Loss: 2443.829303\tAverage Discriminator Loss: 0.016411\n",
      "\n",
      "Train time for epoch #17032 (step 17032): 1.874380\n",
      "Batch #10\tAverage Generator Loss: 1806.270129\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #17033 (step 17033): 1.351350\n",
      "Batch #10\tAverage Generator Loss: 2182.757483\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #17034 (step 17034): 1.393862\n",
      "Batch #10\tAverage Generator Loss: 2739.567725\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #17035 (step 17035): 1.898909\n",
      "Batch #10\tAverage Generator Loss: 2133.198633\tAverage Discriminator Loss: 0.000023\n",
      "\n",
      "Train time for epoch #17036 (step 17036): 1.332039\n",
      "Batch #10\tAverage Generator Loss: 2690.026343\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #17037 (step 17037): 1.472360\n",
      "Batch #10\tAverage Generator Loss: 2383.786737\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #17038 (step 17038): 1.926889\n",
      "Batch #10\tAverage Generator Loss: 2447.952258\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #17039 (step 17039): 1.394475\n",
      "Batch #10\tAverage Generator Loss: 2463.207043\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #17040 (step 17040): 1.312309\n",
      "Batch #10\tAverage Generator Loss: 2240.412512\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #17041 (step 17041): 1.339950\n",
      "Batch #10\tAverage Generator Loss: 1799.741449\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #17042 (step 17042): 1.972325\n",
      "Batch #10\tAverage Generator Loss: 2388.256305\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #17043 (step 17043): 1.294838\n",
      "Batch #10\tAverage Generator Loss: 2314.984387\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #17044 (step 17044): 1.280618\n",
      "Batch #10\tAverage Generator Loss: 2366.307178\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #17045 (step 17045): 1.409399\n",
      "Batch #10\tAverage Generator Loss: 2447.328564\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #17046 (step 17046): 1.956909\n",
      "Batch #10\tAverage Generator Loss: 2675.088574\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #17047 (step 17047): 1.286222\n",
      "Batch #10\tAverage Generator Loss: 2347.554150\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #17048 (step 17048): 1.274321\n",
      "Batch #10\tAverage Generator Loss: 2394.338928\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17049 (step 17049): 1.861391\n",
      "Batch #10\tAverage Generator Loss: 2355.656488\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17050 (step 17050): 1.294257\n",
      "Batch #10\tAverage Generator Loss: 2473.940695\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17051 (step 17051): 1.328094\n",
      "Batch #10\tAverage Generator Loss: 2412.181531\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #17052 (step 17052): 1.293095\n",
      "Batch #10\tAverage Generator Loss: 2215.412585\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #17053 (step 17053): 1.922705\n",
      "Batch #10\tAverage Generator Loss: 2246.456873\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17054 (step 17054): 1.339000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2311.341577\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #17055 (step 17055): 1.375929\n",
      "Batch #10\tAverage Generator Loss: 2000.083362\tAverage Discriminator Loss: 0.295216\n",
      "\n",
      "Train time for epoch #17056 (step 17056): 1.900748\n",
      "Batch #10\tAverage Generator Loss: 2580.980383\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17057 (step 17057): 1.389696\n",
      "Batch #10\tAverage Generator Loss: 2093.398792\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17058 (step 17058): 1.325004\n",
      "Batch #10\tAverage Generator Loss: 2689.793518\tAverage Discriminator Loss: 0.189061\n",
      "\n",
      "Train time for epoch #17059 (step 17059): 1.381860\n",
      "Batch #10\tAverage Generator Loss: 2986.525439\tAverage Discriminator Loss: 1.226323\n",
      "\n",
      "Train time for epoch #17060 (step 17060): 1.910324\n",
      "Batch #10\tAverage Generator Loss: 2680.628748\tAverage Discriminator Loss: 0.021930\n",
      "\n",
      "Train time for epoch #17061 (step 17061): 1.285783\n",
      "Batch #10\tAverage Generator Loss: 3578.824976\tAverage Discriminator Loss: 0.000072\n",
      "\n",
      "Train time for epoch #17062 (step 17062): 1.351104\n",
      "Batch #10\tAverage Generator Loss: 3348.004968\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17063 (step 17063): 1.801461\n",
      "Batch #10\tAverage Generator Loss: 3487.664160\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17064 (step 17064): 1.343120\n",
      "Batch #10\tAverage Generator Loss: 3500.174561\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17065 (step 17065): 1.404241\n",
      "Batch #10\tAverage Generator Loss: 3310.603394\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17066 (step 17066): 1.285265\n",
      "Batch #10\tAverage Generator Loss: 3480.694861\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17067 (step 17067): 1.917327\n",
      "Batch #10\tAverage Generator Loss: 3335.750427\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17068 (step 17068): 1.279550\n",
      "Batch #10\tAverage Generator Loss: 2731.221796\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17069 (step 17069): 1.446599\n",
      "Batch #10\tAverage Generator Loss: 3029.933289\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17070 (step 17070): 1.825982\n",
      "Batch #10\tAverage Generator Loss: 3120.302502\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17071 (step 17071): 1.290262\n",
      "Batch #10\tAverage Generator Loss: 2984.876501\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17072 (step 17072): 1.294234\n",
      "Batch #10\tAverage Generator Loss: 3451.975024\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17073 (step 17073): 1.925524\n",
      "Batch #10\tAverage Generator Loss: 3046.753674\tAverage Discriminator Loss: 0.001397\n",
      "\n",
      "Train time for epoch #17074 (step 17074): 1.293058\n",
      "Batch #10\tAverage Generator Loss: 3533.057056\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17075 (step 17075): 1.291593\n",
      "Batch #10\tAverage Generator Loss: 2960.194336\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17076 (step 17076): 1.306455\n",
      "Batch #10\tAverage Generator Loss: 3150.400574\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17077 (step 17077): 1.852770\n",
      "Batch #10\tAverage Generator Loss: 3301.185486\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17078 (step 17078): 1.395428\n",
      "Batch #10\tAverage Generator Loss: 2988.715491\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17079 (step 17079): 1.362196\n",
      "Batch #10\tAverage Generator Loss: 2856.636792\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17080 (step 17080): 1.865207\n",
      "Batch #10\tAverage Generator Loss: 3349.234424\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17081 (step 17081): 1.384448\n",
      "Batch #10\tAverage Generator Loss: 3246.743555\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17082 (step 17082): 1.289476\n",
      "Batch #10\tAverage Generator Loss: 3284.022339\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17083 (step 17083): 1.304130\n",
      "Batch #10\tAverage Generator Loss: 3118.038708\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17084 (step 17084): 1.857144\n",
      "Batch #10\tAverage Generator Loss: 2637.779510\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17085 (step 17085): 1.239222\n",
      "Batch #10\tAverage Generator Loss: 3372.240662\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17086 (step 17086): 1.292011\n",
      "Batch #10\tAverage Generator Loss: 2993.167224\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17087 (step 17087): 1.977374\n",
      "Batch #10\tAverage Generator Loss: 3044.758228\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17088 (step 17088): 1.308086\n",
      "Batch #10\tAverage Generator Loss: 2875.641333\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17089 (step 17089): 1.278425\n",
      "Batch #10\tAverage Generator Loss: 3240.776538\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17090 (step 17090): 1.240026\n",
      "Batch #10\tAverage Generator Loss: 4107.777319\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17091 (step 17091): 1.862980\n",
      "Batch #10\tAverage Generator Loss: 2763.996826\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17092 (step 17092): 1.458892\n",
      "Batch #10\tAverage Generator Loss: 2962.422473\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17093 (step 17093): 1.303912\n",
      "Batch #10\tAverage Generator Loss: 3414.705200\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17094 (step 17094): 1.862496\n",
      "Batch #10\tAverage Generator Loss: 3291.083936\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17095 (step 17095): 1.353273\n",
      "Batch #10\tAverage Generator Loss: 2658.961353\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17096 (step 17096): 1.398755\n",
      "Batch #10\tAverage Generator Loss: 3272.351892\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17097 (step 17097): 1.281150\n",
      "Batch #10\tAverage Generator Loss: 3527.878857\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17098 (step 17098): 1.863369\n",
      "Batch #10\tAverage Generator Loss: 2930.704834\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17099 (step 17099): 1.283676\n",
      "Batch #10\tAverage Generator Loss: 2736.908679\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17100 (step 17100): 1.314934\n",
      "Batch #10\tAverage Generator Loss: 2945.226575\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17101 (step 17101): 1.852712\n",
      "Batch #10\tAverage Generator Loss: 3068.016858\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17102 (step 17102): 1.405272\n",
      "Batch #10\tAverage Generator Loss: 3121.478394\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17103 (step 17103): 1.273924\n",
      "Batch #10\tAverage Generator Loss: 3359.930005\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17104 (step 17104): 1.273075\n",
      "Batch #10\tAverage Generator Loss: 2933.168774\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17105 (step 17105): 1.865569\n",
      "Batch #10\tAverage Generator Loss: 3413.732812\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17106 (step 17106): 1.337020\n",
      "Batch #10\tAverage Generator Loss: 3134.496143\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17107 (step 17107): 1.236063\n",
      "Batch #10\tAverage Generator Loss: 3000.558472\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17108 (step 17108): 1.855932\n",
      "Batch #10\tAverage Generator Loss: 3677.955847\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17109 (step 17109): 1.333639\n",
      "Batch #10\tAverage Generator Loss: 3029.480078\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17110 (step 17110): 1.411198\n",
      "Batch #10\tAverage Generator Loss: 2970.271613\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17111 (step 17111): 1.298526\n",
      "Batch #10\tAverage Generator Loss: 3142.659119\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17112 (step 17112): 1.902933\n",
      "Batch #10\tAverage Generator Loss: 3521.053711\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17113 (step 17113): 1.295424\n",
      "Batch #10\tAverage Generator Loss: 3438.302295\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17114 (step 17114): 1.454755\n",
      "Batch #10\tAverage Generator Loss: 3210.072803\tAverage Discriminator Loss: 0.008094\n",
      "\n",
      "Train time for epoch #17115 (step 17115): 1.865024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 3243.055579\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17116 (step 17116): 1.349825\n",
      "Batch #10\tAverage Generator Loss: 3155.988013\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17117 (step 17117): 1.287612\n",
      "Batch #10\tAverage Generator Loss: 3079.554456\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17118 (step 17118): 1.344071\n",
      "Batch #10\tAverage Generator Loss: 3383.113892\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17119 (step 17119): 1.854777\n",
      "Batch #10\tAverage Generator Loss: 3502.550952\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17120 (step 17120): 1.526417\n",
      "Batch #10\tAverage Generator Loss: 3009.680188\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17121 (step 17121): 1.403584\n",
      "Batch #10\tAverage Generator Loss: 3152.632324\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17122 (step 17122): 1.917461\n",
      "Batch #10\tAverage Generator Loss: 3194.607031\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17123 (step 17123): 1.407561\n",
      "Batch #10\tAverage Generator Loss: 3273.244922\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17124 (step 17124): 1.303168\n",
      "Batch #10\tAverage Generator Loss: 2947.856177\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17125 (step 17125): 2.150137\n",
      "Batch #10\tAverage Generator Loss: 3447.669531\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17126 (step 17126): 1.437717\n",
      "Batch #10\tAverage Generator Loss: 3561.439844\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17127 (step 17127): 1.342161\n",
      "Batch #10\tAverage Generator Loss: 3010.989325\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17128 (step 17128): 1.413290\n",
      "Batch #10\tAverage Generator Loss: 3063.813623\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17129 (step 17129): 1.873579\n",
      "Batch #10\tAverage Generator Loss: 2999.009338\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17130 (step 17130): 1.350659\n",
      "Batch #10\tAverage Generator Loss: 3435.177014\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17131 (step 17131): 1.283836\n",
      "Batch #10\tAverage Generator Loss: 3245.959790\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17132 (step 17132): 1.943987\n",
      "Batch #10\tAverage Generator Loss: 3397.297949\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17133 (step 17133): 1.338397\n",
      "Batch #10\tAverage Generator Loss: 3572.800916\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17134 (step 17134): 1.328185\n",
      "Batch #10\tAverage Generator Loss: 3043.897156\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17135 (step 17135): 1.252658\n",
      "Batch #10\tAverage Generator Loss: 2929.828314\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17136 (step 17136): 1.832087\n",
      "Batch #10\tAverage Generator Loss: 3020.254529\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17137 (step 17137): 1.389553\n",
      "Batch #10\tAverage Generator Loss: 3040.879065\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17138 (step 17138): 1.392562\n",
      "Batch #10\tAverage Generator Loss: 3063.544702\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17139 (step 17139): 1.944080\n",
      "Batch #10\tAverage Generator Loss: 3367.485461\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17140 (step 17140): 1.286063\n",
      "Batch #10\tAverage Generator Loss: 3097.290930\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17141 (step 17141): 1.292024\n",
      "Batch #10\tAverage Generator Loss: 3173.812744\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17142 (step 17142): 1.285223\n",
      "Batch #10\tAverage Generator Loss: 3493.427734\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17143 (step 17143): 1.920792\n",
      "Batch #10\tAverage Generator Loss: 3162.504211\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17144 (step 17144): 1.372347\n",
      "Batch #10\tAverage Generator Loss: 3220.323047\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17145 (step 17145): 1.346026\n",
      "Batch #10\tAverage Generator Loss: 3262.817035\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17146 (step 17146): 1.880508\n",
      "Batch #10\tAverage Generator Loss: 3529.181311\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17147 (step 17147): 1.368348\n",
      "Batch #10\tAverage Generator Loss: 3309.905139\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17148 (step 17148): 1.344144\n",
      "Batch #10\tAverage Generator Loss: 3192.985291\tAverage Discriminator Loss: 0.611719\n",
      "\n",
      "Train time for epoch #17149 (step 17149): 1.340088\n",
      "Batch #10\tAverage Generator Loss: 3174.144873\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17150 (step 17150): 1.925781\n",
      "Batch #10\tAverage Generator Loss: 3008.293469\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17151 (step 17151): 1.303284\n",
      "Batch #10\tAverage Generator Loss: 3354.743909\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17152 (step 17152): 1.237693\n",
      "Batch #10\tAverage Generator Loss: 3406.250867\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17153 (step 17153): 1.290262\n",
      "Batch #10\tAverage Generator Loss: 2930.515259\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17154 (step 17154): 1.929246\n",
      "Batch #10\tAverage Generator Loss: 3258.666040\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17155 (step 17155): 1.290827\n",
      "Batch #10\tAverage Generator Loss: 2844.725067\tAverage Discriminator Loss: 0.005028\n",
      "\n",
      "Train time for epoch #17156 (step 17156): 1.402108\n",
      "Batch #10\tAverage Generator Loss: 3309.573975\tAverage Discriminator Loss: 0.009933\n",
      "\n",
      "Train time for epoch #17157 (step 17157): 1.876441\n",
      "Batch #10\tAverage Generator Loss: 2636.693225\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17158 (step 17158): 1.295676\n",
      "Batch #10\tAverage Generator Loss: 2991.631079\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17159 (step 17159): 1.351200\n",
      "Batch #10\tAverage Generator Loss: 2753.941162\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17160 (step 17160): 1.344310\n",
      "Batch #10\tAverage Generator Loss: 3161.709790\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17161 (step 17161): 1.876574\n",
      "Batch #10\tAverage Generator Loss: 2929.348108\tAverage Discriminator Loss: 0.016989\n",
      "\n",
      "Train time for epoch #17162 (step 17162): 1.276546\n",
      "Batch #10\tAverage Generator Loss: 3087.891199\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17163 (step 17163): 1.386679\n",
      "Batch #10\tAverage Generator Loss: 3274.602563\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17164 (step 17164): 1.989061\n",
      "Batch #10\tAverage Generator Loss: 3155.234167\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17165 (step 17165): 1.291434\n",
      "Batch #10\tAverage Generator Loss: 3279.777783\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17166 (step 17166): 1.343866\n",
      "Batch #10\tAverage Generator Loss: 3142.960303\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17167 (step 17167): 1.881361\n",
      "Batch #10\tAverage Generator Loss: 2739.883508\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17168 (step 17168): 1.362313\n",
      "Batch #10\tAverage Generator Loss: 2684.947742\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17169 (step 17169): 1.296381\n",
      "Batch #10\tAverage Generator Loss: 2838.930884\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17170 (step 17170): 1.402745\n",
      "Batch #10\tAverage Generator Loss: 3018.623047\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17171 (step 17171): 1.980233\n",
      "Batch #10\tAverage Generator Loss: 2643.156653\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17172 (step 17172): 1.309527\n",
      "Batch #10\tAverage Generator Loss: 2735.419397\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17173 (step 17173): 1.250739\n",
      "Batch #10\tAverage Generator Loss: 2570.485266\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17174 (step 17174): 1.927426\n",
      "Batch #10\tAverage Generator Loss: 3128.040845\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17175 (step 17175): 1.446513\n",
      "Batch #10\tAverage Generator Loss: 2638.124963\tAverage Discriminator Loss: 0.038130\n",
      "\n",
      "Train time for epoch #17176 (step 17176): 1.307967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 3134.584229\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17177 (step 17177): 1.245511\n",
      "Batch #10\tAverage Generator Loss: 2988.304309\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17178 (step 17178): 1.820527\n",
      "Batch #10\tAverage Generator Loss: 2899.959167\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17179 (step 17179): 1.578489\n",
      "Batch #10\tAverage Generator Loss: 2924.608899\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17180 (step 17180): 1.285954\n",
      "Batch #10\tAverage Generator Loss: 2160.415344\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17181 (step 17181): 1.946269\n",
      "Batch #10\tAverage Generator Loss: 2938.443311\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17182 (step 17182): 1.268516\n",
      "Batch #10\tAverage Generator Loss: 2679.729041\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17183 (step 17183): 1.393727\n",
      "Batch #10\tAverage Generator Loss: 2707.191486\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17184 (step 17184): 1.373226\n",
      "Batch #10\tAverage Generator Loss: 3025.400244\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17185 (step 17185): 1.892342\n",
      "Batch #10\tAverage Generator Loss: 2905.544873\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17186 (step 17186): 1.308674\n",
      "Batch #10\tAverage Generator Loss: 2891.934033\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17187 (step 17187): 1.346269\n",
      "Batch #10\tAverage Generator Loss: 2741.709900\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17188 (step 17188): 1.328798\n",
      "Batch #10\tAverage Generator Loss: 2282.349518\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17189 (step 17189): 1.885893\n",
      "Batch #10\tAverage Generator Loss: 2947.665881\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17190 (step 17190): 1.346605\n",
      "Batch #10\tAverage Generator Loss: 2674.552246\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17191 (step 17191): 1.319117\n",
      "Batch #10\tAverage Generator Loss: 3035.337244\tAverage Discriminator Loss: 0.007065\n",
      "\n",
      "Train time for epoch #17192 (step 17192): 1.801634\n",
      "Batch #10\tAverage Generator Loss: 2380.224847\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17193 (step 17193): 1.390167\n",
      "Batch #10\tAverage Generator Loss: 2567.844299\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17194 (step 17194): 1.329615\n",
      "Batch #10\tAverage Generator Loss: 2665.255542\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17195 (step 17195): 1.393471\n",
      "Batch #10\tAverage Generator Loss: 2700.658875\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17196 (step 17196): 1.930511\n",
      "Batch #10\tAverage Generator Loss: 2565.794171\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17197 (step 17197): 1.337984\n",
      "Batch #10\tAverage Generator Loss: 2381.136792\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17198 (step 17198): 1.390655\n",
      "Batch #10\tAverage Generator Loss: 2402.237042\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17199 (step 17199): 1.836541\n",
      "Batch #10\tAverage Generator Loss: 2486.583789\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17200 (step 17200): 1.385969\n",
      "Batch #10\tAverage Generator Loss: 2433.777173\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17201 (step 17201): 1.291946\n",
      "Batch #10\tAverage Generator Loss: 2620.846936\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17202 (step 17202): 1.883061\n",
      "Batch #10\tAverage Generator Loss: 2671.541602\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17203 (step 17203): 1.516045\n",
      "Batch #10\tAverage Generator Loss: 2965.738794\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17204 (step 17204): 1.333580\n",
      "Batch #10\tAverage Generator Loss: 2699.890479\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17205 (step 17205): 1.325802\n",
      "Batch #10\tAverage Generator Loss: 2833.318970\tAverage Discriminator Loss: 0.006291\n",
      "\n",
      "Train time for epoch #17206 (step 17206): 1.975523\n",
      "Batch #10\tAverage Generator Loss: 2531.388147\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17207 (step 17207): 1.296419\n",
      "Batch #10\tAverage Generator Loss: 2722.396631\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17208 (step 17208): 1.395570\n",
      "Batch #10\tAverage Generator Loss: 2761.611621\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17209 (step 17209): 1.840844\n",
      "Batch #10\tAverage Generator Loss: 2724.766248\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17210 (step 17210): 1.289927\n",
      "Batch #10\tAverage Generator Loss: 2635.486707\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17211 (step 17211): 1.342627\n",
      "Batch #10\tAverage Generator Loss: 2411.283130\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17212 (step 17212): 1.255139\n",
      "Batch #10\tAverage Generator Loss: 2385.256000\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17213 (step 17213): 1.882724\n",
      "Batch #10\tAverage Generator Loss: 2688.086572\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17214 (step 17214): 1.382881\n",
      "Batch #10\tAverage Generator Loss: 2483.075220\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17215 (step 17215): 1.326731\n",
      "Batch #10\tAverage Generator Loss: 2549.578284\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17216 (step 17216): 1.837480\n",
      "Batch #10\tAverage Generator Loss: 2568.608337\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17217 (step 17217): 1.271100\n",
      "Batch #10\tAverage Generator Loss: 2775.398242\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17218 (step 17218): 1.403372\n",
      "Batch #10\tAverage Generator Loss: 2722.910937\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17219 (step 17219): 1.342124\n",
      "Batch #10\tAverage Generator Loss: 2914.015527\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17220 (step 17220): 1.974725\n",
      "Batch #10\tAverage Generator Loss: 2457.777283\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #17221 (step 17221): 1.381101\n",
      "Batch #10\tAverage Generator Loss: 2604.953601\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17222 (step 17222): 1.275104\n",
      "Batch #10\tAverage Generator Loss: 2356.116910\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17223 (step 17223): 1.946100\n",
      "Batch #10\tAverage Generator Loss: 2427.503345\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17224 (step 17224): 1.350024\n",
      "Batch #10\tAverage Generator Loss: 2449.693677\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17225 (step 17225): 1.370599\n",
      "Batch #10\tAverage Generator Loss: 2691.013318\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17226 (step 17226): 1.332144\n",
      "Batch #10\tAverage Generator Loss: 2952.009595\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17227 (step 17227): 1.941303\n",
      "Batch #10\tAverage Generator Loss: 2528.647424\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17228 (step 17228): 1.427415\n",
      "Batch #10\tAverage Generator Loss: 2670.038733\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17229 (step 17229): 1.349566\n",
      "Batch #10\tAverage Generator Loss: 2885.197583\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17230 (step 17230): 1.917652\n",
      "Batch #10\tAverage Generator Loss: 2182.783447\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17231 (step 17231): 1.311944\n",
      "Batch #10\tAverage Generator Loss: 2779.780981\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17232 (step 17232): 1.427968\n",
      "Batch #10\tAverage Generator Loss: 2871.817712\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17233 (step 17233): 1.969667\n",
      "Batch #10\tAverage Generator Loss: 2628.414893\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17234 (step 17234): 1.513285\n",
      "Batch #10\tAverage Generator Loss: 2325.006506\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17235 (step 17235): 1.346397\n",
      "Batch #10\tAverage Generator Loss: 2596.021277\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17236 (step 17236): 1.432182\n",
      "Batch #10\tAverage Generator Loss: 2533.846594\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17237 (step 17237): 2.025676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2433.624945\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17238 (step 17238): 1.430895\n",
      "Batch #10\tAverage Generator Loss: 2783.966357\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17239 (step 17239): 1.284829\n",
      "Batch #10\tAverage Generator Loss: 2818.001245\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17240 (step 17240): 1.940876\n",
      "Batch #10\tAverage Generator Loss: 2834.531201\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17241 (step 17241): 1.416526\n",
      "Batch #10\tAverage Generator Loss: 2925.757922\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17242 (step 17242): 1.410327\n",
      "Batch #10\tAverage Generator Loss: 2490.225842\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17243 (step 17243): 1.289396\n",
      "Batch #10\tAverage Generator Loss: 2455.000964\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17244 (step 17244): 1.936961\n",
      "Batch #10\tAverage Generator Loss: 2542.252075\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17245 (step 17245): 1.345898\n",
      "Batch #10\tAverage Generator Loss: 2497.818127\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17246 (step 17246): 1.300669\n",
      "Batch #10\tAverage Generator Loss: 2778.822729\tAverage Discriminator Loss: 0.000023\n",
      "\n",
      "Train time for epoch #17247 (step 17247): 1.978145\n",
      "Batch #10\tAverage Generator Loss: 2671.209302\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17248 (step 17248): 1.360054\n",
      "Batch #10\tAverage Generator Loss: 2471.253418\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17249 (step 17249): 1.338396\n",
      "Batch #10\tAverage Generator Loss: 2918.115894\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17250 (step 17250): 1.347873\n",
      "Batch #10\tAverage Generator Loss: 2761.554114\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17251 (step 17251): 1.842563\n",
      "Batch #10\tAverage Generator Loss: 2793.781128\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17252 (step 17252): 1.382003\n",
      "Batch #10\tAverage Generator Loss: 2660.269861\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17253 (step 17253): 1.301209\n",
      "Batch #10\tAverage Generator Loss: 2558.559570\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17254 (step 17254): 1.978315\n",
      "Batch #10\tAverage Generator Loss: 2315.494055\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17255 (step 17255): 1.339259\n",
      "Batch #10\tAverage Generator Loss: 2672.889014\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17256 (step 17256): 1.412259\n",
      "Batch #10\tAverage Generator Loss: 3008.038428\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17257 (step 17257): 1.289791\n",
      "Batch #10\tAverage Generator Loss: 2800.910974\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17258 (step 17258): 1.875411\n",
      "Batch #10\tAverage Generator Loss: 2819.680872\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17259 (step 17259): 1.283768\n",
      "Batch #10\tAverage Generator Loss: 2590.523236\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17260 (step 17260): 1.349792\n",
      "Batch #10\tAverage Generator Loss: 2211.917114\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17261 (step 17261): 1.924264\n",
      "Batch #10\tAverage Generator Loss: 2662.604871\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17262 (step 17262): 1.339331\n",
      "Batch #10\tAverage Generator Loss: 2932.007422\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17263 (step 17263): 1.306257\n",
      "Batch #10\tAverage Generator Loss: 2590.613794\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17264 (step 17264): 1.352580\n",
      "Batch #10\tAverage Generator Loss: 2618.923486\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17265 (step 17265): 1.954458\n",
      "Batch #10\tAverage Generator Loss: 2587.693225\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17266 (step 17266): 1.282667\n",
      "Batch #10\tAverage Generator Loss: 2870.622827\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17267 (step 17267): 1.406081\n",
      "Batch #10\tAverage Generator Loss: 2687.493579\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17268 (step 17268): 1.999183\n",
      "Batch #10\tAverage Generator Loss: 2431.656903\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17269 (step 17269): 1.371562\n",
      "Batch #10\tAverage Generator Loss: 2431.871533\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17270 (step 17270): 1.360680\n",
      "Batch #10\tAverage Generator Loss: 2485.110693\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17271 (step 17271): 1.339944\n",
      "Batch #10\tAverage Generator Loss: 2378.028491\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17272 (step 17272): 1.995748\n",
      "Batch #10\tAverage Generator Loss: 2583.035205\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17273 (step 17273): 1.336241\n",
      "Batch #10\tAverage Generator Loss: 2530.573267\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17274 (step 17274): 1.315783\n",
      "Batch #10\tAverage Generator Loss: 2844.200330\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17275 (step 17275): 1.288097\n",
      "Batch #10\tAverage Generator Loss: 2835.181201\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17276 (step 17276): 1.983699\n",
      "Batch #10\tAverage Generator Loss: 2694.087897\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17277 (step 17277): 1.463913\n",
      "Batch #10\tAverage Generator Loss: 2349.342590\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17278 (step 17278): 1.388066\n",
      "Batch #10\tAverage Generator Loss: 2470.948865\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17279 (step 17279): 1.964318\n",
      "Batch #10\tAverage Generator Loss: 2479.187677\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17280 (step 17280): 1.338258\n",
      "Batch #10\tAverage Generator Loss: 2632.434192\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17281 (step 17281): 1.490190\n",
      "Batch #10\tAverage Generator Loss: 2785.691528\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17282 (step 17282): 1.954495\n",
      "Batch #10\tAverage Generator Loss: 2550.232251\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17283 (step 17283): 1.406066\n",
      "Batch #10\tAverage Generator Loss: 2373.519739\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17284 (step 17284): 1.343485\n",
      "Batch #10\tAverage Generator Loss: 2967.051965\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17285 (step 17285): 1.298954\n",
      "Batch #10\tAverage Generator Loss: 2766.327283\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17286 (step 17286): 1.873190\n",
      "Batch #10\tAverage Generator Loss: 2421.287555\tAverage Discriminator Loss: 0.000057\n",
      "\n",
      "Train time for epoch #17287 (step 17287): 1.386744\n",
      "Batch #10\tAverage Generator Loss: 2525.665198\tAverage Discriminator Loss: 0.000030\n",
      "\n",
      "Train time for epoch #17288 (step 17288): 1.340474\n",
      "Batch #10\tAverage Generator Loss: 2737.101172\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #17289 (step 17289): 1.982816\n",
      "Batch #10\tAverage Generator Loss: 2319.712891\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17290 (step 17290): 1.328656\n",
      "Batch #10\tAverage Generator Loss: 2612.180750\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #17291 (step 17291): 1.338209\n",
      "Batch #10\tAverage Generator Loss: 2369.638599\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17292 (step 17292): 1.347529\n",
      "Batch #10\tAverage Generator Loss: 2070.198688\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17293 (step 17293): 1.897920\n",
      "Batch #10\tAverage Generator Loss: 2667.612073\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17294 (step 17294): 1.345826\n",
      "Batch #10\tAverage Generator Loss: 2794.041016\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17295 (step 17295): 1.294401\n",
      "Batch #10\tAverage Generator Loss: 2856.522180\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17296 (step 17296): 1.893836\n",
      "Batch #10\tAverage Generator Loss: 2288.031067\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17297 (step 17297): 1.386994\n",
      "Batch #10\tAverage Generator Loss: 2518.861938\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17298 (step 17298): 1.293553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2422.276831\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17299 (step 17299): 1.346298\n",
      "Batch #10\tAverage Generator Loss: 2439.767957\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17300 (step 17300): 1.800364\n",
      "Batch #10\tAverage Generator Loss: 2694.042151\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17301 (step 17301): 1.273134\n",
      "Batch #10\tAverage Generator Loss: 2884.266675\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17302 (step 17302): 1.281792\n",
      "Batch #10\tAverage Generator Loss: 2832.441455\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17303 (step 17303): 1.832778\n",
      "Batch #10\tAverage Generator Loss: 2205.630554\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17304 (step 17304): 1.359465\n",
      "Batch #10\tAverage Generator Loss: 2289.430548\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17305 (step 17305): 1.346393\n",
      "Batch #10\tAverage Generator Loss: 2251.594495\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17306 (step 17306): 1.385298\n",
      "Batch #10\tAverage Generator Loss: 2293.675317\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17307 (step 17307): 1.998843\n",
      "Batch #10\tAverage Generator Loss: 2455.636084\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17308 (step 17308): 1.338526\n",
      "Batch #10\tAverage Generator Loss: 2741.719092\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17309 (step 17309): 1.465117\n",
      "Batch #10\tAverage Generator Loss: 2475.177173\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17310 (step 17310): 1.952107\n",
      "Batch #10\tAverage Generator Loss: 2862.264038\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17311 (step 17311): 1.290494\n",
      "Batch #10\tAverage Generator Loss: 2842.213196\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17312 (step 17312): 1.290164\n",
      "Batch #10\tAverage Generator Loss: 2530.790344\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17313 (step 17313): 1.343225\n",
      "Batch #10\tAverage Generator Loss: 2759.369727\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17314 (step 17314): 1.832494\n",
      "Batch #10\tAverage Generator Loss: 2493.212024\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17315 (step 17315): 1.303169\n",
      "Batch #10\tAverage Generator Loss: 2888.376868\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17316 (step 17316): 1.548934\n",
      "Batch #10\tAverage Generator Loss: 2007.831830\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17317 (step 17317): 1.940288\n",
      "Batch #10\tAverage Generator Loss: 2983.458228\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17318 (step 17318): 1.287810\n",
      "Batch #10\tAverage Generator Loss: 2844.845422\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17319 (step 17319): 1.360349\n",
      "Batch #10\tAverage Generator Loss: 2441.717554\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17320 (step 17320): 1.284983\n",
      "Batch #10\tAverage Generator Loss: 2602.611890\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17321 (step 17321): 1.930687\n",
      "Batch #10\tAverage Generator Loss: 2830.071851\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17322 (step 17322): 1.296250\n",
      "Batch #10\tAverage Generator Loss: 2812.380286\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17323 (step 17323): 1.340794\n",
      "Batch #10\tAverage Generator Loss: 2627.304248\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17324 (step 17324): 1.979751\n",
      "Batch #10\tAverage Generator Loss: 2866.453870\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17325 (step 17325): 1.342571\n",
      "Batch #10\tAverage Generator Loss: 2713.322925\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17326 (step 17326): 1.334594\n",
      "Batch #10\tAverage Generator Loss: 2445.584558\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17327 (step 17327): 1.304030\n",
      "Batch #10\tAverage Generator Loss: 2149.248877\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17328 (step 17328): 1.903008\n",
      "Batch #10\tAverage Generator Loss: 2701.991431\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17329 (step 17329): 1.399584\n",
      "Batch #10\tAverage Generator Loss: 2785.501404\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17330 (step 17330): 1.292624\n",
      "Batch #10\tAverage Generator Loss: 2730.606128\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17331 (step 17331): 1.881369\n",
      "Batch #10\tAverage Generator Loss: 2713.387134\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17332 (step 17332): 1.275127\n",
      "Batch #10\tAverage Generator Loss: 2265.871289\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17333 (step 17333): 1.295455\n",
      "Batch #10\tAverage Generator Loss: 2866.839368\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17334 (step 17334): 1.296052\n",
      "Batch #10\tAverage Generator Loss: 2623.975745\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17335 (step 17335): 1.924659\n",
      "Batch #10\tAverage Generator Loss: 2618.606055\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17336 (step 17336): 1.440434\n",
      "Batch #10\tAverage Generator Loss: 2555.489893\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17337 (step 17337): 1.393611\n",
      "Batch #10\tAverage Generator Loss: 2644.427344\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17338 (step 17338): 1.847847\n",
      "Batch #10\tAverage Generator Loss: 2246.176562\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17339 (step 17339): 1.355690\n",
      "Batch #10\tAverage Generator Loss: 2919.166809\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17340 (step 17340): 1.404592\n",
      "Batch #10\tAverage Generator Loss: 2804.497192\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17341 (step 17341): 1.301687\n",
      "Batch #10\tAverage Generator Loss: 2786.459131\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17342 (step 17342): 1.936526\n",
      "Batch #10\tAverage Generator Loss: 2681.745874\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17343 (step 17343): 1.293010\n",
      "Batch #10\tAverage Generator Loss: 2252.722491\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17344 (step 17344): 1.335444\n",
      "Batch #10\tAverage Generator Loss: 2726.670935\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17345 (step 17345): 1.780931\n",
      "Batch #10\tAverage Generator Loss: 2545.397253\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17346 (step 17346): 1.299985\n",
      "Batch #10\tAverage Generator Loss: 2651.583325\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17347 (step 17347): 1.341556\n",
      "Batch #10\tAverage Generator Loss: 2619.691980\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17348 (step 17348): 1.379346\n",
      "Batch #10\tAverage Generator Loss: 2763.223865\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17349 (step 17349): 1.877048\n",
      "Batch #10\tAverage Generator Loss: 2718.544604\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17350 (step 17350): 1.306631\n",
      "Batch #10\tAverage Generator Loss: 2315.622803\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17351 (step 17351): 1.365932\n",
      "Batch #10\tAverage Generator Loss: 2912.882678\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17352 (step 17352): 1.915274\n",
      "Batch #10\tAverage Generator Loss: 2224.305676\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17353 (step 17353): 1.334237\n",
      "Batch #10\tAverage Generator Loss: 2865.538159\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17354 (step 17354): 1.292368\n",
      "Batch #10\tAverage Generator Loss: 2344.937976\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17355 (step 17355): 1.360817\n",
      "Batch #10\tAverage Generator Loss: 2631.167822\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17356 (step 17356): 1.855843\n",
      "Batch #10\tAverage Generator Loss: 2332.296545\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17357 (step 17357): 1.344511\n",
      "Batch #10\tAverage Generator Loss: 2714.370227\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17358 (step 17358): 1.357017\n",
      "Batch #10\tAverage Generator Loss: 2480.786646\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17359 (step 17359): 1.945190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2764.263977\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17360 (step 17360): 1.506296\n",
      "Batch #10\tAverage Generator Loss: 2948.957617\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17361 (step 17361): 1.301800\n",
      "Batch #10\tAverage Generator Loss: 2700.235706\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17362 (step 17362): 1.346953\n",
      "Batch #10\tAverage Generator Loss: 2459.081409\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17363 (step 17363): 1.977165\n",
      "Batch #10\tAverage Generator Loss: 2854.294458\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17364 (step 17364): 1.265926\n",
      "Batch #10\tAverage Generator Loss: 2834.719580\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17365 (step 17365): 1.403091\n",
      "Batch #10\tAverage Generator Loss: 2503.909338\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17366 (step 17366): 1.988268\n",
      "Batch #10\tAverage Generator Loss: 2261.904211\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17367 (step 17367): 1.307559\n",
      "Batch #10\tAverage Generator Loss: 2583.144226\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17368 (step 17368): 1.280245\n",
      "Batch #10\tAverage Generator Loss: 2584.831274\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17369 (step 17369): 1.379166\n",
      "Batch #10\tAverage Generator Loss: 2666.833215\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17370 (step 17370): 1.888485\n",
      "Batch #10\tAverage Generator Loss: 2583.753845\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17371 (step 17371): 1.291382\n",
      "Batch #10\tAverage Generator Loss: 2771.251062\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17372 (step 17372): 1.347619\n",
      "Batch #10\tAverage Generator Loss: 2975.896509\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17373 (step 17373): 1.308183\n",
      "Batch #10\tAverage Generator Loss: 2931.177246\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17374 (step 17374): 2.005420\n",
      "Batch #10\tAverage Generator Loss: 2500.232397\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17375 (step 17375): 1.502624\n",
      "Batch #10\tAverage Generator Loss: 2851.580090\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17376 (step 17376): 1.308006\n",
      "Batch #10\tAverage Generator Loss: 2643.190161\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17377 (step 17377): 1.964721\n",
      "Batch #10\tAverage Generator Loss: 2748.856836\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17378 (step 17378): 1.276882\n",
      "Batch #10\tAverage Generator Loss: 2539.456018\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17379 (step 17379): 1.500317\n",
      "Batch #10\tAverage Generator Loss: 3066.726306\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17380 (step 17380): 1.329349\n",
      "Batch #10\tAverage Generator Loss: 2848.170483\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17381 (step 17381): 1.913238\n",
      "Batch #10\tAverage Generator Loss: 2672.975580\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17382 (step 17382): 1.392551\n",
      "Batch #10\tAverage Generator Loss: 2605.832532\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17383 (step 17383): 1.334420\n",
      "Batch #10\tAverage Generator Loss: 2594.363330\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17384 (step 17384): 1.878183\n",
      "Batch #10\tAverage Generator Loss: 2706.196484\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17385 (step 17385): 1.349961\n",
      "Batch #10\tAverage Generator Loss: 2588.873718\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17386 (step 17386): 1.366074\n",
      "Batch #10\tAverage Generator Loss: 2532.898389\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17387 (step 17387): 1.884550\n",
      "Batch #10\tAverage Generator Loss: 2749.947803\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17388 (step 17388): 1.349089\n",
      "Batch #10\tAverage Generator Loss: 2542.042615\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17389 (step 17389): 1.381989\n",
      "Batch #10\tAverage Generator Loss: 2667.925293\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17390 (step 17390): 1.294048\n",
      "Batch #10\tAverage Generator Loss: 2376.342444\tAverage Discriminator Loss: 0.121526\n",
      "\n",
      "Train time for epoch #17391 (step 17391): 2.015414\n",
      "Batch #10\tAverage Generator Loss: 2260.971875\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17392 (step 17392): 1.313776\n",
      "Batch #10\tAverage Generator Loss: 2528.420691\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17393 (step 17393): 1.287809\n",
      "Batch #10\tAverage Generator Loss: 2421.802539\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17394 (step 17394): 1.289163\n",
      "Batch #10\tAverage Generator Loss: 2165.423291\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17395 (step 17395): 1.887376\n",
      "Batch #10\tAverage Generator Loss: 2126.781824\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17396 (step 17396): 1.248038\n",
      "Batch #10\tAverage Generator Loss: 2023.917938\tAverage Discriminator Loss: 0.079246\n",
      "\n",
      "Train time for epoch #17397 (step 17397): 1.353688\n",
      "Batch #10\tAverage Generator Loss: 1782.508673\tAverage Discriminator Loss: 0.061785\n",
      "\n",
      "Train time for epoch #17398 (step 17398): 2.032983\n",
      "Batch #10\tAverage Generator Loss: 1621.773227\tAverage Discriminator Loss: 0.000120\n",
      "\n",
      "Train time for epoch #17399 (step 17399): 1.254463\n",
      "Batch #10\tAverage Generator Loss: 1801.611414\tAverage Discriminator Loss: 0.000931\n",
      "\n",
      "Train time for epoch #17400 (step 17400): 1.353849\n",
      "Batch #10\tAverage Generator Loss: 1752.250861\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17401 (step 17401): 1.341432\n",
      "Batch #10\tAverage Generator Loss: 1770.787708\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17402 (step 17402): 1.946049\n",
      "Batch #10\tAverage Generator Loss: 1699.536316\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17403 (step 17403): 1.354099\n",
      "Batch #10\tAverage Generator Loss: 2032.565869\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17404 (step 17404): 1.272689\n",
      "Batch #10\tAverage Generator Loss: 1791.990363\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17405 (step 17405): 1.953297\n",
      "Batch #10\tAverage Generator Loss: 1925.519421\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17406 (step 17406): 1.300912\n",
      "Batch #10\tAverage Generator Loss: 1815.173523\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17407 (step 17407): 1.302649\n",
      "Batch #10\tAverage Generator Loss: 1583.849738\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17408 (step 17408): 1.361405\n",
      "Batch #10\tAverage Generator Loss: 1626.827472\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17409 (step 17409): 1.835504\n",
      "Batch #10\tAverage Generator Loss: 1618.721826\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17410 (step 17410): 1.329443\n",
      "Batch #10\tAverage Generator Loss: 1420.846411\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17411 (step 17411): 1.345156\n",
      "Batch #10\tAverage Generator Loss: 1600.800903\tAverage Discriminator Loss: 0.468918\n",
      "\n",
      "Train time for epoch #17412 (step 17412): 2.040482\n",
      "Batch #10\tAverage Generator Loss: 1774.696948\tAverage Discriminator Loss: 0.931641\n",
      "\n",
      "Train time for epoch #17413 (step 17413): 1.355761\n",
      "Batch #10\tAverage Generator Loss: 1925.650507\tAverage Discriminator Loss: 0.030855\n",
      "\n",
      "Train time for epoch #17414 (step 17414): 1.327280\n",
      "Batch #10\tAverage Generator Loss: 1644.007196\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17415 (step 17415): 1.397092\n",
      "Batch #10\tAverage Generator Loss: 1418.878979\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #17416 (step 17416): 1.921171\n",
      "Batch #10\tAverage Generator Loss: 1836.694519\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #17417 (step 17417): 1.292925\n",
      "Batch #10\tAverage Generator Loss: 1692.813922\tAverage Discriminator Loss: 0.000018\n",
      "\n",
      "Train time for epoch #17418 (step 17418): 1.291733\n",
      "Batch #10\tAverage Generator Loss: 1790.587341\tAverage Discriminator Loss: 0.096628\n",
      "\n",
      "Train time for epoch #17419 (step 17419): 1.853819\n",
      "Batch #10\tAverage Generator Loss: 1670.061914\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17420 (step 17420): 1.394415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 1809.903784\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17421 (step 17421): 1.292100\n",
      "Batch #10\tAverage Generator Loss: 1876.952197\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17422 (step 17422): 1.384656\n",
      "Batch #10\tAverage Generator Loss: 1714.429681\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17423 (step 17423): 1.840079\n",
      "Batch #10\tAverage Generator Loss: 1980.067664\tAverage Discriminator Loss: 0.000199\n",
      "\n",
      "Train time for epoch #17424 (step 17424): 1.304563\n",
      "Batch #10\tAverage Generator Loss: 1654.925867\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17425 (step 17425): 1.330073\n",
      "Batch #10\tAverage Generator Loss: 1846.632666\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17426 (step 17426): 1.844435\n",
      "Batch #10\tAverage Generator Loss: 1762.923755\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17427 (step 17427): 1.289116\n",
      "Batch #10\tAverage Generator Loss: 1731.614246\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17428 (step 17428): 1.406915\n",
      "Batch #10\tAverage Generator Loss: 1845.232172\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17429 (step 17429): 1.294826\n",
      "Batch #10\tAverage Generator Loss: 1789.372034\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17430 (step 17430): 1.971007\n",
      "Batch #10\tAverage Generator Loss: 1735.839630\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17431 (step 17431): 1.301986\n",
      "Batch #10\tAverage Generator Loss: 1620.737592\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17432 (step 17432): 1.312252\n",
      "Batch #10\tAverage Generator Loss: 1823.138641\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17433 (step 17433): 1.414067\n",
      "Batch #10\tAverage Generator Loss: 1679.863037\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17434 (step 17434): 1.939102\n",
      "Batch #10\tAverage Generator Loss: 1696.874927\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17435 (step 17435): 1.417733\n",
      "Batch #10\tAverage Generator Loss: 1718.818762\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17436 (step 17436): 1.291267\n",
      "Batch #10\tAverage Generator Loss: 1697.211407\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17437 (step 17437): 1.948563\n",
      "Batch #10\tAverage Generator Loss: 1945.865564\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17438 (step 17438): 1.572056\n",
      "Batch #10\tAverage Generator Loss: 1643.596338\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17439 (step 17439): 1.456541\n",
      "Batch #10\tAverage Generator Loss: 1830.831445\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #17440 (step 17440): 1.397292\n",
      "Batch #10\tAverage Generator Loss: 1823.982227\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17441 (step 17441): 1.857339\n",
      "Batch #10\tAverage Generator Loss: 1486.340723\tAverage Discriminator Loss: 0.014629\n",
      "\n",
      "Train time for epoch #17442 (step 17442): 1.383793\n",
      "Batch #10\tAverage Generator Loss: 1654.401971\tAverage Discriminator Loss: 0.000114\n",
      "\n",
      "Train time for epoch #17443 (step 17443): 1.287615\n",
      "Batch #10\tAverage Generator Loss: 1677.591919\tAverage Discriminator Loss: 0.000049\n",
      "\n",
      "Train time for epoch #17444 (step 17444): 2.018639\n",
      "Batch #10\tAverage Generator Loss: 1756.702771\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #17445 (step 17445): 1.303063\n",
      "Batch #10\tAverage Generator Loss: 1774.400586\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #17446 (step 17446): 1.392729\n",
      "Batch #10\tAverage Generator Loss: 1640.697021\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #17447 (step 17447): 1.307323\n",
      "Batch #10\tAverage Generator Loss: 1796.515674\tAverage Discriminator Loss: 0.002731\n",
      "\n",
      "Train time for epoch #17448 (step 17448): 1.965658\n",
      "Batch #10\tAverage Generator Loss: 1759.538733\tAverage Discriminator Loss: 0.000186\n",
      "\n",
      "Train time for epoch #17449 (step 17449): 1.317196\n",
      "Batch #10\tAverage Generator Loss: 2069.062006\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #17450 (step 17450): 1.340789\n",
      "Batch #10\tAverage Generator Loss: 1957.651562\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17451 (step 17451): 1.918505\n",
      "Batch #10\tAverage Generator Loss: 1788.842334\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17452 (step 17452): 1.374323\n",
      "Batch #10\tAverage Generator Loss: 1951.452722\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17453 (step 17453): 1.345606\n",
      "Batch #10\tAverage Generator Loss: 1947.347729\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17454 (step 17454): 1.320805\n",
      "Batch #10\tAverage Generator Loss: 1646.759003\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17455 (step 17455): 1.918001\n",
      "Batch #10\tAverage Generator Loss: 1730.185425\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17456 (step 17456): 1.411731\n",
      "Batch #10\tAverage Generator Loss: 2115.537610\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17457 (step 17457): 1.285302\n",
      "Batch #10\tAverage Generator Loss: 1865.670715\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17458 (step 17458): 1.338931\n",
      "Batch #10\tAverage Generator Loss: 1553.963635\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17459 (step 17459): 1.848403\n",
      "Batch #10\tAverage Generator Loss: 2029.647375\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17460 (step 17460): 1.389324\n",
      "Batch #10\tAverage Generator Loss: 1892.827728\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17461 (step 17461): 1.349787\n",
      "Batch #10\tAverage Generator Loss: 1773.764319\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17462 (step 17462): 1.900198\n",
      "Batch #10\tAverage Generator Loss: 1851.712439\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17463 (step 17463): 1.437439\n",
      "Batch #10\tAverage Generator Loss: 2030.824744\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17464 (step 17464): 1.390495\n",
      "Batch #10\tAverage Generator Loss: 1920.934790\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17465 (step 17465): 1.247735\n",
      "Batch #10\tAverage Generator Loss: 1735.766772\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17466 (step 17466): 1.872767\n",
      "Batch #10\tAverage Generator Loss: 1653.625952\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17467 (step 17467): 1.301717\n",
      "Batch #10\tAverage Generator Loss: 1831.083423\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17468 (step 17468): 1.293575\n",
      "Batch #10\tAverage Generator Loss: 1719.403467\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17469 (step 17469): 1.890190\n",
      "Batch #10\tAverage Generator Loss: 1894.154614\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17470 (step 17470): 1.394045\n",
      "Batch #10\tAverage Generator Loss: 1745.014844\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17471 (step 17471): 1.297179\n",
      "Batch #10\tAverage Generator Loss: 1672.458002\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17472 (step 17472): 1.888134\n",
      "Batch #10\tAverage Generator Loss: 2171.118481\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17473 (step 17473): 1.398733\n",
      "Batch #10\tAverage Generator Loss: 1803.992255\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17474 (step 17474): 1.289246\n",
      "Batch #10\tAverage Generator Loss: 1580.915295\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17475 (step 17475): 1.301696\n",
      "Batch #10\tAverage Generator Loss: 1621.056311\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17476 (step 17476): 1.941095\n",
      "Batch #10\tAverage Generator Loss: 1868.165955\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17477 (step 17477): 1.286398\n",
      "Batch #10\tAverage Generator Loss: 1832.174615\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17478 (step 17478): 1.306554\n",
      "Batch #10\tAverage Generator Loss: 1628.398755\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17479 (step 17479): 1.386482\n",
      "Batch #10\tAverage Generator Loss: 2006.980896\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17480 (step 17480): 1.907398\n",
      "Batch #10\tAverage Generator Loss: 2008.644641\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17481 (step 17481): 1.296314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2112.633020\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17482 (step 17482): 1.382317\n",
      "Batch #10\tAverage Generator Loss: 1884.421216\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17483 (step 17483): 1.944618\n",
      "Batch #10\tAverage Generator Loss: 1909.327386\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17484 (step 17484): 1.301275\n",
      "Batch #10\tAverage Generator Loss: 1984.078235\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17485 (step 17485): 1.240498\n",
      "Batch #10\tAverage Generator Loss: 1551.290942\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17486 (step 17486): 1.929484\n",
      "Batch #10\tAverage Generator Loss: 1982.942664\tAverage Discriminator Loss: 0.022269\n",
      "\n",
      "Train time for epoch #17487 (step 17487): 1.289760\n",
      "Batch #10\tAverage Generator Loss: 1883.848547\tAverage Discriminator Loss: 0.000119\n",
      "\n",
      "Train time for epoch #17488 (step 17488): 1.331265\n",
      "Batch #10\tAverage Generator Loss: 1681.108252\tAverage Discriminator Loss: 0.400055\n",
      "\n",
      "Train time for epoch #17489 (step 17489): 1.337911\n",
      "Batch #10\tAverage Generator Loss: 2058.309656\tAverage Discriminator Loss: 0.022792\n",
      "\n",
      "Train time for epoch #17490 (step 17490): 1.892665\n",
      "Batch #10\tAverage Generator Loss: 1499.446814\tAverage Discriminator Loss: 0.001175\n",
      "\n",
      "Train time for epoch #17491 (step 17491): 1.351776\n",
      "Batch #10\tAverage Generator Loss: 1797.691669\tAverage Discriminator Loss: 0.000023\n",
      "\n",
      "Train time for epoch #17492 (step 17492): 1.494546\n",
      "Batch #10\tAverage Generator Loss: 1721.820459\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17493 (step 17493): 1.289719\n",
      "Batch #10\tAverage Generator Loss: 1564.945807\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #17494 (step 17494): 1.919242\n",
      "Batch #10\tAverage Generator Loss: 1746.871210\tAverage Discriminator Loss: 0.006868\n",
      "\n",
      "Train time for epoch #17495 (step 17495): 1.329366\n",
      "Batch #10\tAverage Generator Loss: 1437.431360\tAverage Discriminator Loss: 0.000103\n",
      "\n",
      "Train time for epoch #17496 (step 17496): 1.292507\n",
      "Batch #10\tAverage Generator Loss: 1778.782550\tAverage Discriminator Loss: 0.000028\n",
      "\n",
      "Train time for epoch #17497 (step 17497): 1.899503\n",
      "Batch #10\tAverage Generator Loss: 1686.437793\tAverage Discriminator Loss: 0.000021\n",
      "\n",
      "Train time for epoch #17498 (step 17498): 1.336682\n",
      "Batch #10\tAverage Generator Loss: 1775.245734\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #17499 (step 17499): 1.350165\n",
      "Batch #10\tAverage Generator Loss: 1741.907324\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #17500 (step 17500): 1.299241\n",
      "Batch #10\tAverage Generator Loss: 1467.430444\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #17501 (step 17501): 2.007909\n",
      "Batch #10\tAverage Generator Loss: 1968.827405\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #17502 (step 17502): 1.412016\n",
      "Batch #10\tAverage Generator Loss: 1751.944080\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #17503 (step 17503): 1.332807\n",
      "Batch #10\tAverage Generator Loss: 1772.946533\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17504 (step 17504): 1.349940\n",
      "Batch #10\tAverage Generator Loss: 1888.844348\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #17505 (step 17505): 1.878554\n",
      "Batch #10\tAverage Generator Loss: 1560.833801\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #17506 (step 17506): 1.376841\n",
      "Batch #10\tAverage Generator Loss: 1658.822833\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #17507 (step 17507): 1.332961\n",
      "Batch #10\tAverage Generator Loss: 1747.049310\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17508 (step 17508): 1.847332\n",
      "Batch #10\tAverage Generator Loss: 1717.217743\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17509 (step 17509): 1.320524\n",
      "Batch #10\tAverage Generator Loss: 1823.825879\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #17510 (step 17510): 1.269526\n",
      "Batch #10\tAverage Generator Loss: 1816.522400\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #17511 (step 17511): 1.447181\n",
      "Batch #10\tAverage Generator Loss: 1881.357703\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #17512 (step 17512): 1.977640\n",
      "Batch #10\tAverage Generator Loss: 1791.982764\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #17513 (step 17513): 1.295691\n",
      "Batch #10\tAverage Generator Loss: 1667.918683\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #17514 (step 17514): 1.283956\n",
      "Batch #10\tAverage Generator Loss: 1794.262585\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17515 (step 17515): 1.872154\n",
      "Batch #10\tAverage Generator Loss: 1723.067377\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #17516 (step 17516): 1.334970\n",
      "Batch #10\tAverage Generator Loss: 1739.242236\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #17517 (step 17517): 1.477201\n",
      "Batch #10\tAverage Generator Loss: 1747.616199\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #17518 (step 17518): 1.398751\n",
      "Batch #10\tAverage Generator Loss: 1891.914563\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #17519 (step 17519): 1.928530\n",
      "Batch #10\tAverage Generator Loss: 1590.058148\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17520 (step 17520): 1.394946\n",
      "Batch #10\tAverage Generator Loss: 1548.377844\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17521 (step 17521): 1.350125\n",
      "Batch #10\tAverage Generator Loss: 1570.200977\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17522 (step 17522): 1.934390\n",
      "Batch #10\tAverage Generator Loss: 1826.897626\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17523 (step 17523): 1.341845\n",
      "Batch #10\tAverage Generator Loss: 1614.363934\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17524 (step 17524): 1.350738\n",
      "Batch #10\tAverage Generator Loss: 1794.522791\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17525 (step 17525): 1.441274\n",
      "Batch #10\tAverage Generator Loss: 1638.736707\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17526 (step 17526): 1.968120\n",
      "Batch #10\tAverage Generator Loss: 1889.609705\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17527 (step 17527): 1.397095\n",
      "Batch #10\tAverage Generator Loss: 1842.063019\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17528 (step 17528): 1.325965\n",
      "Batch #10\tAverage Generator Loss: 1857.934363\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17529 (step 17529): 1.377782\n",
      "Batch #10\tAverage Generator Loss: 1692.372260\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17530 (step 17530): 2.090888\n",
      "Batch #10\tAverage Generator Loss: 1884.550293\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17531 (step 17531): 1.433088\n",
      "Batch #10\tAverage Generator Loss: 1780.492456\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17532 (step 17532): 1.386264\n",
      "Batch #10\tAverage Generator Loss: 1648.675238\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17533 (step 17533): 1.837323\n",
      "Batch #10\tAverage Generator Loss: 1856.837427\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17534 (step 17534): 1.278374\n",
      "Batch #10\tAverage Generator Loss: 1610.293750\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17535 (step 17535): 1.296757\n",
      "Batch #10\tAverage Generator Loss: 1676.191919\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17536 (step 17536): 1.273671\n",
      "Batch #10\tAverage Generator Loss: 1587.903131\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17537 (step 17537): 1.892004\n",
      "Batch #10\tAverage Generator Loss: 1765.856885\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17538 (step 17538): 1.507515\n",
      "Batch #10\tAverage Generator Loss: 1632.799170\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17539 (step 17539): 1.484497\n",
      "Batch #10\tAverage Generator Loss: 1705.001953\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17540 (step 17540): 1.848702\n",
      "Batch #10\tAverage Generator Loss: 1596.456696\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17541 (step 17541): 1.298155\n",
      "Batch #10\tAverage Generator Loss: 1790.185132\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17542 (step 17542): 1.285685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 1896.700220\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17543 (step 17543): 1.299629\n",
      "Batch #10\tAverage Generator Loss: 1730.023303\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17544 (step 17544): 1.878452\n",
      "Batch #10\tAverage Generator Loss: 1696.305933\tAverage Discriminator Loss: 0.000094\n",
      "\n",
      "Train time for epoch #17545 (step 17545): 1.286979\n",
      "Batch #10\tAverage Generator Loss: 1904.080200\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17546 (step 17546): 1.499226\n",
      "Batch #10\tAverage Generator Loss: 1884.216724\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17547 (step 17547): 1.342166\n",
      "Batch #10\tAverage Generator Loss: 1947.897083\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17548 (step 17548): 1.864877\n",
      "Batch #10\tAverage Generator Loss: 1625.949915\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17549 (step 17549): 1.389809\n",
      "Batch #10\tAverage Generator Loss: 1831.148682\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17550 (step 17550): 1.338162\n",
      "Batch #10\tAverage Generator Loss: 1866.527271\tAverage Discriminator Loss: 0.015691\n",
      "\n",
      "Train time for epoch #17551 (step 17551): 1.921044\n",
      "Batch #10\tAverage Generator Loss: 1439.378522\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17552 (step 17552): 1.325391\n",
      "Batch #10\tAverage Generator Loss: 1652.076599\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #17553 (step 17553): 1.295708\n",
      "Batch #10\tAverage Generator Loss: 1784.548291\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #17554 (step 17554): 1.286767\n",
      "Batch #10\tAverage Generator Loss: 1648.914825\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #17555 (step 17555): 1.926766\n",
      "Batch #10\tAverage Generator Loss: 1570.535925\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #17556 (step 17556): 1.306123\n",
      "Batch #10\tAverage Generator Loss: 1696.149249\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #17557 (step 17557): 1.434662\n",
      "Batch #10\tAverage Generator Loss: 1537.953711\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #17558 (step 17558): 1.413504\n",
      "Batch #10\tAverage Generator Loss: 1788.072864\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #17559 (step 17559): 1.901436\n",
      "Batch #10\tAverage Generator Loss: 1416.633868\tAverage Discriminator Loss: 0.000030\n",
      "\n",
      "Train time for epoch #17560 (step 17560): 1.394552\n",
      "Batch #10\tAverage Generator Loss: 1595.738678\tAverage Discriminator Loss: 0.000077\n",
      "\n",
      "Train time for epoch #17561 (step 17561): 1.286479\n",
      "Batch #10\tAverage Generator Loss: 1771.152802\tAverage Discriminator Loss: 0.000033\n",
      "\n",
      "Train time for epoch #17562 (step 17562): 1.855052\n",
      "Batch #10\tAverage Generator Loss: 1545.872498\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #17563 (step 17563): 1.339196\n",
      "Batch #10\tAverage Generator Loss: 1808.544788\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #17564 (step 17564): 1.347349\n",
      "Batch #10\tAverage Generator Loss: 1791.220679\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #17565 (step 17565): 1.475310\n",
      "Batch #10\tAverage Generator Loss: 1817.095129\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #17566 (step 17566): 2.036053\n",
      "Batch #10\tAverage Generator Loss: 1609.798059\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #17567 (step 17567): 1.305470\n",
      "Batch #10\tAverage Generator Loss: 1814.651538\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #17568 (step 17568): 1.333767\n",
      "Batch #10\tAverage Generator Loss: 1923.758868\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #17569 (step 17569): 1.902261\n",
      "Batch #10\tAverage Generator Loss: 1777.082104\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #17570 (step 17570): 1.355385\n",
      "Batch #10\tAverage Generator Loss: 2008.350580\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #17571 (step 17571): 1.325995\n",
      "Batch #10\tAverage Generator Loss: 1727.420569\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17572 (step 17572): 1.298711\n",
      "Batch #10\tAverage Generator Loss: 1802.027063\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #17573 (step 17573): 1.872580\n",
      "Batch #10\tAverage Generator Loss: 2053.127124\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #17574 (step 17574): 1.419448\n",
      "Batch #10\tAverage Generator Loss: 1902.108521\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #17575 (step 17575): 1.287889\n",
      "Batch #10\tAverage Generator Loss: 1714.449756\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #17576 (step 17576): 1.936129\n",
      "Batch #10\tAverage Generator Loss: 1899.454456\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #17577 (step 17577): 1.306677\n",
      "Batch #10\tAverage Generator Loss: 1667.502222\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #17578 (step 17578): 1.316693\n",
      "Batch #10\tAverage Generator Loss: 1970.541980\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17579 (step 17579): 1.402291\n",
      "Batch #10\tAverage Generator Loss: 1808.886206\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17580 (step 17580): 1.864514\n",
      "Batch #10\tAverage Generator Loss: 1961.817627\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #17581 (step 17581): 1.256270\n",
      "Batch #10\tAverage Generator Loss: 1736.950507\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17582 (step 17582): 1.288047\n",
      "Batch #10\tAverage Generator Loss: 1913.778125\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #17583 (step 17583): 1.921848\n",
      "Batch #10\tAverage Generator Loss: 1856.911346\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17584 (step 17584): 1.263224\n",
      "Batch #10\tAverage Generator Loss: 1759.295215\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17585 (step 17585): 1.364448\n",
      "Batch #10\tAverage Generator Loss: 1954.224158\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17586 (step 17586): 1.288283\n",
      "Batch #10\tAverage Generator Loss: 2055.105542\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #17587 (step 17587): 1.958868\n",
      "Batch #10\tAverage Generator Loss: 1903.243896\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #17588 (step 17588): 1.304800\n",
      "Batch #10\tAverage Generator Loss: 1752.866083\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17589 (step 17589): 1.350108\n",
      "Batch #10\tAverage Generator Loss: 1742.140784\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17590 (step 17590): 1.282685\n",
      "Batch #10\tAverage Generator Loss: 1937.570947\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17591 (step 17591): 1.864669\n",
      "Batch #10\tAverage Generator Loss: 1719.020703\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17592 (step 17592): 1.340596\n",
      "Batch #10\tAverage Generator Loss: 1680.684753\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17593 (step 17593): 1.311381\n",
      "Batch #10\tAverage Generator Loss: 1960.819702\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17594 (step 17594): 1.971131\n",
      "Batch #10\tAverage Generator Loss: 1891.614233\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17595 (step 17595): 1.374937\n",
      "Batch #10\tAverage Generator Loss: 2034.147363\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17596 (step 17596): 1.346132\n",
      "Batch #10\tAverage Generator Loss: 1860.687408\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17597 (step 17597): 1.426525\n",
      "Batch #10\tAverage Generator Loss: 1885.066046\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17598 (step 17598): 1.910105\n",
      "Batch #10\tAverage Generator Loss: 1675.834308\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17599 (step 17599): 1.422752\n",
      "Batch #10\tAverage Generator Loss: 1959.606000\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17600 (step 17600): 1.292788\n",
      "Batch #10\tAverage Generator Loss: 1692.530280\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17601 (step 17601): 1.981858\n",
      "Batch #10\tAverage Generator Loss: 2022.834607\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17602 (step 17602): 1.296685\n",
      "Batch #10\tAverage Generator Loss: 1813.758862\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17603 (step 17603): 1.294909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 1663.656360\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17604 (step 17604): 1.304934\n",
      "Batch #10\tAverage Generator Loss: 1876.141534\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17605 (step 17605): 1.983412\n",
      "Batch #10\tAverage Generator Loss: 1948.604315\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17606 (step 17606): 1.439665\n",
      "Batch #10\tAverage Generator Loss: 1787.258307\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17607 (step 17607): 1.253142\n",
      "Batch #10\tAverage Generator Loss: 1727.507739\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17608 (step 17608): 1.916754\n",
      "Batch #10\tAverage Generator Loss: 1802.085840\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17609 (step 17609): 1.293737\n",
      "Batch #10\tAverage Generator Loss: 1478.577979\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17610 (step 17610): 1.403874\n",
      "Batch #10\tAverage Generator Loss: 1812.211542\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17611 (step 17611): 1.321306\n",
      "Batch #10\tAverage Generator Loss: 1898.594238\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17612 (step 17612): 1.959412\n",
      "Batch #10\tAverage Generator Loss: 1849.750391\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17613 (step 17613): 1.288456\n",
      "Batch #10\tAverage Generator Loss: 1847.395715\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17614 (step 17614): 1.300919\n",
      "Batch #10\tAverage Generator Loss: 1828.365833\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #17615 (step 17615): 1.846090\n",
      "Batch #10\tAverage Generator Loss: 1887.817322\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17616 (step 17616): 1.293457\n",
      "Batch #10\tAverage Generator Loss: 1627.052222\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17617 (step 17617): 1.406794\n",
      "Batch #10\tAverage Generator Loss: 1764.583209\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17618 (step 17618): 1.407276\n",
      "Batch #10\tAverage Generator Loss: 2033.144983\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17619 (step 17619): 1.842228\n",
      "Batch #10\tAverage Generator Loss: 1832.339105\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17620 (step 17620): 1.299816\n",
      "Batch #10\tAverage Generator Loss: 1881.573145\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17621 (step 17621): 1.324885\n",
      "Batch #10\tAverage Generator Loss: 1440.040588\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17622 (step 17622): 1.874349\n",
      "Batch #10\tAverage Generator Loss: 1757.123145\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17623 (step 17623): 1.461059\n",
      "Batch #10\tAverage Generator Loss: 1835.145941\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17624 (step 17624): 1.346383\n",
      "Batch #10\tAverage Generator Loss: 1938.247961\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17625 (step 17625): 1.486099\n",
      "Batch #10\tAverage Generator Loss: 1900.598352\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17626 (step 17626): 1.889827\n",
      "Batch #10\tAverage Generator Loss: 2011.121545\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17627 (step 17627): 1.299534\n",
      "Batch #10\tAverage Generator Loss: 1780.583997\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17628 (step 17628): 1.461923\n",
      "Batch #10\tAverage Generator Loss: 1760.977875\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17629 (step 17629): 2.030552\n",
      "Batch #10\tAverage Generator Loss: 1824.407117\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17630 (step 17630): 1.362042\n",
      "Batch #10\tAverage Generator Loss: 1729.311682\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17631 (step 17631): 1.356330\n",
      "Batch #10\tAverage Generator Loss: 1929.243713\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17632 (step 17632): 1.335906\n",
      "Batch #10\tAverage Generator Loss: 1979.758655\tAverage Discriminator Loss: 0.006033\n",
      "\n",
      "Train time for epoch #17633 (step 17633): 2.048788\n",
      "Batch #10\tAverage Generator Loss: 1793.349896\tAverage Discriminator Loss: 0.000026\n",
      "\n",
      "Train time for epoch #17634 (step 17634): 1.343978\n",
      "Batch #10\tAverage Generator Loss: 2091.545752\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17635 (step 17635): 1.329130\n",
      "Batch #10\tAverage Generator Loss: 1893.057196\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17636 (step 17636): 2.003466\n",
      "Batch #10\tAverage Generator Loss: 1883.744104\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17637 (step 17637): 1.400343\n",
      "Batch #10\tAverage Generator Loss: 2089.229016\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17638 (step 17638): 1.349713\n",
      "Batch #10\tAverage Generator Loss: 2149.960095\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17639 (step 17639): 1.334108\n",
      "Batch #10\tAverage Generator Loss: 2082.868237\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17640 (step 17640): 1.912217\n",
      "Batch #10\tAverage Generator Loss: 2184.585205\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17641 (step 17641): 1.347601\n",
      "Batch #10\tAverage Generator Loss: 2051.637231\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17642 (step 17642): 1.296417\n",
      "Batch #10\tAverage Generator Loss: 1978.059106\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17643 (step 17643): 1.981379\n",
      "Batch #10\tAverage Generator Loss: 2225.364111\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17644 (step 17644): 1.395674\n",
      "Batch #10\tAverage Generator Loss: 2002.722754\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17645 (step 17645): 1.366077\n",
      "Batch #10\tAverage Generator Loss: 2117.632849\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17646 (step 17646): 1.245154\n",
      "Batch #10\tAverage Generator Loss: 2286.857593\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17647 (step 17647): 1.837190\n",
      "Batch #10\tAverage Generator Loss: 1686.199823\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17648 (step 17648): 1.441216\n",
      "Batch #10\tAverage Generator Loss: 2395.171765\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17649 (step 17649): 1.353317\n",
      "Batch #10\tAverage Generator Loss: 2113.005518\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17650 (step 17650): 1.957673\n",
      "Batch #10\tAverage Generator Loss: 2089.428711\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17651 (step 17651): 1.388990\n",
      "Batch #10\tAverage Generator Loss: 2044.576367\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17652 (step 17652): 1.302300\n",
      "Batch #10\tAverage Generator Loss: 2141.656531\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17653 (step 17653): 1.468959\n",
      "Batch #10\tAverage Generator Loss: 1797.839838\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17654 (step 17654): 1.855177\n",
      "Batch #10\tAverage Generator Loss: 1913.651459\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17655 (step 17655): 1.309919\n",
      "Batch #10\tAverage Generator Loss: 2073.790698\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17656 (step 17656): 1.408665\n",
      "Batch #10\tAverage Generator Loss: 2179.011719\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17657 (step 17657): 1.389728\n",
      "Batch #10\tAverage Generator Loss: 1806.594342\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17658 (step 17658): 1.943606\n",
      "Batch #10\tAverage Generator Loss: 2095.044690\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17659 (step 17659): 1.333490\n",
      "Batch #10\tAverage Generator Loss: 1833.640442\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17660 (step 17660): 1.320422\n",
      "Batch #10\tAverage Generator Loss: 1886.078998\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17661 (step 17661): 1.837840\n",
      "Batch #10\tAverage Generator Loss: 1890.897766\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17662 (step 17662): 1.384942\n",
      "Batch #10\tAverage Generator Loss: 1947.737048\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17663 (step 17663): 1.283831\n",
      "Batch #10\tAverage Generator Loss: 2028.965869\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17664 (step 17664): 1.344327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 1832.085419\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17665 (step 17665): 1.829180\n",
      "Batch #10\tAverage Generator Loss: 1731.826843\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17666 (step 17666): 1.299705\n",
      "Batch #10\tAverage Generator Loss: 1882.483423\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17667 (step 17667): 1.339540\n",
      "Batch #10\tAverage Generator Loss: 2190.120142\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17668 (step 17668): 1.919133\n",
      "Batch #10\tAverage Generator Loss: 2092.792297\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17669 (step 17669): 1.368999\n",
      "Batch #10\tAverage Generator Loss: 1810.183038\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17670 (step 17670): 1.347141\n",
      "Batch #10\tAverage Generator Loss: 2343.478833\tAverage Discriminator Loss: 0.023340\n",
      "\n",
      "Train time for epoch #17671 (step 17671): 1.307425\n",
      "Batch #10\tAverage Generator Loss: 2324.428516\tAverage Discriminator Loss: 0.000037\n",
      "\n",
      "Train time for epoch #17672 (step 17672): 1.985812\n",
      "Batch #10\tAverage Generator Loss: 2337.667371\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17673 (step 17673): 1.361474\n",
      "Batch #10\tAverage Generator Loss: 2435.387720\tAverage Discriminator Loss: 0.010253\n",
      "\n",
      "Train time for epoch #17674 (step 17674): 1.286030\n",
      "Batch #10\tAverage Generator Loss: 2405.208728\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17675 (step 17675): 1.948691\n",
      "Batch #10\tAverage Generator Loss: 2176.403986\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #17676 (step 17676): 1.358311\n",
      "Batch #10\tAverage Generator Loss: 2236.488135\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #17677 (step 17677): 1.355372\n",
      "Batch #10\tAverage Generator Loss: 2388.837219\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #17678 (step 17678): 1.359010\n",
      "Batch #10\tAverage Generator Loss: 1913.093774\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #17679 (step 17679): 1.895903\n",
      "Batch #10\tAverage Generator Loss: 2219.745605\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #17680 (step 17680): 1.304066\n",
      "Batch #10\tAverage Generator Loss: 2332.114545\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #17681 (step 17681): 1.349504\n",
      "Batch #10\tAverage Generator Loss: 2506.928076\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #17682 (step 17682): 1.963454\n",
      "Batch #10\tAverage Generator Loss: 2727.078748\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #17683 (step 17683): 1.333205\n",
      "Batch #10\tAverage Generator Loss: 2231.838159\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #17684 (step 17684): 1.453686\n",
      "Batch #10\tAverage Generator Loss: 1774.288672\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #17685 (step 17685): 1.325757\n",
      "Batch #10\tAverage Generator Loss: 1963.731042\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #17686 (step 17686): 1.959224\n",
      "Batch #10\tAverage Generator Loss: 2494.645325\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #17687 (step 17687): 1.300472\n",
      "Batch #10\tAverage Generator Loss: 2317.479211\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17688 (step 17688): 1.447702\n",
      "Batch #10\tAverage Generator Loss: 2054.499658\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #17689 (step 17689): 1.393344\n",
      "Batch #10\tAverage Generator Loss: 2221.112671\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #17690 (step 17690): 1.890141\n",
      "Batch #10\tAverage Generator Loss: 2577.877417\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #17691 (step 17691): 1.325042\n",
      "Batch #10\tAverage Generator Loss: 2530.179236\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #17692 (step 17692): 1.300609\n",
      "Batch #10\tAverage Generator Loss: 2026.659790\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #17693 (step 17693): 1.845942\n",
      "Batch #10\tAverage Generator Loss: 2541.820227\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #17694 (step 17694): 1.345920\n",
      "Batch #10\tAverage Generator Loss: 2098.069119\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #17695 (step 17695): 1.293069\n",
      "Batch #10\tAverage Generator Loss: 2700.974573\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17696 (step 17696): 1.389768\n",
      "Batch #10\tAverage Generator Loss: 2002.561829\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #17697 (step 17697): 1.784700\n",
      "Batch #10\tAverage Generator Loss: 2485.923999\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17698 (step 17698): 1.349144\n",
      "Batch #10\tAverage Generator Loss: 2029.984351\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17699 (step 17699): 1.285697\n",
      "Batch #10\tAverage Generator Loss: 2286.436328\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17700 (step 17700): 1.885620\n",
      "Batch #10\tAverage Generator Loss: 2630.730164\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17701 (step 17701): 1.350283\n",
      "Batch #10\tAverage Generator Loss: 2248.148676\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17702 (step 17702): 1.298282\n",
      "Batch #10\tAverage Generator Loss: 2177.972559\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17703 (step 17703): 1.409027\n",
      "Batch #10\tAverage Generator Loss: 2403.768079\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17704 (step 17704): 1.968853\n",
      "Batch #10\tAverage Generator Loss: 2181.152295\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17705 (step 17705): 1.402446\n",
      "Batch #10\tAverage Generator Loss: 1962.411945\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17706 (step 17706): 1.323967\n",
      "Batch #10\tAverage Generator Loss: 2828.223047\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17707 (step 17707): 1.902845\n",
      "Batch #10\tAverage Generator Loss: 2237.944324\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17708 (step 17708): 1.298395\n",
      "Batch #10\tAverage Generator Loss: 2027.802185\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17709 (step 17709): 1.305181\n",
      "Batch #10\tAverage Generator Loss: 2223.439453\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17710 (step 17710): 1.501641\n",
      "Batch #10\tAverage Generator Loss: 2046.723358\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17711 (step 17711): 1.918806\n",
      "Batch #10\tAverage Generator Loss: 2330.845203\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17712 (step 17712): 1.304447\n",
      "Batch #10\tAverage Generator Loss: 2014.658392\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17713 (step 17713): 1.463512\n",
      "Batch #10\tAverage Generator Loss: 2316.292554\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17714 (step 17714): 2.003499\n",
      "Batch #10\tAverage Generator Loss: 2009.985254\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17715 (step 17715): 1.301311\n",
      "Batch #10\tAverage Generator Loss: 2183.471521\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17716 (step 17716): 1.277277\n",
      "Batch #10\tAverage Generator Loss: 2089.901318\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17717 (step 17717): 1.389296\n",
      "Batch #10\tAverage Generator Loss: 1981.230969\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17718 (step 17718): 2.013602\n",
      "Batch #10\tAverage Generator Loss: 2405.967847\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17719 (step 17719): 1.346735\n",
      "Batch #10\tAverage Generator Loss: 2167.576343\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17720 (step 17720): 1.353303\n",
      "Batch #10\tAverage Generator Loss: 2471.260913\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17721 (step 17721): 1.981169\n",
      "Batch #10\tAverage Generator Loss: 2427.379669\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17722 (step 17722): 1.305101\n",
      "Batch #10\tAverage Generator Loss: 2119.465375\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17723 (step 17723): 1.342889\n",
      "Batch #10\tAverage Generator Loss: 2827.301794\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17724 (step 17724): 1.290795\n",
      "Batch #10\tAverage Generator Loss: 2286.826819\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17725 (step 17725): 1.896934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2204.759705\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17726 (step 17726): 1.346901\n",
      "Batch #10\tAverage Generator Loss: 1967.983057\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17727 (step 17727): 1.369972\n",
      "Batch #10\tAverage Generator Loss: 2795.167151\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17728 (step 17728): 1.333287\n",
      "Batch #10\tAverage Generator Loss: 2511.481311\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #17729 (step 17729): 1.857681\n",
      "Batch #10\tAverage Generator Loss: 2589.673499\tAverage Discriminator Loss: 0.000136\n",
      "\n",
      "Train time for epoch #17730 (step 17730): 1.417975\n",
      "Batch #10\tAverage Generator Loss: 2178.576331\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #17731 (step 17731): 1.374913\n",
      "Batch #10\tAverage Generator Loss: 2380.739819\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #17732 (step 17732): 1.951133\n",
      "Batch #10\tAverage Generator Loss: 2662.872156\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #17733 (step 17733): 1.441769\n",
      "Batch #10\tAverage Generator Loss: 2361.656030\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #17734 (step 17734): 1.363528\n",
      "Batch #10\tAverage Generator Loss: 2336.985669\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #17735 (step 17735): 1.311302\n",
      "Batch #10\tAverage Generator Loss: 2247.043933\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #17736 (step 17736): 1.906277\n",
      "Batch #10\tAverage Generator Loss: 2072.926697\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #17737 (step 17737): 1.358223\n",
      "Batch #10\tAverage Generator Loss: 2560.541931\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #17738 (step 17738): 1.438932\n",
      "Batch #10\tAverage Generator Loss: 2232.966003\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #17739 (step 17739): 1.958995\n",
      "Batch #10\tAverage Generator Loss: 2252.286108\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #17740 (step 17740): 1.286801\n",
      "Batch #10\tAverage Generator Loss: 2225.053894\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #17741 (step 17741): 1.369720\n",
      "Batch #10\tAverage Generator Loss: 2459.795837\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #17742 (step 17742): 1.475013\n",
      "Batch #10\tAverage Generator Loss: 2265.581299\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #17743 (step 17743): 1.839601\n",
      "Batch #10\tAverage Generator Loss: 2547.648401\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #17744 (step 17744): 1.296398\n",
      "Batch #10\tAverage Generator Loss: 2127.339233\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #17745 (step 17745): 1.357405\n",
      "Batch #10\tAverage Generator Loss: 2066.097241\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #17746 (step 17746): 1.344476\n",
      "Batch #10\tAverage Generator Loss: 2581.135449\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #17747 (step 17747): 1.946127\n",
      "Batch #10\tAverage Generator Loss: 2372.470996\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17748 (step 17748): 1.416465\n",
      "Batch #10\tAverage Generator Loss: 1870.177472\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #17749 (step 17749): 1.289666\n",
      "Batch #10\tAverage Generator Loss: 2416.525122\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #17750 (step 17750): 2.034010\n",
      "Batch #10\tAverage Generator Loss: 2043.341809\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17751 (step 17751): 1.636286\n",
      "Batch #10\tAverage Generator Loss: 2054.670935\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #17752 (step 17752): 1.258988\n",
      "Batch #10\tAverage Generator Loss: 2200.380249\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17753 (step 17753): 1.378951\n",
      "Batch #10\tAverage Generator Loss: 2275.331653\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #17754 (step 17754): 1.899816\n",
      "Batch #10\tAverage Generator Loss: 1994.855579\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17755 (step 17755): 1.298227\n",
      "Batch #10\tAverage Generator Loss: 2337.013403\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17756 (step 17756): 1.435601\n",
      "Batch #10\tAverage Generator Loss: 2119.717834\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17757 (step 17757): 1.399108\n",
      "Batch #10\tAverage Generator Loss: 2376.352942\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17758 (step 17758): 1.938028\n",
      "Batch #10\tAverage Generator Loss: 1996.614984\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17759 (step 17759): 1.438902\n",
      "Batch #10\tAverage Generator Loss: 2252.529028\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17760 (step 17760): 1.327498\n",
      "Batch #10\tAverage Generator Loss: 2278.366504\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17761 (step 17761): 1.905364\n",
      "Batch #10\tAverage Generator Loss: 2288.373773\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17762 (step 17762): 1.286488\n",
      "Batch #10\tAverage Generator Loss: 1951.951978\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17763 (step 17763): 1.346844\n",
      "Batch #10\tAverage Generator Loss: 2278.319507\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17764 (step 17764): 1.277267\n",
      "Batch #10\tAverage Generator Loss: 1851.308575\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17765 (step 17765): 1.854508\n",
      "Batch #10\tAverage Generator Loss: 2243.281775\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17766 (step 17766): 1.583120\n",
      "Batch #10\tAverage Generator Loss: 2264.010425\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17767 (step 17767): 1.346022\n",
      "Batch #10\tAverage Generator Loss: 2236.305225\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17768 (step 17768): 1.957498\n",
      "Batch #10\tAverage Generator Loss: 2473.227319\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17769 (step 17769): 1.465415\n",
      "Batch #10\tAverage Generator Loss: 2324.087012\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17770 (step 17770): 1.286828\n",
      "Batch #10\tAverage Generator Loss: 2435.884412\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17771 (step 17771): 1.328155\n",
      "Batch #10\tAverage Generator Loss: 1740.444226\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17772 (step 17772): 1.857612\n",
      "Batch #10\tAverage Generator Loss: 2044.139014\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17773 (step 17773): 1.552730\n",
      "Batch #10\tAverage Generator Loss: 2069.823505\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17774 (step 17774): 1.347708\n",
      "Batch #10\tAverage Generator Loss: 2026.543665\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17775 (step 17775): 2.275487\n",
      "Batch #10\tAverage Generator Loss: 1987.719629\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17776 (step 17776): 1.306410\n",
      "Batch #10\tAverage Generator Loss: 2235.460828\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17777 (step 17777): 1.474329\n",
      "Batch #10\tAverage Generator Loss: 2041.463861\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #17778 (step 17778): 1.300013\n",
      "Batch #10\tAverage Generator Loss: 2589.791858\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17779 (step 17779): 1.898274\n",
      "Batch #10\tAverage Generator Loss: 2118.569397\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17780 (step 17780): 1.306036\n",
      "Batch #10\tAverage Generator Loss: 2077.458801\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17781 (step 17781): 1.259221\n",
      "Batch #10\tAverage Generator Loss: 2382.929089\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17782 (step 17782): 1.897910\n",
      "Batch #10\tAverage Generator Loss: 2565.974402\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17783 (step 17783): 1.335120\n",
      "Batch #10\tAverage Generator Loss: 2085.438086\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17784 (step 17784): 1.338596\n",
      "Batch #10\tAverage Generator Loss: 2084.029724\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17785 (step 17785): 1.396296\n",
      "Batch #10\tAverage Generator Loss: 2123.539783\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17786 (step 17786): 1.793502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2171.428149\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17787 (step 17787): 1.352235\n",
      "Batch #10\tAverage Generator Loss: 2247.741235\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17788 (step 17788): 1.346004\n",
      "Batch #10\tAverage Generator Loss: 2099.405359\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17789 (step 17789): 1.920660\n",
      "Batch #10\tAverage Generator Loss: 2562.201538\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17790 (step 17790): 1.290903\n",
      "Batch #10\tAverage Generator Loss: 2340.256201\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17791 (step 17791): 1.289478\n",
      "Batch #10\tAverage Generator Loss: 2192.781885\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17792 (step 17792): 1.431634\n",
      "Batch #10\tAverage Generator Loss: 2274.069604\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17793 (step 17793): 1.863979\n",
      "Batch #10\tAverage Generator Loss: 2340.658154\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17794 (step 17794): 1.383277\n",
      "Batch #10\tAverage Generator Loss: 2133.002374\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17795 (step 17795): 1.310018\n",
      "Batch #10\tAverage Generator Loss: 2097.082727\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17796 (step 17796): 1.387988\n",
      "Batch #10\tAverage Generator Loss: 2435.285144\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17797 (step 17797): 1.879990\n",
      "Batch #10\tAverage Generator Loss: 1905.919275\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17798 (step 17798): 1.298245\n",
      "Batch #10\tAverage Generator Loss: 2179.331445\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17799 (step 17799): 1.240526\n",
      "Batch #10\tAverage Generator Loss: 2102.781787\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17800 (step 17800): 1.957408\n",
      "Batch #10\tAverage Generator Loss: 2196.064209\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17801 (step 17801): 1.398823\n",
      "Batch #10\tAverage Generator Loss: 2371.311810\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17802 (step 17802): 1.339242\n",
      "Batch #10\tAverage Generator Loss: 2420.107092\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17803 (step 17803): 1.304474\n",
      "Batch #10\tAverage Generator Loss: 2544.447913\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17804 (step 17804): 2.018659\n",
      "Batch #10\tAverage Generator Loss: 2131.724469\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17805 (step 17805): 1.310712\n",
      "Batch #10\tAverage Generator Loss: 1959.970801\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17806 (step 17806): 1.282604\n",
      "Batch #10\tAverage Generator Loss: 2380.630933\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17807 (step 17807): 1.900597\n",
      "Batch #10\tAverage Generator Loss: 2650.021899\tAverage Discriminator Loss: 0.008598\n",
      "\n",
      "Train time for epoch #17808 (step 17808): 1.284443\n",
      "Batch #10\tAverage Generator Loss: 2296.566724\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17809 (step 17809): 1.383553\n",
      "Batch #10\tAverage Generator Loss: 2124.566119\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17810 (step 17810): 1.448305\n",
      "Batch #10\tAverage Generator Loss: 2210.848047\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17811 (step 17811): 1.885896\n",
      "Batch #10\tAverage Generator Loss: 2307.061914\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17812 (step 17812): 1.295215\n",
      "Batch #10\tAverage Generator Loss: 2578.740405\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17813 (step 17813): 1.440228\n",
      "Batch #10\tAverage Generator Loss: 1830.933020\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17814 (step 17814): 1.339683\n",
      "Batch #10\tAverage Generator Loss: 2275.541858\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17815 (step 17815): 1.946266\n",
      "Batch #10\tAverage Generator Loss: 2184.651465\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17816 (step 17816): 1.335832\n",
      "Batch #10\tAverage Generator Loss: 2452.018445\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17817 (step 17817): 1.409437\n",
      "Batch #10\tAverage Generator Loss: 2142.109473\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17818 (step 17818): 1.908759\n",
      "Batch #10\tAverage Generator Loss: 2444.230981\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17819 (step 17819): 1.372208\n",
      "Batch #10\tAverage Generator Loss: 2177.616345\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17820 (step 17820): 1.299724\n",
      "Batch #10\tAverage Generator Loss: 1893.582617\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17821 (step 17821): 1.337886\n",
      "Batch #10\tAverage Generator Loss: 2206.981305\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17822 (step 17822): 1.879394\n",
      "Batch #10\tAverage Generator Loss: 2172.071924\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17823 (step 17823): 1.323362\n",
      "Batch #10\tAverage Generator Loss: 2202.045630\tAverage Discriminator Loss: 0.055190\n",
      "\n",
      "Train time for epoch #17824 (step 17824): 1.330399\n",
      "Batch #10\tAverage Generator Loss: 2308.610229\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17825 (step 17825): 1.831332\n",
      "Batch #10\tAverage Generator Loss: 2430.764099\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17826 (step 17826): 1.301759\n",
      "Batch #10\tAverage Generator Loss: 2240.384656\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17827 (step 17827): 1.307522\n",
      "Batch #10\tAverage Generator Loss: 2082.358875\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17828 (step 17828): 1.287441\n",
      "Batch #10\tAverage Generator Loss: 2052.326025\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17829 (step 17829): 2.027519\n",
      "Batch #10\tAverage Generator Loss: 2265.301660\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17830 (step 17830): 1.392827\n",
      "Batch #10\tAverage Generator Loss: 2331.295538\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17831 (step 17831): 1.302173\n",
      "Batch #10\tAverage Generator Loss: 2513.586438\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17832 (step 17832): 1.391073\n",
      "Batch #10\tAverage Generator Loss: 2285.874829\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17833 (step 17833): 1.961743\n",
      "Batch #10\tAverage Generator Loss: 2212.977234\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17834 (step 17834): 1.435039\n",
      "Batch #10\tAverage Generator Loss: 2025.384735\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17835 (step 17835): 1.294540\n",
      "Batch #10\tAverage Generator Loss: 2492.237952\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17836 (step 17836): 1.914393\n",
      "Batch #10\tAverage Generator Loss: 2620.899866\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17837 (step 17837): 1.277681\n",
      "Batch #10\tAverage Generator Loss: 2270.964221\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17838 (step 17838): 1.283640\n",
      "Batch #10\tAverage Generator Loss: 2107.492358\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17839 (step 17839): 1.402204\n",
      "Batch #10\tAverage Generator Loss: 2253.409448\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17840 (step 17840): 1.900237\n",
      "Batch #10\tAverage Generator Loss: 2469.219580\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17841 (step 17841): 1.441417\n",
      "Batch #10\tAverage Generator Loss: 2147.263220\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17842 (step 17842): 1.236086\n",
      "Batch #10\tAverage Generator Loss: 2189.141711\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17843 (step 17843): 1.954209\n",
      "Batch #10\tAverage Generator Loss: 2140.916974\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17844 (step 17844): 1.369072\n",
      "Batch #10\tAverage Generator Loss: 2179.710797\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17845 (step 17845): 1.372910\n",
      "Batch #10\tAverage Generator Loss: 2370.691663\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17846 (step 17846): 1.294041\n",
      "Batch #10\tAverage Generator Loss: 1952.439948\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17847 (step 17847): 2.020394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2320.261664\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17848 (step 17848): 1.346157\n",
      "Batch #10\tAverage Generator Loss: 2217.102319\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17849 (step 17849): 1.337201\n",
      "Batch #10\tAverage Generator Loss: 1903.538043\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17850 (step 17850): 1.349838\n",
      "Batch #10\tAverage Generator Loss: 2167.598010\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17851 (step 17851): 1.883825\n",
      "Batch #10\tAverage Generator Loss: 2346.233472\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17852 (step 17852): 1.376174\n",
      "Batch #10\tAverage Generator Loss: 2287.321826\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17853 (step 17853): 1.341401\n",
      "Batch #10\tAverage Generator Loss: 2013.376172\tAverage Discriminator Loss: 0.054461\n",
      "\n",
      "Train time for epoch #17854 (step 17854): 1.841893\n",
      "Batch #10\tAverage Generator Loss: 2356.829163\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17855 (step 17855): 1.254534\n",
      "Batch #10\tAverage Generator Loss: 2777.213574\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17856 (step 17856): 1.501532\n",
      "Batch #10\tAverage Generator Loss: 2407.476343\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17857 (step 17857): 1.359870\n",
      "Batch #10\tAverage Generator Loss: 1806.723804\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17858 (step 17858): 1.846835\n",
      "Batch #10\tAverage Generator Loss: 2358.386768\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17859 (step 17859): 1.346556\n",
      "Batch #10\tAverage Generator Loss: 2958.380042\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17860 (step 17860): 1.318513\n",
      "Batch #10\tAverage Generator Loss: 2712.810217\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17861 (step 17861): 1.856490\n",
      "Batch #10\tAverage Generator Loss: 2238.952905\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17862 (step 17862): 1.315395\n",
      "Batch #10\tAverage Generator Loss: 2669.465295\tAverage Discriminator Loss: 0.023130\n",
      "\n",
      "Train time for epoch #17863 (step 17863): 1.422054\n",
      "Batch #10\tAverage Generator Loss: 2190.220337\tAverage Discriminator Loss: 0.007750\n",
      "\n",
      "Train time for epoch #17864 (step 17864): 1.334166\n",
      "Batch #10\tAverage Generator Loss: 2204.125061\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17865 (step 17865): 1.924961\n",
      "Batch #10\tAverage Generator Loss: 2517.878296\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17866 (step 17866): 1.336850\n",
      "Batch #10\tAverage Generator Loss: 2756.859042\tAverage Discriminator Loss: 0.023081\n",
      "\n",
      "Train time for epoch #17867 (step 17867): 1.356830\n",
      "Batch #10\tAverage Generator Loss: 2476.270160\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17868 (step 17868): 1.862562\n",
      "Batch #10\tAverage Generator Loss: 2577.317676\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17869 (step 17869): 1.341033\n",
      "Batch #10\tAverage Generator Loss: 2372.599866\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17870 (step 17870): 1.301313\n",
      "Batch #10\tAverage Generator Loss: 2494.792615\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17871 (step 17871): 1.292252\n",
      "Batch #10\tAverage Generator Loss: 2258.072534\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17872 (step 17872): 1.891306\n",
      "Batch #10\tAverage Generator Loss: 2442.626245\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17873 (step 17873): 1.295681\n",
      "Batch #10\tAverage Generator Loss: 2230.684753\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17874 (step 17874): 1.280575\n",
      "Batch #10\tAverage Generator Loss: 2207.299268\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17875 (step 17875): 1.944422\n",
      "Batch #10\tAverage Generator Loss: 2489.800452\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17876 (step 17876): 1.293037\n",
      "Batch #10\tAverage Generator Loss: 2599.507288\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17877 (step 17877): 1.290541\n",
      "Batch #10\tAverage Generator Loss: 2373.967322\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17878 (step 17878): 1.409167\n",
      "Batch #10\tAverage Generator Loss: 2594.963953\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17879 (step 17879): 2.058388\n",
      "Batch #10\tAverage Generator Loss: 2184.407983\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17880 (step 17880): 1.411227\n",
      "Batch #10\tAverage Generator Loss: 2809.291553\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17881 (step 17881): 1.347189\n",
      "Batch #10\tAverage Generator Loss: 2874.355872\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17882 (step 17882): 1.343347\n",
      "Batch #10\tAverage Generator Loss: 2146.175110\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17883 (step 17883): 1.947565\n",
      "Batch #10\tAverage Generator Loss: 2603.346063\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17884 (step 17884): 1.318397\n",
      "Batch #10\tAverage Generator Loss: 2451.874829\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17885 (step 17885): 1.274889\n",
      "Batch #10\tAverage Generator Loss: 2595.320337\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17886 (step 17886): 1.900669\n",
      "Batch #10\tAverage Generator Loss: 2363.959625\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17887 (step 17887): 1.287735\n",
      "Batch #10\tAverage Generator Loss: 2547.986829\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17888 (step 17888): 1.292003\n",
      "Batch #10\tAverage Generator Loss: 2391.265381\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17889 (step 17889): 1.321764\n",
      "Batch #10\tAverage Generator Loss: 2799.116003\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17890 (step 17890): 1.908985\n",
      "Batch #10\tAverage Generator Loss: 2609.464868\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17891 (step 17891): 1.448638\n",
      "Batch #10\tAverage Generator Loss: 2367.457080\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #17892 (step 17892): 1.349162\n",
      "Batch #10\tAverage Generator Loss: 2854.383057\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17893 (step 17893): 1.290069\n",
      "Batch #10\tAverage Generator Loss: 2562.368286\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17894 (step 17894): 1.806070\n",
      "Batch #10\tAverage Generator Loss: 2548.386560\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17895 (step 17895): 1.251172\n",
      "Batch #10\tAverage Generator Loss: 2054.077692\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17896 (step 17896): 1.365417\n",
      "Batch #10\tAverage Generator Loss: 2683.409485\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17897 (step 17897): 1.959616\n",
      "Batch #10\tAverage Generator Loss: 2382.590076\tAverage Discriminator Loss: 0.000791\n",
      "\n",
      "Train time for epoch #17898 (step 17898): 1.460645\n",
      "Batch #10\tAverage Generator Loss: 2253.742944\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17899 (step 17899): 1.234296\n",
      "Batch #10\tAverage Generator Loss: 2766.610400\tAverage Discriminator Loss: 0.012481\n",
      "\n",
      "Train time for epoch #17900 (step 17900): 1.328920\n",
      "Batch #10\tAverage Generator Loss: 2429.072864\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17901 (step 17901): 1.840604\n",
      "Batch #10\tAverage Generator Loss: 2665.631128\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17902 (step 17902): 1.338503\n",
      "Batch #10\tAverage Generator Loss: 2367.807886\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17903 (step 17903): 1.338667\n",
      "Batch #10\tAverage Generator Loss: 2662.189087\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17904 (step 17904): 1.899846\n",
      "Batch #10\tAverage Generator Loss: 3071.349170\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17905 (step 17905): 1.297650\n",
      "Batch #10\tAverage Generator Loss: 2550.046521\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17906 (step 17906): 1.410218\n",
      "Batch #10\tAverage Generator Loss: 2400.433209\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17907 (step 17907): 1.353775\n",
      "Batch #10\tAverage Generator Loss: 2823.405322\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17908 (step 17908): 2.044568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2267.665930\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17909 (step 17909): 1.302211\n",
      "Batch #10\tAverage Generator Loss: 2546.241516\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17910 (step 17910): 1.301578\n",
      "Batch #10\tAverage Generator Loss: 2097.879163\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17911 (step 17911): 1.456360\n",
      "Batch #10\tAverage Generator Loss: 2759.729810\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17912 (step 17912): 1.952816\n",
      "Batch #10\tAverage Generator Loss: 2715.980164\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17913 (step 17913): 1.402313\n",
      "Batch #10\tAverage Generator Loss: 2199.581110\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17914 (step 17914): 1.375823\n",
      "Batch #10\tAverage Generator Loss: 2566.740820\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17915 (step 17915): 1.945183\n",
      "Batch #10\tAverage Generator Loss: 2678.213806\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17916 (step 17916): 1.435535\n",
      "Batch #10\tAverage Generator Loss: 2770.071997\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17917 (step 17917): 1.336712\n",
      "Batch #10\tAverage Generator Loss: 2644.596997\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17918 (step 17918): 1.284037\n",
      "Batch #10\tAverage Generator Loss: 2842.245166\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17919 (step 17919): 2.042235\n",
      "Batch #10\tAverage Generator Loss: 2244.956146\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17920 (step 17920): 1.447321\n",
      "Batch #10\tAverage Generator Loss: 2398.311945\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17921 (step 17921): 1.427774\n",
      "Batch #10\tAverage Generator Loss: 2371.195264\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17922 (step 17922): 2.005598\n",
      "Batch #10\tAverage Generator Loss: 2680.857861\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17923 (step 17923): 1.334347\n",
      "Batch #10\tAverage Generator Loss: 2451.812146\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17924 (step 17924): 1.341259\n",
      "Batch #10\tAverage Generator Loss: 2576.573608\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17925 (step 17925): 1.297876\n",
      "Batch #10\tAverage Generator Loss: 2170.233667\tAverage Discriminator Loss: 0.406516\n",
      "\n",
      "Train time for epoch #17926 (step 17926): 1.971152\n",
      "Batch #10\tAverage Generator Loss: 2753.660913\tAverage Discriminator Loss: 0.003393\n",
      "\n",
      "Train time for epoch #17927 (step 17927): 1.346038\n",
      "Batch #10\tAverage Generator Loss: 2643.832056\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17928 (step 17928): 1.392926\n",
      "Batch #10\tAverage Generator Loss: 2122.306152\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17929 (step 17929): 1.376409\n",
      "Batch #10\tAverage Generator Loss: 2355.808722\tAverage Discriminator Loss: 0.000031\n",
      "\n",
      "Train time for epoch #17930 (step 17930): 1.912558\n",
      "Batch #10\tAverage Generator Loss: 2634.798425\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17931 (step 17931): 1.286432\n",
      "Batch #10\tAverage Generator Loss: 2733.888440\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17932 (step 17932): 1.364827\n",
      "Batch #10\tAverage Generator Loss: 2616.497083\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17933 (step 17933): 1.851550\n",
      "Batch #10\tAverage Generator Loss: 2827.877112\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17934 (step 17934): 1.350313\n",
      "Batch #10\tAverage Generator Loss: 2750.756555\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17935 (step 17935): 1.380552\n",
      "Batch #10\tAverage Generator Loss: 2635.880408\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17936 (step 17936): 1.335507\n",
      "Batch #10\tAverage Generator Loss: 2211.472412\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17937 (step 17937): 1.941312\n",
      "Batch #10\tAverage Generator Loss: 2845.142786\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17938 (step 17938): 1.292969\n",
      "Batch #10\tAverage Generator Loss: 2459.288336\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17939 (step 17939): 1.509926\n",
      "Batch #10\tAverage Generator Loss: 2169.265991\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17940 (step 17940): 1.966438\n",
      "Batch #10\tAverage Generator Loss: 3044.291003\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17941 (step 17941): 1.286049\n",
      "Batch #10\tAverage Generator Loss: 2801.662469\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17942 (step 17942): 1.299651\n",
      "Batch #10\tAverage Generator Loss: 2356.541217\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17943 (step 17943): 1.344306\n",
      "Batch #10\tAverage Generator Loss: 2971.536969\tAverage Discriminator Loss: 0.064326\n",
      "\n",
      "Train time for epoch #17944 (step 17944): 1.847245\n",
      "Batch #10\tAverage Generator Loss: 3173.877258\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17945 (step 17945): 1.331434\n",
      "Batch #10\tAverage Generator Loss: 3238.685693\tAverage Discriminator Loss: 0.004264\n",
      "\n",
      "Train time for epoch #17946 (step 17946): 1.394051\n",
      "Batch #10\tAverage Generator Loss: 2122.325500\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #17947 (step 17947): 1.918802\n",
      "Batch #10\tAverage Generator Loss: 2840.070276\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17948 (step 17948): 1.298878\n",
      "Batch #10\tAverage Generator Loss: 2425.947360\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17949 (step 17949): 1.456449\n",
      "Batch #10\tAverage Generator Loss: 2593.268420\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17950 (step 17950): 1.299271\n",
      "Batch #10\tAverage Generator Loss: 3201.673145\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17951 (step 17951): 1.884227\n",
      "Batch #10\tAverage Generator Loss: 2648.191003\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17952 (step 17952): 1.363922\n",
      "Batch #10\tAverage Generator Loss: 2543.078003\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17953 (step 17953): 1.306098\n",
      "Batch #10\tAverage Generator Loss: 2526.602002\tAverage Discriminator Loss: 0.042978\n",
      "\n",
      "Train time for epoch #17954 (step 17954): 1.303101\n",
      "Batch #10\tAverage Generator Loss: 2568.502252\tAverage Discriminator Loss: 0.000031\n",
      "\n",
      "Train time for epoch #17955 (step 17955): 1.932510\n",
      "Batch #10\tAverage Generator Loss: 2384.355865\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17956 (step 17956): 1.301217\n",
      "Batch #10\tAverage Generator Loss: 2612.922144\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17957 (step 17957): 1.254981\n",
      "Batch #10\tAverage Generator Loss: 2727.971399\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17958 (step 17958): 1.362421\n",
      "Batch #10\tAverage Generator Loss: 2990.554614\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17959 (step 17959): 1.916008\n",
      "Batch #10\tAverage Generator Loss: 2077.477954\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17960 (step 17960): 1.392791\n",
      "Batch #10\tAverage Generator Loss: 2541.646680\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17961 (step 17961): 1.383030\n",
      "Batch #10\tAverage Generator Loss: 2568.515204\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17962 (step 17962): 2.010689\n",
      "Batch #10\tAverage Generator Loss: 2005.010425\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17963 (step 17963): 1.340899\n",
      "Batch #10\tAverage Generator Loss: 2189.412683\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17964 (step 17964): 1.349977\n",
      "Batch #10\tAverage Generator Loss: 3251.803638\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17965 (step 17965): 1.337797\n",
      "Batch #10\tAverage Generator Loss: 3286.536926\tAverage Discriminator Loss: 0.052732\n",
      "\n",
      "Train time for epoch #17966 (step 17966): 1.975413\n",
      "Batch #10\tAverage Generator Loss: 2942.143018\tAverage Discriminator Loss: 0.018092\n",
      "\n",
      "Train time for epoch #17967 (step 17967): 1.244795\n",
      "Batch #10\tAverage Generator Loss: 3114.322437\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17968 (step 17968): 1.387568\n",
      "Batch #10\tAverage Generator Loss: 2689.688812\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17969 (step 17969): 2.016386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2469.549554\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17970 (step 17970): 1.285217\n",
      "Batch #10\tAverage Generator Loss: 3014.023279\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17971 (step 17971): 1.287205\n",
      "Batch #10\tAverage Generator Loss: 2818.369580\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17972 (step 17972): 1.287998\n",
      "Batch #10\tAverage Generator Loss: 2848.102991\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17973 (step 17973): 1.986031\n",
      "Batch #10\tAverage Generator Loss: 3080.586841\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17974 (step 17974): 1.293334\n",
      "Batch #10\tAverage Generator Loss: 3940.448492\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17975 (step 17975): 1.287308\n",
      "Batch #10\tAverage Generator Loss: 3266.394226\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17976 (step 17976): 1.848567\n",
      "Batch #10\tAverage Generator Loss: 3167.458252\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17977 (step 17977): 1.385231\n",
      "Batch #10\tAverage Generator Loss: 2572.167511\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17978 (step 17978): 1.289841\n",
      "Batch #10\tAverage Generator Loss: 2854.376282\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17979 (step 17979): 1.389784\n",
      "Batch #10\tAverage Generator Loss: 2824.032074\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17980 (step 17980): 1.927817\n",
      "Batch #10\tAverage Generator Loss: 2644.128992\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17981 (step 17981): 1.307440\n",
      "Batch #10\tAverage Generator Loss: 2542.648602\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17982 (step 17982): 1.338236\n",
      "Batch #10\tAverage Generator Loss: 3014.149036\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17983 (step 17983): 1.395307\n",
      "Batch #10\tAverage Generator Loss: 3091.541943\tAverage Discriminator Loss: 0.048487\n",
      "\n",
      "Train time for epoch #17984 (step 17984): 1.947654\n",
      "Batch #10\tAverage Generator Loss: 2526.763605\tAverage Discriminator Loss: 0.118013\n",
      "\n",
      "Train time for epoch #17985 (step 17985): 1.259693\n",
      "Batch #10\tAverage Generator Loss: 2755.002710\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17986 (step 17986): 1.775246\n",
      "Batch #10\tAverage Generator Loss: 2962.494397\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17987 (step 17987): 1.902370\n",
      "Batch #10\tAverage Generator Loss: 2290.906879\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17988 (step 17988): 1.383800\n",
      "Batch #10\tAverage Generator Loss: 2585.369983\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17989 (step 17989): 1.447305\n",
      "Batch #10\tAverage Generator Loss: 3282.635083\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17990 (step 17990): 1.387283\n",
      "Batch #10\tAverage Generator Loss: 2626.892212\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17991 (step 17991): 1.899986\n",
      "Batch #10\tAverage Generator Loss: 2704.214319\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17992 (step 17992): 1.623330\n",
      "Batch #10\tAverage Generator Loss: 2811.677563\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #17993 (step 17993): 1.266151\n",
      "Batch #10\tAverage Generator Loss: 2901.106177\tAverage Discriminator Loss: 0.000051\n",
      "\n",
      "Train time for epoch #17994 (step 17994): 1.248330\n",
      "Batch #10\tAverage Generator Loss: 2704.721265\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #17995 (step 17995): 1.945312\n",
      "Batch #10\tAverage Generator Loss: 2847.993127\tAverage Discriminator Loss: 0.373988\n",
      "\n",
      "Train time for epoch #17996 (step 17996): 1.237741\n",
      "Batch #10\tAverage Generator Loss: 2674.623608\tAverage Discriminator Loss: 0.005049\n",
      "\n",
      "Train time for epoch #17997 (step 17997): 1.340509\n",
      "Batch #10\tAverage Generator Loss: 2143.416467\tAverage Discriminator Loss: 0.000024\n",
      "\n",
      "Train time for epoch #17998 (step 17998): 1.895416\n",
      "Batch #10\tAverage Generator Loss: 2367.727649\tAverage Discriminator Loss: 0.000027\n",
      "\n",
      "Train time for epoch #17999 (step 17999): 1.300649\n",
      "Batch #10\tAverage Generator Loss: 2301.241858\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #18000 (step 18000): 1.296354\n",
      "Batch #10\tAverage Generator Loss: 1999.424902\tAverage Discriminator Loss: 0.000023\n",
      "\n",
      "Train time for epoch #18001 (step 18001): 1.321923\n",
      "Batch #10\tAverage Generator Loss: 2116.202429\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #18002 (step 18002): 1.899475\n",
      "Batch #10\tAverage Generator Loss: 2166.344971\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #18003 (step 18003): 1.300162\n",
      "Batch #10\tAverage Generator Loss: 2357.397021\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #18004 (step 18004): 1.281104\n",
      "Batch #10\tAverage Generator Loss: 1916.063831\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #18005 (step 18005): 1.912634\n",
      "Batch #10\tAverage Generator Loss: 2279.142883\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #18006 (step 18006): 1.312876\n",
      "Batch #10\tAverage Generator Loss: 1911.631836\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #18007 (step 18007): 1.393553\n",
      "Batch #10\tAverage Generator Loss: 2344.765637\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #18008 (step 18008): 1.287965\n",
      "Batch #10\tAverage Generator Loss: 2052.395532\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #18009 (step 18009): 1.867148\n",
      "Batch #10\tAverage Generator Loss: 2367.703003\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #18010 (step 18010): 1.348138\n",
      "Batch #10\tAverage Generator Loss: 2422.797949\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #18011 (step 18011): 1.289492\n",
      "Batch #10\tAverage Generator Loss: 2292.649597\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #18012 (step 18012): 1.945261\n",
      "Batch #10\tAverage Generator Loss: 2093.585767\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #18013 (step 18013): 1.388543\n",
      "Batch #10\tAverage Generator Loss: 1680.787866\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #18014 (step 18014): 1.251656\n",
      "Batch #10\tAverage Generator Loss: 2353.985400\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #18015 (step 18015): 1.389235\n",
      "Batch #10\tAverage Generator Loss: 2394.835596\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #18016 (step 18016): 1.925293\n",
      "Batch #10\tAverage Generator Loss: 2256.867236\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #18017 (step 18017): 1.337809\n",
      "Batch #10\tAverage Generator Loss: 2259.447632\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #18018 (step 18018): 1.404406\n",
      "Batch #10\tAverage Generator Loss: 2123.200549\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #18019 (step 18019): 1.913797\n",
      "Batch #10\tAverage Generator Loss: 2083.733435\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #18020 (step 18020): 1.277150\n",
      "Batch #10\tAverage Generator Loss: 2341.908289\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #18021 (step 18021): 1.376557\n",
      "Batch #10\tAverage Generator Loss: 2299.148877\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #18022 (step 18022): 1.301083\n",
      "Batch #10\tAverage Generator Loss: 2349.844763\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #18023 (step 18023): 1.912959\n",
      "Batch #10\tAverage Generator Loss: 2166.967273\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #18024 (step 18024): 1.449057\n",
      "Batch #10\tAverage Generator Loss: 2164.687671\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #18025 (step 18025): 1.278155\n",
      "Batch #10\tAverage Generator Loss: 1962.992334\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #18026 (step 18026): 1.238473\n",
      "Batch #10\tAverage Generator Loss: 2355.993787\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #18027 (step 18027): 1.880342\n",
      "Batch #10\tAverage Generator Loss: 2154.944165\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #18028 (step 18028): 1.413998\n",
      "Batch #10\tAverage Generator Loss: 2392.756274\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #18029 (step 18029): 1.333913\n",
      "Batch #10\tAverage Generator Loss: 1985.392767\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #18030 (step 18030): 1.837739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2176.266010\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #18031 (step 18031): 1.352579\n",
      "Batch #10\tAverage Generator Loss: 2263.791577\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #18032 (step 18032): 1.291288\n",
      "Batch #10\tAverage Generator Loss: 2460.849646\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #18033 (step 18033): 1.310619\n",
      "Batch #10\tAverage Generator Loss: 2345.334302\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #18034 (step 18034): 1.856004\n",
      "Batch #10\tAverage Generator Loss: 2005.707605\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #18035 (step 18035): 1.290800\n",
      "Batch #10\tAverage Generator Loss: 2298.474335\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #18036 (step 18036): 1.352588\n",
      "Batch #10\tAverage Generator Loss: 2435.165979\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #18037 (step 18037): 1.330579\n",
      "Batch #10\tAverage Generator Loss: 2034.021594\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #18038 (step 18038): 1.955242\n",
      "Batch #10\tAverage Generator Loss: 2074.961157\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #18039 (step 18039): 1.282262\n",
      "Batch #10\tAverage Generator Loss: 2030.567981\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #18040 (step 18040): 1.338111\n",
      "Batch #10\tAverage Generator Loss: 1942.390967\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #18041 (step 18041): 1.278273\n",
      "Batch #10\tAverage Generator Loss: 2271.014612\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #18042 (step 18042): 1.893441\n",
      "Batch #10\tAverage Generator Loss: 2064.218042\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #18043 (step 18043): 1.379257\n",
      "Batch #10\tAverage Generator Loss: 2130.269373\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18044 (step 18044): 1.350086\n",
      "Batch #10\tAverage Generator Loss: 2093.370569\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18045 (step 18045): 1.911075\n",
      "Batch #10\tAverage Generator Loss: 2242.466357\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #18046 (step 18046): 1.363947\n",
      "Batch #10\tAverage Generator Loss: 2289.019714\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #18047 (step 18047): 1.336710\n",
      "Batch #10\tAverage Generator Loss: 2130.685779\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #18048 (step 18048): 1.419270\n",
      "Batch #10\tAverage Generator Loss: 1976.767621\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #18049 (step 18049): 1.949434\n",
      "Batch #10\tAverage Generator Loss: 1778.702710\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #18050 (step 18050): 1.395578\n",
      "Batch #10\tAverage Generator Loss: 2498.855609\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #18051 (step 18051): 1.317740\n",
      "Batch #10\tAverage Generator Loss: 2303.965784\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #18052 (step 18052): 1.873622\n",
      "Batch #10\tAverage Generator Loss: 2338.737378\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #18053 (step 18053): 1.328858\n",
      "Batch #10\tAverage Generator Loss: 2211.156189\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #18054 (step 18054): 1.327215\n",
      "Batch #10\tAverage Generator Loss: 2242.526123\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #18055 (step 18055): 1.240401\n",
      "Batch #10\tAverage Generator Loss: 2163.131787\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #18056 (step 18056): 1.786931\n",
      "Batch #10\tAverage Generator Loss: 2102.989160\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #18057 (step 18057): 1.298895\n",
      "Batch #10\tAverage Generator Loss: 2254.953308\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #18058 (step 18058): 1.350237\n",
      "Batch #10\tAverage Generator Loss: 2070.663727\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #18059 (step 18059): 1.373086\n",
      "Batch #10\tAverage Generator Loss: 1782.739641\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #18060 (step 18060): 1.988269\n",
      "Batch #10\tAverage Generator Loss: 2173.894739\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #18061 (step 18061): 1.333624\n",
      "Batch #10\tAverage Generator Loss: 2225.578455\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #18062 (step 18062): 1.427638\n",
      "Batch #10\tAverage Generator Loss: 2153.744495\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #18063 (step 18063): 1.837956\n",
      "Batch #10\tAverage Generator Loss: 2073.378308\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #18064 (step 18064): 1.296116\n",
      "Batch #10\tAverage Generator Loss: 2071.324695\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #18065 (step 18065): 1.617966\n",
      "Batch #10\tAverage Generator Loss: 2147.338208\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #18066 (step 18066): 1.284836\n",
      "Batch #10\tAverage Generator Loss: 2245.745331\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #18067 (step 18067): 1.965975\n",
      "Batch #10\tAverage Generator Loss: 2317.700525\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18068 (step 18068): 1.346719\n",
      "Batch #10\tAverage Generator Loss: 2271.969458\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18069 (step 18069): 1.290611\n",
      "Batch #10\tAverage Generator Loss: 1893.613245\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #18070 (step 18070): 1.891442\n",
      "Batch #10\tAverage Generator Loss: 2166.456274\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #18071 (step 18071): 1.386265\n",
      "Batch #10\tAverage Generator Loss: 1903.898181\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18072 (step 18072): 1.295519\n",
      "Batch #10\tAverage Generator Loss: 2505.332227\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #18073 (step 18073): 1.300165\n",
      "Batch #10\tAverage Generator Loss: 2420.171082\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18074 (step 18074): 1.980982\n",
      "Batch #10\tAverage Generator Loss: 2575.158789\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #18075 (step 18075): 1.344937\n",
      "Batch #10\tAverage Generator Loss: 2305.078467\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #18076 (step 18076): 1.402522\n",
      "Batch #10\tAverage Generator Loss: 2406.902905\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18077 (step 18077): 1.901098\n",
      "Batch #10\tAverage Generator Loss: 2008.432373\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18078 (step 18078): 1.408745\n",
      "Batch #10\tAverage Generator Loss: 2300.363306\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18079 (step 18079): 1.404528\n",
      "Batch #10\tAverage Generator Loss: 2203.590759\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18080 (step 18080): 1.421776\n",
      "Batch #10\tAverage Generator Loss: 2319.525061\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18081 (step 18081): 1.942420\n",
      "Batch #10\tAverage Generator Loss: 2289.033447\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #18082 (step 18082): 1.353361\n",
      "Batch #10\tAverage Generator Loss: 1877.966736\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #18083 (step 18083): 1.437231\n",
      "Batch #10\tAverage Generator Loss: 2073.438953\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18084 (step 18084): 1.484898\n",
      "Batch #10\tAverage Generator Loss: 2360.104541\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18085 (step 18085): 1.970339\n",
      "Batch #10\tAverage Generator Loss: 2197.691223\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18086 (step 18086): 1.331656\n",
      "Batch #10\tAverage Generator Loss: 2026.848840\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18087 (step 18087): 1.390262\n",
      "Batch #10\tAverage Generator Loss: 2028.921564\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18088 (step 18088): 1.924579\n",
      "Batch #10\tAverage Generator Loss: 1831.204993\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18089 (step 18089): 1.359823\n",
      "Batch #10\tAverage Generator Loss: 2370.183850\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18090 (step 18090): 1.332103\n",
      "Batch #10\tAverage Generator Loss: 2304.604034\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18091 (step 18091): 1.302030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2438.827917\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18092 (step 18092): 1.850885\n",
      "Batch #10\tAverage Generator Loss: 2330.095508\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18093 (step 18093): 1.416451\n",
      "Batch #10\tAverage Generator Loss: 1992.424115\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18094 (step 18094): 1.325793\n",
      "Batch #10\tAverage Generator Loss: 2076.532690\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18095 (step 18095): 1.284532\n",
      "Batch #10\tAverage Generator Loss: 2208.492981\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18096 (step 18096): 1.839505\n",
      "Batch #10\tAverage Generator Loss: 2135.057837\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18097 (step 18097): 1.387236\n",
      "Batch #10\tAverage Generator Loss: 2621.826611\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18098 (step 18098): 1.340592\n",
      "Batch #10\tAverage Generator Loss: 2013.040582\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18099 (step 18099): 1.917682\n",
      "Batch #10\tAverage Generator Loss: 2338.479700\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18100 (step 18100): 1.292231\n",
      "Batch #10\tAverage Generator Loss: 2268.946130\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18101 (step 18101): 1.327364\n",
      "Batch #10\tAverage Generator Loss: 2278.551099\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18102 (step 18102): 1.292578\n",
      "Batch #10\tAverage Generator Loss: 2109.570715\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18103 (step 18103): 1.990497\n",
      "Batch #10\tAverage Generator Loss: 2077.609546\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18104 (step 18104): 1.297855\n",
      "Batch #10\tAverage Generator Loss: 2636.762305\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18105 (step 18105): 1.435171\n",
      "Batch #10\tAverage Generator Loss: 2360.074988\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18106 (step 18106): 1.932472\n",
      "Batch #10\tAverage Generator Loss: 2182.669324\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18107 (step 18107): 1.307877\n",
      "Batch #10\tAverage Generator Loss: 2322.059509\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18108 (step 18108): 1.304026\n",
      "Batch #10\tAverage Generator Loss: 1628.096088\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18109 (step 18109): 1.378406\n",
      "Batch #10\tAverage Generator Loss: 2433.430054\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18110 (step 18110): 1.906917\n",
      "Batch #10\tAverage Generator Loss: 2066.722705\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18111 (step 18111): 1.368321\n",
      "Batch #10\tAverage Generator Loss: 2135.217578\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18112 (step 18112): 1.390399\n",
      "Batch #10\tAverage Generator Loss: 2046.533643\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18113 (step 18113): 1.307342\n",
      "Batch #10\tAverage Generator Loss: 2105.919788\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18114 (step 18114): 2.062949\n",
      "Batch #10\tAverage Generator Loss: 2348.821667\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18115 (step 18115): 1.293607\n",
      "Batch #10\tAverage Generator Loss: 2217.222595\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18116 (step 18116): 1.352079\n",
      "Batch #10\tAverage Generator Loss: 2229.565155\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18117 (step 18117): 1.926961\n",
      "Batch #10\tAverage Generator Loss: 2125.139111\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18118 (step 18118): 1.362411\n",
      "Batch #10\tAverage Generator Loss: 2381.079553\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18119 (step 18119): 1.333830\n",
      "Batch #10\tAverage Generator Loss: 2163.237207\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18120 (step 18120): 1.304285\n",
      "Batch #10\tAverage Generator Loss: 1984.761938\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18121 (step 18121): 1.976752\n",
      "Batch #10\tAverage Generator Loss: 2230.316089\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18122 (step 18122): 1.528616\n",
      "Batch #10\tAverage Generator Loss: 1928.919934\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18123 (step 18123): 1.385957\n",
      "Batch #10\tAverage Generator Loss: 2394.506348\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18124 (step 18124): 1.335212\n",
      "Batch #10\tAverage Generator Loss: 2173.167236\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18125 (step 18125): 1.964001\n",
      "Batch #10\tAverage Generator Loss: 2313.180664\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18126 (step 18126): 1.229715\n",
      "Batch #10\tAverage Generator Loss: 2219.934180\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18127 (step 18127): 1.292813\n",
      "Batch #10\tAverage Generator Loss: 2215.680963\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18128 (step 18128): 1.897319\n",
      "Batch #10\tAverage Generator Loss: 2300.132050\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18129 (step 18129): 1.277560\n",
      "Batch #10\tAverage Generator Loss: 2324.134167\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18130 (step 18130): 1.299954\n",
      "Batch #10\tAverage Generator Loss: 2272.724530\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18131 (step 18131): 1.288641\n",
      "Batch #10\tAverage Generator Loss: 2205.774695\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18132 (step 18132): 1.864965\n",
      "Batch #10\tAverage Generator Loss: 2293.876245\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18133 (step 18133): 1.400891\n",
      "Batch #10\tAverage Generator Loss: 2264.910876\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18134 (step 18134): 1.409312\n",
      "Batch #10\tAverage Generator Loss: 2092.491241\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18135 (step 18135): 1.386793\n",
      "Batch #10\tAverage Generator Loss: 2061.382544\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18136 (step 18136): 1.844767\n",
      "Batch #10\tAverage Generator Loss: 2216.110828\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18137 (step 18137): 1.324743\n",
      "Batch #10\tAverage Generator Loss: 2240.538086\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18138 (step 18138): 1.298768\n",
      "Batch #10\tAverage Generator Loss: 2509.079883\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18139 (step 18139): 1.842335\n",
      "Batch #10\tAverage Generator Loss: 2617.348535\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18140 (step 18140): 1.288045\n",
      "Batch #10\tAverage Generator Loss: 2381.942346\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18141 (step 18141): 1.388088\n",
      "Batch #10\tAverage Generator Loss: 2128.440448\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18142 (step 18142): 1.292334\n",
      "Batch #10\tAverage Generator Loss: 2366.025043\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18143 (step 18143): 1.924596\n",
      "Batch #10\tAverage Generator Loss: 2316.048413\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18144 (step 18144): 1.332882\n",
      "Batch #10\tAverage Generator Loss: 2185.551111\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18145 (step 18145): 1.403445\n",
      "Batch #10\tAverage Generator Loss: 2389.075806\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18146 (step 18146): 1.341639\n",
      "Batch #10\tAverage Generator Loss: 2384.002588\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18147 (step 18147): 1.906692\n",
      "Batch #10\tAverage Generator Loss: 2320.304053\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18148 (step 18148): 1.294349\n",
      "Batch #10\tAverage Generator Loss: 2208.275439\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18149 (step 18149): 1.287252\n",
      "Batch #10\tAverage Generator Loss: 2001.401379\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18150 (step 18150): 1.974342\n",
      "Batch #10\tAverage Generator Loss: 2289.446851\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18151 (step 18151): 1.332228\n",
      "Batch #10\tAverage Generator Loss: 2463.294470\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18152 (step 18152): 1.353671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2169.393457\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18153 (step 18153): 1.339072\n",
      "Batch #10\tAverage Generator Loss: 2409.725366\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18154 (step 18154): 1.897095\n",
      "Batch #10\tAverage Generator Loss: 2104.172131\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18155 (step 18155): 1.286301\n",
      "Batch #10\tAverage Generator Loss: 2017.758716\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18156 (step 18156): 1.436556\n",
      "Batch #10\tAverage Generator Loss: 2220.842877\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18157 (step 18157): 1.986740\n",
      "Batch #10\tAverage Generator Loss: 2118.743103\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18158 (step 18158): 1.455480\n",
      "Batch #10\tAverage Generator Loss: 2349.536279\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18159 (step 18159): 1.407022\n",
      "Batch #10\tAverage Generator Loss: 1936.701941\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18160 (step 18160): 1.297836\n",
      "Batch #10\tAverage Generator Loss: 2019.715771\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18161 (step 18161): 2.013648\n",
      "Batch #10\tAverage Generator Loss: 2243.652844\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18162 (step 18162): 2.421314\n",
      "Batch #10\tAverage Generator Loss: 2257.282825\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18163 (step 18163): 1.587668\n",
      "Batch #10\tAverage Generator Loss: 2360.989429\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18164 (step 18164): 1.280438\n",
      "Batch #10\tAverage Generator Loss: 2144.510864\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18165 (step 18165): 2.311754\n",
      "Batch #10\tAverage Generator Loss: 2467.186365\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18166 (step 18166): 1.269313\n",
      "Batch #10\tAverage Generator Loss: 2451.030493\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18167 (step 18167): 1.316265\n",
      "Batch #10\tAverage Generator Loss: 2097.999036\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18168 (step 18168): 4.376739\n",
      "Batch #10\tAverage Generator Loss: 2542.448792\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18169 (step 18169): 1.685384\n",
      "Batch #10\tAverage Generator Loss: 2134.980804\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18170 (step 18170): 1.293181\n",
      "Batch #10\tAverage Generator Loss: 2379.608228\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18171 (step 18171): 1.523970\n",
      "Batch #10\tAverage Generator Loss: 2205.305237\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18172 (step 18172): 2.260319\n",
      "Batch #10\tAverage Generator Loss: 1598.931866\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18173 (step 18173): 1.291930\n",
      "Batch #10\tAverage Generator Loss: 1987.517273\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18174 (step 18174): 1.290479\n",
      "Batch #10\tAverage Generator Loss: 2318.490417\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18175 (step 18175): 1.389138\n",
      "Batch #10\tAverage Generator Loss: 2297.199475\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18176 (step 18176): 2.107112\n",
      "Batch #10\tAverage Generator Loss: 2153.416296\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18177 (step 18177): 1.287992\n",
      "Batch #10\tAverage Generator Loss: 2173.689996\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18178 (step 18178): 1.719143\n",
      "Batch #10\tAverage Generator Loss: 2053.900317\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18179 (step 18179): 3.322149\n",
      "Batch #10\tAverage Generator Loss: 2005.484875\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18180 (step 18180): 1.389970\n",
      "Batch #10\tAverage Generator Loss: 2057.967322\tAverage Discriminator Loss: 0.060996\n",
      "\n",
      "Train time for epoch #18181 (step 18181): 1.400098\n",
      "Batch #10\tAverage Generator Loss: 2744.820667\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18182 (step 18182): 1.375898\n",
      "Batch #10\tAverage Generator Loss: 2480.030627\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18183 (step 18183): 2.212173\n",
      "Batch #10\tAverage Generator Loss: 2742.900916\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18184 (step 18184): 1.276912\n",
      "Batch #10\tAverage Generator Loss: 3220.321680\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18185 (step 18185): 1.334785\n",
      "Batch #10\tAverage Generator Loss: 3169.799817\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18186 (step 18186): 1.271741\n",
      "Batch #10\tAverage Generator Loss: 2822.666541\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18187 (step 18187): 1.909094\n",
      "Batch #10\tAverage Generator Loss: 2541.011450\tAverage Discriminator Loss: 0.034638\n",
      "\n",
      "Train time for epoch #18188 (step 18188): 1.357580\n",
      "Batch #10\tAverage Generator Loss: 2488.725726\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18189 (step 18189): 1.331800\n",
      "Batch #10\tAverage Generator Loss: 2299.501709\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18190 (step 18190): 1.897385\n",
      "Batch #10\tAverage Generator Loss: 2562.115784\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18191 (step 18191): 1.302845\n",
      "Batch #10\tAverage Generator Loss: 2321.830664\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18192 (step 18192): 1.362988\n",
      "Batch #10\tAverage Generator Loss: 2421.318445\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18193 (step 18193): 1.347146\n",
      "Batch #10\tAverage Generator Loss: 3131.109045\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18194 (step 18194): 1.956137\n",
      "Batch #10\tAverage Generator Loss: 2118.513361\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18195 (step 18195): 1.345371\n",
      "Batch #10\tAverage Generator Loss: 2522.346375\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18196 (step 18196): 1.390502\n",
      "Batch #10\tAverage Generator Loss: 2294.281213\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18197 (step 18197): 1.281332\n",
      "Batch #10\tAverage Generator Loss: 2815.682971\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18198 (step 18198): 1.931305\n",
      "Batch #10\tAverage Generator Loss: 2202.124976\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18199 (step 18199): 1.387040\n",
      "Batch #10\tAverage Generator Loss: 2328.371985\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18200 (step 18200): 1.381298\n",
      "Batch #10\tAverage Generator Loss: 2492.449609\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18201 (step 18201): 1.953675\n",
      "Batch #10\tAverage Generator Loss: 2727.024548\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18202 (step 18202): 1.390437\n",
      "Batch #10\tAverage Generator Loss: 2493.576172\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18203 (step 18203): 1.314837\n",
      "Batch #10\tAverage Generator Loss: 2467.833582\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18204 (step 18204): 1.394429\n",
      "Batch #10\tAverage Generator Loss: 2272.476733\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18205 (step 18205): 1.897163\n",
      "Batch #10\tAverage Generator Loss: 2599.399878\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18206 (step 18206): 1.292233\n",
      "Batch #10\tAverage Generator Loss: 2739.733105\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18207 (step 18207): 1.454095\n",
      "Batch #10\tAverage Generator Loss: 2275.356970\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18208 (step 18208): 1.327325\n",
      "Batch #10\tAverage Generator Loss: 2499.100720\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18209 (step 18209): 1.906484\n",
      "Batch #10\tAverage Generator Loss: 2613.779602\tAverage Discriminator Loss: 0.010869\n",
      "\n",
      "Train time for epoch #18210 (step 18210): 1.379424\n",
      "Batch #10\tAverage Generator Loss: 2509.344202\tAverage Discriminator Loss: 0.000150\n",
      "\n",
      "Train time for epoch #18211 (step 18211): 1.368963\n",
      "Batch #10\tAverage Generator Loss: 2126.319116\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #18212 (step 18212): 1.904134\n",
      "Batch #10\tAverage Generator Loss: 2385.191504\tAverage Discriminator Loss: 0.000034\n",
      "\n",
      "Train time for epoch #18213 (step 18213): 1.371465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2345.651428\tAverage Discriminator Loss: 0.000020\n",
      "\n",
      "Train time for epoch #18214 (step 18214): 1.359284\n",
      "Batch #10\tAverage Generator Loss: 2292.518915\tAverage Discriminator Loss: 0.000057\n",
      "\n",
      "Train time for epoch #18215 (step 18215): 1.286630\n",
      "Batch #10\tAverage Generator Loss: 2515.778113\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #18216 (step 18216): 1.970763\n",
      "Batch #10\tAverage Generator Loss: 2368.352655\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #18217 (step 18217): 1.341611\n",
      "Batch #10\tAverage Generator Loss: 2245.672693\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #18218 (step 18218): 1.351797\n",
      "Batch #10\tAverage Generator Loss: 2322.150763\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18219 (step 18219): 1.331780\n",
      "Batch #10\tAverage Generator Loss: 2270.537573\tAverage Discriminator Loss: 0.000399\n",
      "\n",
      "Train time for epoch #18220 (step 18220): 1.902321\n",
      "Batch #10\tAverage Generator Loss: 1886.469110\tAverage Discriminator Loss: 0.000033\n",
      "\n",
      "Train time for epoch #18221 (step 18221): 1.384749\n",
      "Batch #10\tAverage Generator Loss: 2274.481677\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #18222 (step 18222): 1.285683\n",
      "Batch #10\tAverage Generator Loss: 2248.013367\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #18223 (step 18223): 1.855890\n",
      "Batch #10\tAverage Generator Loss: 2225.174963\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #18224 (step 18224): 1.342119\n",
      "Batch #10\tAverage Generator Loss: 2693.360181\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #18225 (step 18225): 1.291150\n",
      "Batch #10\tAverage Generator Loss: 2204.476562\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #18226 (step 18226): 1.416523\n",
      "Batch #10\tAverage Generator Loss: 2393.394116\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #18227 (step 18227): 1.884192\n",
      "Batch #10\tAverage Generator Loss: 2824.850281\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18228 (step 18228): 1.332436\n",
      "Batch #10\tAverage Generator Loss: 2457.268372\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18229 (step 18229): 1.378940\n",
      "Batch #10\tAverage Generator Loss: 2056.116138\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #18230 (step 18230): 1.405457\n",
      "Batch #10\tAverage Generator Loss: 2210.935779\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18231 (step 18231): 1.958805\n",
      "Batch #10\tAverage Generator Loss: 2329.109741\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18232 (step 18232): 1.334116\n",
      "Batch #10\tAverage Generator Loss: 2441.773035\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18233 (step 18233): 1.340106\n",
      "Batch #10\tAverage Generator Loss: 2304.529529\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18234 (step 18234): 1.885872\n",
      "Batch #10\tAverage Generator Loss: 2502.887720\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18235 (step 18235): 1.316246\n",
      "Batch #10\tAverage Generator Loss: 2237.528162\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18236 (step 18236): 1.338657\n",
      "Batch #10\tAverage Generator Loss: 2051.913239\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18237 (step 18237): 1.349785\n",
      "Batch #10\tAverage Generator Loss: 2211.663757\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18238 (step 18238): 1.916542\n",
      "Batch #10\tAverage Generator Loss: 2297.623914\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18239 (step 18239): 1.279012\n",
      "Batch #10\tAverage Generator Loss: 2110.504309\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18240 (step 18240): 1.369107\n",
      "Batch #10\tAverage Generator Loss: 2667.997009\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18241 (step 18241): 1.325953\n",
      "Batch #10\tAverage Generator Loss: 2092.814612\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18242 (step 18242): 1.949529\n",
      "Batch #10\tAverage Generator Loss: 2201.985376\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18243 (step 18243): 1.344160\n",
      "Batch #10\tAverage Generator Loss: 2299.215051\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18244 (step 18244): 1.479517\n",
      "Batch #10\tAverage Generator Loss: 2460.346387\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18245 (step 18245): 1.912096\n",
      "Batch #10\tAverage Generator Loss: 2355.707202\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18246 (step 18246): 1.308877\n",
      "Batch #10\tAverage Generator Loss: 2183.144177\tAverage Discriminator Loss: 0.021680\n",
      "\n",
      "Train time for epoch #18247 (step 18247): 1.255730\n",
      "Batch #10\tAverage Generator Loss: 2609.420508\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18248 (step 18248): 1.299108\n",
      "Batch #10\tAverage Generator Loss: 2202.740106\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18249 (step 18249): 2.028716\n",
      "Batch #10\tAverage Generator Loss: 2248.329639\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18250 (step 18250): 1.275575\n",
      "Batch #10\tAverage Generator Loss: 2560.100000\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18251 (step 18251): 1.335264\n",
      "Batch #10\tAverage Generator Loss: 2622.000671\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18252 (step 18252): 1.324054\n",
      "Batch #10\tAverage Generator Loss: 2290.062158\tAverage Discriminator Loss: 0.000019\n",
      "\n",
      "Train time for epoch #18253 (step 18253): 1.851505\n",
      "Batch #10\tAverage Generator Loss: 2309.462891\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18254 (step 18254): 1.348305\n",
      "Batch #10\tAverage Generator Loss: 2229.891467\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18255 (step 18255): 1.287452\n",
      "Batch #10\tAverage Generator Loss: 2304.574414\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18256 (step 18256): 1.299461\n",
      "Batch #10\tAverage Generator Loss: 2253.876489\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18257 (step 18257): 1.946167\n",
      "Batch #10\tAverage Generator Loss: 2754.046558\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18258 (step 18258): 1.376409\n",
      "Batch #10\tAverage Generator Loss: 2414.531287\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18259 (step 18259): 1.274954\n",
      "Batch #10\tAverage Generator Loss: 2429.301160\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18260 (step 18260): 1.933950\n",
      "Batch #10\tAverage Generator Loss: 2831.082397\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18261 (step 18261): 1.395181\n",
      "Batch #10\tAverage Generator Loss: 2524.339417\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18262 (step 18262): 1.327242\n",
      "Batch #10\tAverage Generator Loss: 2501.169312\tAverage Discriminator Loss: 0.020857\n",
      "\n",
      "Train time for epoch #18263 (step 18263): 1.423515\n",
      "Batch #10\tAverage Generator Loss: 2165.794513\tAverage Discriminator Loss: 0.117247\n",
      "\n",
      "Train time for epoch #18264 (step 18264): 1.889034\n",
      "Batch #10\tAverage Generator Loss: 2025.746350\tAverage Discriminator Loss: 0.021387\n",
      "\n",
      "Train time for epoch #18265 (step 18265): 1.422027\n",
      "Batch #10\tAverage Generator Loss: 1831.169617\tAverage Discriminator Loss: 0.000036\n",
      "\n",
      "Train time for epoch #18266 (step 18266): 1.377259\n",
      "Batch #10\tAverage Generator Loss: 1849.121796\tAverage Discriminator Loss: 0.000044\n",
      "\n",
      "Train time for epoch #18267 (step 18267): 1.882457\n",
      "Batch #10\tAverage Generator Loss: 1905.736035\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #18268 (step 18268): 1.384876\n",
      "Batch #10\tAverage Generator Loss: 2170.483624\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #18269 (step 18269): 1.340689\n",
      "Batch #10\tAverage Generator Loss: 1560.847424\tAverage Discriminator Loss: 0.026714\n",
      "\n",
      "Train time for epoch #18270 (step 18270): 1.410805\n",
      "Batch #10\tAverage Generator Loss: 2162.423743\tAverage Discriminator Loss: 0.000147\n",
      "\n",
      "Train time for epoch #18271 (step 18271): 1.907646\n",
      "Batch #10\tAverage Generator Loss: 1992.597693\tAverage Discriminator Loss: 0.000131\n",
      "\n",
      "Train time for epoch #18272 (step 18272): 1.302010\n",
      "Batch #10\tAverage Generator Loss: 2024.025641\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #18273 (step 18273): 1.367683\n",
      "Batch #10\tAverage Generator Loss: 2400.311951\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #18274 (step 18274): 1.453918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2112.206653\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #18275 (step 18275): 1.949078\n",
      "Batch #10\tAverage Generator Loss: 2159.955841\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18276 (step 18276): 1.334569\n",
      "Batch #10\tAverage Generator Loss: 2273.913306\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18277 (step 18277): 1.418443\n",
      "Batch #10\tAverage Generator Loss: 2434.410486\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #18278 (step 18278): 1.852790\n",
      "Batch #10\tAverage Generator Loss: 2253.434595\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #18279 (step 18279): 1.278402\n",
      "Batch #10\tAverage Generator Loss: 1936.327307\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #18280 (step 18280): 1.305921\n",
      "Batch #10\tAverage Generator Loss: 2032.595667\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #18281 (step 18281): 1.330173\n",
      "Batch #10\tAverage Generator Loss: 1921.139636\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18282 (step 18282): 1.907065\n",
      "Batch #10\tAverage Generator Loss: 2189.402136\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18283 (step 18283): 1.379963\n",
      "Batch #10\tAverage Generator Loss: 2051.334412\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18284 (step 18284): 1.325185\n",
      "Batch #10\tAverage Generator Loss: 2261.321985\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18285 (step 18285): 1.451656\n",
      "Batch #10\tAverage Generator Loss: 2228.752881\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18286 (step 18286): 1.988728\n",
      "Batch #10\tAverage Generator Loss: 2279.762341\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18287 (step 18287): 1.341654\n",
      "Batch #10\tAverage Generator Loss: 2060.038391\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18288 (step 18288): 1.280470\n",
      "Batch #10\tAverage Generator Loss: 2064.269299\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18289 (step 18289): 1.933472\n",
      "Batch #10\tAverage Generator Loss: 2114.893127\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18290 (step 18290): 1.340360\n",
      "Batch #10\tAverage Generator Loss: 1840.659332\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18291 (step 18291): 1.243475\n",
      "Batch #10\tAverage Generator Loss: 2189.177637\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18292 (step 18292): 1.389080\n",
      "Batch #10\tAverage Generator Loss: 2143.352100\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18293 (step 18293): 1.889599\n",
      "Batch #10\tAverage Generator Loss: 1922.635498\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18294 (step 18294): 1.390198\n",
      "Batch #10\tAverage Generator Loss: 2067.705859\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18295 (step 18295): 1.461765\n",
      "Batch #10\tAverage Generator Loss: 2068.394714\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18296 (step 18296): 1.341851\n",
      "Batch #10\tAverage Generator Loss: 2102.847925\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18297 (step 18297): 2.007070\n",
      "Batch #10\tAverage Generator Loss: 1801.632245\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18298 (step 18298): 1.293111\n",
      "Batch #10\tAverage Generator Loss: 2164.847583\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18299 (step 18299): 1.359871\n",
      "Batch #10\tAverage Generator Loss: 2017.092816\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18300 (step 18300): 1.373899\n",
      "Batch #10\tAverage Generator Loss: 2015.393085\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18301 (step 18301): 1.882601\n",
      "Batch #10\tAverage Generator Loss: 2005.183972\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18302 (step 18302): 1.332861\n",
      "Batch #10\tAverage Generator Loss: 2265.845752\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18303 (step 18303): 1.339718\n",
      "Batch #10\tAverage Generator Loss: 2505.484033\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18304 (step 18304): 1.850085\n",
      "Batch #10\tAverage Generator Loss: 2193.964502\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18305 (step 18305): 1.340528\n",
      "Batch #10\tAverage Generator Loss: 2158.772021\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18306 (step 18306): 1.334582\n",
      "Batch #10\tAverage Generator Loss: 2244.780627\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18307 (step 18307): 1.297999\n",
      "Batch #10\tAverage Generator Loss: 2255.866602\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18308 (step 18308): 1.902483\n",
      "Batch #10\tAverage Generator Loss: 1909.814905\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18309 (step 18309): 1.375604\n",
      "Batch #10\tAverage Generator Loss: 2171.156213\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18310 (step 18310): 1.333149\n",
      "Batch #10\tAverage Generator Loss: 2215.762598\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18311 (step 18311): 1.294354\n",
      "Batch #10\tAverage Generator Loss: 2064.571851\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18312 (step 18312): 1.914990\n",
      "Batch #10\tAverage Generator Loss: 2201.981580\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18313 (step 18313): 1.339340\n",
      "Batch #10\tAverage Generator Loss: 2241.464478\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18314 (step 18314): 1.339047\n",
      "Batch #10\tAverage Generator Loss: 2010.670789\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18315 (step 18315): 1.965947\n",
      "Batch #10\tAverage Generator Loss: 2209.951367\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18316 (step 18316): 1.296338\n",
      "Batch #10\tAverage Generator Loss: 2131.890076\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18317 (step 18317): 1.339589\n",
      "Batch #10\tAverage Generator Loss: 1862.652380\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18318 (step 18318): 1.296135\n",
      "Batch #10\tAverage Generator Loss: 1990.229028\tAverage Discriminator Loss: 0.002569\n",
      "\n",
      "Train time for epoch #18319 (step 18319): 1.956065\n",
      "Batch #10\tAverage Generator Loss: 2212.102661\tAverage Discriminator Loss: 0.000029\n",
      "\n",
      "Train time for epoch #18320 (step 18320): 1.411357\n",
      "Batch #10\tAverage Generator Loss: 1667.441760\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #18321 (step 18321): 1.288882\n",
      "Batch #10\tAverage Generator Loss: 1871.532715\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18322 (step 18322): 2.032052\n",
      "Batch #10\tAverage Generator Loss: 1890.907379\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #18323 (step 18323): 1.288791\n",
      "Batch #10\tAverage Generator Loss: 2153.510693\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #18324 (step 18324): 1.330444\n",
      "Batch #10\tAverage Generator Loss: 1799.344952\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18325 (step 18325): 1.290616\n",
      "Batch #10\tAverage Generator Loss: 2170.520959\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18326 (step 18326): 1.960997\n",
      "Batch #10\tAverage Generator Loss: 1982.273694\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18327 (step 18327): 1.302655\n",
      "Batch #10\tAverage Generator Loss: 1892.869318\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18328 (step 18328): 1.288633\n",
      "Batch #10\tAverage Generator Loss: 1931.690601\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18329 (step 18329): 1.377727\n",
      "Batch #10\tAverage Generator Loss: 2166.253540\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18330 (step 18330): 1.903691\n",
      "Batch #10\tAverage Generator Loss: 1984.226093\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18331 (step 18331): 1.286012\n",
      "Batch #10\tAverage Generator Loss: 2054.306445\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18332 (step 18332): 1.276010\n",
      "Batch #10\tAverage Generator Loss: 1887.269006\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18333 (step 18333): 1.899928\n",
      "Batch #10\tAverage Generator Loss: 1843.275354\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18334 (step 18334): 1.405495\n",
      "Batch #10\tAverage Generator Loss: 1934.168927\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18335 (step 18335): 1.288324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2435.545447\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18336 (step 18336): 1.284620\n",
      "Batch #10\tAverage Generator Loss: 1982.830212\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18337 (step 18337): 1.856896\n",
      "Batch #10\tAverage Generator Loss: 1718.241162\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18338 (step 18338): 1.298069\n",
      "Batch #10\tAverage Generator Loss: 1884.036438\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18339 (step 18339): 1.423711\n",
      "Batch #10\tAverage Generator Loss: 2112.043250\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18340 (step 18340): 1.332229\n",
      "Batch #10\tAverage Generator Loss: 1761.442999\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18341 (step 18341): 1.846711\n",
      "Batch #10\tAverage Generator Loss: 2273.102026\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18342 (step 18342): 1.280866\n",
      "Batch #10\tAverage Generator Loss: 1872.082703\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18343 (step 18343): 1.284570\n",
      "Batch #10\tAverage Generator Loss: 2095.433276\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18344 (step 18344): 1.933425\n",
      "Batch #10\tAverage Generator Loss: 1811.340271\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18345 (step 18345): 1.333164\n",
      "Batch #10\tAverage Generator Loss: 2113.842395\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18346 (step 18346): 1.376889\n",
      "Batch #10\tAverage Generator Loss: 1987.791486\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18347 (step 18347): 1.290110\n",
      "Batch #10\tAverage Generator Loss: 2163.296973\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18348 (step 18348): 1.887795\n",
      "Batch #10\tAverage Generator Loss: 1974.594977\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18349 (step 18349): 1.290170\n",
      "Batch #10\tAverage Generator Loss: 1772.078516\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18350 (step 18350): 1.423691\n",
      "Batch #10\tAverage Generator Loss: 1984.503674\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18351 (step 18351): 1.385282\n",
      "Batch #10\tAverage Generator Loss: 2195.756995\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18352 (step 18352): 1.981097\n",
      "Batch #10\tAverage Generator Loss: 1913.021057\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18353 (step 18353): 1.385428\n",
      "Batch #10\tAverage Generator Loss: 2146.932581\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18354 (step 18354): 1.353623\n",
      "Batch #10\tAverage Generator Loss: 1802.497528\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18355 (step 18355): 1.978868\n",
      "Batch #10\tAverage Generator Loss: 2019.563184\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18356 (step 18356): 1.343888\n",
      "Batch #10\tAverage Generator Loss: 1878.585632\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18357 (step 18357): 1.354084\n",
      "Batch #10\tAverage Generator Loss: 2009.958759\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18358 (step 18358): 1.288021\n",
      "Batch #10\tAverage Generator Loss: 1745.287500\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18359 (step 18359): 1.911106\n",
      "Batch #10\tAverage Generator Loss: 2034.141956\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18360 (step 18360): 1.272006\n",
      "Batch #10\tAverage Generator Loss: 2146.010571\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18361 (step 18361): 1.280013\n",
      "Batch #10\tAverage Generator Loss: 2007.334143\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18362 (step 18362): 1.951725\n",
      "Batch #10\tAverage Generator Loss: 2047.158203\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18363 (step 18363): 1.360646\n",
      "Batch #10\tAverage Generator Loss: 1742.229260\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18364 (step 18364): 1.301610\n",
      "Batch #10\tAverage Generator Loss: 2278.803357\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18365 (step 18365): 1.248700\n",
      "Batch #10\tAverage Generator Loss: 2328.112561\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18366 (step 18366): 1.911570\n",
      "Batch #10\tAverage Generator Loss: 2078.433179\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18367 (step 18367): 1.301905\n",
      "Batch #10\tAverage Generator Loss: 2030.040149\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18368 (step 18368): 1.349033\n",
      "Batch #10\tAverage Generator Loss: 2029.687585\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18369 (step 18369): 1.338261\n",
      "Batch #10\tAverage Generator Loss: 2049.440918\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18370 (step 18370): 1.864241\n",
      "Batch #10\tAverage Generator Loss: 1720.227667\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18371 (step 18371): 1.383149\n",
      "Batch #10\tAverage Generator Loss: 1916.146375\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18372 (step 18372): 1.534316\n",
      "Batch #10\tAverage Generator Loss: 2078.441565\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18373 (step 18373): 1.358176\n",
      "Batch #10\tAverage Generator Loss: 2271.677856\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18374 (step 18374): 1.993535\n",
      "Batch #10\tAverage Generator Loss: 2296.278650\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18375 (step 18375): 1.289562\n",
      "Batch #10\tAverage Generator Loss: 1930.482800\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18376 (step 18376): 1.414812\n",
      "Batch #10\tAverage Generator Loss: 2001.024884\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18377 (step 18377): 1.930520\n",
      "Batch #10\tAverage Generator Loss: 1723.157550\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18378 (step 18378): 1.338223\n",
      "Batch #10\tAverage Generator Loss: 1912.294861\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18379 (step 18379): 1.385324\n",
      "Batch #10\tAverage Generator Loss: 1942.717859\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18380 (step 18380): 1.338690\n",
      "Batch #10\tAverage Generator Loss: 2072.044885\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18381 (step 18381): 1.934369\n",
      "Batch #10\tAverage Generator Loss: 2105.750745\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18382 (step 18382): 1.418803\n",
      "Batch #10\tAverage Generator Loss: 1902.730054\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18383 (step 18383): 1.341153\n",
      "Batch #10\tAverage Generator Loss: 1913.480560\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18384 (step 18384): 1.394561\n",
      "Batch #10\tAverage Generator Loss: 2105.579596\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18385 (step 18385): 1.875159\n",
      "Batch #10\tAverage Generator Loss: 2035.235876\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18386 (step 18386): 1.372342\n",
      "Batch #10\tAverage Generator Loss: 2177.966211\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18387 (step 18387): 1.297685\n",
      "Batch #10\tAverage Generator Loss: 1981.041528\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18388 (step 18388): 1.982157\n",
      "Batch #10\tAverage Generator Loss: 1895.450238\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18389 (step 18389): 1.323100\n",
      "Batch #10\tAverage Generator Loss: 1862.886279\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18390 (step 18390): 1.287018\n",
      "Batch #10\tAverage Generator Loss: 1885.496387\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18391 (step 18391): 1.326803\n",
      "Batch #10\tAverage Generator Loss: 2056.578772\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18392 (step 18392): 1.917900\n",
      "Batch #10\tAverage Generator Loss: 1958.992529\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18393 (step 18393): 1.347716\n",
      "Batch #10\tAverage Generator Loss: 1782.938892\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18394 (step 18394): 1.267873\n",
      "Batch #10\tAverage Generator Loss: 2087.163977\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18395 (step 18395): 1.288683\n",
      "Batch #10\tAverage Generator Loss: 2023.580151\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18396 (step 18396): 1.905106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2061.545801\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18397 (step 18397): 1.238633\n",
      "Batch #10\tAverage Generator Loss: 1972.571375\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18398 (step 18398): 1.297429\n",
      "Batch #10\tAverage Generator Loss: 2043.092090\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18399 (step 18399): 1.916266\n",
      "Batch #10\tAverage Generator Loss: 2207.404517\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18400 (step 18400): 1.283292\n",
      "Batch #10\tAverage Generator Loss: 2044.619531\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18401 (step 18401): 1.435107\n",
      "Batch #10\tAverage Generator Loss: 2103.092542\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18402 (step 18402): 1.306026\n",
      "Batch #10\tAverage Generator Loss: 1957.433276\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18403 (step 18403): 1.894406\n",
      "Batch #10\tAverage Generator Loss: 2294.971863\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18404 (step 18404): 1.344800\n",
      "Batch #10\tAverage Generator Loss: 1900.389429\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18405 (step 18405): 1.295156\n",
      "Batch #10\tAverage Generator Loss: 1949.673035\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18406 (step 18406): 1.352999\n",
      "Batch #10\tAverage Generator Loss: 1864.224799\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18407 (step 18407): 1.961382\n",
      "Batch #10\tAverage Generator Loss: 2202.447290\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18408 (step 18408): 1.256134\n",
      "Batch #10\tAverage Generator Loss: 2244.770770\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18409 (step 18409): 1.313251\n",
      "Batch #10\tAverage Generator Loss: 1998.901245\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18410 (step 18410): 1.928306\n",
      "Batch #10\tAverage Generator Loss: 2096.662720\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18411 (step 18411): 1.349897\n",
      "Batch #10\tAverage Generator Loss: 1884.486707\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18412 (step 18412): 1.438318\n",
      "Batch #10\tAverage Generator Loss: 2027.027271\tAverage Discriminator Loss: 0.139279\n",
      "\n",
      "Train time for epoch #18413 (step 18413): 1.282291\n",
      "Batch #10\tAverage Generator Loss: 1951.876111\tAverage Discriminator Loss: 0.000040\n",
      "\n",
      "Train time for epoch #18414 (step 18414): 1.951848\n",
      "Batch #10\tAverage Generator Loss: 2507.611987\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18415 (step 18415): 1.281362\n",
      "Batch #10\tAverage Generator Loss: 2431.631995\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18416 (step 18416): 1.394090\n",
      "Batch #10\tAverage Generator Loss: 2569.022913\tAverage Discriminator Loss: 0.000349\n",
      "\n",
      "Train time for epoch #18417 (step 18417): 1.292149\n",
      "Batch #10\tAverage Generator Loss: 2399.063062\tAverage Discriminator Loss: 0.000019\n",
      "\n",
      "Train time for epoch #18418 (step 18418): 2.009671\n",
      "Batch #10\tAverage Generator Loss: 2230.671075\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #18419 (step 18419): 1.344543\n",
      "Batch #10\tAverage Generator Loss: 2139.878711\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #18420 (step 18420): 1.373871\n",
      "Batch #10\tAverage Generator Loss: 2276.121729\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18421 (step 18421): 1.842520\n",
      "Batch #10\tAverage Generator Loss: 2425.743982\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18422 (step 18422): 1.293189\n",
      "Batch #10\tAverage Generator Loss: 2214.037622\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18423 (step 18423): 1.253557\n",
      "Batch #10\tAverage Generator Loss: 2798.441321\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18424 (step 18424): 1.291747\n",
      "Batch #10\tAverage Generator Loss: 2398.499896\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18425 (step 18425): 1.958972\n",
      "Batch #10\tAverage Generator Loss: 2774.690692\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18426 (step 18426): 1.272344\n",
      "Batch #10\tAverage Generator Loss: 2448.780737\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18427 (step 18427): 1.290728\n",
      "Batch #10\tAverage Generator Loss: 2619.282617\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18428 (step 18428): 1.984612\n",
      "Batch #10\tAverage Generator Loss: 2435.478210\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18429 (step 18429): 1.356956\n",
      "Batch #10\tAverage Generator Loss: 3235.243420\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18430 (step 18430): 1.384000\n",
      "Batch #10\tAverage Generator Loss: 2834.450305\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18431 (step 18431): 1.365092\n",
      "Batch #10\tAverage Generator Loss: 2777.783606\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18432 (step 18432): 1.912838\n",
      "Batch #10\tAverage Generator Loss: 2820.796387\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18433 (step 18433): 1.236909\n",
      "Batch #10\tAverage Generator Loss: 2346.834729\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18434 (step 18434): 1.350708\n",
      "Batch #10\tAverage Generator Loss: 2796.907776\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18435 (step 18435): 1.290895\n",
      "Batch #10\tAverage Generator Loss: 2211.726929\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18436 (step 18436): 1.913381\n",
      "Batch #10\tAverage Generator Loss: 2334.407520\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18437 (step 18437): 1.325697\n",
      "Batch #10\tAverage Generator Loss: 2826.728418\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18438 (step 18438): 1.395713\n",
      "Batch #10\tAverage Generator Loss: 2656.490906\tAverage Discriminator Loss: 0.000693\n",
      "\n",
      "Train time for epoch #18439 (step 18439): 1.910773\n",
      "Batch #10\tAverage Generator Loss: 2341.645312\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #18440 (step 18440): 1.293032\n",
      "Batch #10\tAverage Generator Loss: 2366.626868\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18441 (step 18441): 1.351466\n",
      "Batch #10\tAverage Generator Loss: 2258.284601\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18442 (step 18442): 1.323649\n",
      "Batch #10\tAverage Generator Loss: 2207.658313\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18443 (step 18443): 2.014404\n",
      "Batch #10\tAverage Generator Loss: 2331.154053\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18444 (step 18444): 1.339727\n",
      "Batch #10\tAverage Generator Loss: 2288.959180\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18445 (step 18445): 1.294293\n",
      "Batch #10\tAverage Generator Loss: 2491.083997\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18446 (step 18446): 1.412057\n",
      "Batch #10\tAverage Generator Loss: 2646.739880\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18447 (step 18447): 1.887215\n",
      "Batch #10\tAverage Generator Loss: 2262.555273\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18448 (step 18448): 1.280309\n",
      "Batch #10\tAverage Generator Loss: 2236.130518\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18449 (step 18449): 1.380055\n",
      "Batch #10\tAverage Generator Loss: 2379.369238\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18450 (step 18450): 1.369261\n",
      "Batch #10\tAverage Generator Loss: 2579.161719\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18451 (step 18451): 1.820089\n",
      "Batch #10\tAverage Generator Loss: 2263.570764\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18452 (step 18452): 1.471276\n",
      "Batch #10\tAverage Generator Loss: 2254.316101\tAverage Discriminator Loss: 0.019293\n",
      "\n",
      "Train time for epoch #18453 (step 18453): 1.339494\n",
      "Batch #10\tAverage Generator Loss: 2656.001086\tAverage Discriminator Loss: 0.006595\n",
      "\n",
      "Train time for epoch #18454 (step 18454): 1.891885\n",
      "Batch #10\tAverage Generator Loss: 2114.238690\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18455 (step 18455): 1.380461\n",
      "Batch #10\tAverage Generator Loss: 2244.667896\tAverage Discriminator Loss: 0.021662\n",
      "\n",
      "Train time for epoch #18456 (step 18456): 1.370661\n",
      "Batch #10\tAverage Generator Loss: 2523.943494\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18457 (step 18457): 1.290243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2270.954187\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18458 (step 18458): 1.903065\n",
      "Batch #10\tAverage Generator Loss: 2907.677002\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18459 (step 18459): 1.278537\n",
      "Batch #10\tAverage Generator Loss: 2835.843091\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18460 (step 18460): 1.373448\n",
      "Batch #10\tAverage Generator Loss: 2403.582471\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18461 (step 18461): 1.353302\n",
      "Batch #10\tAverage Generator Loss: 2914.864307\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18462 (step 18462): 1.919576\n",
      "Batch #10\tAverage Generator Loss: 2083.989563\tAverage Discriminator Loss: 0.034152\n",
      "\n",
      "Train time for epoch #18463 (step 18463): 1.308856\n",
      "Batch #10\tAverage Generator Loss: 2749.028467\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18464 (step 18464): 1.293736\n",
      "Batch #10\tAverage Generator Loss: 2559.316821\tAverage Discriminator Loss: 0.067515\n",
      "\n",
      "Train time for epoch #18465 (step 18465): 1.871167\n",
      "Batch #10\tAverage Generator Loss: 3075.232410\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18466 (step 18466): 1.305640\n",
      "Batch #10\tAverage Generator Loss: 2956.590131\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18467 (step 18467): 1.354766\n",
      "Batch #10\tAverage Generator Loss: 2992.606970\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18468 (step 18468): 1.300123\n",
      "Batch #10\tAverage Generator Loss: 3234.044098\tAverage Discriminator Loss: 1.141669\n",
      "\n",
      "Train time for epoch #18469 (step 18469): 1.912420\n",
      "Batch #10\tAverage Generator Loss: 4447.638916\tAverage Discriminator Loss: 0.101162\n",
      "\n",
      "Train time for epoch #18470 (step 18470): 1.301221\n",
      "Batch #10\tAverage Generator Loss: 4080.901563\tAverage Discriminator Loss: 0.005830\n",
      "\n",
      "Train time for epoch #18471 (step 18471): 1.351824\n",
      "Batch #10\tAverage Generator Loss: 4089.347632\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18472 (step 18472): 1.286124\n",
      "Batch #10\tAverage Generator Loss: 3722.540894\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18473 (step 18473): 2.014821\n",
      "Batch #10\tAverage Generator Loss: 3464.027917\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18474 (step 18474): 1.385359\n",
      "Batch #10\tAverage Generator Loss: 3482.816248\tAverage Discriminator Loss: 0.136421\n",
      "\n",
      "Train time for epoch #18475 (step 18475): 1.339522\n",
      "Batch #10\tAverage Generator Loss: 2137.375183\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18476 (step 18476): 2.001049\n",
      "Batch #10\tAverage Generator Loss: 2100.159680\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18477 (step 18477): 1.403028\n",
      "Batch #10\tAverage Generator Loss: 2106.602234\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18478 (step 18478): 1.284473\n",
      "Batch #10\tAverage Generator Loss: 2194.116846\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18479 (step 18479): 1.373257\n",
      "Batch #10\tAverage Generator Loss: 2219.387823\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18480 (step 18480): 1.963143\n",
      "Batch #10\tAverage Generator Loss: 1761.595905\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18481 (step 18481): 1.436203\n",
      "Batch #10\tAverage Generator Loss: 2067.101343\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18482 (step 18482): 1.303558\n",
      "Batch #10\tAverage Generator Loss: 1633.105096\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18483 (step 18483): 1.394252\n",
      "Batch #10\tAverage Generator Loss: 1984.887964\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18484 (step 18484): 1.922375\n",
      "Batch #10\tAverage Generator Loss: 1980.901221\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18485 (step 18485): 1.238773\n",
      "Batch #10\tAverage Generator Loss: 1957.865292\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18486 (step 18486): 1.295863\n",
      "Batch #10\tAverage Generator Loss: 1496.919351\tAverage Discriminator Loss: 0.088434\n",
      "\n",
      "Train time for epoch #18487 (step 18487): 2.002556\n",
      "Batch #10\tAverage Generator Loss: 1877.189246\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18488 (step 18488): 1.328360\n",
      "Batch #10\tAverage Generator Loss: 1800.814539\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18489 (step 18489): 1.333921\n",
      "Batch #10\tAverage Generator Loss: 1892.590344\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18490 (step 18490): 1.344884\n",
      "Batch #10\tAverage Generator Loss: 2187.810095\tAverage Discriminator Loss: 0.001496\n",
      "\n",
      "Train time for epoch #18491 (step 18491): 1.869720\n",
      "Batch #10\tAverage Generator Loss: 2209.058057\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18492 (step 18492): 1.413909\n",
      "Batch #10\tAverage Generator Loss: 2678.377039\tAverage Discriminator Loss: 0.100374\n",
      "\n",
      "Train time for epoch #18493 (step 18493): 1.342431\n",
      "Batch #10\tAverage Generator Loss: 2148.205762\tAverage Discriminator Loss: 0.003566\n",
      "\n",
      "Train time for epoch #18494 (step 18494): 1.345129\n",
      "Batch #10\tAverage Generator Loss: 2069.351135\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #18495 (step 18495): 1.840966\n",
      "Batch #10\tAverage Generator Loss: 2367.113171\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #18496 (step 18496): 1.345384\n",
      "Batch #10\tAverage Generator Loss: 1982.221686\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #18497 (step 18497): 1.240658\n",
      "Batch #10\tAverage Generator Loss: 1833.592566\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #18498 (step 18498): 1.897144\n",
      "Batch #10\tAverage Generator Loss: 2030.872870\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #18499 (step 18499): 1.421684\n",
      "Batch #10\tAverage Generator Loss: 1774.186923\tAverage Discriminator Loss: 0.090375\n",
      "\n",
      "Train time for epoch #18500 (step 18500): 1.331982\n",
      "Batch #10\tAverage Generator Loss: 2127.763696\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #18501 (step 18501): 1.250280\n",
      "Batch #10\tAverage Generator Loss: 1895.817053\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #18502 (step 18502): 1.845339\n",
      "Batch #10\tAverage Generator Loss: 2295.889130\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #18503 (step 18503): 1.384587\n",
      "Batch #10\tAverage Generator Loss: 2135.169617\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #18504 (step 18504): 1.339391\n",
      "Batch #10\tAverage Generator Loss: 2133.824255\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #18505 (step 18505): 1.352481\n",
      "Batch #10\tAverage Generator Loss: 2122.888928\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #18506 (step 18506): 1.865080\n",
      "Batch #10\tAverage Generator Loss: 2023.671362\tAverage Discriminator Loss: 0.023830\n",
      "\n",
      "Train time for epoch #18507 (step 18507): 1.370736\n",
      "Batch #10\tAverage Generator Loss: 2137.143652\tAverage Discriminator Loss: 0.016149\n",
      "\n",
      "Train time for epoch #18508 (step 18508): 1.331153\n",
      "Batch #10\tAverage Generator Loss: 2340.299683\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #18509 (step 18509): 1.297632\n",
      "Batch #10\tAverage Generator Loss: 2275.695715\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18510 (step 18510): 1.965399\n",
      "Batch #10\tAverage Generator Loss: 1981.789624\tAverage Discriminator Loss: 0.000664\n",
      "\n",
      "Train time for epoch #18511 (step 18511): 1.324014\n",
      "Batch #10\tAverage Generator Loss: 2291.286218\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18512 (step 18512): 1.290701\n",
      "Batch #10\tAverage Generator Loss: 2101.212878\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18513 (step 18513): 1.918008\n",
      "Batch #10\tAverage Generator Loss: 2181.113049\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18514 (step 18514): 1.296751\n",
      "Batch #10\tAverage Generator Loss: 2376.355896\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18515 (step 18515): 1.346498\n",
      "Batch #10\tAverage Generator Loss: 2373.510321\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18516 (step 18516): 1.322614\n",
      "Batch #10\tAverage Generator Loss: 2370.993713\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18517 (step 18517): 1.965226\n",
      "Batch #10\tAverage Generator Loss: 2668.210925\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18518 (step 18518): 1.282239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 1822.862610\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18519 (step 18519): 1.435823\n",
      "Batch #10\tAverage Generator Loss: 1999.883893\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18520 (step 18520): 1.295537\n",
      "Batch #10\tAverage Generator Loss: 2275.375342\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18521 (step 18521): 1.901437\n",
      "Batch #10\tAverage Generator Loss: 2146.904150\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18522 (step 18522): 1.349185\n",
      "Batch #10\tAverage Generator Loss: 2335.682300\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18523 (step 18523): 1.303194\n",
      "Batch #10\tAverage Generator Loss: 2184.295581\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18524 (step 18524): 2.024244\n",
      "Batch #10\tAverage Generator Loss: 1975.221875\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18525 (step 18525): 1.348269\n",
      "Batch #10\tAverage Generator Loss: 2113.920618\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18526 (step 18526): 1.289896\n",
      "Batch #10\tAverage Generator Loss: 2334.279590\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18527 (step 18527): 1.396148\n",
      "Batch #10\tAverage Generator Loss: 2077.495416\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18528 (step 18528): 1.916258\n",
      "Batch #10\tAverage Generator Loss: 2103.047949\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18529 (step 18529): 1.346374\n",
      "Batch #10\tAverage Generator Loss: 2394.252136\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18530 (step 18530): 1.441182\n",
      "Batch #10\tAverage Generator Loss: 2080.635983\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18531 (step 18531): 1.386398\n",
      "Batch #10\tAverage Generator Loss: 1841.387836\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18532 (step 18532): 1.889595\n",
      "Batch #10\tAverage Generator Loss: 1741.617688\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18533 (step 18533): 1.300040\n",
      "Batch #10\tAverage Generator Loss: 2316.361462\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18534 (step 18534): 1.378750\n",
      "Batch #10\tAverage Generator Loss: 2143.837219\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18535 (step 18535): 1.866119\n",
      "Batch #10\tAverage Generator Loss: 2481.494348\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18536 (step 18536): 1.390368\n",
      "Batch #10\tAverage Generator Loss: 2056.001160\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18537 (step 18537): 1.331264\n",
      "Batch #10\tAverage Generator Loss: 2170.140039\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18538 (step 18538): 1.251535\n",
      "Batch #10\tAverage Generator Loss: 2124.676788\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18539 (step 18539): 1.849559\n",
      "Batch #10\tAverage Generator Loss: 1871.482574\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18540 (step 18540): 1.391314\n",
      "Batch #10\tAverage Generator Loss: 1852.190466\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18541 (step 18541): 1.335714\n",
      "Batch #10\tAverage Generator Loss: 2267.719824\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18542 (step 18542): 1.361875\n",
      "Batch #10\tAverage Generator Loss: 2043.364606\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18543 (step 18543): 1.817819\n",
      "Batch #10\tAverage Generator Loss: 2094.810907\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18544 (step 18544): 1.283613\n",
      "Batch #10\tAverage Generator Loss: 2178.915125\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18545 (step 18545): 1.345160\n",
      "Batch #10\tAverage Generator Loss: 2018.428888\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18546 (step 18546): 1.872493\n",
      "Batch #10\tAverage Generator Loss: 2283.196948\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18547 (step 18547): 1.457347\n",
      "Batch #10\tAverage Generator Loss: 2256.795007\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18548 (step 18548): 1.356398\n",
      "Batch #10\tAverage Generator Loss: 2061.547192\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18549 (step 18549): 1.392594\n",
      "Batch #10\tAverage Generator Loss: 2177.703937\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18550 (step 18550): 1.986089\n",
      "Batch #10\tAverage Generator Loss: 1876.937341\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18551 (step 18551): 1.294234\n",
      "Batch #10\tAverage Generator Loss: 2210.594336\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18552 (step 18552): 1.350028\n",
      "Batch #10\tAverage Generator Loss: 2033.255627\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18553 (step 18553): 1.373688\n",
      "Batch #10\tAverage Generator Loss: 2173.084229\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18554 (step 18554): 1.955842\n",
      "Batch #10\tAverage Generator Loss: 1795.292908\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18555 (step 18555): 1.325018\n",
      "Batch #10\tAverage Generator Loss: 2367.337085\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18556 (step 18556): 1.356250\n",
      "Batch #10\tAverage Generator Loss: 1872.783118\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18557 (step 18557): 1.910444\n",
      "Batch #10\tAverage Generator Loss: 2272.243640\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18558 (step 18558): 1.310552\n",
      "Batch #10\tAverage Generator Loss: 2184.071838\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18559 (step 18559): 1.389284\n",
      "Batch #10\tAverage Generator Loss: 2204.570947\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18560 (step 18560): 1.339614\n",
      "Batch #10\tAverage Generator Loss: 2314.195605\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18561 (step 18561): 1.974183\n",
      "Batch #10\tAverage Generator Loss: 1874.620831\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18562 (step 18562): 1.314150\n",
      "Batch #10\tAverage Generator Loss: 2060.038104\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18563 (step 18563): 1.329595\n",
      "Batch #10\tAverage Generator Loss: 2057.658582\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18564 (step 18564): 1.296853\n",
      "Batch #10\tAverage Generator Loss: 2076.976807\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18565 (step 18565): 2.065377\n",
      "Batch #10\tAverage Generator Loss: 2220.582239\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18566 (step 18566): 1.299370\n",
      "Batch #10\tAverage Generator Loss: 2050.683600\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18567 (step 18567): 1.307638\n",
      "Batch #10\tAverage Generator Loss: 2180.507663\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18568 (step 18568): 1.338637\n",
      "Batch #10\tAverage Generator Loss: 2145.360095\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18569 (step 18569): 1.907956\n",
      "Batch #10\tAverage Generator Loss: 2291.384790\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18570 (step 18570): 1.339992\n",
      "Batch #10\tAverage Generator Loss: 1880.921655\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18571 (step 18571): 1.316929\n",
      "Batch #10\tAverage Generator Loss: 2053.736798\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18572 (step 18572): 1.880895\n",
      "Batch #10\tAverage Generator Loss: 2087.777374\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18573 (step 18573): 1.303688\n",
      "Batch #10\tAverage Generator Loss: 2308.102686\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18574 (step 18574): 1.385495\n",
      "Batch #10\tAverage Generator Loss: 2032.127838\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18575 (step 18575): 1.431081\n",
      "Batch #10\tAverage Generator Loss: 2128.578479\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18576 (step 18576): 1.956383\n",
      "Batch #10\tAverage Generator Loss: 2174.498340\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18577 (step 18577): 1.295501\n",
      "Batch #10\tAverage Generator Loss: 2151.289526\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18578 (step 18578): 1.389884\n",
      "Batch #10\tAverage Generator Loss: 2414.033887\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18579 (step 18579): 1.353532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 1769.667542\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18580 (step 18580): 1.901276\n",
      "Batch #10\tAverage Generator Loss: 1935.024573\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18581 (step 18581): 1.339965\n",
      "Batch #10\tAverage Generator Loss: 2070.712256\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18582 (step 18582): 1.304962\n",
      "Batch #10\tAverage Generator Loss: 2089.034009\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18583 (step 18583): 1.322637\n",
      "Batch #10\tAverage Generator Loss: 2303.989569\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18584 (step 18584): 1.913927\n",
      "Batch #10\tAverage Generator Loss: 2204.633081\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18585 (step 18585): 1.340364\n",
      "Batch #10\tAverage Generator Loss: 2382.355170\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18586 (step 18586): 1.331312\n",
      "Batch #10\tAverage Generator Loss: 2273.182056\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18587 (step 18587): 1.388277\n",
      "Batch #10\tAverage Generator Loss: 2097.732312\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18588 (step 18588): 1.860826\n",
      "Batch #10\tAverage Generator Loss: 2160.398865\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18589 (step 18589): 1.420267\n",
      "Batch #10\tAverage Generator Loss: 1940.007751\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18590 (step 18590): 1.444516\n",
      "Batch #10\tAverage Generator Loss: 1853.736914\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18591 (step 18591): 1.964774\n",
      "Batch #10\tAverage Generator Loss: 1812.653351\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18592 (step 18592): 1.344890\n",
      "Batch #10\tAverage Generator Loss: 2053.567883\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18593 (step 18593): 1.331463\n",
      "Batch #10\tAverage Generator Loss: 2014.482147\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #18594 (step 18594): 1.301593\n",
      "Batch #10\tAverage Generator Loss: 2286.053723\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #18595 (step 18595): 1.905199\n",
      "Batch #10\tAverage Generator Loss: 2024.468622\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #18596 (step 18596): 1.415143\n",
      "Batch #10\tAverage Generator Loss: 2356.505115\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #18597 (step 18597): 1.290811\n",
      "Batch #10\tAverage Generator Loss: 2120.807898\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #18598 (step 18598): 1.358151\n",
      "Batch #10\tAverage Generator Loss: 2091.008224\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #18599 (step 18599): 1.944743\n",
      "Batch #10\tAverage Generator Loss: 2224.832092\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #18600 (step 18600): 1.400316\n",
      "Batch #10\tAverage Generator Loss: 2405.054822\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #18601 (step 18601): 1.291727\n",
      "Batch #10\tAverage Generator Loss: 2248.199146\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18602 (step 18602): 1.956056\n",
      "Batch #10\tAverage Generator Loss: 2248.854785\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #18603 (step 18603): 1.242108\n",
      "Batch #10\tAverage Generator Loss: 2012.399622\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18604 (step 18604): 1.299576\n",
      "Batch #10\tAverage Generator Loss: 1953.970380\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #18605 (step 18605): 1.306241\n",
      "Batch #10\tAverage Generator Loss: 2146.055371\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18606 (step 18606): 1.858402\n",
      "Batch #10\tAverage Generator Loss: 1995.752832\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18607 (step 18607): 1.302260\n",
      "Batch #10\tAverage Generator Loss: 2169.862891\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #18608 (step 18608): 1.293503\n",
      "Batch #10\tAverage Generator Loss: 2477.583838\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18609 (step 18609): 1.331615\n",
      "Batch #10\tAverage Generator Loss: 2105.456445\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18610 (step 18610): 1.942263\n",
      "Batch #10\tAverage Generator Loss: 2034.545996\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18611 (step 18611): 1.331439\n",
      "Batch #10\tAverage Generator Loss: 2339.386121\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18612 (step 18612): 1.453167\n",
      "Batch #10\tAverage Generator Loss: 2077.153455\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18613 (step 18613): 1.398306\n",
      "Batch #10\tAverage Generator Loss: 2459.842725\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18614 (step 18614): 1.907890\n",
      "Batch #10\tAverage Generator Loss: 2032.362537\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18615 (step 18615): 1.327894\n",
      "Batch #10\tAverage Generator Loss: 2212.645129\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18616 (step 18616): 1.303171\n",
      "Batch #10\tAverage Generator Loss: 2170.234131\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18617 (step 18617): 1.883210\n",
      "Batch #10\tAverage Generator Loss: 2322.156970\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18618 (step 18618): 1.369217\n",
      "Batch #10\tAverage Generator Loss: 2292.324304\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18619 (step 18619): 1.389113\n",
      "Batch #10\tAverage Generator Loss: 2322.879370\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18620 (step 18620): 1.307147\n",
      "Batch #10\tAverage Generator Loss: 2083.254065\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18621 (step 18621): 1.863107\n",
      "Batch #10\tAverage Generator Loss: 2168.895203\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18622 (step 18622): 1.325206\n",
      "Batch #10\tAverage Generator Loss: 2378.410461\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18623 (step 18623): 1.292706\n",
      "Batch #10\tAverage Generator Loss: 2292.866467\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18624 (step 18624): 1.353975\n",
      "Batch #10\tAverage Generator Loss: 1853.606036\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18625 (step 18625): 1.865444\n",
      "Batch #10\tAverage Generator Loss: 2250.086511\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18626 (step 18626): 1.283423\n",
      "Batch #10\tAverage Generator Loss: 2271.251111\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18627 (step 18627): 1.281183\n",
      "Batch #10\tAverage Generator Loss: 2271.824829\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18628 (step 18628): 1.949042\n",
      "Batch #10\tAverage Generator Loss: 2071.019373\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18629 (step 18629): 1.346167\n",
      "Batch #10\tAverage Generator Loss: 2260.437805\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18630 (step 18630): 1.327163\n",
      "Batch #10\tAverage Generator Loss: 2151.731702\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18631 (step 18631): 1.297320\n",
      "Batch #10\tAverage Generator Loss: 2550.910718\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18632 (step 18632): 1.918228\n",
      "Batch #10\tAverage Generator Loss: 1829.755438\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18633 (step 18633): 1.292812\n",
      "Batch #10\tAverage Generator Loss: 1935.513495\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18634 (step 18634): 1.377077\n",
      "Batch #10\tAverage Generator Loss: 2130.585339\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18635 (step 18635): 1.363515\n",
      "Batch #10\tAverage Generator Loss: 2179.729739\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #18636 (step 18636): 1.991838\n",
      "Batch #10\tAverage Generator Loss: 2048.409851\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18637 (step 18637): 1.294140\n",
      "Batch #10\tAverage Generator Loss: 1899.836359\tAverage Discriminator Loss: 0.019583\n",
      "\n",
      "Train time for epoch #18638 (step 18638): 1.490819\n",
      "Batch #10\tAverage Generator Loss: 2112.164954\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18639 (step 18639): 1.283842\n",
      "Batch #10\tAverage Generator Loss: 2077.793231\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18640 (step 18640): 1.955402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 1925.460132\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18641 (step 18641): 1.337547\n",
      "Batch #10\tAverage Generator Loss: 2252.456409\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18642 (step 18642): 1.340933\n",
      "Batch #10\tAverage Generator Loss: 2309.357861\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18643 (step 18643): 1.955084\n",
      "Batch #10\tAverage Generator Loss: 2219.898889\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18644 (step 18644): 1.321822\n",
      "Batch #10\tAverage Generator Loss: 2139.234021\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18645 (step 18645): 1.337683\n",
      "Batch #10\tAverage Generator Loss: 2001.501563\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18646 (step 18646): 1.395967\n",
      "Batch #10\tAverage Generator Loss: 1752.313599\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18647 (step 18647): 2.106700\n",
      "Batch #10\tAverage Generator Loss: 2024.798401\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18648 (step 18648): 1.371109\n",
      "Batch #10\tAverage Generator Loss: 2374.460706\tAverage Discriminator Loss: 0.008933\n",
      "\n",
      "Train time for epoch #18649 (step 18649): 1.290055\n",
      "Batch #10\tAverage Generator Loss: 2228.194995\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18650 (step 18650): 1.394384\n",
      "Batch #10\tAverage Generator Loss: 2408.636279\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #18651 (step 18651): 1.874107\n",
      "Batch #10\tAverage Generator Loss: 2113.894110\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #18652 (step 18652): 1.289779\n",
      "Batch #10\tAverage Generator Loss: 2166.578955\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #18653 (step 18653): 1.241292\n",
      "Batch #10\tAverage Generator Loss: 1981.662964\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #18654 (step 18654): 1.917721\n",
      "Batch #10\tAverage Generator Loss: 2142.297339\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #18655 (step 18655): 1.389080\n",
      "Batch #10\tAverage Generator Loss: 2033.024792\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #18656 (step 18656): 1.291146\n",
      "Batch #10\tAverage Generator Loss: 1997.782739\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18657 (step 18657): 1.349249\n",
      "Batch #10\tAverage Generator Loss: 2083.336847\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #18658 (step 18658): 1.391308\n",
      "Batch #10\tAverage Generator Loss: 2334.935168\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #18659 (step 18659): 1.914579\n",
      "Batch #10\tAverage Generator Loss: 2126.747034\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #18660 (step 18660): 1.361865\n",
      "Batch #10\tAverage Generator Loss: 2223.152405\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #18661 (step 18661): 1.358827\n",
      "Batch #10\tAverage Generator Loss: 2147.093152\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18662 (step 18662): 1.901151\n",
      "Batch #10\tAverage Generator Loss: 2006.033478\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #18663 (step 18663): 1.284146\n",
      "Batch #10\tAverage Generator Loss: 2413.559814\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #18664 (step 18664): 1.380620\n",
      "Batch #10\tAverage Generator Loss: 2014.193323\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18665 (step 18665): 1.301220\n",
      "Batch #10\tAverage Generator Loss: 1872.251477\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18666 (step 18666): 1.906225\n",
      "Batch #10\tAverage Generator Loss: 2257.836938\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #18667 (step 18667): 1.393400\n",
      "Batch #10\tAverage Generator Loss: 2010.010608\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18668 (step 18668): 1.439974\n",
      "Batch #10\tAverage Generator Loss: 1999.315649\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18669 (step 18669): 1.354534\n",
      "Batch #10\tAverage Generator Loss: 2249.724695\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18670 (step 18670): 1.930104\n",
      "Batch #10\tAverage Generator Loss: 2194.798828\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18671 (step 18671): 1.299108\n",
      "Batch #10\tAverage Generator Loss: 2003.441608\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18672 (step 18672): 1.493416\n",
      "Batch #10\tAverage Generator Loss: 2172.359314\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18673 (step 18673): 2.013654\n",
      "Batch #10\tAverage Generator Loss: 1925.599048\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18674 (step 18674): 1.502538\n",
      "Batch #10\tAverage Generator Loss: 1856.125476\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18675 (step 18675): 1.317921\n",
      "Batch #10\tAverage Generator Loss: 2185.511389\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18676 (step 18676): 1.283962\n",
      "Batch #10\tAverage Generator Loss: 2358.460913\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18677 (step 18677): 1.921887\n",
      "Batch #10\tAverage Generator Loss: 2012.319983\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18678 (step 18678): 1.327125\n",
      "Batch #10\tAverage Generator Loss: 1851.395764\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18679 (step 18679): 1.300095\n",
      "Batch #10\tAverage Generator Loss: 2065.773047\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18680 (step 18680): 1.401033\n",
      "Batch #10\tAverage Generator Loss: 2279.135583\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18681 (step 18681): 1.933706\n",
      "Batch #10\tAverage Generator Loss: 2423.906238\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18682 (step 18682): 1.335974\n",
      "Batch #10\tAverage Generator Loss: 2419.974756\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18683 (step 18683): 1.312066\n",
      "Batch #10\tAverage Generator Loss: 1987.866089\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18684 (step 18684): 1.975106\n",
      "Batch #10\tAverage Generator Loss: 2206.802710\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18685 (step 18685): 1.343684\n",
      "Batch #10\tAverage Generator Loss: 1865.861169\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18686 (step 18686): 1.278887\n",
      "Batch #10\tAverage Generator Loss: 2491.307727\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18687 (step 18687): 1.348135\n",
      "Batch #10\tAverage Generator Loss: 2293.663989\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18688 (step 18688): 2.099838\n",
      "Batch #10\tAverage Generator Loss: 2192.630542\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18689 (step 18689): 1.366842\n",
      "Batch #10\tAverage Generator Loss: 2307.231824\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18690 (step 18690): 1.324551\n",
      "Batch #10\tAverage Generator Loss: 2056.099390\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18691 (step 18691): 1.393717\n",
      "Batch #10\tAverage Generator Loss: 2043.213013\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18692 (step 18692): 1.864219\n",
      "Batch #10\tAverage Generator Loss: 2037.655304\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18693 (step 18693): 1.356553\n",
      "Batch #10\tAverage Generator Loss: 1907.308582\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18694 (step 18694): 1.389986\n",
      "Batch #10\tAverage Generator Loss: 2727.057043\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18695 (step 18695): 1.917093\n",
      "Batch #10\tAverage Generator Loss: 2286.216016\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18696 (step 18696): 1.277208\n",
      "Batch #10\tAverage Generator Loss: 2301.720715\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18697 (step 18697): 1.313009\n",
      "Batch #10\tAverage Generator Loss: 2108.079419\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18698 (step 18698): 1.330709\n",
      "Batch #10\tAverage Generator Loss: 1805.959918\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18699 (step 18699): 1.931553\n",
      "Batch #10\tAverage Generator Loss: 2027.571051\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18700 (step 18700): 1.357121\n",
      "Batch #10\tAverage Generator Loss: 1914.432196\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18701 (step 18701): 1.300689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2093.550317\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18702 (step 18702): 1.337704\n",
      "Batch #10\tAverage Generator Loss: 2062.992712\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18703 (step 18703): 2.009198\n",
      "Batch #10\tAverage Generator Loss: 2082.515649\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18704 (step 18704): 1.360389\n",
      "Batch #10\tAverage Generator Loss: 1803.527625\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18705 (step 18705): 1.363412\n",
      "Batch #10\tAverage Generator Loss: 2491.297083\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18706 (step 18706): 1.249565\n",
      "Batch #10\tAverage Generator Loss: 2058.389404\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18707 (step 18707): 2.129676\n",
      "Batch #10\tAverage Generator Loss: 2154.185266\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18708 (step 18708): 1.343727\n",
      "Batch #10\tAverage Generator Loss: 2088.914612\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18709 (step 18709): 1.296185\n",
      "Batch #10\tAverage Generator Loss: 2245.260925\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18710 (step 18710): 1.870754\n",
      "Batch #10\tAverage Generator Loss: 2426.458960\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18711 (step 18711): 1.342193\n",
      "Batch #10\tAverage Generator Loss: 2325.374683\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18712 (step 18712): 1.360783\n",
      "Batch #10\tAverage Generator Loss: 2696.214807\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18713 (step 18713): 1.399940\n",
      "Batch #10\tAverage Generator Loss: 2004.070789\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18714 (step 18714): 2.143465\n",
      "Batch #10\tAverage Generator Loss: 2021.364856\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18715 (step 18715): 1.342731\n",
      "Batch #10\tAverage Generator Loss: 2317.624390\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18716 (step 18716): 1.333644\n",
      "Batch #10\tAverage Generator Loss: 2212.623706\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18717 (step 18717): 1.337101\n",
      "Batch #10\tAverage Generator Loss: 1915.274634\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18718 (step 18718): 1.928645\n",
      "Batch #10\tAverage Generator Loss: 2226.273535\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18719 (step 18719): 1.493335\n",
      "Batch #10\tAverage Generator Loss: 2196.341797\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18720 (step 18720): 1.287625\n",
      "Batch #10\tAverage Generator Loss: 2150.953247\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18721 (step 18721): 1.944188\n",
      "Batch #10\tAverage Generator Loss: 2330.677783\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18722 (step 18722): 1.296824\n",
      "Batch #10\tAverage Generator Loss: 2124.462073\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18723 (step 18723): 1.348153\n",
      "Batch #10\tAverage Generator Loss: 1873.404578\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18724 (step 18724): 1.288868\n",
      "Batch #10\tAverage Generator Loss: 2111.687231\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18725 (step 18725): 2.015855\n",
      "Batch #10\tAverage Generator Loss: 1951.377228\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18726 (step 18726): 1.372561\n",
      "Batch #10\tAverage Generator Loss: 2125.053650\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18727 (step 18727): 1.342817\n",
      "Batch #10\tAverage Generator Loss: 2109.334583\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18728 (step 18728): 1.380767\n",
      "Batch #10\tAverage Generator Loss: 1894.773578\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18729 (step 18729): 1.973634\n",
      "Batch #10\tAverage Generator Loss: 2066.617169\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18730 (step 18730): 1.294766\n",
      "Batch #10\tAverage Generator Loss: 1970.625256\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18731 (step 18731): 1.425492\n",
      "Batch #10\tAverage Generator Loss: 2229.837476\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18732 (step 18732): 1.346749\n",
      "Batch #10\tAverage Generator Loss: 1979.722375\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18733 (step 18733): 1.954042\n",
      "Batch #10\tAverage Generator Loss: 2004.085052\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18734 (step 18734): 1.273213\n",
      "Batch #10\tAverage Generator Loss: 2290.961182\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18735 (step 18735): 1.317938\n",
      "Batch #10\tAverage Generator Loss: 2072.560449\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18736 (step 18736): 1.356951\n",
      "Batch #10\tAverage Generator Loss: 1971.952075\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18737 (step 18737): 1.961070\n",
      "Batch #10\tAverage Generator Loss: 2203.245105\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18738 (step 18738): 1.389811\n",
      "Batch #10\tAverage Generator Loss: 2170.310730\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18739 (step 18739): 1.343424\n",
      "Batch #10\tAverage Generator Loss: 1967.851160\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18740 (step 18740): 1.900696\n",
      "Batch #10\tAverage Generator Loss: 2094.652350\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18741 (step 18741): 1.351721\n",
      "Batch #10\tAverage Generator Loss: 2144.798950\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18742 (step 18742): 1.397045\n",
      "Batch #10\tAverage Generator Loss: 2034.053082\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18743 (step 18743): 1.440382\n",
      "Batch #10\tAverage Generator Loss: 2128.056848\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18744 (step 18744): 2.014067\n",
      "Batch #10\tAverage Generator Loss: 2057.818738\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18745 (step 18745): 1.324957\n",
      "Batch #10\tAverage Generator Loss: 1982.006598\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18746 (step 18746): 1.287809\n",
      "Batch #10\tAverage Generator Loss: 2113.465869\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18747 (step 18747): 1.309280\n",
      "Batch #10\tAverage Generator Loss: 1956.774158\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18748 (step 18748): 1.968764\n",
      "Batch #10\tAverage Generator Loss: 1933.899463\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18749 (step 18749): 1.427555\n",
      "Batch #10\tAverage Generator Loss: 2272.819324\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18750 (step 18750): 1.340338\n",
      "Batch #10\tAverage Generator Loss: 2320.804541\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18751 (step 18751): 1.916561\n",
      "Batch #10\tAverage Generator Loss: 2312.843292\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18752 (step 18752): 1.296144\n",
      "Batch #10\tAverage Generator Loss: 2221.414075\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18753 (step 18753): 1.349041\n",
      "Batch #10\tAverage Generator Loss: 2038.511353\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18754 (step 18754): 1.287453\n",
      "Batch #10\tAverage Generator Loss: 2046.776630\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18755 (step 18755): 2.017025\n",
      "Batch #10\tAverage Generator Loss: 1828.306219\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18756 (step 18756): 1.305855\n",
      "Batch #10\tAverage Generator Loss: 2190.775806\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18757 (step 18757): 1.301524\n",
      "Batch #10\tAverage Generator Loss: 1989.148682\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18758 (step 18758): 1.296168\n",
      "Batch #10\tAverage Generator Loss: 1989.584680\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18759 (step 18759): 1.969689\n",
      "Batch #10\tAverage Generator Loss: 1871.893884\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18760 (step 18760): 1.302555\n",
      "Batch #10\tAverage Generator Loss: 2239.724414\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18761 (step 18761): 1.436373\n",
      "Batch #10\tAverage Generator Loss: 2266.027515\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18762 (step 18762): 1.375047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2239.892114\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18763 (step 18763): 1.931883\n",
      "Batch #10\tAverage Generator Loss: 2081.906323\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18764 (step 18764): 1.342566\n",
      "Batch #10\tAverage Generator Loss: 2120.071851\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18765 (step 18765): 1.286235\n",
      "Batch #10\tAverage Generator Loss: 2145.604633\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18766 (step 18766): 1.281737\n",
      "Batch #10\tAverage Generator Loss: 1676.236652\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18767 (step 18767): 2.022545\n",
      "Batch #10\tAverage Generator Loss: 2187.820471\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18768 (step 18768): 1.345435\n",
      "Batch #10\tAverage Generator Loss: 2059.340112\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18769 (step 18769): 1.346415\n",
      "Batch #10\tAverage Generator Loss: 2303.631677\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18770 (step 18770): 1.962103\n",
      "Batch #10\tAverage Generator Loss: 1900.662848\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18771 (step 18771): 1.284612\n",
      "Batch #10\tAverage Generator Loss: 1817.982166\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18772 (step 18772): 1.297556\n",
      "Batch #10\tAverage Generator Loss: 2087.410327\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #18773 (step 18773): 1.234309\n",
      "Batch #10\tAverage Generator Loss: 2171.257935\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18774 (step 18774): 1.852900\n",
      "Batch #10\tAverage Generator Loss: 2035.870770\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18775 (step 18775): 1.292516\n",
      "Batch #10\tAverage Generator Loss: 2334.864026\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18776 (step 18776): 1.388055\n",
      "Batch #10\tAverage Generator Loss: 1958.709082\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18777 (step 18777): 1.301253\n",
      "Batch #10\tAverage Generator Loss: 2129.575580\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18778 (step 18778): 1.864559\n",
      "Batch #10\tAverage Generator Loss: 2051.388049\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18779 (step 18779): 1.370609\n",
      "Batch #10\tAverage Generator Loss: 2054.635303\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18780 (step 18780): 1.358986\n",
      "Batch #10\tAverage Generator Loss: 2097.655957\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18781 (step 18781): 1.912840\n",
      "Batch #10\tAverage Generator Loss: 1975.637817\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18782 (step 18782): 1.332226\n",
      "Batch #10\tAverage Generator Loss: 2107.442578\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18783 (step 18783): 1.396884\n",
      "Batch #10\tAverage Generator Loss: 1988.937146\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18784 (step 18784): 1.288166\n",
      "Batch #10\tAverage Generator Loss: 2119.351001\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18785 (step 18785): 2.083769\n",
      "Batch #10\tAverage Generator Loss: 2054.678748\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18786 (step 18786): 1.429988\n",
      "Batch #10\tAverage Generator Loss: 2048.425574\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18787 (step 18787): 1.405387\n",
      "Batch #10\tAverage Generator Loss: 1946.924390\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18788 (step 18788): 1.398625\n",
      "Batch #10\tAverage Generator Loss: 2544.212134\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18789 (step 18789): 1.914919\n",
      "Batch #10\tAverage Generator Loss: 2380.026941\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18790 (step 18790): 1.289458\n",
      "Batch #10\tAverage Generator Loss: 2271.028723\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18791 (step 18791): 1.351692\n",
      "Batch #10\tAverage Generator Loss: 1994.545679\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18792 (step 18792): 1.953745\n",
      "Batch #10\tAverage Generator Loss: 2022.716370\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18793 (step 18793): 1.375815\n",
      "Batch #10\tAverage Generator Loss: 1963.956622\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18794 (step 18794): 1.293773\n",
      "Batch #10\tAverage Generator Loss: 1836.866461\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18795 (step 18795): 1.288514\n",
      "Batch #10\tAverage Generator Loss: 1744.769385\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18796 (step 18796): 1.925260\n",
      "Batch #10\tAverage Generator Loss: 2028.024622\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18797 (step 18797): 1.385005\n",
      "Batch #10\tAverage Generator Loss: 2128.843079\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18798 (step 18798): 1.403167\n",
      "Batch #10\tAverage Generator Loss: 2163.875647\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18799 (step 18799): 1.251739\n",
      "Batch #10\tAverage Generator Loss: 2099.890509\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18800 (step 18800): 1.967871\n",
      "Batch #10\tAverage Generator Loss: 1934.323096\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18801 (step 18801): 1.284107\n",
      "Batch #10\tAverage Generator Loss: 2012.351038\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18802 (step 18802): 1.331442\n",
      "Batch #10\tAverage Generator Loss: 1939.543835\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18803 (step 18803): 1.973815\n",
      "Batch #10\tAverage Generator Loss: 2004.971692\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18804 (step 18804): 1.326906\n",
      "Batch #10\tAverage Generator Loss: 1939.481836\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18805 (step 18805): 1.305691\n",
      "Batch #10\tAverage Generator Loss: 1987.550061\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18806 (step 18806): 1.244295\n",
      "Batch #10\tAverage Generator Loss: 1998.453302\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18807 (step 18807): 1.907940\n",
      "Batch #10\tAverage Generator Loss: 2148.154785\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18808 (step 18808): 1.317141\n",
      "Batch #10\tAverage Generator Loss: 2084.664978\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18809 (step 18809): 1.358531\n",
      "Batch #10\tAverage Generator Loss: 2032.560229\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18810 (step 18810): 1.298493\n",
      "Batch #10\tAverage Generator Loss: 2060.545544\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18811 (step 18811): 1.856344\n",
      "Batch #10\tAverage Generator Loss: 2074.697229\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18812 (step 18812): 1.383004\n",
      "Batch #10\tAverage Generator Loss: 2322.947192\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18813 (step 18813): 1.305076\n",
      "Batch #10\tAverage Generator Loss: 2065.115063\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18814 (step 18814): 1.868111\n",
      "Batch #10\tAverage Generator Loss: 2278.788379\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18815 (step 18815): 1.316882\n",
      "Batch #10\tAverage Generator Loss: 2005.887183\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18816 (step 18816): 1.337601\n",
      "Batch #10\tAverage Generator Loss: 2127.283826\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18817 (step 18817): 1.387277\n",
      "Batch #10\tAverage Generator Loss: 2384.696594\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18818 (step 18818): 1.854931\n",
      "Batch #10\tAverage Generator Loss: 2099.588708\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18819 (step 18819): 1.303988\n",
      "Batch #10\tAverage Generator Loss: 2292.852820\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18820 (step 18820): 1.338126\n",
      "Batch #10\tAverage Generator Loss: 2086.363977\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18821 (step 18821): 1.352151\n",
      "Batch #10\tAverage Generator Loss: 1945.691010\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18822 (step 18822): 1.853012\n",
      "Batch #10\tAverage Generator Loss: 1894.674310\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18823 (step 18823): 1.382608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 1984.572485\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18824 (step 18824): 1.516979\n",
      "Batch #10\tAverage Generator Loss: 2258.193945\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18825 (step 18825): 2.033693\n",
      "Batch #10\tAverage Generator Loss: 2321.524146\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18826 (step 18826): 1.362276\n",
      "Batch #10\tAverage Generator Loss: 2095.565527\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18827 (step 18827): 1.309652\n",
      "Batch #10\tAverage Generator Loss: 2323.748889\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18828 (step 18828): 1.302816\n",
      "Batch #10\tAverage Generator Loss: 2103.029614\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18829 (step 18829): 1.913581\n",
      "Batch #10\tAverage Generator Loss: 2126.128735\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18830 (step 18830): 1.291311\n",
      "Batch #10\tAverage Generator Loss: 2094.119861\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18831 (step 18831): 1.325230\n",
      "Batch #10\tAverage Generator Loss: 2141.335754\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18832 (step 18832): 1.404210\n",
      "Batch #10\tAverage Generator Loss: 2047.046631\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18833 (step 18833): 1.930804\n",
      "Batch #10\tAverage Generator Loss: 2054.381775\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18834 (step 18834): 1.291381\n",
      "Batch #10\tAverage Generator Loss: 1736.462634\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18835 (step 18835): 1.356678\n",
      "Batch #10\tAverage Generator Loss: 2007.825574\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18836 (step 18836): 1.356685\n",
      "Batch #10\tAverage Generator Loss: 1879.641638\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18837 (step 18837): 1.947639\n",
      "Batch #10\tAverage Generator Loss: 2234.988269\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18838 (step 18838): 1.285865\n",
      "Batch #10\tAverage Generator Loss: 2168.122015\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18839 (step 18839): 1.336146\n",
      "Batch #10\tAverage Generator Loss: 2131.658301\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18840 (step 18840): 1.917564\n",
      "Batch #10\tAverage Generator Loss: 2136.671643\tAverage Discriminator Loss: 0.001765\n",
      "\n",
      "Train time for epoch #18841 (step 18841): 1.354508\n",
      "Batch #10\tAverage Generator Loss: 2142.476440\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #18842 (step 18842): 1.292078\n",
      "Batch #10\tAverage Generator Loss: 2055.008337\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #18843 (step 18843): 1.392984\n",
      "Batch #10\tAverage Generator Loss: 2040.934454\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18844 (step 18844): 2.046359\n",
      "Batch #10\tAverage Generator Loss: 2189.207275\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18845 (step 18845): 1.324860\n",
      "Batch #10\tAverage Generator Loss: 2068.068469\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18846 (step 18846): 1.379814\n",
      "Batch #10\tAverage Generator Loss: 2107.470190\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18847 (step 18847): 1.315487\n",
      "Batch #10\tAverage Generator Loss: 2088.594312\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18848 (step 18848): 1.882838\n",
      "Batch #10\tAverage Generator Loss: 2542.625476\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18849 (step 18849): 1.413508\n",
      "Batch #10\tAverage Generator Loss: 2160.786145\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18850 (step 18850): 1.440125\n",
      "Batch #10\tAverage Generator Loss: 2180.747815\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18851 (step 18851): 1.335050\n",
      "Batch #10\tAverage Generator Loss: 2243.713373\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18852 (step 18852): 1.958699\n",
      "Batch #10\tAverage Generator Loss: 1992.617200\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18853 (step 18853): 1.345078\n",
      "Batch #10\tAverage Generator Loss: 2194.649481\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18854 (step 18854): 1.335740\n",
      "Batch #10\tAverage Generator Loss: 2113.682666\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18855 (step 18855): 1.882796\n",
      "Batch #10\tAverage Generator Loss: 2106.651996\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18856 (step 18856): 1.428340\n",
      "Batch #10\tAverage Generator Loss: 2407.729822\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18857 (step 18857): 1.290923\n",
      "Batch #10\tAverage Generator Loss: 2022.856293\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18858 (step 18858): 1.379426\n",
      "Batch #10\tAverage Generator Loss: 2571.352466\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18859 (step 18859): 1.886463\n",
      "Batch #10\tAverage Generator Loss: 2109.997998\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18860 (step 18860): 1.379586\n",
      "Batch #10\tAverage Generator Loss: 2507.331311\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18861 (step 18861): 1.415532\n",
      "Batch #10\tAverage Generator Loss: 2161.888477\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18862 (step 18862): 1.395412\n",
      "Batch #10\tAverage Generator Loss: 1815.606274\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18863 (step 18863): 2.034644\n",
      "Batch #10\tAverage Generator Loss: 2106.906647\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18864 (step 18864): 1.376219\n",
      "Batch #10\tAverage Generator Loss: 2115.476254\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18865 (step 18865): 1.356483\n",
      "Batch #10\tAverage Generator Loss: 2201.384497\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18866 (step 18866): 1.236547\n",
      "Batch #10\tAverage Generator Loss: 2199.482471\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18867 (step 18867): 1.922846\n",
      "Batch #10\tAverage Generator Loss: 2184.946771\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18868 (step 18868): 1.320581\n",
      "Batch #10\tAverage Generator Loss: 2399.545215\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18869 (step 18869): 1.409494\n",
      "Batch #10\tAverage Generator Loss: 2117.314478\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18870 (step 18870): 1.969946\n",
      "Batch #10\tAverage Generator Loss: 2129.830261\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18871 (step 18871): 1.335715\n",
      "Batch #10\tAverage Generator Loss: 2560.333313\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18872 (step 18872): 1.293818\n",
      "Batch #10\tAverage Generator Loss: 1894.816504\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18873 (step 18873): 1.290064\n",
      "Batch #10\tAverage Generator Loss: 2266.412158\tAverage Discriminator Loss: 0.031137\n",
      "\n",
      "Train time for epoch #18874 (step 18874): 1.925846\n",
      "Batch #10\tAverage Generator Loss: 2279.259460\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18875 (step 18875): 1.325574\n",
      "Batch #10\tAverage Generator Loss: 2016.852454\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18876 (step 18876): 1.333774\n",
      "Batch #10\tAverage Generator Loss: 2271.335370\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18877 (step 18877): 1.333507\n",
      "Batch #10\tAverage Generator Loss: 2140.482275\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18878 (step 18878): 1.914327\n",
      "Batch #10\tAverage Generator Loss: 2106.268671\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18879 (step 18879): 1.326064\n",
      "Batch #10\tAverage Generator Loss: 2201.781299\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18880 (step 18880): 1.289634\n",
      "Batch #10\tAverage Generator Loss: 2378.315253\tAverage Discriminator Loss: 0.056109\n",
      "\n",
      "Train time for epoch #18881 (step 18881): 1.338371\n",
      "Batch #10\tAverage Generator Loss: 2451.653595\tAverage Discriminator Loss: 0.233447\n",
      "\n",
      "Train time for epoch #18882 (step 18882): 1.981185\n",
      "Batch #10\tAverage Generator Loss: 2380.645642\tAverage Discriminator Loss: 0.000059\n",
      "\n",
      "Train time for epoch #18883 (step 18883): 1.346378\n",
      "Batch #10\tAverage Generator Loss: 3244.224646\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18884 (step 18884): 1.421157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 3031.115137\tAverage Discriminator Loss: 0.002919\n",
      "\n",
      "Train time for epoch #18885 (step 18885): 1.957159\n",
      "Batch #10\tAverage Generator Loss: 3857.864258\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18886 (step 18886): 1.306197\n",
      "Batch #10\tAverage Generator Loss: 3751.907349\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18887 (step 18887): 1.314663\n",
      "Batch #10\tAverage Generator Loss: 3106.788647\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18888 (step 18888): 1.376221\n",
      "Batch #10\tAverage Generator Loss: 3685.381885\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18889 (step 18889): 1.894271\n",
      "Batch #10\tAverage Generator Loss: 3765.541736\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18890 (step 18890): 1.339688\n",
      "Batch #10\tAverage Generator Loss: 3517.857959\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18891 (step 18891): 1.303840\n",
      "Batch #10\tAverage Generator Loss: 3596.618604\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18892 (step 18892): 1.469601\n",
      "Batch #10\tAverage Generator Loss: 3834.981567\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18893 (step 18893): 1.873358\n",
      "Batch #10\tAverage Generator Loss: 3064.143604\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18894 (step 18894): 1.347265\n",
      "Batch #10\tAverage Generator Loss: 4058.278687\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18895 (step 18895): 1.479423\n",
      "Batch #10\tAverage Generator Loss: 3742.782324\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18896 (step 18896): 1.396049\n",
      "Batch #10\tAverage Generator Loss: 3141.951794\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18897 (step 18897): 1.954697\n",
      "Batch #10\tAverage Generator Loss: 3688.733752\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18898 (step 18898): 1.392372\n",
      "Batch #10\tAverage Generator Loss: 3861.777087\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18899 (step 18899): 1.253600\n",
      "Batch #10\tAverage Generator Loss: 3484.143970\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18900 (step 18900): 1.338697\n",
      "Batch #10\tAverage Generator Loss: 3986.931311\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18901 (step 18901): 1.884154\n",
      "Batch #10\tAverage Generator Loss: 4173.366553\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18902 (step 18902): 1.333290\n",
      "Batch #10\tAverage Generator Loss: 3032.436206\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18903 (step 18903): 1.307161\n",
      "Batch #10\tAverage Generator Loss: 3414.704053\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18904 (step 18904): 2.034490\n",
      "Batch #10\tAverage Generator Loss: 3698.884045\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18905 (step 18905): 1.285995\n",
      "Batch #10\tAverage Generator Loss: 3720.683862\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18906 (step 18906): 1.296547\n",
      "Batch #10\tAverage Generator Loss: 3382.482593\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18907 (step 18907): 1.432698\n",
      "Batch #10\tAverage Generator Loss: 3502.223297\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18908 (step 18908): 2.065963\n",
      "Batch #10\tAverage Generator Loss: 3573.634424\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18909 (step 18909): 1.346648\n",
      "Batch #10\tAverage Generator Loss: 3648.480139\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18910 (step 18910): 1.386181\n",
      "Batch #10\tAverage Generator Loss: 3554.276648\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18911 (step 18911): 1.355013\n",
      "Batch #10\tAverage Generator Loss: 3437.528046\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18912 (step 18912): 2.022634\n",
      "Batch #10\tAverage Generator Loss: 3651.550580\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18913 (step 18913): 1.329000\n",
      "Batch #10\tAverage Generator Loss: 3736.913879\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18914 (step 18914): 1.342846\n",
      "Batch #10\tAverage Generator Loss: 3224.843774\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18915 (step 18915): 1.371382\n",
      "Batch #10\tAverage Generator Loss: 3550.677234\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18916 (step 18916): 1.929455\n",
      "Batch #10\tAverage Generator Loss: 3387.901904\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18917 (step 18917): 1.373698\n",
      "Batch #10\tAverage Generator Loss: 3246.575061\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18918 (step 18918): 1.272312\n",
      "Batch #10\tAverage Generator Loss: 3632.133179\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18919 (step 18919): 1.912919\n",
      "Batch #10\tAverage Generator Loss: 3384.656335\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18920 (step 18920): 1.302872\n",
      "Batch #10\tAverage Generator Loss: 3561.237744\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18921 (step 18921): 1.241956\n",
      "Batch #10\tAverage Generator Loss: 3570.780676\tAverage Discriminator Loss: 0.148562\n",
      "\n",
      "Train time for epoch #18922 (step 18922): 1.357871\n",
      "Batch #10\tAverage Generator Loss: 3421.053516\tAverage Discriminator Loss: 0.030139\n",
      "\n",
      "Train time for epoch #18923 (step 18923): 1.912219\n",
      "Batch #10\tAverage Generator Loss: 2710.750903\tAverage Discriminator Loss: 0.007687\n",
      "\n",
      "Train time for epoch #18924 (step 18924): 1.506330\n",
      "Batch #10\tAverage Generator Loss: 2592.652698\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #18925 (step 18925): 1.295939\n",
      "Batch #10\tAverage Generator Loss: 2336.950311\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18926 (step 18926): 1.388753\n",
      "Batch #10\tAverage Generator Loss: 2809.481433\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18927 (step 18927): 1.966506\n",
      "Batch #10\tAverage Generator Loss: 2971.655249\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18928 (step 18928): 1.343574\n",
      "Batch #10\tAverage Generator Loss: 2432.702490\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18929 (step 18929): 1.341908\n",
      "Batch #10\tAverage Generator Loss: 3108.410010\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18930 (step 18930): 1.352976\n",
      "Batch #10\tAverage Generator Loss: 2951.257507\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18931 (step 18931): 1.909937\n",
      "Batch #10\tAverage Generator Loss: 2198.350945\tAverage Discriminator Loss: 0.551506\n",
      "\n",
      "Train time for epoch #18932 (step 18932): 1.385546\n",
      "Batch #10\tAverage Generator Loss: 2204.211182\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18933 (step 18933): 1.345536\n",
      "Batch #10\tAverage Generator Loss: 2363.187793\tAverage Discriminator Loss: 0.219359\n",
      "\n",
      "Train time for epoch #18934 (step 18934): 1.922853\n",
      "Batch #10\tAverage Generator Loss: 2698.469690\tAverage Discriminator Loss: 0.010069\n",
      "\n",
      "Train time for epoch #18935 (step 18935): 1.346796\n",
      "Batch #10\tAverage Generator Loss: 2632.503882\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18936 (step 18936): 1.456662\n",
      "Batch #10\tAverage Generator Loss: 2992.150964\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18937 (step 18937): 1.392152\n",
      "Batch #10\tAverage Generator Loss: 2547.342200\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #18938 (step 18938): 1.900828\n",
      "Batch #10\tAverage Generator Loss: 2715.520056\tAverage Discriminator Loss: 0.032933\n",
      "\n",
      "Train time for epoch #18939 (step 18939): 1.348472\n",
      "Batch #10\tAverage Generator Loss: 2563.717432\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18940 (step 18940): 1.408495\n",
      "Batch #10\tAverage Generator Loss: 3150.937354\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18941 (step 18941): 1.301647\n",
      "Batch #10\tAverage Generator Loss: 2912.404559\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18942 (step 18942): 2.085045\n",
      "Batch #10\tAverage Generator Loss: 2806.773059\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18943 (step 18943): 1.382752\n",
      "Batch #10\tAverage Generator Loss: 2450.643542\tAverage Discriminator Loss: 0.000019\n",
      "\n",
      "Train time for epoch #18944 (step 18944): 1.289819\n",
      "Batch #10\tAverage Generator Loss: 2547.808496\tAverage Discriminator Loss: 0.017666\n",
      "\n",
      "Train time for epoch #18945 (step 18945): 1.291233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 3136.474646\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18946 (step 18946): 2.130796\n",
      "Batch #10\tAverage Generator Loss: 2300.071454\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18947 (step 18947): 1.295621\n",
      "Batch #10\tAverage Generator Loss: 2958.406677\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18948 (step 18948): 1.323992\n",
      "Batch #10\tAverage Generator Loss: 2622.612158\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18949 (step 18949): 1.925970\n",
      "Batch #10\tAverage Generator Loss: 2879.492969\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18950 (step 18950): 1.403475\n",
      "Batch #10\tAverage Generator Loss: 2674.729956\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18951 (step 18951): 1.330771\n",
      "Batch #10\tAverage Generator Loss: 2629.718213\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18952 (step 18952): 1.391509\n",
      "Batch #10\tAverage Generator Loss: 3010.635522\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18953 (step 18953): 1.993582\n",
      "Batch #10\tAverage Generator Loss: 2560.429706\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18954 (step 18954): 1.414582\n",
      "Batch #10\tAverage Generator Loss: 2374.631323\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18955 (step 18955): 1.385148\n",
      "Batch #10\tAverage Generator Loss: 2556.221277\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18956 (step 18956): 1.423394\n",
      "Batch #10\tAverage Generator Loss: 2317.405798\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18957 (step 18957): 1.943985\n",
      "Batch #10\tAverage Generator Loss: 2989.463525\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18958 (step 18958): 1.336546\n",
      "Batch #10\tAverage Generator Loss: 2680.968115\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18959 (step 18959): 1.399845\n",
      "Batch #10\tAverage Generator Loss: 2962.292920\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18960 (step 18960): 1.337234\n",
      "Batch #10\tAverage Generator Loss: 2880.760034\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18961 (step 18961): 1.941791\n",
      "Batch #10\tAverage Generator Loss: 2845.871643\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18962 (step 18962): 1.351672\n",
      "Batch #10\tAverage Generator Loss: 2618.457489\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18963 (step 18963): 1.351076\n",
      "Batch #10\tAverage Generator Loss: 2779.700757\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18964 (step 18964): 2.034558\n",
      "Batch #10\tAverage Generator Loss: 2964.536584\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18965 (step 18965): 1.345150\n",
      "Batch #10\tAverage Generator Loss: 2702.252576\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18966 (step 18966): 1.492265\n",
      "Batch #10\tAverage Generator Loss: 2994.894739\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18967 (step 18967): 1.290256\n",
      "Batch #10\tAverage Generator Loss: 2861.989954\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18968 (step 18968): 1.289670\n",
      "Batch #10\tAverage Generator Loss: 2802.691479\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18969 (step 18969): 1.863838\n",
      "Batch #10\tAverage Generator Loss: 3143.324463\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18970 (step 18970): 1.291218\n",
      "Batch #10\tAverage Generator Loss: 3154.822656\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18971 (step 18971): 1.379333\n",
      "Batch #10\tAverage Generator Loss: 2875.915430\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18972 (step 18972): 1.895096\n",
      "Batch #10\tAverage Generator Loss: 2830.370825\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18973 (step 18973): 1.284279\n",
      "Batch #10\tAverage Generator Loss: 2515.406555\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18974 (step 18974): 1.281267\n",
      "Batch #10\tAverage Generator Loss: 2717.719067\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18975 (step 18975): 1.241084\n",
      "Batch #10\tAverage Generator Loss: 3098.973962\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18976 (step 18976): 1.870304\n",
      "Batch #10\tAverage Generator Loss: 2910.995520\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18977 (step 18977): 1.284092\n",
      "Batch #10\tAverage Generator Loss: 2844.982703\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #18978 (step 18978): 1.424111\n",
      "Batch #10\tAverage Generator Loss: 3209.383875\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18979 (step 18979): 1.471030\n",
      "Batch #10\tAverage Generator Loss: 2482.075012\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18980 (step 18980): 1.945704\n",
      "Batch #10\tAverage Generator Loss: 2802.401978\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18981 (step 18981): 1.346043\n",
      "Batch #10\tAverage Generator Loss: 2538.273596\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18982 (step 18982): 1.281903\n",
      "Batch #10\tAverage Generator Loss: 2740.083167\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18983 (step 18983): 1.332867\n",
      "Batch #10\tAverage Generator Loss: 2953.276062\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18984 (step 18984): 2.073693\n",
      "Batch #10\tAverage Generator Loss: 2804.719165\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18985 (step 18985): 1.350127\n",
      "Batch #10\tAverage Generator Loss: 2703.724792\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18986 (step 18986): 1.343007\n",
      "Batch #10\tAverage Generator Loss: 2602.315552\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18987 (step 18987): 1.991617\n",
      "Batch #10\tAverage Generator Loss: 2888.244287\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18988 (step 18988): 1.280146\n",
      "Batch #10\tAverage Generator Loss: 2616.436902\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18989 (step 18989): 1.338428\n",
      "Batch #10\tAverage Generator Loss: 3138.058911\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18990 (step 18990): 1.278061\n",
      "Batch #10\tAverage Generator Loss: 2442.273608\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18991 (step 18991): 1.922437\n",
      "Batch #10\tAverage Generator Loss: 2725.434534\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18992 (step 18992): 1.528028\n",
      "Batch #10\tAverage Generator Loss: 2961.950720\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18993 (step 18993): 1.280608\n",
      "Batch #10\tAverage Generator Loss: 2775.247705\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18994 (step 18994): 1.289406\n",
      "Batch #10\tAverage Generator Loss: 2688.247241\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18995 (step 18995): 1.920809\n",
      "Batch #10\tAverage Generator Loss: 2775.761755\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18996 (step 18996): 1.288602\n",
      "Batch #10\tAverage Generator Loss: 2717.735461\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18997 (step 18997): 1.295243\n",
      "Batch #10\tAverage Generator Loss: 3012.886389\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18998 (step 18998): 1.348182\n",
      "Batch #10\tAverage Generator Loss: 2851.603015\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #18999 (step 18999): 1.916337\n",
      "Batch #10\tAverage Generator Loss: 3106.412952\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19000 (step 19000): 1.349545\n",
      "Batch #10\tAverage Generator Loss: 2924.881250\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19001 (step 19001): 1.341884\n",
      "Batch #10\tAverage Generator Loss: 2706.015710\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19002 (step 19002): 1.917190\n",
      "Batch #10\tAverage Generator Loss: 2426.685181\tAverage Discriminator Loss: 0.005887\n",
      "\n",
      "Train time for epoch #19003 (step 19003): 1.298097\n",
      "Batch #10\tAverage Generator Loss: 2976.196094\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #19004 (step 19004): 1.326194\n",
      "Batch #10\tAverage Generator Loss: 2975.308044\tAverage Discriminator Loss: 0.000045\n",
      "\n",
      "Train time for epoch #19005 (step 19005): 1.351722\n",
      "Batch #10\tAverage Generator Loss: 2769.867773\tAverage Discriminator Loss: 0.000031\n",
      "\n",
      "Train time for epoch #19006 (step 19006): 2.017122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 3016.451709\tAverage Discriminator Loss: 0.000014\n",
      "\n",
      "Train time for epoch #19007 (step 19007): 1.333714\n",
      "Batch #10\tAverage Generator Loss: 3013.629504\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #19008 (step 19008): 1.372251\n",
      "Batch #10\tAverage Generator Loss: 2976.628857\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #19009 (step 19009): 1.351543\n",
      "Batch #10\tAverage Generator Loss: 3124.271558\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #19010 (step 19010): 1.877073\n",
      "Batch #10\tAverage Generator Loss: 2690.690161\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #19011 (step 19011): 1.272349\n",
      "Batch #10\tAverage Generator Loss: 2976.079419\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #19012 (step 19012): 1.362061\n",
      "Batch #10\tAverage Generator Loss: 3004.849268\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #19013 (step 19013): 2.034147\n",
      "Batch #10\tAverage Generator Loss: 3052.365515\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #19014 (step 19014): 1.366004\n",
      "Batch #10\tAverage Generator Loss: 2603.872009\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19015 (step 19015): 1.359623\n",
      "Batch #10\tAverage Generator Loss: 2861.182733\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19016 (step 19016): 1.387770\n",
      "Batch #10\tAverage Generator Loss: 2934.671558\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19017 (step 19017): 1.918185\n",
      "Batch #10\tAverage Generator Loss: 3011.806396\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #19018 (step 19018): 1.301054\n",
      "Batch #10\tAverage Generator Loss: 2684.130981\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #19019 (step 19019): 1.295974\n",
      "Batch #10\tAverage Generator Loss: 2716.542065\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19020 (step 19020): 1.366135\n",
      "Batch #10\tAverage Generator Loss: 2485.590674\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #19021 (step 19021): 1.960015\n",
      "Batch #10\tAverage Generator Loss: 2774.488428\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #19022 (step 19022): 1.288650\n",
      "Batch #10\tAverage Generator Loss: 3024.193262\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #19023 (step 19023): 1.344913\n",
      "Batch #10\tAverage Generator Loss: 2949.008508\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #19024 (step 19024): 1.326462\n",
      "Batch #10\tAverage Generator Loss: 2834.686340\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19025 (step 19025): 1.924768\n",
      "Batch #10\tAverage Generator Loss: 2551.648193\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19026 (step 19026): 1.344075\n",
      "Batch #10\tAverage Generator Loss: 2802.425134\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19027 (step 19027): 1.327182\n",
      "Batch #10\tAverage Generator Loss: 3089.342957\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19028 (step 19028): 1.271800\n",
      "Batch #10\tAverage Generator Loss: 2804.660010\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19029 (step 19029): 2.059165\n",
      "Batch #10\tAverage Generator Loss: 2405.258276\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19030 (step 19030): 1.297305\n",
      "Batch #10\tAverage Generator Loss: 2811.721759\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19031 (step 19031): 1.326694\n",
      "Batch #10\tAverage Generator Loss: 3068.561450\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19032 (step 19032): 1.286892\n",
      "Batch #10\tAverage Generator Loss: 3278.351086\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19033 (step 19033): 1.981675\n",
      "Batch #10\tAverage Generator Loss: 2823.694678\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19034 (step 19034): 1.346201\n",
      "Batch #10\tAverage Generator Loss: 2884.327393\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19035 (step 19035): 1.291264\n",
      "Batch #10\tAverage Generator Loss: 2996.253003\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19036 (step 19036): 1.426735\n",
      "Batch #10\tAverage Generator Loss: 3073.991553\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19037 (step 19037): 2.002792\n",
      "Batch #10\tAverage Generator Loss: 2877.844727\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19038 (step 19038): 1.378811\n",
      "Batch #10\tAverage Generator Loss: 2292.804834\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19039 (step 19039): 1.336668\n",
      "Batch #10\tAverage Generator Loss: 2837.565540\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19040 (step 19040): 2.039950\n",
      "Batch #10\tAverage Generator Loss: 2989.248254\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19041 (step 19041): 1.286447\n",
      "Batch #10\tAverage Generator Loss: 2739.418982\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19042 (step 19042): 1.450402\n",
      "Batch #10\tAverage Generator Loss: 2545.101831\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19043 (step 19043): 1.344017\n",
      "Batch #10\tAverage Generator Loss: 3086.361670\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19044 (step 19044): 1.835386\n",
      "Batch #10\tAverage Generator Loss: 2684.615558\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19045 (step 19045): 1.286125\n",
      "Batch #10\tAverage Generator Loss: 3131.698273\tAverage Discriminator Loss: 0.000084\n",
      "\n",
      "Train time for epoch #19046 (step 19046): 1.281798\n",
      "Batch #10\tAverage Generator Loss: 2518.907788\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19047 (step 19047): 1.287166\n",
      "Batch #10\tAverage Generator Loss: 2553.672144\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19048 (step 19048): 1.872301\n",
      "Batch #10\tAverage Generator Loss: 2800.935614\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19049 (step 19049): 1.382644\n",
      "Batch #10\tAverage Generator Loss: 3296.095740\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19050 (step 19050): 1.352661\n",
      "Batch #10\tAverage Generator Loss: 2471.406567\tAverage Discriminator Loss: 0.224380\n",
      "\n",
      "Train time for epoch #19051 (step 19051): 2.076228\n",
      "Batch #10\tAverage Generator Loss: 2231.241132\tAverage Discriminator Loss: 0.002665\n",
      "\n",
      "Train time for epoch #19052 (step 19052): 1.421828\n",
      "Batch #10\tAverage Generator Loss: 2146.714758\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19053 (step 19053): 1.297208\n",
      "Batch #10\tAverage Generator Loss: 2437.052832\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19054 (step 19054): 1.392567\n",
      "Batch #10\tAverage Generator Loss: 2153.093829\tAverage Discriminator Loss: 0.228812\n",
      "\n",
      "Train time for epoch #19055 (step 19055): 1.931712\n",
      "Batch #10\tAverage Generator Loss: 2194.948975\tAverage Discriminator Loss: 0.004538\n",
      "\n",
      "Train time for epoch #19056 (step 19056): 1.348758\n",
      "Batch #10\tAverage Generator Loss: 2115.547607\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19057 (step 19057): 1.397302\n",
      "Batch #10\tAverage Generator Loss: 2188.678174\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19058 (step 19058): 1.276244\n",
      "Batch #10\tAverage Generator Loss: 2247.364392\tAverage Discriminator Loss: 0.002232\n",
      "\n",
      "Train time for epoch #19059 (step 19059): 1.869183\n",
      "Batch #10\tAverage Generator Loss: 2310.046655\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19060 (step 19060): 1.333624\n",
      "Batch #10\tAverage Generator Loss: 2286.707617\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19061 (step 19061): 1.390460\n",
      "Batch #10\tAverage Generator Loss: 2554.560681\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19062 (step 19062): 1.323570\n",
      "Batch #10\tAverage Generator Loss: 2415.468909\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #19063 (step 19063): 1.857514\n",
      "Batch #10\tAverage Generator Loss: 2468.929065\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #19064 (step 19064): 1.330315\n",
      "Batch #10\tAverage Generator Loss: 2332.860474\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19065 (step 19065): 1.369965\n",
      "Batch #10\tAverage Generator Loss: 2263.719836\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #19066 (step 19066): 1.292997\n",
      "Batch #10\tAverage Generator Loss: 2410.171716\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19067 (step 19067): 1.885924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2487.743829\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #19068 (step 19068): 1.334422\n",
      "Batch #10\tAverage Generator Loss: 2929.048816\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19069 (step 19069): 1.372792\n",
      "Batch #10\tAverage Generator Loss: 2380.351404\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #19070 (step 19070): 1.386795\n",
      "Batch #10\tAverage Generator Loss: 2482.880737\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19071 (step 19071): 2.050439\n",
      "Batch #10\tAverage Generator Loss: 2620.904663\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19072 (step 19072): 1.491985\n",
      "Batch #10\tAverage Generator Loss: 2400.640674\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19073 (step 19073): 1.405746\n",
      "Batch #10\tAverage Generator Loss: 2448.410583\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19074 (step 19074): 1.305322\n",
      "Batch #10\tAverage Generator Loss: 2334.777258\tAverage Discriminator Loss: 0.000891\n",
      "\n",
      "Train time for epoch #19075 (step 19075): 1.934406\n",
      "Batch #10\tAverage Generator Loss: 2655.980615\tAverage Discriminator Loss: 0.000137\n",
      "\n",
      "Train time for epoch #19076 (step 19076): 1.333559\n",
      "Batch #10\tAverage Generator Loss: 2324.377698\tAverage Discriminator Loss: 0.000029\n",
      "\n",
      "Train time for epoch #19077 (step 19077): 1.327849\n",
      "Batch #10\tAverage Generator Loss: 2434.461658\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #19078 (step 19078): 1.288690\n",
      "Batch #10\tAverage Generator Loss: 2319.638037\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #19079 (step 19079): 1.970751\n",
      "Batch #10\tAverage Generator Loss: 2402.349341\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #19080 (step 19080): 1.345198\n",
      "Batch #10\tAverage Generator Loss: 2464.197632\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #19081 (step 19081): 1.481946\n",
      "Batch #10\tAverage Generator Loss: 2120.690662\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #19082 (step 19082): 1.937431\n",
      "Batch #10\tAverage Generator Loss: 2394.359338\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #19083 (step 19083): 1.343981\n",
      "Batch #10\tAverage Generator Loss: 2347.051086\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #19084 (step 19084): 1.298716\n",
      "Batch #10\tAverage Generator Loss: 2200.756134\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #19085 (step 19085): 1.248610\n",
      "Batch #10\tAverage Generator Loss: 2530.981543\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #19086 (step 19086): 1.862348\n",
      "Batch #10\tAverage Generator Loss: 2426.020996\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #19087 (step 19087): 1.249555\n",
      "Batch #10\tAverage Generator Loss: 2441.732922\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19088 (step 19088): 1.293146\n",
      "Batch #10\tAverage Generator Loss: 2411.584241\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #19089 (step 19089): 1.274904\n",
      "Batch #10\tAverage Generator Loss: 2620.743054\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19090 (step 19090): 1.862579\n",
      "Batch #10\tAverage Generator Loss: 2477.499487\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #19091 (step 19091): 1.332498\n",
      "Batch #10\tAverage Generator Loss: 2111.127234\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19092 (step 19092): 1.384452\n",
      "Batch #10\tAverage Generator Loss: 2601.425049\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19093 (step 19093): 1.329699\n",
      "Batch #10\tAverage Generator Loss: 2415.782434\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19094 (step 19094): 1.904080\n",
      "Batch #10\tAverage Generator Loss: 2188.354926\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19095 (step 19095): 1.415958\n",
      "Batch #10\tAverage Generator Loss: 2535.831458\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19096 (step 19096): 1.300965\n",
      "Batch #10\tAverage Generator Loss: 2166.656934\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19097 (step 19097): 1.396103\n",
      "Batch #10\tAverage Generator Loss: 2088.669617\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19098 (step 19098): 1.823630\n",
      "Batch #10\tAverage Generator Loss: 2629.053992\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19099 (step 19099): 1.400896\n",
      "Batch #10\tAverage Generator Loss: 2529.376660\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19100 (step 19100): 1.290619\n",
      "Batch #10\tAverage Generator Loss: 2781.452393\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19101 (step 19101): 1.908905\n",
      "Batch #10\tAverage Generator Loss: 2444.001965\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19102 (step 19102): 1.344402\n",
      "Batch #10\tAverage Generator Loss: 2109.714172\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19103 (step 19103): 1.282323\n",
      "Batch #10\tAverage Generator Loss: 2567.112488\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19104 (step 19104): 1.341177\n",
      "Batch #10\tAverage Generator Loss: 2772.493152\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19105 (step 19105): 1.945005\n",
      "Batch #10\tAverage Generator Loss: 2423.472424\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19106 (step 19106): 1.670969\n",
      "Batch #10\tAverage Generator Loss: 2448.923279\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19107 (step 19107): 1.335037\n",
      "Batch #10\tAverage Generator Loss: 2429.061322\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19108 (step 19108): 1.252161\n",
      "Batch #10\tAverage Generator Loss: 2403.350745\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19109 (step 19109): 1.895335\n",
      "Batch #10\tAverage Generator Loss: 2386.251489\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19110 (step 19110): 1.288111\n",
      "Batch #10\tAverage Generator Loss: 2456.531360\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19111 (step 19111): 1.347903\n",
      "Batch #10\tAverage Generator Loss: 2139.517151\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19112 (step 19112): 1.999087\n",
      "Batch #10\tAverage Generator Loss: 2615.098608\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19113 (step 19113): 1.379256\n",
      "Batch #10\tAverage Generator Loss: 2330.846289\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19114 (step 19114): 1.385126\n",
      "Batch #10\tAverage Generator Loss: 2080.627136\tAverage Discriminator Loss: 0.024839\n",
      "\n",
      "Train time for epoch #19115 (step 19115): 1.339925\n",
      "Batch #10\tAverage Generator Loss: 2349.412634\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #19116 (step 19116): 2.034296\n",
      "Batch #10\tAverage Generator Loss: 1962.152887\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #19117 (step 19117): 1.328608\n",
      "Batch #10\tAverage Generator Loss: 2723.682849\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #19118 (step 19118): 1.450647\n",
      "Batch #10\tAverage Generator Loss: 2209.719104\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #19119 (step 19119): 1.305157\n",
      "Batch #10\tAverage Generator Loss: 2241.201529\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #19120 (step 19120): 2.091583\n",
      "Batch #10\tAverage Generator Loss: 2351.364282\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #19121 (step 19121): 1.349704\n",
      "Batch #10\tAverage Generator Loss: 2197.424719\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #19122 (step 19122): 1.290670\n",
      "Batch #10\tAverage Generator Loss: 2245.373907\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #19123 (step 19123): 1.289716\n",
      "Batch #10\tAverage Generator Loss: 2346.447766\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #19124 (step 19124): 1.888739\n",
      "Batch #10\tAverage Generator Loss: 2411.056238\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19125 (step 19125): 1.371843\n",
      "Batch #10\tAverage Generator Loss: 2217.909369\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19126 (step 19126): 1.299573\n",
      "Batch #10\tAverage Generator Loss: 2423.336658\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19127 (step 19127): 1.349234\n",
      "Batch #10\tAverage Generator Loss: 2392.112219\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19128 (step 19128): 2.005841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2466.258643\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19129 (step 19129): 1.348149\n",
      "Batch #10\tAverage Generator Loss: 2396.295691\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19130 (step 19130): 1.330296\n",
      "Batch #10\tAverage Generator Loss: 2235.301880\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19131 (step 19131): 1.298748\n",
      "Batch #10\tAverage Generator Loss: 2433.709772\tAverage Discriminator Loss: 0.002005\n",
      "\n",
      "Train time for epoch #19132 (step 19132): 1.979180\n",
      "Batch #10\tAverage Generator Loss: 2140.539746\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19133 (step 19133): 1.339789\n",
      "Batch #10\tAverage Generator Loss: 2362.986755\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #19134 (step 19134): 1.296717\n",
      "Batch #10\tAverage Generator Loss: 2411.399084\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19135 (step 19135): 1.918731\n",
      "Batch #10\tAverage Generator Loss: 2309.853113\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #19136 (step 19136): 1.435902\n",
      "Batch #10\tAverage Generator Loss: 2564.507227\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #19137 (step 19137): 1.295101\n",
      "Batch #10\tAverage Generator Loss: 2427.072559\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19138 (step 19138): 1.288936\n",
      "Batch #10\tAverage Generator Loss: 2277.076160\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #19139 (step 19139): 2.040388\n",
      "Batch #10\tAverage Generator Loss: 2257.265320\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #19140 (step 19140): 1.333459\n",
      "Batch #10\tAverage Generator Loss: 2618.138269\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #19141 (step 19141): 1.348827\n",
      "Batch #10\tAverage Generator Loss: 2297.882019\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19142 (step 19142): 1.247031\n",
      "Batch #10\tAverage Generator Loss: 2339.656598\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #19143 (step 19143): 1.929210\n",
      "Batch #10\tAverage Generator Loss: 2267.668298\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #19144 (step 19144): 1.323780\n",
      "Batch #10\tAverage Generator Loss: 2387.985089\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #19145 (step 19145): 1.336015\n",
      "Batch #10\tAverage Generator Loss: 1824.313208\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19146 (step 19146): 1.331040\n",
      "Batch #10\tAverage Generator Loss: 2417.484021\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19147 (step 19147): 1.932361\n",
      "Batch #10\tAverage Generator Loss: 2436.815430\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19148 (step 19148): 1.285106\n",
      "Batch #10\tAverage Generator Loss: 1972.915033\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19149 (step 19149): 1.286448\n",
      "Batch #10\tAverage Generator Loss: 2314.892920\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19150 (step 19150): 2.014254\n",
      "Batch #10\tAverage Generator Loss: 2367.060583\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19151 (step 19151): 1.393768\n",
      "Batch #10\tAverage Generator Loss: 2169.705554\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19152 (step 19152): 1.377545\n",
      "Batch #10\tAverage Generator Loss: 2141.027344\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19153 (step 19153): 1.322195\n",
      "Batch #10\tAverage Generator Loss: 2182.846411\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19154 (step 19154): 2.052428\n",
      "Batch #10\tAverage Generator Loss: 2510.258826\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19155 (step 19155): 1.339112\n",
      "Batch #10\tAverage Generator Loss: 2221.864746\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19156 (step 19156): 1.353676\n",
      "Batch #10\tAverage Generator Loss: 2284.098975\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19157 (step 19157): 1.397779\n",
      "Batch #10\tAverage Generator Loss: 2233.764783\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19158 (step 19158): 1.933668\n",
      "Batch #10\tAverage Generator Loss: 2065.894995\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19159 (step 19159): 1.353316\n",
      "Batch #10\tAverage Generator Loss: 2409.176416\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19160 (step 19160): 1.472343\n",
      "Batch #10\tAverage Generator Loss: 2108.884277\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19161 (step 19161): 1.363616\n",
      "Batch #10\tAverage Generator Loss: 2172.929492\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19162 (step 19162): 1.905797\n",
      "Batch #10\tAverage Generator Loss: 2422.933960\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19163 (step 19163): 1.291516\n",
      "Batch #10\tAverage Generator Loss: 2255.729321\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19164 (step 19164): 1.398230\n",
      "Batch #10\tAverage Generator Loss: 2540.563672\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19165 (step 19165): 1.288683\n",
      "Batch #10\tAverage Generator Loss: 2210.243188\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19166 (step 19166): 1.885102\n",
      "Batch #10\tAverage Generator Loss: 2449.882202\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19167 (step 19167): 1.281407\n",
      "Batch #10\tAverage Generator Loss: 2493.014062\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19168 (step 19168): 1.251854\n",
      "Batch #10\tAverage Generator Loss: 2494.443896\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19169 (step 19169): 1.349357\n",
      "Batch #10\tAverage Generator Loss: 2122.208228\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19170 (step 19170): 1.939960\n",
      "Batch #10\tAverage Generator Loss: 2162.407581\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19171 (step 19171): 1.399868\n",
      "Batch #10\tAverage Generator Loss: 2405.748596\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19172 (step 19172): 1.288805\n",
      "Batch #10\tAverage Generator Loss: 2359.101648\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19173 (step 19173): 1.991710\n",
      "Batch #10\tAverage Generator Loss: 2076.232861\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19174 (step 19174): 1.383406\n",
      "Batch #10\tAverage Generator Loss: 2275.969055\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19175 (step 19175): 1.296987\n",
      "Batch #10\tAverage Generator Loss: 2277.669177\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19176 (step 19176): 1.345243\n",
      "Batch #10\tAverage Generator Loss: 2290.448315\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19177 (step 19177): 1.875232\n",
      "Batch #10\tAverage Generator Loss: 2158.843384\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19178 (step 19178): 1.289822\n",
      "Batch #10\tAverage Generator Loss: 2214.419312\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19179 (step 19179): 1.288973\n",
      "Batch #10\tAverage Generator Loss: 2311.910815\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19180 (step 19180): 1.362602\n",
      "Batch #10\tAverage Generator Loss: 2325.981287\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19181 (step 19181): 1.891880\n",
      "Batch #10\tAverage Generator Loss: 2038.105920\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19182 (step 19182): 1.291269\n",
      "Batch #10\tAverage Generator Loss: 2316.418933\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19183 (step 19183): 1.396394\n",
      "Batch #10\tAverage Generator Loss: 1868.292810\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19184 (step 19184): 1.918527\n",
      "Batch #10\tAverage Generator Loss: 2255.180127\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19185 (step 19185): 1.293982\n",
      "Batch #10\tAverage Generator Loss: 2628.582446\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19186 (step 19186): 1.349351\n",
      "Batch #10\tAverage Generator Loss: 2318.969714\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19187 (step 19187): 1.291358\n",
      "Batch #10\tAverage Generator Loss: 2450.065662\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19188 (step 19188): 1.342145\n",
      "Batch #10\tAverage Generator Loss: 2337.745801\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19189 (step 19189): 1.900620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2149.412793\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19190 (step 19190): 1.296772\n",
      "Batch #10\tAverage Generator Loss: 2430.033521\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19191 (step 19191): 1.440810\n",
      "Batch #10\tAverage Generator Loss: 2152.588141\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19192 (step 19192): 1.931410\n",
      "Batch #10\tAverage Generator Loss: 2376.453308\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19193 (step 19193): 1.387895\n",
      "Batch #10\tAverage Generator Loss: 2495.572339\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19194 (step 19194): 1.232696\n",
      "Batch #10\tAverage Generator Loss: 2442.287683\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19195 (step 19195): 1.437685\n",
      "Batch #10\tAverage Generator Loss: 2332.792737\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19196 (step 19196): 1.922178\n",
      "Batch #10\tAverage Generator Loss: 2380.937292\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19197 (step 19197): 1.296033\n",
      "Batch #10\tAverage Generator Loss: 2267.207703\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19198 (step 19198): 1.293277\n",
      "Batch #10\tAverage Generator Loss: 2385.699622\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19199 (step 19199): 1.338329\n",
      "Batch #10\tAverage Generator Loss: 2305.763367\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19200 (step 19200): 2.056005\n",
      "Batch #10\tAverage Generator Loss: 2176.778101\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19201 (step 19201): 1.299643\n",
      "Batch #10\tAverage Generator Loss: 2135.613989\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19202 (step 19202): 1.326718\n",
      "Batch #10\tAverage Generator Loss: 2389.863501\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19203 (step 19203): 1.307360\n",
      "Batch #10\tAverage Generator Loss: 2521.258044\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19204 (step 19204): 1.937701\n",
      "Batch #10\tAverage Generator Loss: 2220.297498\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19205 (step 19205): 1.331051\n",
      "Batch #10\tAverage Generator Loss: 2451.848743\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19206 (step 19206): 1.342990\n",
      "Batch #10\tAverage Generator Loss: 2123.422656\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19207 (step 19207): 1.374500\n",
      "Batch #10\tAverage Generator Loss: 1960.895355\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19208 (step 19208): 1.977823\n",
      "Batch #10\tAverage Generator Loss: 2113.923547\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19209 (step 19209): 1.384986\n",
      "Batch #10\tAverage Generator Loss: 2593.619080\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19210 (step 19210): 1.245765\n",
      "Batch #10\tAverage Generator Loss: 2181.527206\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19211 (step 19211): 1.987133\n",
      "Batch #10\tAverage Generator Loss: 2335.104041\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19212 (step 19212): 1.379288\n",
      "Batch #10\tAverage Generator Loss: 2329.286597\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19213 (step 19213): 1.454046\n",
      "Batch #10\tAverage Generator Loss: 2155.016382\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19214 (step 19214): 1.274455\n",
      "Batch #10\tAverage Generator Loss: 2167.658044\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19215 (step 19215): 1.931527\n",
      "Batch #10\tAverage Generator Loss: 2323.504224\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19216 (step 19216): 1.321180\n",
      "Batch #10\tAverage Generator Loss: 2161.229919\tAverage Discriminator Loss: 0.002219\n",
      "\n",
      "Train time for epoch #19217 (step 19217): 1.392393\n",
      "Batch #10\tAverage Generator Loss: 1993.410876\tAverage Discriminator Loss: 0.000603\n",
      "\n",
      "Train time for epoch #19218 (step 19218): 1.393062\n",
      "Batch #10\tAverage Generator Loss: 2188.996631\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19219 (step 19219): 1.935688\n",
      "Batch #10\tAverage Generator Loss: 2067.633716\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19220 (step 19220): 1.285397\n",
      "Batch #10\tAverage Generator Loss: 2045.612341\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19221 (step 19221): 1.346538\n",
      "Batch #10\tAverage Generator Loss: 2557.476025\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19222 (step 19222): 1.340258\n",
      "Batch #10\tAverage Generator Loss: 2295.339734\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19223 (step 19223): 1.952996\n",
      "Batch #10\tAverage Generator Loss: 1997.949640\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19224 (step 19224): 1.443398\n",
      "Batch #10\tAverage Generator Loss: 2267.374438\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19225 (step 19225): 1.292673\n",
      "Batch #10\tAverage Generator Loss: 2183.060669\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19226 (step 19226): 1.389492\n",
      "Batch #10\tAverage Generator Loss: 2226.717395\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19227 (step 19227): 2.001163\n",
      "Batch #10\tAverage Generator Loss: 2289.898108\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19228 (step 19228): 1.347010\n",
      "Batch #10\tAverage Generator Loss: 2165.548865\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19229 (step 19229): 1.301382\n",
      "Batch #10\tAverage Generator Loss: 2290.288184\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19230 (step 19230): 1.949613\n",
      "Batch #10\tAverage Generator Loss: 2362.416467\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19231 (step 19231): 1.348772\n",
      "Batch #10\tAverage Generator Loss: 2051.327234\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19232 (step 19232): 1.329325\n",
      "Batch #10\tAverage Generator Loss: 2339.769397\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19233 (step 19233): 1.330494\n",
      "Batch #10\tAverage Generator Loss: 2199.084119\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19234 (step 19234): 2.019063\n",
      "Batch #10\tAverage Generator Loss: 2411.657397\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19235 (step 19235): 1.392205\n",
      "Batch #10\tAverage Generator Loss: 2468.751135\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19236 (step 19236): 1.291739\n",
      "Batch #10\tAverage Generator Loss: 2381.281702\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19237 (step 19237): 1.382411\n",
      "Batch #10\tAverage Generator Loss: 2140.469403\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19238 (step 19238): 1.972768\n",
      "Batch #10\tAverage Generator Loss: 2178.167975\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19239 (step 19239): 1.538046\n",
      "Batch #10\tAverage Generator Loss: 2456.214478\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19240 (step 19240): 1.236887\n",
      "Batch #10\tAverage Generator Loss: 2407.225195\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19241 (step 19241): 1.404933\n",
      "Batch #10\tAverage Generator Loss: 2389.162085\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19242 (step 19242): 1.969223\n",
      "Batch #10\tAverage Generator Loss: 2242.019080\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19243 (step 19243): 1.287752\n",
      "Batch #10\tAverage Generator Loss: 2152.650513\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19244 (step 19244): 1.455408\n",
      "Batch #10\tAverage Generator Loss: 2230.882666\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19245 (step 19245): 1.393988\n",
      "Batch #10\tAverage Generator Loss: 2321.222803\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19246 (step 19246): 1.829460\n",
      "Batch #10\tAverage Generator Loss: 2349.465967\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19247 (step 19247): 1.363316\n",
      "Batch #10\tAverage Generator Loss: 2306.300549\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19248 (step 19248): 1.254906\n",
      "Batch #10\tAverage Generator Loss: 2140.809137\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19249 (step 19249): 1.934220\n",
      "Batch #10\tAverage Generator Loss: 2336.322742\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19250 (step 19250): 1.235209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2190.081091\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19251 (step 19251): 1.296575\n",
      "Batch #10\tAverage Generator Loss: 2131.460565\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19252 (step 19252): 1.343982\n",
      "Batch #10\tAverage Generator Loss: 2223.942871\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19253 (step 19253): 1.886263\n",
      "Batch #10\tAverage Generator Loss: 2292.997571\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19254 (step 19254): 1.338238\n",
      "Batch #10\tAverage Generator Loss: 2474.533374\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19255 (step 19255): 1.392199\n",
      "Batch #10\tAverage Generator Loss: 2360.899878\tAverage Discriminator Loss: 0.185834\n",
      "\n",
      "Train time for epoch #19256 (step 19256): 1.335378\n",
      "Batch #10\tAverage Generator Loss: 3089.847070\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19257 (step 19257): 1.998832\n",
      "Batch #10\tAverage Generator Loss: 3047.715302\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19258 (step 19258): 1.347583\n",
      "Batch #10\tAverage Generator Loss: 2918.641516\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19259 (step 19259): 1.285697\n",
      "Batch #10\tAverage Generator Loss: 3001.206177\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19260 (step 19260): 1.341506\n",
      "Batch #10\tAverage Generator Loss: 3125.504614\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19261 (step 19261): 1.916890\n",
      "Batch #10\tAverage Generator Loss: 3176.479797\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19262 (step 19262): 1.285672\n",
      "Batch #10\tAverage Generator Loss: 3549.156494\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19263 (step 19263): 1.309336\n",
      "Batch #10\tAverage Generator Loss: 2961.870813\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19264 (step 19264): 1.928262\n",
      "Batch #10\tAverage Generator Loss: 3333.117603\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19265 (step 19265): 1.294740\n",
      "Batch #10\tAverage Generator Loss: 2898.930890\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19266 (step 19266): 1.487228\n",
      "Batch #10\tAverage Generator Loss: 3288.100659\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19267 (step 19267): 1.394000\n",
      "Batch #10\tAverage Generator Loss: 3385.731433\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19268 (step 19268): 2.001927\n",
      "Batch #10\tAverage Generator Loss: 2680.078882\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19269 (step 19269): 1.297488\n",
      "Batch #10\tAverage Generator Loss: 3464.558228\tAverage Discriminator Loss: 0.018519\n",
      "\n",
      "Train time for epoch #19270 (step 19270): 1.392310\n",
      "Batch #10\tAverage Generator Loss: 2849.999994\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19271 (step 19271): 1.460580\n",
      "Batch #10\tAverage Generator Loss: 3846.970410\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19272 (step 19272): 2.038425\n",
      "Batch #10\tAverage Generator Loss: 3614.158716\tAverage Discriminator Loss: 0.011844\n",
      "\n",
      "Train time for epoch #19273 (step 19273): 1.426486\n",
      "Batch #10\tAverage Generator Loss: 3708.424121\tAverage Discriminator Loss: 0.004457\n",
      "\n",
      "Train time for epoch #19274 (step 19274): 1.243268\n",
      "Batch #10\tAverage Generator Loss: 3618.707251\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19275 (step 19275): 1.384870\n",
      "Batch #10\tAverage Generator Loss: 3229.836084\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19276 (step 19276): 2.027750\n",
      "Batch #10\tAverage Generator Loss: 3385.930652\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19277 (step 19277): 1.337869\n",
      "Batch #10\tAverage Generator Loss: 3661.208472\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19278 (step 19278): 1.326226\n",
      "Batch #10\tAverage Generator Loss: 3307.637280\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19279 (step 19279): 1.353666\n",
      "Batch #10\tAverage Generator Loss: 3654.982788\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19280 (step 19280): 1.884736\n",
      "Batch #10\tAverage Generator Loss: 3377.925305\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19281 (step 19281): 1.379261\n",
      "Batch #10\tAverage Generator Loss: 3434.327344\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19282 (step 19282): 1.284233\n",
      "Batch #10\tAverage Generator Loss: 3622.946655\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19283 (step 19283): 1.293738\n",
      "Batch #10\tAverage Generator Loss: 3680.315674\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19284 (step 19284): 1.925811\n",
      "Batch #10\tAverage Generator Loss: 3663.093909\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19285 (step 19285): 1.252718\n",
      "Batch #10\tAverage Generator Loss: 2997.173730\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19286 (step 19286): 1.322024\n",
      "Batch #10\tAverage Generator Loss: 3533.537378\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19287 (step 19287): 1.936745\n",
      "Batch #10\tAverage Generator Loss: 3313.025623\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19288 (step 19288): 1.283898\n",
      "Batch #10\tAverage Generator Loss: 3576.023828\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19289 (step 19289): 1.331544\n",
      "Batch #10\tAverage Generator Loss: 3584.846960\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19290 (step 19290): 1.290274\n",
      "Batch #10\tAverage Generator Loss: 3211.112573\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19291 (step 19291): 1.828243\n",
      "Batch #10\tAverage Generator Loss: 3711.885645\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19292 (step 19292): 1.290210\n",
      "Batch #10\tAverage Generator Loss: 3382.275146\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19293 (step 19293): 1.334094\n",
      "Batch #10\tAverage Generator Loss: 3103.821167\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19294 (step 19294): 1.288835\n",
      "Batch #10\tAverage Generator Loss: 3395.980505\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19295 (step 19295): 1.866081\n",
      "Batch #10\tAverage Generator Loss: 3439.060278\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19296 (step 19296): 1.340998\n",
      "Batch #10\tAverage Generator Loss: 3227.269678\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19297 (step 19297): 1.251282\n",
      "Batch #10\tAverage Generator Loss: 2952.090173\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19298 (step 19298): 1.380804\n",
      "Batch #10\tAverage Generator Loss: 3353.475574\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19299 (step 19299): 1.949410\n",
      "Batch #10\tAverage Generator Loss: 3516.213232\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19300 (step 19300): 1.318664\n",
      "Batch #10\tAverage Generator Loss: 3563.113782\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19301 (step 19301): 1.300129\n",
      "Batch #10\tAverage Generator Loss: 3538.159045\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19302 (step 19302): 1.289748\n",
      "Batch #10\tAverage Generator Loss: 3337.316968\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19303 (step 19303): 1.963822\n",
      "Batch #10\tAverage Generator Loss: 3641.854688\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19304 (step 19304): 1.292111\n",
      "Batch #10\tAverage Generator Loss: 2994.689063\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19305 (step 19305): 1.433175\n",
      "Batch #10\tAverage Generator Loss: 3741.433752\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19306 (step 19306): 1.240261\n",
      "Batch #10\tAverage Generator Loss: 3391.646130\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19307 (step 19307): 1.990366\n",
      "Batch #10\tAverage Generator Loss: 3456.542798\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19308 (step 19308): 1.344012\n",
      "Batch #10\tAverage Generator Loss: 3352.145605\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19309 (step 19309): 1.370482\n",
      "Batch #10\tAverage Generator Loss: 3362.153882\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19310 (step 19310): 1.994718\n",
      "Batch #10\tAverage Generator Loss: 2919.194470\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19311 (step 19311): 1.290656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 3887.447144\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19312 (step 19312): 1.347713\n",
      "Batch #10\tAverage Generator Loss: 3026.499072\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19313 (step 19313): 1.334335\n",
      "Batch #10\tAverage Generator Loss: 2675.543799\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19314 (step 19314): 1.946660\n",
      "Batch #10\tAverage Generator Loss: 3149.429700\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19315 (step 19315): 1.321629\n",
      "Batch #10\tAverage Generator Loss: 3265.970874\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19316 (step 19316): 1.304845\n",
      "Batch #10\tAverage Generator Loss: 3179.819824\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19317 (step 19317): 1.310652\n",
      "Batch #10\tAverage Generator Loss: 3765.794507\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19318 (step 19318): 2.108405\n",
      "Batch #10\tAverage Generator Loss: 3115.476917\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19319 (step 19319): 1.385033\n",
      "Batch #10\tAverage Generator Loss: 3068.673181\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19320 (step 19320): 1.297688\n",
      "Batch #10\tAverage Generator Loss: 3352.091736\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19321 (step 19321): 1.363022\n",
      "Batch #10\tAverage Generator Loss: 2956.959412\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19322 (step 19322): 2.137092\n",
      "Batch #10\tAverage Generator Loss: 3782.460632\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19323 (step 19323): 1.378549\n",
      "Batch #10\tAverage Generator Loss: 3601.318542\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19324 (step 19324): 1.346832\n",
      "Batch #10\tAverage Generator Loss: 3477.406201\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19325 (step 19325): 1.380414\n",
      "Batch #10\tAverage Generator Loss: 3235.827954\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19326 (step 19326): 2.000278\n",
      "Batch #10\tAverage Generator Loss: 3477.856128\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19327 (step 19327): 1.292536\n",
      "Batch #10\tAverage Generator Loss: 3426.793506\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19328 (step 19328): 1.291254\n",
      "Batch #10\tAverage Generator Loss: 3041.720923\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19329 (step 19329): 1.340179\n",
      "Batch #10\tAverage Generator Loss: 3122.657678\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19330 (step 19330): 1.920588\n",
      "Batch #10\tAverage Generator Loss: 3363.761646\tAverage Discriminator Loss: 0.025561\n",
      "\n",
      "Train time for epoch #19331 (step 19331): 1.242075\n",
      "Batch #10\tAverage Generator Loss: 3367.857068\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19332 (step 19332): 1.306078\n",
      "Batch #10\tAverage Generator Loss: 3067.407800\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19333 (step 19333): 1.336536\n",
      "Batch #10\tAverage Generator Loss: 3027.976025\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19334 (step 19334): 1.883401\n",
      "Batch #10\tAverage Generator Loss: 2998.099268\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19335 (step 19335): 1.429960\n",
      "Batch #10\tAverage Generator Loss: 2929.641064\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19336 (step 19336): 1.276106\n",
      "Batch #10\tAverage Generator Loss: 2942.185181\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19337 (step 19337): 1.299417\n",
      "Batch #10\tAverage Generator Loss: 2987.707788\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19338 (step 19338): 1.835037\n",
      "Batch #10\tAverage Generator Loss: 2702.879382\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19339 (step 19339): 1.238832\n",
      "Batch #10\tAverage Generator Loss: 2993.322961\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19340 (step 19340): 1.280493\n",
      "Batch #10\tAverage Generator Loss: 2596.043591\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19341 (step 19341): 1.929353\n",
      "Batch #10\tAverage Generator Loss: 2713.614734\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19342 (step 19342): 1.309290\n",
      "Batch #10\tAverage Generator Loss: 3492.599170\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19343 (step 19343): 1.301393\n",
      "Batch #10\tAverage Generator Loss: 2705.742664\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19344 (step 19344): 1.292588\n",
      "Batch #10\tAverage Generator Loss: 2966.311035\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19345 (step 19345): 2.003961\n",
      "Batch #10\tAverage Generator Loss: 2606.289294\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19346 (step 19346): 1.481855\n",
      "Batch #10\tAverage Generator Loss: 2726.731586\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19347 (step 19347): 1.307509\n",
      "Batch #10\tAverage Generator Loss: 3214.480432\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19348 (step 19348): 1.294123\n",
      "Batch #10\tAverage Generator Loss: 3167.637903\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19349 (step 19349): 1.933341\n",
      "Batch #10\tAverage Generator Loss: 2891.374023\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19350 (step 19350): 1.308114\n",
      "Batch #10\tAverage Generator Loss: 2972.935815\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19351 (step 19351): 1.282431\n",
      "Batch #10\tAverage Generator Loss: 3189.310571\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19352 (step 19352): 1.284627\n",
      "Batch #10\tAverage Generator Loss: 3123.190649\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19353 (step 19353): 1.947648\n",
      "Batch #10\tAverage Generator Loss: 3155.687817\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19354 (step 19354): 1.451099\n",
      "Batch #10\tAverage Generator Loss: 3206.350098\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19355 (step 19355): 1.392290\n",
      "Batch #10\tAverage Generator Loss: 2688.575476\tAverage Discriminator Loss: 0.011832\n",
      "\n",
      "Train time for epoch #19356 (step 19356): 2.034831\n",
      "Batch #10\tAverage Generator Loss: 3314.207544\tAverage Discriminator Loss: 0.002522\n",
      "\n",
      "Train time for epoch #19357 (step 19357): 1.340476\n",
      "Batch #10\tAverage Generator Loss: 2960.304797\tAverage Discriminator Loss: 0.063589\n",
      "\n",
      "Train time for epoch #19358 (step 19358): 1.407177\n",
      "Batch #10\tAverage Generator Loss: 2736.958997\tAverage Discriminator Loss: 0.018562\n",
      "\n",
      "Train time for epoch #19359 (step 19359): 1.405631\n",
      "Batch #10\tAverage Generator Loss: 2340.117871\tAverage Discriminator Loss: 0.025097\n",
      "\n",
      "Train time for epoch #19360 (step 19360): 1.432990\n",
      "Batch #10\tAverage Generator Loss: 2972.227344\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19361 (step 19361): 1.944826\n",
      "Batch #10\tAverage Generator Loss: 2629.463318\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19362 (step 19362): 1.426581\n",
      "Batch #10\tAverage Generator Loss: 3074.017261\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19363 (step 19363): 1.348239\n",
      "Batch #10\tAverage Generator Loss: 3318.464941\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19364 (step 19364): 1.943855\n",
      "Batch #10\tAverage Generator Loss: 2900.768384\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19365 (step 19365): 1.292382\n",
      "Batch #10\tAverage Generator Loss: 2854.901740\tAverage Discriminator Loss: 0.059665\n",
      "\n",
      "Train time for epoch #19366 (step 19366): 1.284668\n",
      "Batch #10\tAverage Generator Loss: 3096.253259\tAverage Discriminator Loss: 0.006223\n",
      "\n",
      "Train time for epoch #19367 (step 19367): 1.307563\n",
      "Batch #10\tAverage Generator Loss: 3239.603552\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19368 (step 19368): 1.967367\n",
      "Batch #10\tAverage Generator Loss: 3956.526709\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19369 (step 19369): 1.333769\n",
      "Batch #10\tAverage Generator Loss: 3767.702979\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19370 (step 19370): 1.279005\n",
      "Batch #10\tAverage Generator Loss: 3730.142761\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #19371 (step 19371): 1.337945\n",
      "Batch #10\tAverage Generator Loss: 4079.438354\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19372 (step 19372): 1.959837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 3763.972473\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19373 (step 19373): 1.401614\n",
      "Batch #10\tAverage Generator Loss: 3483.003784\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19374 (step 19374): 1.483299\n",
      "Batch #10\tAverage Generator Loss: 4034.967480\tAverage Discriminator Loss: 0.012874\n",
      "\n",
      "Train time for epoch #19375 (step 19375): 1.383927\n",
      "Batch #10\tAverage Generator Loss: 4978.080127\tAverage Discriminator Loss: 0.094466\n",
      "\n",
      "Train time for epoch #19376 (step 19376): 1.887591\n",
      "Batch #10\tAverage Generator Loss: 5387.099829\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19377 (step 19377): 1.329932\n",
      "Batch #10\tAverage Generator Loss: 4990.512329\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19378 (step 19378): 1.338469\n",
      "Batch #10\tAverage Generator Loss: 5270.601050\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19379 (step 19379): 2.007569\n",
      "Batch #10\tAverage Generator Loss: 6275.030664\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19380 (step 19380): 1.290023\n",
      "Batch #10\tAverage Generator Loss: 5313.202441\tAverage Discriminator Loss: 0.093805\n",
      "\n",
      "Train time for epoch #19381 (step 19381): 1.324181\n",
      "Batch #10\tAverage Generator Loss: 4742.425757\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19382 (step 19382): 1.292595\n",
      "Batch #10\tAverage Generator Loss: 4156.804626\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19383 (step 19383): 1.986619\n",
      "Batch #10\tAverage Generator Loss: 4537.207910\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19384 (step 19384): 1.244393\n",
      "Batch #10\tAverage Generator Loss: 4056.087598\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19385 (step 19385): 1.320972\n",
      "Batch #10\tAverage Generator Loss: 3661.794879\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19386 (step 19386): 1.252885\n",
      "Batch #10\tAverage Generator Loss: 3781.233618\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19387 (step 19387): 1.917891\n",
      "Batch #10\tAverage Generator Loss: 3339.563147\tAverage Discriminator Loss: 0.002804\n",
      "\n",
      "Train time for epoch #19388 (step 19388): 1.361335\n",
      "Batch #10\tAverage Generator Loss: 3508.768164\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19389 (step 19389): 1.344199\n",
      "Batch #10\tAverage Generator Loss: 3602.947943\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19390 (step 19390): 1.382765\n",
      "Batch #10\tAverage Generator Loss: 3354.666248\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19391 (step 19391): 1.976579\n",
      "Batch #10\tAverage Generator Loss: 3199.271509\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19392 (step 19392): 1.326296\n",
      "Batch #10\tAverage Generator Loss: 3448.116064\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19393 (step 19393): 1.286826\n",
      "Batch #10\tAverage Generator Loss: 3437.623267\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19394 (step 19394): 1.442080\n",
      "Batch #10\tAverage Generator Loss: 3950.623242\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19395 (step 19395): 1.935951\n",
      "Batch #10\tAverage Generator Loss: 3632.947534\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19396 (step 19396): 1.383674\n",
      "Batch #10\tAverage Generator Loss: 3605.980347\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19397 (step 19397): 1.373445\n",
      "Batch #10\tAverage Generator Loss: 3146.297791\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19398 (step 19398): 1.992954\n",
      "Batch #10\tAverage Generator Loss: 3312.528125\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19399 (step 19399): 1.335600\n",
      "Batch #10\tAverage Generator Loss: 3445.347241\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19400 (step 19400): 1.308533\n",
      "Batch #10\tAverage Generator Loss: 3490.585852\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19401 (step 19401): 1.491823\n",
      "Batch #10\tAverage Generator Loss: 3629.263403\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19402 (step 19402): 1.904431\n",
      "Batch #10\tAverage Generator Loss: 3246.182935\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19403 (step 19403): 1.346774\n",
      "Batch #10\tAverage Generator Loss: 3572.357642\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19404 (step 19404): 1.305452\n",
      "Batch #10\tAverage Generator Loss: 3241.356189\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19405 (step 19405): 1.340774\n",
      "Batch #10\tAverage Generator Loss: 3634.493274\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19406 (step 19406): 1.932783\n",
      "Batch #10\tAverage Generator Loss: 3232.496643\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19407 (step 19407): 1.380292\n",
      "Batch #10\tAverage Generator Loss: 2715.078351\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19408 (step 19408): 1.347697\n",
      "Batch #10\tAverage Generator Loss: 2738.270038\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19409 (step 19409): 1.241555\n",
      "Batch #10\tAverage Generator Loss: 2917.995569\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19410 (step 19410): 1.888303\n",
      "Batch #10\tAverage Generator Loss: 3126.371594\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19411 (step 19411): 1.363369\n",
      "Batch #10\tAverage Generator Loss: 3215.875970\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19412 (step 19412): 1.385827\n",
      "Batch #10\tAverage Generator Loss: 3359.951929\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19413 (step 19413): 1.285473\n",
      "Batch #10\tAverage Generator Loss: 2888.055283\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19414 (step 19414): 1.879999\n",
      "Batch #10\tAverage Generator Loss: 3340.058044\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19415 (step 19415): 1.334099\n",
      "Batch #10\tAverage Generator Loss: 3330.545740\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19416 (step 19416): 1.291671\n",
      "Batch #10\tAverage Generator Loss: 3422.608887\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19417 (step 19417): 1.923702\n",
      "Batch #10\tAverage Generator Loss: 3999.163623\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19418 (step 19418): 1.334039\n",
      "Batch #10\tAverage Generator Loss: 3246.909937\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19419 (step 19419): 1.378384\n",
      "Batch #10\tAverage Generator Loss: 3395.695569\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19420 (step 19420): 1.323908\n",
      "Batch #10\tAverage Generator Loss: 3197.122070\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19421 (step 19421): 2.049230\n",
      "Batch #10\tAverage Generator Loss: 2774.781848\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19422 (step 19422): 1.339753\n",
      "Batch #10\tAverage Generator Loss: 3859.839575\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19423 (step 19423): 1.305303\n",
      "Batch #10\tAverage Generator Loss: 3218.598010\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19424 (step 19424): 1.299150\n",
      "Batch #10\tAverage Generator Loss: 3259.377307\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19425 (step 19425): 1.914248\n",
      "Batch #10\tAverage Generator Loss: 3418.774792\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19426 (step 19426): 1.405761\n",
      "Batch #10\tAverage Generator Loss: 3046.896338\tAverage Discriminator Loss: 0.020172\n",
      "\n",
      "Train time for epoch #19427 (step 19427): 1.400870\n",
      "Batch #10\tAverage Generator Loss: 3242.270728\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19428 (step 19428): 1.291109\n",
      "Batch #10\tAverage Generator Loss: 2953.059595\tAverage Discriminator Loss: 0.081627\n",
      "\n",
      "Train time for epoch #19429 (step 19429): 1.934748\n",
      "Batch #10\tAverage Generator Loss: 2413.348450\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19430 (step 19430): 1.281787\n",
      "Batch #10\tAverage Generator Loss: 2714.520032\tAverage Discriminator Loss: 0.087339\n",
      "\n",
      "Train time for epoch #19431 (step 19431): 1.239492\n",
      "Batch #10\tAverage Generator Loss: 2248.870728\tAverage Discriminator Loss: 0.084701\n",
      "\n",
      "Train time for epoch #19432 (step 19432): 1.291512\n",
      "Batch #10\tAverage Generator Loss: 2256.198499\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #19433 (step 19433): 1.981561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2236.637054\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19434 (step 19434): 1.310064\n",
      "Batch #10\tAverage Generator Loss: 2078.024280\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19435 (step 19435): 1.280632\n",
      "Batch #10\tAverage Generator Loss: 2153.920996\tAverage Discriminator Loss: 0.017545\n",
      "\n",
      "Train time for epoch #19436 (step 19436): 1.321467\n",
      "Batch #10\tAverage Generator Loss: 2078.032825\tAverage Discriminator Loss: 0.000095\n",
      "\n",
      "Train time for epoch #19437 (step 19437): 2.050537\n",
      "Batch #10\tAverage Generator Loss: 2373.380139\tAverage Discriminator Loss: 0.000022\n",
      "\n",
      "Train time for epoch #19438 (step 19438): 1.344854\n",
      "Batch #10\tAverage Generator Loss: 2367.148486\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #19439 (step 19439): 1.322780\n",
      "Batch #10\tAverage Generator Loss: 2625.973364\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #19440 (step 19440): 1.454776\n",
      "Batch #10\tAverage Generator Loss: 2316.825580\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #19441 (step 19441): 2.005109\n",
      "Batch #10\tAverage Generator Loss: 2302.445752\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #19442 (step 19442): 1.379208\n",
      "Batch #10\tAverage Generator Loss: 2445.133850\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #19443 (step 19443): 1.296192\n",
      "Batch #10\tAverage Generator Loss: 2498.456909\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #19444 (step 19444): 2.051888\n",
      "Batch #10\tAverage Generator Loss: 2848.173071\tAverage Discriminator Loss: 0.048659\n",
      "\n",
      "Train time for epoch #19445 (step 19445): 1.278149\n",
      "Batch #10\tAverage Generator Loss: 3168.964807\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19446 (step 19446): 1.336025\n",
      "Batch #10\tAverage Generator Loss: 2784.052643\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19447 (step 19447): 1.349049\n",
      "Batch #10\tAverage Generator Loss: 3072.392456\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19448 (step 19448): 1.982476\n",
      "Batch #10\tAverage Generator Loss: 2793.510449\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19449 (step 19449): 1.377084\n",
      "Batch #10\tAverage Generator Loss: 2903.514307\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19450 (step 19450): 1.416968\n",
      "Batch #10\tAverage Generator Loss: 3345.145654\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19451 (step 19451): 1.356199\n",
      "Batch #10\tAverage Generator Loss: 2799.425903\tAverage Discriminator Loss: 0.118397\n",
      "\n",
      "Train time for epoch #19452 (step 19452): 1.924056\n",
      "Batch #10\tAverage Generator Loss: 2941.359473\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19453 (step 19453): 1.333007\n",
      "Batch #10\tAverage Generator Loss: 3086.536719\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19454 (step 19454): 1.319175\n",
      "Batch #10\tAverage Generator Loss: 2516.285156\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19455 (step 19455): 1.390341\n",
      "Batch #10\tAverage Generator Loss: 2694.522791\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19456 (step 19456): 2.017685\n",
      "Batch #10\tAverage Generator Loss: 2827.935522\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19457 (step 19457): 1.295910\n",
      "Batch #10\tAverage Generator Loss: 2665.697937\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19458 (step 19458): 1.336112\n",
      "Batch #10\tAverage Generator Loss: 2976.773804\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19459 (step 19459): 1.351806\n",
      "Batch #10\tAverage Generator Loss: 2913.661145\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19460 (step 19460): 1.904962\n",
      "Batch #10\tAverage Generator Loss: 2987.881738\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19461 (step 19461): 1.371122\n",
      "Batch #10\tAverage Generator Loss: 3020.101343\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19462 (step 19462): 1.304179\n",
      "Batch #10\tAverage Generator Loss: 2527.507922\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19463 (step 19463): 1.287679\n",
      "Batch #10\tAverage Generator Loss: 3263.756714\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19464 (step 19464): 2.009786\n",
      "Batch #10\tAverage Generator Loss: 2749.970166\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19465 (step 19465): 1.379727\n",
      "Batch #10\tAverage Generator Loss: 3127.906519\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19466 (step 19466): 1.328756\n",
      "Batch #10\tAverage Generator Loss: 2872.781250\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19467 (step 19467): 1.294960\n",
      "Batch #10\tAverage Generator Loss: 3122.357483\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19468 (step 19468): 2.000294\n",
      "Batch #10\tAverage Generator Loss: 2629.240094\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19469 (step 19469): 1.378350\n",
      "Batch #10\tAverage Generator Loss: 3277.736719\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19470 (step 19470): 1.341065\n",
      "Batch #10\tAverage Generator Loss: 2887.492273\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19471 (step 19471): 1.363207\n",
      "Batch #10\tAverage Generator Loss: 2864.389270\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19472 (step 19472): 1.938070\n",
      "Batch #10\tAverage Generator Loss: 3091.217041\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19473 (step 19473): 1.313309\n",
      "Batch #10\tAverage Generator Loss: 3000.466858\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19474 (step 19474): 1.263835\n",
      "Batch #10\tAverage Generator Loss: 3157.126611\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19475 (step 19475): 2.119208\n",
      "Batch #10\tAverage Generator Loss: 2727.934106\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19476 (step 19476): 1.297767\n",
      "Batch #10\tAverage Generator Loss: 2726.042456\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19477 (step 19477): 1.268600\n",
      "Batch #10\tAverage Generator Loss: 3180.005530\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19478 (step 19478): 1.342609\n",
      "Batch #10\tAverage Generator Loss: 3096.609705\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19479 (step 19479): 1.941720\n",
      "Batch #10\tAverage Generator Loss: 2661.666321\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19480 (step 19480): 1.325026\n",
      "Batch #10\tAverage Generator Loss: 2257.471515\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19481 (step 19481): 1.301116\n",
      "Batch #10\tAverage Generator Loss: 2671.504150\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19482 (step 19482): 1.385049\n",
      "Batch #10\tAverage Generator Loss: 2829.063281\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19483 (step 19483): 1.978721\n",
      "Batch #10\tAverage Generator Loss: 2818.278589\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19484 (step 19484): 1.262461\n",
      "Batch #10\tAverage Generator Loss: 2693.830652\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19485 (step 19485): 1.350640\n",
      "Batch #10\tAverage Generator Loss: 2749.949341\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19486 (step 19486): 1.293000\n",
      "Batch #10\tAverage Generator Loss: 2565.540924\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19487 (step 19487): 2.054622\n",
      "Batch #10\tAverage Generator Loss: 2414.580005\tAverage Discriminator Loss: 0.000163\n",
      "\n",
      "Train time for epoch #19488 (step 19488): 1.286838\n",
      "Batch #10\tAverage Generator Loss: 2701.324622\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19489 (step 19489): 1.303725\n",
      "Batch #10\tAverage Generator Loss: 2819.549158\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19490 (step 19490): 1.245355\n",
      "Batch #10\tAverage Generator Loss: 3039.950159\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19491 (step 19491): 1.915960\n",
      "Batch #10\tAverage Generator Loss: 2934.421954\tAverage Discriminator Loss: 0.009390\n",
      "\n",
      "Train time for epoch #19492 (step 19492): 1.301405\n",
      "Batch #10\tAverage Generator Loss: 2659.660596\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19493 (step 19493): 1.321236\n",
      "Batch #10\tAverage Generator Loss: 2840.370764\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19494 (step 19494): 1.286943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2943.647974\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19495 (step 19495): 1.978172\n",
      "Batch #10\tAverage Generator Loss: 2743.911096\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19496 (step 19496): 1.400420\n",
      "Batch #10\tAverage Generator Loss: 2758.625305\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19497 (step 19497): 1.452561\n",
      "Batch #10\tAverage Generator Loss: 2449.209705\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19498 (step 19498): 1.965053\n",
      "Batch #10\tAverage Generator Loss: 2573.588086\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19499 (step 19499): 1.340554\n",
      "Batch #10\tAverage Generator Loss: 2691.491150\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19500 (step 19500): 1.334036\n",
      "Batch #10\tAverage Generator Loss: 2824.694934\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19501 (step 19501): 1.290292\n",
      "Batch #10\tAverage Generator Loss: 2678.757751\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19502 (step 19502): 1.961058\n",
      "Batch #10\tAverage Generator Loss: 2987.737659\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19503 (step 19503): 1.369569\n",
      "Batch #10\tAverage Generator Loss: 2472.627429\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19504 (step 19504): 1.383710\n",
      "Batch #10\tAverage Generator Loss: 2998.143909\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19505 (step 19505): 1.334856\n",
      "Batch #10\tAverage Generator Loss: 2958.505371\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19506 (step 19506): 1.979322\n",
      "Batch #10\tAverage Generator Loss: 2600.196729\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19507 (step 19507): 1.378647\n",
      "Batch #10\tAverage Generator Loss: 2648.659070\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19508 (step 19508): 1.345884\n",
      "Batch #10\tAverage Generator Loss: 3030.064685\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19509 (step 19509): 1.294606\n",
      "Batch #10\tAverage Generator Loss: 2835.010645\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19510 (step 19510): 1.965231\n",
      "Batch #10\tAverage Generator Loss: 2731.927173\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19511 (step 19511): 1.346095\n",
      "Batch #10\tAverage Generator Loss: 2817.735413\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19512 (step 19512): 1.355830\n",
      "Batch #10\tAverage Generator Loss: 3046.561731\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19513 (step 19513): 1.348011\n",
      "Batch #10\tAverage Generator Loss: 3048.772949\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19514 (step 19514): 1.913213\n",
      "Batch #10\tAverage Generator Loss: 3037.251477\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19515 (step 19515): 1.347579\n",
      "Batch #10\tAverage Generator Loss: 2755.549890\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19516 (step 19516): 1.250531\n",
      "Batch #10\tAverage Generator Loss: 2874.238611\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19517 (step 19517): 1.347295\n",
      "Batch #10\tAverage Generator Loss: 2746.692249\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19518 (step 19518): 1.966035\n",
      "Batch #10\tAverage Generator Loss: 2562.329242\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19519 (step 19519): 1.250727\n",
      "Batch #10\tAverage Generator Loss: 2117.887231\tAverage Discriminator Loss: 0.101069\n",
      "\n",
      "Train time for epoch #19520 (step 19520): 1.330967\n",
      "Batch #10\tAverage Generator Loss: 1902.921356\tAverage Discriminator Loss: 0.000011\n",
      "\n",
      "Train time for epoch #19521 (step 19521): 2.006402\n",
      "Batch #10\tAverage Generator Loss: 2266.319159\tAverage Discriminator Loss: 0.000016\n",
      "\n",
      "Train time for epoch #19522 (step 19522): 1.329866\n",
      "Batch #10\tAverage Generator Loss: 2465.788672\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #19523 (step 19523): 1.240903\n",
      "Batch #10\tAverage Generator Loss: 2305.398828\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #19524 (step 19524): 1.331759\n",
      "Batch #10\tAverage Generator Loss: 2378.673840\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #19525 (step 19525): 1.883149\n",
      "Batch #10\tAverage Generator Loss: 2421.219763\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #19526 (step 19526): 1.385966\n",
      "Batch #10\tAverage Generator Loss: 1967.756317\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #19527 (step 19527): 1.432213\n",
      "Batch #10\tAverage Generator Loss: 2138.266199\tAverage Discriminator Loss: 0.000017\n",
      "\n",
      "Train time for epoch #19528 (step 19528): 1.292933\n",
      "Batch #10\tAverage Generator Loss: 2067.356830\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #19529 (step 19529): 1.896904\n",
      "Batch #10\tAverage Generator Loss: 2167.256995\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19530 (step 19530): 1.382414\n",
      "Batch #10\tAverage Generator Loss: 2598.602771\tAverage Discriminator Loss: 0.000688\n",
      "\n",
      "Train time for epoch #19531 (step 19531): 1.283031\n",
      "Batch #10\tAverage Generator Loss: 2109.049182\tAverage Discriminator Loss: 0.000038\n",
      "\n",
      "Train time for epoch #19532 (step 19532): 1.274829\n",
      "Batch #10\tAverage Generator Loss: 2186.972949\tAverage Discriminator Loss: 0.000037\n",
      "\n",
      "Train time for epoch #19533 (step 19533): 1.889137\n",
      "Batch #10\tAverage Generator Loss: 2626.894421\tAverage Discriminator Loss: 0.000012\n",
      "\n",
      "Train time for epoch #19534 (step 19534): 1.285901\n",
      "Batch #10\tAverage Generator Loss: 2149.508545\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #19535 (step 19535): 1.333824\n",
      "Batch #10\tAverage Generator Loss: 2184.741577\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #19536 (step 19536): 1.331798\n",
      "Batch #10\tAverage Generator Loss: 2578.731653\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #19537 (step 19537): 1.830863\n",
      "Batch #10\tAverage Generator Loss: 2262.529578\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #19538 (step 19538): 1.397673\n",
      "Batch #10\tAverage Generator Loss: 2482.396021\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #19539 (step 19539): 1.376409\n",
      "Batch #10\tAverage Generator Loss: 2221.647723\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19540 (step 19540): 1.292413\n",
      "Batch #10\tAverage Generator Loss: 2393.266248\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #19541 (step 19541): 1.971291\n",
      "Batch #10\tAverage Generator Loss: 2639.975830\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19542 (step 19542): 1.378828\n",
      "Batch #10\tAverage Generator Loss: 2770.066699\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19543 (step 19543): 1.293254\n",
      "Batch #10\tAverage Generator Loss: 2572.464148\tAverage Discriminator Loss: 0.009722\n",
      "\n",
      "Train time for epoch #19544 (step 19544): 1.292769\n",
      "Batch #10\tAverage Generator Loss: 2253.089832\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19545 (step 19545): 1.958248\n",
      "Batch #10\tAverage Generator Loss: 2732.760889\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19546 (step 19546): 1.254870\n",
      "Batch #10\tAverage Generator Loss: 2440.680920\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19547 (step 19547): 1.392089\n",
      "Batch #10\tAverage Generator Loss: 2947.823291\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19548 (step 19548): 1.943003\n",
      "Batch #10\tAverage Generator Loss: 2303.985587\tAverage Discriminator Loss: 0.032737\n",
      "\n",
      "Train time for epoch #19549 (step 19549): 1.303359\n",
      "Batch #10\tAverage Generator Loss: 3087.481580\tAverage Discriminator Loss: 0.000053\n",
      "\n",
      "Train time for epoch #19550 (step 19550): 1.279148\n",
      "Batch #10\tAverage Generator Loss: 2573.316479\tAverage Discriminator Loss: 0.000186\n",
      "\n",
      "Train time for epoch #19551 (step 19551): 1.339581\n",
      "Batch #10\tAverage Generator Loss: 2238.667218\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #19552 (step 19552): 1.942391\n",
      "Batch #10\tAverage Generator Loss: 2463.707043\tAverage Discriminator Loss: 0.003104\n",
      "\n",
      "Train time for epoch #19553 (step 19553): 1.292969\n",
      "Batch #10\tAverage Generator Loss: 2631.613354\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19554 (step 19554): 1.449907\n",
      "Batch #10\tAverage Generator Loss: 3012.556628\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19555 (step 19555): 1.315981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2814.940906\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19556 (step 19556): 1.960947\n",
      "Batch #10\tAverage Generator Loss: 2829.049609\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19557 (step 19557): 1.285670\n",
      "Batch #10\tAverage Generator Loss: 2466.697937\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19558 (step 19558): 1.437519\n",
      "Batch #10\tAverage Generator Loss: 2719.832574\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19559 (step 19559): 1.374173\n",
      "Batch #10\tAverage Generator Loss: 2744.651282\tAverage Discriminator Loss: 0.000863\n",
      "\n",
      "Train time for epoch #19560 (step 19560): 2.099800\n",
      "Batch #10\tAverage Generator Loss: 2462.527863\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19561 (step 19561): 1.274223\n",
      "Batch #10\tAverage Generator Loss: 2714.578491\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19562 (step 19562): 1.335436\n",
      "Batch #10\tAverage Generator Loss: 2480.740039\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19563 (step 19563): 1.285626\n",
      "Batch #10\tAverage Generator Loss: 3063.037231\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19564 (step 19564): 1.923271\n",
      "Batch #10\tAverage Generator Loss: 2264.245129\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19565 (step 19565): 1.291134\n",
      "Batch #10\tAverage Generator Loss: 2960.949493\tAverage Discriminator Loss: 0.403179\n",
      "\n",
      "Train time for epoch #19566 (step 19566): 1.335605\n",
      "Batch #10\tAverage Generator Loss: 2534.565161\tAverage Discriminator Loss: 0.000054\n",
      "\n",
      "Train time for epoch #19567 (step 19567): 1.246113\n",
      "Batch #10\tAverage Generator Loss: 1935.002515\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #19568 (step 19568): 1.907908\n",
      "Batch #10\tAverage Generator Loss: 2088.317743\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19569 (step 19569): 1.287585\n",
      "Batch #10\tAverage Generator Loss: 2337.630859\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19570 (step 19570): 1.418830\n",
      "Batch #10\tAverage Generator Loss: 1900.789771\tAverage Discriminator Loss: 0.037641\n",
      "\n",
      "Train time for epoch #19571 (step 19571): 1.899950\n",
      "Batch #10\tAverage Generator Loss: 2385.363013\tAverage Discriminator Loss: 0.037156\n",
      "\n",
      "Train time for epoch #19572 (step 19572): 1.379401\n",
      "Batch #10\tAverage Generator Loss: 2873.156592\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19573 (step 19573): 1.306340\n",
      "Batch #10\tAverage Generator Loss: 2532.035364\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19574 (step 19574): 1.357037\n",
      "Batch #10\tAverage Generator Loss: 2758.088953\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19575 (step 19575): 1.889649\n",
      "Batch #10\tAverage Generator Loss: 2706.771411\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19576 (step 19576): 1.291690\n",
      "Batch #10\tAverage Generator Loss: 2279.844055\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19577 (step 19577): 1.380374\n",
      "Batch #10\tAverage Generator Loss: 2957.137048\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19578 (step 19578): 1.295788\n",
      "Batch #10\tAverage Generator Loss: 2621.883179\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19579 (step 19579): 2.078937\n",
      "Batch #10\tAverage Generator Loss: 2514.933167\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19580 (step 19580): 1.284847\n",
      "Batch #10\tAverage Generator Loss: 2971.681799\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19581 (step 19581): 1.290361\n",
      "Batch #10\tAverage Generator Loss: 2960.545117\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19582 (step 19582): 1.399173\n",
      "Batch #10\tAverage Generator Loss: 2124.818060\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19583 (step 19583): 2.103317\n",
      "Batch #10\tAverage Generator Loss: 2405.074646\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19584 (step 19584): 1.344583\n",
      "Batch #10\tAverage Generator Loss: 2764.842920\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19585 (step 19585): 1.444397\n",
      "Batch #10\tAverage Generator Loss: 2380.795013\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19586 (step 19586): 1.274319\n",
      "Batch #10\tAverage Generator Loss: 2684.666821\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19587 (step 19587): 1.941274\n",
      "Batch #10\tAverage Generator Loss: 2675.957031\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19588 (step 19588): 1.289955\n",
      "Batch #10\tAverage Generator Loss: 2643.956702\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19589 (step 19589): 1.273910\n",
      "Batch #10\tAverage Generator Loss: 2617.280774\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19590 (step 19590): 1.314727\n",
      "Batch #10\tAverage Generator Loss: 2842.675183\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19591 (step 19591): 1.942169\n",
      "Batch #10\tAverage Generator Loss: 2722.466821\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19592 (step 19592): 1.320973\n",
      "Batch #10\tAverage Generator Loss: 2623.618829\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19593 (step 19593): 1.344934\n",
      "Batch #10\tAverage Generator Loss: 2969.980737\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19594 (step 19594): 1.342625\n",
      "Batch #10\tAverage Generator Loss: 2750.635602\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19595 (step 19595): 2.022372\n",
      "Batch #10\tAverage Generator Loss: 2780.072412\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19596 (step 19596): 1.281964\n",
      "Batch #10\tAverage Generator Loss: 3012.666736\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19597 (step 19597): 1.295370\n",
      "Batch #10\tAverage Generator Loss: 3185.802771\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19598 (step 19598): 1.410101\n",
      "Batch #10\tAverage Generator Loss: 2946.487683\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19599 (step 19599): 1.937092\n",
      "Batch #10\tAverage Generator Loss: 2609.546179\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19600 (step 19600): 1.405256\n",
      "Batch #10\tAverage Generator Loss: 2782.976135\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19601 (step 19601): 1.283671\n",
      "Batch #10\tAverage Generator Loss: 2371.027228\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19602 (step 19602): 1.513124\n",
      "Batch #10\tAverage Generator Loss: 3139.278345\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19603 (step 19603): 2.031288\n",
      "Batch #10\tAverage Generator Loss: 2717.328601\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19604 (step 19604): 1.294116\n",
      "Batch #10\tAverage Generator Loss: 3426.259375\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19605 (step 19605): 1.323559\n",
      "Batch #10\tAverage Generator Loss: 2477.757190\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19606 (step 19606): 1.333984\n",
      "Batch #10\tAverage Generator Loss: 3100.518579\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19607 (step 19607): 1.866763\n",
      "Batch #10\tAverage Generator Loss: 3134.204822\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19608 (step 19608): 1.372837\n",
      "Batch #10\tAverage Generator Loss: 2836.713983\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19609 (step 19609): 1.293005\n",
      "Batch #10\tAverage Generator Loss: 2671.020105\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19610 (step 19610): 1.344119\n",
      "Batch #10\tAverage Generator Loss: 2755.567065\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19611 (step 19611): 1.879528\n",
      "Batch #10\tAverage Generator Loss: 2874.621741\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19612 (step 19612): 1.288914\n",
      "Batch #10\tAverage Generator Loss: 2252.066943\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19613 (step 19613): 1.438992\n",
      "Batch #10\tAverage Generator Loss: 3008.320874\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19614 (step 19614): 1.388468\n",
      "Batch #10\tAverage Generator Loss: 2208.668835\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19615 (step 19615): 1.978725\n",
      "Batch #10\tAverage Generator Loss: 2589.696716\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19616 (step 19616): 1.300498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2383.114587\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19617 (step 19617): 1.362940\n",
      "Batch #10\tAverage Generator Loss: 2684.891675\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19618 (step 19618): 1.983487\n",
      "Batch #10\tAverage Generator Loss: 2738.936584\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19619 (step 19619): 1.338516\n",
      "Batch #10\tAverage Generator Loss: 2578.570978\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19620 (step 19620): 1.285478\n",
      "Batch #10\tAverage Generator Loss: 2215.167413\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19621 (step 19621): 1.304593\n",
      "Batch #10\tAverage Generator Loss: 3159.546289\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19622 (step 19622): 2.065970\n",
      "Batch #10\tAverage Generator Loss: 3120.226782\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19623 (step 19623): 1.386272\n",
      "Batch #10\tAverage Generator Loss: 2133.413031\tAverage Discriminator Loss: 0.103156\n",
      "\n",
      "Train time for epoch #19624 (step 19624): 1.247719\n",
      "Batch #10\tAverage Generator Loss: 3544.971252\tAverage Discriminator Loss: 0.023318\n",
      "\n",
      "Train time for epoch #19625 (step 19625): 1.350859\n",
      "Batch #10\tAverage Generator Loss: 3845.403516\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19626 (step 19626): 1.964319\n",
      "Batch #10\tAverage Generator Loss: 3778.431348\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19627 (step 19627): 1.385430\n",
      "Batch #10\tAverage Generator Loss: 3927.964905\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19628 (step 19628): 1.297143\n",
      "Batch #10\tAverage Generator Loss: 3652.397449\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19629 (step 19629): 1.244013\n",
      "Batch #10\tAverage Generator Loss: 3844.319067\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19630 (step 19630): 1.958517\n",
      "Batch #10\tAverage Generator Loss: 3799.583752\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19631 (step 19631): 1.330338\n",
      "Batch #10\tAverage Generator Loss: 3829.051062\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19632 (step 19632): 1.401670\n",
      "Batch #10\tAverage Generator Loss: 4065.785071\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19633 (step 19633): 1.444340\n",
      "Batch #10\tAverage Generator Loss: 2792.022253\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19634 (step 19634): 2.020247\n",
      "Batch #10\tAverage Generator Loss: 3415.841138\tAverage Discriminator Loss: 0.063297\n",
      "\n",
      "Train time for epoch #19635 (step 19635): 1.429545\n",
      "Batch #10\tAverage Generator Loss: 2805.318530\tAverage Discriminator Loss: 0.000312\n",
      "\n",
      "Train time for epoch #19636 (step 19636): 1.297145\n",
      "Batch #10\tAverage Generator Loss: 3447.313794\tAverage Discriminator Loss: 0.000006\n",
      "\n",
      "Train time for epoch #19637 (step 19637): 1.285190\n",
      "Batch #10\tAverage Generator Loss: 3250.066553\tAverage Discriminator Loss: 0.000004\n",
      "\n",
      "Train time for epoch #19638 (step 19638): 1.912470\n",
      "Batch #10\tAverage Generator Loss: 3353.238611\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19639 (step 19639): 1.340236\n",
      "Batch #10\tAverage Generator Loss: 2897.070300\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19640 (step 19640): 1.380483\n",
      "Batch #10\tAverage Generator Loss: 3432.466724\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19641 (step 19641): 1.390842\n",
      "Batch #10\tAverage Generator Loss: 3177.096033\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19642 (step 19642): 1.952541\n",
      "Batch #10\tAverage Generator Loss: 3377.384631\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19643 (step 19643): 1.346539\n",
      "Batch #10\tAverage Generator Loss: 2795.905066\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19644 (step 19644): 1.293931\n",
      "Batch #10\tAverage Generator Loss: 3419.871643\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19645 (step 19645): 1.338001\n",
      "Batch #10\tAverage Generator Loss: 3166.040369\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19646 (step 19646): 1.882426\n",
      "Batch #10\tAverage Generator Loss: 4173.289771\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19647 (step 19647): 1.292066\n",
      "Batch #10\tAverage Generator Loss: 3649.127319\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19648 (step 19648): 1.324508\n",
      "Batch #10\tAverage Generator Loss: 2997.393304\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19649 (step 19649): 2.006940\n",
      "Batch #10\tAverage Generator Loss: 3054.764758\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19650 (step 19650): 1.330299\n",
      "Batch #10\tAverage Generator Loss: 3315.188916\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19651 (step 19651): 1.405038\n",
      "Batch #10\tAverage Generator Loss: 3465.113391\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19652 (step 19652): 1.383326\n",
      "Batch #10\tAverage Generator Loss: 3225.090137\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19653 (step 19653): 1.884253\n",
      "Batch #10\tAverage Generator Loss: 3231.885852\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19654 (step 19654): 1.297098\n",
      "Batch #10\tAverage Generator Loss: 3148.715344\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19655 (step 19655): 1.381843\n",
      "Batch #10\tAverage Generator Loss: 2717.953369\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19656 (step 19656): 1.334947\n",
      "Batch #10\tAverage Generator Loss: 3524.388574\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19657 (step 19657): 2.001902\n",
      "Batch #10\tAverage Generator Loss: 3544.031958\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19658 (step 19658): 1.372882\n",
      "Batch #10\tAverage Generator Loss: 3274.776697\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19659 (step 19659): 1.340393\n",
      "Batch #10\tAverage Generator Loss: 3750.441418\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19660 (step 19660): 1.289946\n",
      "Batch #10\tAverage Generator Loss: 3748.601892\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19661 (step 19661): 2.116351\n",
      "Batch #10\tAverage Generator Loss: 3901.261963\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19662 (step 19662): 1.291403\n",
      "Batch #10\tAverage Generator Loss: 2758.731702\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19663 (step 19663): 1.236899\n",
      "Batch #10\tAverage Generator Loss: 3964.364404\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19664 (step 19664): 1.382572\n",
      "Batch #10\tAverage Generator Loss: 3577.871753\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19665 (step 19665): 1.944969\n",
      "Batch #10\tAverage Generator Loss: 3922.706616\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19666 (step 19666): 1.397099\n",
      "Batch #10\tAverage Generator Loss: 3414.801624\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19667 (step 19667): 1.391982\n",
      "Batch #10\tAverage Generator Loss: 3523.589124\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19668 (step 19668): 1.483565\n",
      "Batch #10\tAverage Generator Loss: 3629.492627\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19669 (step 19669): 2.035904\n",
      "Batch #10\tAverage Generator Loss: 3320.924817\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19670 (step 19670): 1.351115\n",
      "Batch #10\tAverage Generator Loss: 3574.775439\tAverage Discriminator Loss: 0.007550\n",
      "\n",
      "Train time for epoch #19671 (step 19671): 1.288908\n",
      "Batch #10\tAverage Generator Loss: 3477.977429\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19672 (step 19672): 1.950356\n",
      "Batch #10\tAverage Generator Loss: 3765.882178\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19673 (step 19673): 1.327918\n",
      "Batch #10\tAverage Generator Loss: 3492.942126\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #19674 (step 19674): 1.332059\n",
      "Batch #10\tAverage Generator Loss: 2948.431866\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #19675 (step 19675): 1.278857\n",
      "Batch #10\tAverage Generator Loss: 2968.523682\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #19676 (step 19676): 1.957395\n",
      "Batch #10\tAverage Generator Loss: 3691.272168\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #19677 (step 19677): 1.343083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 3588.729224\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19678 (step 19678): 1.304031\n",
      "Batch #10\tAverage Generator Loss: 3518.862646\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19679 (step 19679): 1.387543\n",
      "Batch #10\tAverage Generator Loss: 4566.636963\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19680 (step 19680): 1.983499\n",
      "Batch #10\tAverage Generator Loss: 3333.953162\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19681 (step 19681): 1.444157\n",
      "Batch #10\tAverage Generator Loss: 3141.547314\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19682 (step 19682): 1.281565\n",
      "Batch #10\tAverage Generator Loss: 3912.613867\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19683 (step 19683): 1.330790\n",
      "Batch #10\tAverage Generator Loss: 3445.519812\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19684 (step 19684): 1.904411\n",
      "Batch #10\tAverage Generator Loss: 3762.313428\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19685 (step 19685): 1.288084\n",
      "Batch #10\tAverage Generator Loss: 3504.779663\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19686 (step 19686): 1.383892\n",
      "Batch #10\tAverage Generator Loss: 3682.172339\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19687 (step 19687): 1.386433\n",
      "Batch #10\tAverage Generator Loss: 3896.667261\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19688 (step 19688): 1.963333\n",
      "Batch #10\tAverage Generator Loss: 3215.462903\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19689 (step 19689): 1.383151\n",
      "Batch #10\tAverage Generator Loss: 3257.384753\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19690 (step 19690): 1.293508\n",
      "Batch #10\tAverage Generator Loss: 3602.771021\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19691 (step 19691): 1.844558\n",
      "Batch #10\tAverage Generator Loss: 3473.260388\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19692 (step 19692): 1.347795\n",
      "Batch #10\tAverage Generator Loss: 3396.419336\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19693 (step 19693): 1.382537\n",
      "Batch #10\tAverage Generator Loss: 3149.271558\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19694 (step 19694): 1.297266\n",
      "Batch #10\tAverage Generator Loss: 3746.815308\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19695 (step 19695): 1.906655\n",
      "Batch #10\tAverage Generator Loss: 3358.827112\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19696 (step 19696): 1.305895\n",
      "Batch #10\tAverage Generator Loss: 3852.337305\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19697 (step 19697): 1.398196\n",
      "Batch #10\tAverage Generator Loss: 3001.972046\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19698 (step 19698): 1.275452\n",
      "Batch #10\tAverage Generator Loss: 3093.675806\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19699 (step 19699): 1.951132\n",
      "Batch #10\tAverage Generator Loss: 3552.549243\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19700 (step 19700): 1.350182\n",
      "Batch #10\tAverage Generator Loss: 2841.334253\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19701 (step 19701): 1.410464\n",
      "Batch #10\tAverage Generator Loss: 3180.839777\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19702 (step 19702): 1.334524\n",
      "Batch #10\tAverage Generator Loss: 3245.067993\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19703 (step 19703): 2.116215\n",
      "Batch #10\tAverage Generator Loss: 3164.442505\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19704 (step 19704): 1.381485\n",
      "Batch #10\tAverage Generator Loss: 3107.600262\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19705 (step 19705): 1.365131\n",
      "Batch #10\tAverage Generator Loss: 3146.624243\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19706 (step 19706): 1.426620\n",
      "Batch #10\tAverage Generator Loss: 2972.856921\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19707 (step 19707): 1.959380\n",
      "Batch #10\tAverage Generator Loss: 3015.948102\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19708 (step 19708): 1.332819\n",
      "Batch #10\tAverage Generator Loss: 3525.425424\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19709 (step 19709): 1.307947\n",
      "Batch #10\tAverage Generator Loss: 3382.134814\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19710 (step 19710): 1.284393\n",
      "Batch #10\tAverage Generator Loss: 3404.957941\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19711 (step 19711): 2.107441\n",
      "Batch #10\tAverage Generator Loss: 2709.180945\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19712 (step 19712): 1.376588\n",
      "Batch #10\tAverage Generator Loss: 3148.945850\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19713 (step 19713): 1.378004\n",
      "Batch #10\tAverage Generator Loss: 3312.238843\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19714 (step 19714): 1.371419\n",
      "Batch #10\tAverage Generator Loss: 3659.971680\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19715 (step 19715): 1.988145\n",
      "Batch #10\tAverage Generator Loss: 3341.627173\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19716 (step 19716): 1.388346\n",
      "Batch #10\tAverage Generator Loss: 3402.698853\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19717 (step 19717): 1.323517\n",
      "Batch #10\tAverage Generator Loss: 2719.797693\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19718 (step 19718): 1.330812\n",
      "Batch #10\tAverage Generator Loss: 3395.906250\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19719 (step 19719): 1.937654\n",
      "Batch #10\tAverage Generator Loss: 3465.861414\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19720 (step 19720): 1.307206\n",
      "Batch #10\tAverage Generator Loss: 3419.224829\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19721 (step 19721): 1.347180\n",
      "Batch #10\tAverage Generator Loss: 3451.270447\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19722 (step 19722): 1.247876\n",
      "Batch #10\tAverage Generator Loss: 3433.633655\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19723 (step 19723): 1.889808\n",
      "Batch #10\tAverage Generator Loss: 3168.428943\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19724 (step 19724): 1.283527\n",
      "Batch #10\tAverage Generator Loss: 3090.671411\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19725 (step 19725): 1.357785\n",
      "Batch #10\tAverage Generator Loss: 3362.216541\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19726 (step 19726): 2.003932\n",
      "Batch #10\tAverage Generator Loss: 3192.388562\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19727 (step 19727): 1.319195\n",
      "Batch #10\tAverage Generator Loss: 3374.743799\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19728 (step 19728): 1.349269\n",
      "Batch #10\tAverage Generator Loss: 2957.896204\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19729 (step 19729): 1.387602\n",
      "Batch #10\tAverage Generator Loss: 3448.000934\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19730 (step 19730): 1.885985\n",
      "Batch #10\tAverage Generator Loss: 3107.599866\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19731 (step 19731): 1.497391\n",
      "Batch #10\tAverage Generator Loss: 3537.865063\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19732 (step 19732): 1.338542\n",
      "Batch #10\tAverage Generator Loss: 3298.465515\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19733 (step 19733): 1.296106\n",
      "Batch #10\tAverage Generator Loss: 3827.568091\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19734 (step 19734): 1.895509\n",
      "Batch #10\tAverage Generator Loss: 3451.547021\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19735 (step 19735): 1.246637\n",
      "Batch #10\tAverage Generator Loss: 3363.402124\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19736 (step 19736): 1.342058\n",
      "Batch #10\tAverage Generator Loss: 3449.263806\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19737 (step 19737): 1.395696\n",
      "Batch #10\tAverage Generator Loss: 3619.368652\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19738 (step 19738): 1.936394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 3114.286646\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19739 (step 19739): 1.401070\n",
      "Batch #10\tAverage Generator Loss: 3161.310046\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19740 (step 19740): 1.399010\n",
      "Batch #10\tAverage Generator Loss: 3417.256311\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19741 (step 19741): 1.353657\n",
      "Batch #10\tAverage Generator Loss: 3261.328516\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19742 (step 19742): 2.095576\n",
      "Batch #10\tAverage Generator Loss: 3297.294006\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19743 (step 19743): 1.341737\n",
      "Batch #10\tAverage Generator Loss: 3228.036682\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19744 (step 19744): 1.284030\n",
      "Batch #10\tAverage Generator Loss: 3510.142126\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19745 (step 19745): 1.300472\n",
      "Batch #10\tAverage Generator Loss: 3346.410315\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19746 (step 19746): 2.011715\n",
      "Batch #10\tAverage Generator Loss: 3074.208240\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19747 (step 19747): 1.333846\n",
      "Batch #10\tAverage Generator Loss: 3011.400598\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19748 (step 19748): 1.280989\n",
      "Batch #10\tAverage Generator Loss: 3320.827466\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19749 (step 19749): 1.340430\n",
      "Batch #10\tAverage Generator Loss: 3275.962622\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19750 (step 19750): 2.087742\n",
      "Batch #10\tAverage Generator Loss: 2892.970819\tAverage Discriminator Loss: 0.035789\n",
      "\n",
      "Train time for epoch #19751 (step 19751): 1.337489\n",
      "Batch #10\tAverage Generator Loss: 3191.663525\tAverage Discriminator Loss: 0.004299\n",
      "\n",
      "Train time for epoch #19752 (step 19752): 1.351108\n",
      "Batch #10\tAverage Generator Loss: 2784.895654\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19753 (step 19753): 1.339873\n",
      "Batch #10\tAverage Generator Loss: 2843.861462\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19754 (step 19754): 1.992801\n",
      "Batch #10\tAverage Generator Loss: 2805.634119\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19755 (step 19755): 1.288000\n",
      "Batch #10\tAverage Generator Loss: 3089.520386\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19756 (step 19756): 1.252900\n",
      "Batch #10\tAverage Generator Loss: 2473.830835\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19757 (step 19757): 1.278527\n",
      "Batch #10\tAverage Generator Loss: 2373.052570\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19758 (step 19758): 1.976141\n",
      "Batch #10\tAverage Generator Loss: 2789.240137\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19759 (step 19759): 1.369895\n",
      "Batch #10\tAverage Generator Loss: 3010.120837\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19760 (step 19760): 1.294524\n",
      "Batch #10\tAverage Generator Loss: 2719.962903\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19761 (step 19761): 1.947398\n",
      "Batch #10\tAverage Generator Loss: 2844.555273\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19762 (step 19762): 1.290633\n",
      "Batch #10\tAverage Generator Loss: 2879.459473\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19763 (step 19763): 1.430808\n",
      "Batch #10\tAverage Generator Loss: 3104.501965\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19764 (step 19764): 1.298942\n",
      "Batch #10\tAverage Generator Loss: 3068.861096\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19765 (step 19765): 1.955108\n",
      "Batch #10\tAverage Generator Loss: 3427.182690\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19766 (step 19766): 1.440083\n",
      "Batch #10\tAverage Generator Loss: 3233.075867\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19767 (step 19767): 1.336857\n",
      "Batch #10\tAverage Generator Loss: 3077.286072\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19768 (step 19768): 1.324520\n",
      "Batch #10\tAverage Generator Loss: 2512.960327\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19769 (step 19769): 1.918759\n",
      "Batch #10\tAverage Generator Loss: 3096.205725\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19770 (step 19770): 1.291610\n",
      "Batch #10\tAverage Generator Loss: 2728.511829\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19771 (step 19771): 1.292193\n",
      "Batch #10\tAverage Generator Loss: 3136.262378\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19772 (step 19772): 1.302960\n",
      "Batch #10\tAverage Generator Loss: 2846.225989\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19773 (step 19773): 1.883144\n",
      "Batch #10\tAverage Generator Loss: 2817.610535\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19774 (step 19774): 1.290672\n",
      "Batch #10\tAverage Generator Loss: 3087.971167\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19775 (step 19775): 1.286707\n",
      "Batch #10\tAverage Generator Loss: 2745.526404\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19776 (step 19776): 1.290749\n",
      "Batch #10\tAverage Generator Loss: 2450.087036\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19777 (step 19777): 1.912607\n",
      "Batch #10\tAverage Generator Loss: 3183.883936\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19778 (step 19778): 1.345563\n",
      "Batch #10\tAverage Generator Loss: 2611.745764\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19779 (step 19779): 1.537167\n",
      "Batch #10\tAverage Generator Loss: 2860.065723\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19780 (step 19780): 1.339768\n",
      "Batch #10\tAverage Generator Loss: 2785.183112\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19781 (step 19781): 2.010003\n",
      "Batch #10\tAverage Generator Loss: 3052.176172\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19782 (step 19782): 1.304263\n",
      "Batch #10\tAverage Generator Loss: 2417.516821\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19783 (step 19783): 1.325757\n",
      "Batch #10\tAverage Generator Loss: 3087.148279\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19784 (step 19784): 1.382256\n",
      "Batch #10\tAverage Generator Loss: 2984.073926\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19785 (step 19785): 2.092350\n",
      "Batch #10\tAverage Generator Loss: 2941.573975\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19786 (step 19786): 1.298477\n",
      "Batch #10\tAverage Generator Loss: 2864.030347\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19787 (step 19787): 1.343575\n",
      "Batch #10\tAverage Generator Loss: 2939.708240\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19788 (step 19788): 1.324198\n",
      "Batch #10\tAverage Generator Loss: 2745.351892\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19789 (step 19789): 1.972618\n",
      "Batch #10\tAverage Generator Loss: 2836.466577\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19790 (step 19790): 1.365047\n",
      "Batch #10\tAverage Generator Loss: 2773.701025\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19791 (step 19791): 1.291930\n",
      "Batch #10\tAverage Generator Loss: 2045.940204\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19792 (step 19792): 1.347129\n",
      "Batch #10\tAverage Generator Loss: 2904.483728\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19793 (step 19793): 2.000815\n",
      "Batch #10\tAverage Generator Loss: 2683.741772\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19794 (step 19794): 1.335447\n",
      "Batch #10\tAverage Generator Loss: 2970.834045\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19795 (step 19795): 1.291493\n",
      "Batch #10\tAverage Generator Loss: 3124.569177\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19796 (step 19796): 2.013470\n",
      "Batch #10\tAverage Generator Loss: 2469.298810\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19797 (step 19797): 1.289231\n",
      "Batch #10\tAverage Generator Loss: 3172.438013\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19798 (step 19798): 1.284789\n",
      "Batch #10\tAverage Generator Loss: 2888.199902\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19799 (step 19799): 1.408485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2885.774207\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19800 (step 19800): 2.067914\n",
      "Batch #10\tAverage Generator Loss: 2615.873596\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19801 (step 19801): 1.291679\n",
      "Batch #10\tAverage Generator Loss: 2489.018701\tAverage Discriminator Loss: 0.224342\n",
      "\n",
      "Train time for epoch #19802 (step 19802): 1.488900\n",
      "Batch #10\tAverage Generator Loss: 2445.191345\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19803 (step 19803): 1.331372\n",
      "Batch #10\tAverage Generator Loss: 2067.184857\tAverage Discriminator Loss: 0.644779\n",
      "\n",
      "Train time for epoch #19804 (step 19804): 1.931381\n",
      "Batch #10\tAverage Generator Loss: 2223.415891\tAverage Discriminator Loss: 0.018753\n",
      "\n",
      "Train time for epoch #19805 (step 19805): 1.417081\n",
      "Batch #10\tAverage Generator Loss: 2472.286023\tAverage Discriminator Loss: 0.003393\n",
      "\n",
      "Train time for epoch #19806 (step 19806): 1.318980\n",
      "Batch #10\tAverage Generator Loss: 3136.589941\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19807 (step 19807): 1.328725\n",
      "Batch #10\tAverage Generator Loss: 2738.157166\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19808 (step 19808): 1.949541\n",
      "Batch #10\tAverage Generator Loss: 3385.002087\tAverage Discriminator Loss: 0.000829\n",
      "\n",
      "Train time for epoch #19809 (step 19809): 1.384998\n",
      "Batch #10\tAverage Generator Loss: 3118.467261\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19810 (step 19810): 1.345914\n",
      "Batch #10\tAverage Generator Loss: 3390.801636\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19811 (step 19811): 1.380481\n",
      "Batch #10\tAverage Generator Loss: 2830.196155\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19812 (step 19812): 1.982031\n",
      "Batch #10\tAverage Generator Loss: 3350.125867\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19813 (step 19813): 1.337700\n",
      "Batch #10\tAverage Generator Loss: 3131.771069\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19814 (step 19814): 1.332868\n",
      "Batch #10\tAverage Generator Loss: 2987.039502\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19815 (step 19815): 1.387539\n",
      "Batch #10\tAverage Generator Loss: 3303.571899\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19816 (step 19816): 1.915032\n",
      "Batch #10\tAverage Generator Loss: 3071.356696\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19817 (step 19817): 1.368499\n",
      "Batch #10\tAverage Generator Loss: 3138.823743\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19818 (step 19818): 1.337265\n",
      "Batch #10\tAverage Generator Loss: 3413.939709\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19819 (step 19819): 1.343497\n",
      "Batch #10\tAverage Generator Loss: 3022.451746\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19820 (step 19820): 1.951623\n",
      "Batch #10\tAverage Generator Loss: 3370.147742\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19821 (step 19821): 1.395196\n",
      "Batch #10\tAverage Generator Loss: 2660.814514\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19822 (step 19822): 1.317269\n",
      "Batch #10\tAverage Generator Loss: 3098.154480\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19823 (step 19823): 1.304614\n",
      "Batch #10\tAverage Generator Loss: 3006.894885\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19824 (step 19824): 2.017553\n",
      "Batch #10\tAverage Generator Loss: 3058.747668\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19825 (step 19825): 1.280046\n",
      "Batch #10\tAverage Generator Loss: 2919.326868\tAverage Discriminator Loss: 0.007550\n",
      "\n",
      "Train time for epoch #19826 (step 19826): 1.372875\n",
      "Batch #10\tAverage Generator Loss: 2877.538745\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19827 (step 19827): 2.071992\n",
      "Batch #10\tAverage Generator Loss: 3173.875818\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19828 (step 19828): 1.465078\n",
      "Batch #10\tAverage Generator Loss: 3209.235986\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19829 (step 19829): 1.262512\n",
      "Batch #10\tAverage Generator Loss: 3195.643164\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19830 (step 19830): 1.437047\n",
      "Batch #10\tAverage Generator Loss: 3285.119824\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19831 (step 19831): 1.968668\n",
      "Batch #10\tAverage Generator Loss: 2782.109094\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19832 (step 19832): 1.283843\n",
      "Batch #10\tAverage Generator Loss: 3049.528931\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19833 (step 19833): 1.446838\n",
      "Batch #10\tAverage Generator Loss: 3281.787988\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19834 (step 19834): 1.420895\n",
      "Batch #10\tAverage Generator Loss: 3370.499396\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19835 (step 19835): 1.991220\n",
      "Batch #10\tAverage Generator Loss: 3042.183862\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19836 (step 19836): 1.348042\n",
      "Batch #10\tAverage Generator Loss: 3130.607764\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19837 (step 19837): 1.290245\n",
      "Batch #10\tAverage Generator Loss: 3496.040063\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19838 (step 19838): 1.382193\n",
      "Batch #10\tAverage Generator Loss: 2939.823108\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19839 (step 19839): 1.975948\n",
      "Batch #10\tAverage Generator Loss: 2970.413989\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19840 (step 19840): 1.333374\n",
      "Batch #10\tAverage Generator Loss: 3206.380493\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19841 (step 19841): 1.387698\n",
      "Batch #10\tAverage Generator Loss: 3181.433447\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19842 (step 19842): 1.287172\n",
      "Batch #10\tAverage Generator Loss: 2436.885278\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19843 (step 19843): 1.943660\n",
      "Batch #10\tAverage Generator Loss: 3093.257263\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19844 (step 19844): 1.540380\n",
      "Batch #10\tAverage Generator Loss: 2844.277173\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19845 (step 19845): 1.349728\n",
      "Batch #10\tAverage Generator Loss: 2723.803699\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19846 (step 19846): 1.271078\n",
      "Batch #10\tAverage Generator Loss: 3024.377954\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19847 (step 19847): 2.029320\n",
      "Batch #10\tAverage Generator Loss: 2966.360156\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19848 (step 19848): 1.271747\n",
      "Batch #10\tAverage Generator Loss: 2833.655957\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19849 (step 19849): 1.340675\n",
      "Batch #10\tAverage Generator Loss: 2893.067371\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19850 (step 19850): 1.333702\n",
      "Batch #10\tAverage Generator Loss: 2912.881116\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19851 (step 19851): 1.907068\n",
      "Batch #10\tAverage Generator Loss: 3155.461340\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19852 (step 19852): 1.294972\n",
      "Batch #10\tAverage Generator Loss: 3309.926367\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19853 (step 19853): 1.285299\n",
      "Batch #10\tAverage Generator Loss: 2801.533398\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19854 (step 19854): 1.940830\n",
      "Batch #10\tAverage Generator Loss: 3113.375098\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19855 (step 19855): 1.292965\n",
      "Batch #10\tAverage Generator Loss: 3006.795056\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19856 (step 19856): 1.357912\n",
      "Batch #10\tAverage Generator Loss: 2928.953979\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19857 (step 19857): 1.385854\n",
      "Batch #10\tAverage Generator Loss: 3540.881909\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19858 (step 19858): 1.321730\n",
      "Batch #10\tAverage Generator Loss: 2973.215710\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19859 (step 19859): 1.957768\n",
      "Batch #10\tAverage Generator Loss: 2700.068677\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19860 (step 19860): 1.350121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 3238.066931\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19861 (step 19861): 1.329679\n",
      "Batch #10\tAverage Generator Loss: 3338.629590\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19862 (step 19862): 1.926845\n",
      "Batch #10\tAverage Generator Loss: 3224.367651\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19863 (step 19863): 1.289682\n",
      "Batch #10\tAverage Generator Loss: 3510.868091\tAverage Discriminator Loss: 0.000198\n",
      "\n",
      "Train time for epoch #19864 (step 19864): 1.487014\n",
      "Batch #10\tAverage Generator Loss: 2964.886169\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #19865 (step 19865): 1.334307\n",
      "Batch #10\tAverage Generator Loss: 3543.270557\tAverage Discriminator Loss: 0.000015\n",
      "\n",
      "Train time for epoch #19866 (step 19866): 2.015849\n",
      "Batch #10\tAverage Generator Loss: 3424.291528\tAverage Discriminator Loss: 0.000013\n",
      "\n",
      "Train time for epoch #19867 (step 19867): 1.330038\n",
      "Batch #10\tAverage Generator Loss: 2710.016760\tAverage Discriminator Loss: 1.708332\n",
      "\n",
      "Train time for epoch #19868 (step 19868): 1.354434\n",
      "Batch #10\tAverage Generator Loss: 2674.796033\tAverage Discriminator Loss: 0.000088\n",
      "\n",
      "Train time for epoch #19869 (step 19869): 1.292938\n",
      "Batch #10\tAverage Generator Loss: 3410.157642\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19870 (step 19870): 2.007118\n",
      "Batch #10\tAverage Generator Loss: 2930.386621\tAverage Discriminator Loss: 0.121661\n",
      "\n",
      "Train time for epoch #19871 (step 19871): 1.365863\n",
      "Batch #10\tAverage Generator Loss: 3054.745386\tAverage Discriminator Loss: 0.000685\n",
      "\n",
      "Train time for epoch #19872 (step 19872): 1.237906\n",
      "Batch #10\tAverage Generator Loss: 2793.830127\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19873 (step 19873): 1.341212\n",
      "Batch #10\tAverage Generator Loss: 3139.532532\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19874 (step 19874): 1.910306\n",
      "Batch #10\tAverage Generator Loss: 2575.831104\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19875 (step 19875): 1.303973\n",
      "Batch #10\tAverage Generator Loss: 3105.693414\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19876 (step 19876): 1.323861\n",
      "Batch #10\tAverage Generator Loss: 3083.675269\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19877 (step 19877): 1.302818\n",
      "Batch #10\tAverage Generator Loss: 2483.691833\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19878 (step 19878): 1.912984\n",
      "Batch #10\tAverage Generator Loss: 2997.572803\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19879 (step 19879): 1.450666\n",
      "Batch #10\tAverage Generator Loss: 3289.861853\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19880 (step 19880): 1.336431\n",
      "Batch #10\tAverage Generator Loss: 3548.148743\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19881 (step 19881): 1.290776\n",
      "Batch #10\tAverage Generator Loss: 3161.237317\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19882 (step 19882): 1.887863\n",
      "Batch #10\tAverage Generator Loss: 2610.842450\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19883 (step 19883): 1.284309\n",
      "Batch #10\tAverage Generator Loss: 2970.571826\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19884 (step 19884): 1.439080\n",
      "Batch #10\tAverage Generator Loss: 2847.815295\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19885 (step 19885): 1.331038\n",
      "Batch #10\tAverage Generator Loss: 2600.364612\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19886 (step 19886): 1.971023\n",
      "Batch #10\tAverage Generator Loss: 2911.408228\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19887 (step 19887): 1.337060\n",
      "Batch #10\tAverage Generator Loss: 2771.333838\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19888 (step 19888): 1.294212\n",
      "Batch #10\tAverage Generator Loss: 2959.067395\tAverage Discriminator Loss: 0.010800\n",
      "\n",
      "Train time for epoch #19889 (step 19889): 1.290313\n",
      "Batch #10\tAverage Generator Loss: 2824.915308\tAverage Discriminator Loss: 0.004382\n",
      "\n",
      "Train time for epoch #19890 (step 19890): 1.933218\n",
      "Batch #10\tAverage Generator Loss: 2816.935767\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19891 (step 19891): 1.283668\n",
      "Batch #10\tAverage Generator Loss: 2487.878613\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19892 (step 19892): 1.298235\n",
      "Batch #10\tAverage Generator Loss: 2699.198413\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19893 (step 19893): 1.394135\n",
      "Batch #10\tAverage Generator Loss: 2855.453772\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19894 (step 19894): 1.892790\n",
      "Batch #10\tAverage Generator Loss: 2734.100049\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19895 (step 19895): 1.288974\n",
      "Batch #10\tAverage Generator Loss: 3018.484155\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19896 (step 19896): 1.359568\n",
      "Batch #10\tAverage Generator Loss: 2842.337976\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19897 (step 19897): 1.398271\n",
      "Batch #10\tAverage Generator Loss: 2638.173071\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19898 (step 19898): 1.971480\n",
      "Batch #10\tAverage Generator Loss: 2971.586975\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19899 (step 19899): 1.250641\n",
      "Batch #10\tAverage Generator Loss: 2929.611560\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19900 (step 19900): 1.320878\n",
      "Batch #10\tAverage Generator Loss: 2644.847046\tAverage Discriminator Loss: 0.031169\n",
      "\n",
      "Train time for epoch #19901 (step 19901): 1.399261\n",
      "Batch #10\tAverage Generator Loss: 3018.473706\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19902 (step 19902): 1.957063\n",
      "Batch #10\tAverage Generator Loss: 2478.548596\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19903 (step 19903): 1.330042\n",
      "Batch #10\tAverage Generator Loss: 3162.295605\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19904 (step 19904): 1.310440\n",
      "Batch #10\tAverage Generator Loss: 2648.411414\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19905 (step 19905): 1.381699\n",
      "Batch #10\tAverage Generator Loss: 2875.598218\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19906 (step 19906): 1.956534\n",
      "Batch #10\tAverage Generator Loss: 2644.218042\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19907 (step 19907): 1.390748\n",
      "Batch #10\tAverage Generator Loss: 2713.277820\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19908 (step 19908): 1.335713\n",
      "Batch #10\tAverage Generator Loss: 2701.202124\tAverage Discriminator Loss: 0.020152\n",
      "\n",
      "Train time for epoch #19909 (step 19909): 2.085297\n",
      "Batch #10\tAverage Generator Loss: 2702.687476\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19910 (step 19910): 1.397315\n",
      "Batch #10\tAverage Generator Loss: 2709.348450\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19911 (step 19911): 1.394319\n",
      "Batch #10\tAverage Generator Loss: 2443.654810\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19912 (step 19912): 1.391675\n",
      "Batch #10\tAverage Generator Loss: 2645.651123\tAverage Discriminator Loss: 0.002629\n",
      "\n",
      "Train time for epoch #19913 (step 19913): 1.339783\n",
      "Batch #10\tAverage Generator Loss: 2386.153186\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19914 (step 19914): 2.009469\n",
      "Batch #10\tAverage Generator Loss: 2971.866345\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19915 (step 19915): 1.335491\n",
      "Batch #10\tAverage Generator Loss: 2698.082837\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19916 (step 19916): 1.280033\n",
      "Batch #10\tAverage Generator Loss: 2612.974988\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19917 (step 19917): 1.437490\n",
      "Batch #10\tAverage Generator Loss: 2460.853101\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19918 (step 19918): 2.097717\n",
      "Batch #10\tAverage Generator Loss: 2707.541553\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19919 (step 19919): 1.405699\n",
      "Batch #10\tAverage Generator Loss: 2445.620020\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19920 (step 19920): 1.335025\n",
      "Batch #10\tAverage Generator Loss: 2854.317175\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19921 (step 19921): 1.897739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2865.870264\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19922 (step 19922): 1.385382\n",
      "Batch #10\tAverage Generator Loss: 2506.170837\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19923 (step 19923): 1.450249\n",
      "Batch #10\tAverage Generator Loss: 2312.898376\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19924 (step 19924): 1.297354\n",
      "Batch #10\tAverage Generator Loss: 2516.822986\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19925 (step 19925): 1.892974\n",
      "Batch #10\tAverage Generator Loss: 2166.796191\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19926 (step 19926): 1.346081\n",
      "Batch #10\tAverage Generator Loss: 2249.169971\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19927 (step 19927): 1.426363\n",
      "Batch #10\tAverage Generator Loss: 3022.997314\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19928 (step 19928): 1.284631\n",
      "Batch #10\tAverage Generator Loss: 2856.382751\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19929 (step 19929): 1.954270\n",
      "Batch #10\tAverage Generator Loss: 2580.602197\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19930 (step 19930): 1.238818\n",
      "Batch #10\tAverage Generator Loss: 2493.417029\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19931 (step 19931): 1.331506\n",
      "Batch #10\tAverage Generator Loss: 2597.593994\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19932 (step 19932): 1.355810\n",
      "Batch #10\tAverage Generator Loss: 2657.737231\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19933 (step 19933): 1.965680\n",
      "Batch #10\tAverage Generator Loss: 2505.007324\tAverage Discriminator Loss: 0.035292\n",
      "\n",
      "Train time for epoch #19934 (step 19934): 1.303607\n",
      "Batch #10\tAverage Generator Loss: 2911.554346\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19935 (step 19935): 1.297875\n",
      "Batch #10\tAverage Generator Loss: 2425.164026\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #19936 (step 19936): 1.333253\n",
      "Batch #10\tAverage Generator Loss: 2442.127258\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19937 (step 19937): 1.917539\n",
      "Batch #10\tAverage Generator Loss: 2329.629626\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19938 (step 19938): 1.435497\n",
      "Batch #10\tAverage Generator Loss: 2657.688147\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19939 (step 19939): 1.344153\n",
      "Batch #10\tAverage Generator Loss: 2585.633997\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19940 (step 19940): 1.331316\n",
      "Batch #10\tAverage Generator Loss: 2483.951599\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19941 (step 19941): 2.099806\n",
      "Batch #10\tAverage Generator Loss: 2354.032983\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19942 (step 19942): 1.328347\n",
      "Batch #10\tAverage Generator Loss: 2223.594269\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19943 (step 19943): 1.344040\n",
      "Batch #10\tAverage Generator Loss: 2659.710449\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19944 (step 19944): 1.422744\n",
      "Batch #10\tAverage Generator Loss: 2520.840100\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19945 (step 19945): 2.011072\n",
      "Batch #10\tAverage Generator Loss: 2643.975232\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19946 (step 19946): 1.344090\n",
      "Batch #10\tAverage Generator Loss: 2758.012549\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19947 (step 19947): 1.325300\n",
      "Batch #10\tAverage Generator Loss: 3048.276306\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19948 (step 19948): 1.496943\n",
      "Batch #10\tAverage Generator Loss: 2779.682104\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19949 (step 19949): 1.947741\n",
      "Batch #10\tAverage Generator Loss: 2478.064771\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19950 (step 19950): 1.340665\n",
      "Batch #10\tAverage Generator Loss: 2694.910535\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19951 (step 19951): 1.382086\n",
      "Batch #10\tAverage Generator Loss: 2686.125940\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19952 (step 19952): 1.381906\n",
      "Batch #10\tAverage Generator Loss: 2703.586169\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19953 (step 19953): 2.113549\n",
      "Batch #10\tAverage Generator Loss: 2783.139111\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19954 (step 19954): 1.286105\n",
      "Batch #10\tAverage Generator Loss: 2181.923871\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19955 (step 19955): 1.291057\n",
      "Batch #10\tAverage Generator Loss: 2755.218091\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19956 (step 19956): 1.960802\n",
      "Batch #10\tAverage Generator Loss: 2486.635718\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19957 (step 19957): 1.284428\n",
      "Batch #10\tAverage Generator Loss: 3160.752771\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19958 (step 19958): 1.314311\n",
      "Batch #10\tAverage Generator Loss: 2898.994214\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19959 (step 19959): 1.291586\n",
      "Batch #10\tAverage Generator Loss: 1908.760461\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19960 (step 19960): 1.989231\n",
      "Batch #10\tAverage Generator Loss: 2388.013269\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19961 (step 19961): 1.344332\n",
      "Batch #10\tAverage Generator Loss: 2310.724121\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19962 (step 19962): 1.395415\n",
      "Batch #10\tAverage Generator Loss: 3278.570215\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19963 (step 19963): 1.293850\n",
      "Batch #10\tAverage Generator Loss: 2504.380945\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19964 (step 19964): 1.284443\n",
      "Batch #10\tAverage Generator Loss: 2550.958057\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19965 (step 19965): 1.906719\n",
      "Batch #10\tAverage Generator Loss: 2919.423083\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19966 (step 19966): 1.346649\n",
      "Batch #10\tAverage Generator Loss: 2665.643164\tAverage Discriminator Loss: 0.023884\n",
      "\n",
      "Train time for epoch #19967 (step 19967): 1.301158\n",
      "Batch #10\tAverage Generator Loss: 2922.069519\tAverage Discriminator Loss: 0.073971\n",
      "\n",
      "Train time for epoch #19968 (step 19968): 1.989277\n",
      "Batch #10\tAverage Generator Loss: 2416.156372\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19969 (step 19969): 1.293795\n",
      "Batch #10\tAverage Generator Loss: 3057.577551\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19970 (step 19970): 1.290009\n",
      "Batch #10\tAverage Generator Loss: 3285.272363\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19971 (step 19971): 1.358267\n",
      "Batch #10\tAverage Generator Loss: 3551.404919\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19972 (step 19972): 1.944174\n",
      "Batch #10\tAverage Generator Loss: 2394.100922\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19973 (step 19973): 1.298248\n",
      "Batch #10\tAverage Generator Loss: 2937.204028\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19974 (step 19974): 1.389300\n",
      "Batch #10\tAverage Generator Loss: 2506.502966\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19975 (step 19975): 1.297497\n",
      "Batch #10\tAverage Generator Loss: 3073.019397\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19976 (step 19976): 2.011139\n",
      "Batch #10\tAverage Generator Loss: 2993.010791\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19977 (step 19977): 1.337167\n",
      "Batch #10\tAverage Generator Loss: 2852.131445\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19978 (step 19978): 1.241518\n",
      "Batch #10\tAverage Generator Loss: 3013.370569\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19979 (step 19979): 1.391742\n",
      "Batch #10\tAverage Generator Loss: 3275.157910\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19980 (step 19980): 1.950773\n",
      "Batch #10\tAverage Generator Loss: 2977.784277\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19981 (step 19981): 1.367576\n",
      "Batch #10\tAverage Generator Loss: 3071.562122\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19982 (step 19982): 1.333261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #10\tAverage Generator Loss: 2646.684009\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19983 (step 19983): 1.311570\n",
      "Batch #10\tAverage Generator Loss: 2683.956519\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19984 (step 19984): 2.085973\n",
      "Batch #10\tAverage Generator Loss: 3231.097961\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19985 (step 19985): 1.392604\n",
      "Batch #10\tAverage Generator Loss: 2904.628882\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19986 (step 19986): 1.341294\n",
      "Batch #10\tAverage Generator Loss: 2763.535754\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19987 (step 19987): 1.343883\n",
      "Batch #10\tAverage Generator Loss: 3470.336011\tAverage Discriminator Loss: 0.000000\n",
      "\n",
      "Train time for epoch #19988 (step 19988): 2.099783\n",
      "Batch #10\tAverage Generator Loss: 3204.056189\tAverage Discriminator Loss: 0.003795\n",
      "\n",
      "Train time for epoch #19989 (step 19989): 1.308348\n",
      "Batch #10\tAverage Generator Loss: 2924.782715\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19990 (step 19990): 1.280257\n",
      "Batch #10\tAverage Generator Loss: 2707.886829\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #19991 (step 19991): 1.290202\n",
      "Batch #10\tAverage Generator Loss: 2937.658008\tAverage Discriminator Loss: 0.000009\n",
      "\n",
      "Train time for epoch #19992 (step 19992): 1.959877\n",
      "Batch #10\tAverage Generator Loss: 2584.333514\tAverage Discriminator Loss: 0.000010\n",
      "\n",
      "Train time for epoch #19993 (step 19993): 1.414895\n",
      "Batch #10\tAverage Generator Loss: 2810.289685\tAverage Discriminator Loss: 0.000001\n",
      "\n",
      "Train time for epoch #19994 (step 19994): 1.283652\n",
      "Batch #10\tAverage Generator Loss: 2528.860754\tAverage Discriminator Loss: 0.000008\n",
      "\n",
      "Train time for epoch #19995 (step 19995): 1.339814\n",
      "Batch #10\tAverage Generator Loss: 2918.468933\tAverage Discriminator Loss: 0.000007\n",
      "\n",
      "Train time for epoch #19996 (step 19996): 1.959561\n",
      "Batch #10\tAverage Generator Loss: 2572.125598\tAverage Discriminator Loss: 0.000003\n",
      "\n",
      "Train time for epoch #19997 (step 19997): 1.354311\n",
      "Batch #10\tAverage Generator Loss: 3176.941785\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #19998 (step 19998): 1.365391\n",
      "Batch #10\tAverage Generator Loss: 2567.908191\tAverage Discriminator Loss: 0.000002\n",
      "\n",
      "Train time for epoch #19999 (step 19999): 1.394955\n",
      "Batch #10\tAverage Generator Loss: 2397.780554\tAverage Discriminator Loss: 0.000005\n",
      "\n",
      "Train time for epoch #20000 (step 20000): 2.024944\n",
      "\n",
      "Total training time for 20000 epoch(s) is 30135.787397384644\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    train_start = time.time()\n",
    "    for _ in range(EPOCHS):\n",
    "        start = time.time()\n",
    "        with summary_writer.as_default():\n",
    "            train_one_epoch(benign_dataset=benign_train_dataset,\n",
    "                        attack_dataset=attack_train_dataset,\n",
    "                        log_interval=LOG_INTERVAL,\n",
    "                        modified_feature_num=FEATURE_NUM_MODIFIED,\n",
    "                        random_select_feature=RANDOM_SELECT_FEATURE,\n",
    "                        **model_objects)\n",
    "        end = time.time()\n",
    "        checkpoint.save(checkpoint_prefix)\n",
    "        print('\\nTrain time for epoch #%d (step %d): %f' %\n",
    "            (checkpoint.save_counter.numpy(),\n",
    "             checkpoint.step_counter.numpy(),\n",
    "             end - start))\n",
    "    print('\\nTotal training time for {epoch} epoch(s) is {second}'.format(\n",
    "        second=time.time() - train_start,\n",
    "        epoch=EPOCHS\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Train/Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(DATA_DIR, 'benign_train.npy'), benign_train)\n",
    "np.save(os.path.join(DATA_DIR, 'benign_test.npy'), benign_test)\n",
    "np.save(os.path.join(DATA_DIR, 'attack_train.npy'), attack_train)\n",
    "np.save(os.path.join(DATA_DIR, 'attack_test.npy'), attack_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "loaded_benign_train = np.load(os.path.join(DATA_DIR, 'benign_train.npy'))\n",
    "loaded_benign_test = np.load(os.path.join(DATA_DIR, 'benign_test.npy'))\n",
    "loaded_attack_train = np.load(os.path.join(DATA_DIR, 'attack_train.npy'))\n",
    "loaded_attack_test = np.load(os.path.join(DATA_DIR, 'attack_test.npy'))\n",
    "assert (loaded_benign_train == benign_train).all()\n",
    "assert (loaded_benign_test == benign_test).all()\n",
    "assert (loaded_attack_train == attack_train).all()\n",
    "assert (loaded_attack_test == attack_test).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
