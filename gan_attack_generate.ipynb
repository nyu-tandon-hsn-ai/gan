{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Network\n",
    "\n",
    "In this notebook, we'll be building a generative adversarial network (GAN) trained on the network flow dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/sj2363/hsn/attack_generate/gan_attack_generate/.env/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 1.8.0\n",
      "Eager execution: True\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from importlib import reload\n",
    "import os\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as tfe\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "print(\"TensorFlow version: {}\".format(tf.VERSION))\n",
    "print(\"Eager execution: {}\".format(tf.executing_eagerly()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils, models\n",
    "reload(utils)\n",
    "reload(models)\n",
    "from models import Generator, Discriminator\n",
    "from utils import max_norm, parse_feature_label, loss, grad, sample_n_number, train_one_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDS_DATASET = os.path.join('data', 'ids2017_sampled.csv')\n",
    "RELEVANT_FEATURES = [' Source Port', ' Destination Port', ' Flow Duration', 'Total Length of Fwd Packets', ' Total Length of Bwd Packets', 'Bwd Packet Length Max', ' Bwd Packet Length Min', 'Flow Bytes/s', ' Flow IAT Mean', ' Flow IAT Std', ' Flow IAT Max', ' Flow IAT Min', 'Fwd IAT Total', ' Fwd IAT Mean', ' Fwd IAT Std', ' Fwd IAT Min', 'Bwd IAT Total', ' Bwd IAT Mean', ' Bwd IAT Std', ' Bwd IAT Min', 'Fwd PSH Flags', ' Bwd PSH Flags', ' Fwd URG Flags', ' Fwd Header Length', ' Bwd Packets/s', ' Packet Length Mean', ' ACK Flag Count', ' Down/Up Ratio', ' Avg Fwd Segment Size', ' Fwd Header Length.1', 'Fwd Avg Bytes/Bulk', ' Fwd Avg Packets/Bulk', ' Bwd Avg Bytes/Bulk', 'Bwd Avg Bulk Rate', 'Subflow Fwd Packets', ' Subflow Fwd Bytes', 'Init_Win_bytes_forward', ' act_data_pkt_fwd', ' Active Std', ' Active Min', ' Idle Max']\n",
    "LABEL_NAME = ' Label'\n",
    "BENIGN_LABEL = 0\n",
    "ATTACK_LABEL = 2\n",
    "TRAIN_FRAC = 0.3\n",
    "FEATURE_NUM_MODIFIED = 2\n",
    "LEARNING_RATE = 0.01\n",
    "OUTPUT_DIR = 'SUMMARY/'\n",
    "CHECKPOINT_DIR = 'CHECKPOINT/'\n",
    "EPOCHS = 200\n",
    "LOG_INTERVAL = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flow ID, Source IP, Source Port, Destination IP, Destination Port, Protocol, Timestamp, Flow Duration, Total Fwd Packets, Total Backward Packets,Total Length of Fwd Packets, Total Length of Bwd Packets, Fwd Packet Length Max, Fwd Packet Length Min, Fwd Packet Length Mean, Fwd Packet Length Std,Bwd Packet Length Max, Bwd Packet Length Min, Bwd Packet Length Mean, Bwd Packet Length Std,Flow Bytes/s, Flow Packets/s, Flow IAT Mean, Flow IAT Std, Flow IAT Max, Flow IAT Min,Fwd IAT Total, Fwd IAT Mean, Fwd IAT Std, Fwd IAT Max, Fwd IAT Min,Bwd IAT Total, Bwd IAT Mean, Bwd IAT Std, Bwd IAT Max, Bwd IAT Min,Fwd PSH Flags, Bwd PSH Flags, Fwd URG Flags, Bwd URG Flags, Fwd Header Length, Bwd Header Length,Fwd Packets/s, Bwd Packets/s, Min Packet Length, Max Packet Length, Packet Length Mean, Packet Length Std, Packet Length Variance,FIN Flag Count, SYN Flag Count, RST Flag Count, PSH Flag Count, ACK Flag Count, URG Flag Count, CWE Flag Count, ECE Flag Count, Down/Up Ratio, Average Packet Size, Avg Fwd Segment Size, Avg Bwd Segment Size, Fwd Header Length.1,Fwd Avg Bytes/Bulk, Fwd Avg Packets/Bulk, Fwd Avg Bulk Rate, Bwd Avg Bytes/Bulk, Bwd Avg Packets/Bulk,Bwd Avg Bulk Rate,Subflow Fwd Packets, Subflow Fwd Bytes, Subflow Bwd Packets, Subflow Bwd Bytes,Init_Win_bytes_forward, Init_Win_bytes_backward, act_data_pkt_fwd, min_seg_size_forward,Active Mean, Active Std, Active Max, Active Min,Idle Mean, Idle Std, Idle Max, Idle Min, Label\r\n",
      "214102,192.168.10.8,50305,23.194.108.67,80,6,5/7/2017 9:35,5559809,3,1,12,0.0,6,0,4.0,3.464101615,0,0,0.0,0.0,2.158347526,0.719449175,1853269.667,3189322.073,5535956.0,39.0,5559809.0,2779904.5,3897645.41,5535956.0,23853.0,0.0,0.0,0.0,0.0,0.0,0,0,0,0,72,32,0.539586881,0.179862294,0,6,2.4,3.286335345,10.8,0,0,0,1,0,0,0,0,0,3.0,4.0,0.0,72,0,0,0,0,0,0,3,12,1,0,8192,29200,2,20,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0\r\n",
      "36502,172.217.11.3,80,192.168.10.8,49917,6,5/7/2017 9:31,18,1,1,6,6.0,6,6,6.0,0.0,6,6,6.0,0.0,666666.6667,111111.1111,18.0,0.0,18.0,18.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0,0,0,0,20,20,55555.55556,55555.55556,6,6,6.0,0.0,0.0,0,0,0,0,1,1,0,0,1,9.0,6.0,6.0,20,0,0,0,0,0,0,1,6,1,6,343,16560,0,20,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0\r\n",
      "24975,192.168.10.50,80,172.16.0.1,51484,6,5/7/2017 11:00,12859,1,3,0,18.0,0,0,0.0,0.0,6,6,6.0,0.0,1399.797807,311.0661793,4286.333333,6734.794825,12049.0,1.0,0.0,0.0,0.0,0.0,0.0,12050.0,6025.0,8519.2225,12049.0,1.0,0,0,0,0,32,60,77.76654483,233.2996345,0,6,3.6,3.286335345,10.8,0,0,0,0,1,0,0,0,3,4.5,0.0,6.0,32,0,0,0,0,0,0,1,0,3,18,235,0,0,32,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0\r\n",
      "151291,192.168.10.19,27610,192.168.10.3,53,17,5/7/2017 3:08,231,2,2,62,94.0,31,31,31.0,0.0,47,47,47.0,0.0,675324.6753,17316.01732,77.0,91.27978966,179.0,3.0,3.0,3.0,0.0,3.0,3.0,49.0,49.0,0.0,49.0,49.0,0,0,0,0,40,40,8658.008658,8658.008658,31,47,37.4,8.76356092,76.8,0,0,0,0,0,0,0,0,1,46.75,31.0,47.0,40,0,0,0,0,0,0,2,62,2,94,-1,-1,1,20,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0\r\n"
     ]
    }
   ],
   "source": [
    "# quick view of dataset\n",
    "!head -n5 {IDS_DATASET}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv\n",
    "df = pd.read_csv(IDS_DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract relevant features and label name\n",
    "df = df[RELEVANT_FEATURES + [LABEL_NAME]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract bengin and attack flows we want\n",
    "benign_df, attack_df = df[(df[LABEL_NAME] == BENIGN_LABEL)], df[(df[LABEL_NAME] == ATTACK_LABEL)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/sj2363/hsn/attack_generate/gan_attack_generate/.env/lib/python3.6/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "# rewrite label values\n",
    "benign_df.loc[:, LABEL_NAME] = 0\n",
    "attack_df.loc[:, LABEL_NAME] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to numpy\n",
    "benign, attack = benign_df.values, attack_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max normalization\n",
    "benign[:, :len(RELEVANT_FEATURES)] = max_norm(benign[:, :len(RELEVANT_FEATURES)])\n",
    "attack[:, :len(RELEVANT_FEATURES)] = max_norm(attack[:, :len(RELEVANT_FEATURES)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/sj2363/hsn/attack_generate/gan_attack_generate/.env/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# do train, test split separately on benign and attack\n",
    "benign_train, benign_test = train_test_split(benign, train_size=TRAIN_FRAC)\n",
    "attack_train, attack_test = train_test_split(attack, train_size=TRAIN_FRAC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat to get testing data\n",
    "test_np = np.concatenate([benign_test, attack_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to benign train dataset and attack train dataset\n",
    "benign_train_dataset, attack_train_dataset = tf.data.Dataset.from_tensor_slices(benign_train), tf.data.Dataset.from_tensor_slices(attack_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benign example features: tf.Tensor(\n",
      "[7.88681664e-01 8.26536500e-04 1.48351553e-06 8.54481757e-04\n",
      " 3.45811052e-06 8.30479452e-03 1.66953528e-01 1.37754068e-02\n",
      " 9.36037427e-07 8.96711684e-07 1.06779660e-06 7.80031189e-08\n",
      " 3.33333333e-08 3.38983051e-08 0.00000000e+00 3.38983051e-08\n",
      " 4.00000000e-07 4.06779661e-07 0.00000000e+00 4.06779661e-07\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.70189229e-04\n",
      " 1.12994350e-02 5.88502269e-02 0.00000000e+00 1.42857143e-01\n",
      " 2.80293230e-02 1.70189229e-04 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 5.36250536e-05 8.54481757e-04\n",
      " 0.00000000e+00 5.43714659e-05 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00], shape=(41,), dtype=float64)\n",
      "benign example label: tf.Tensor(0, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# deal with benign train dataset\n",
    "benign_train_dataset = benign_train_dataset.map(parse_feature_label)\n",
    "benign_train_dataset = benign_train_dataset.shuffle(buffer_size=benign_train.shape[0] * 5)  # randomize\n",
    "benign_train_dataset = benign_train_dataset.batch(100) # make batch\n",
    "\n",
    "# View a single example entry from a batch\n",
    "benign_features, benign_label = iter(benign_train_dataset).next()\n",
    "print(\"benign example features:\", benign_features[0])\n",
    "print(\"benign example label:\", benign_label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attack example features: tf.Tensor(\n",
      "[6.27905329e-01 0.00000000e+00 7.11920228e-01 1.35361552e-01\n",
      " 1.00000000e+00 4.99525658e-01 0.00000000e+00 1.33863937e-05\n",
      " 1.54295379e-01 3.85665529e-01 7.16101693e-01 5.51146384e-05\n",
      " 7.10084031e-01 3.07888032e-01 4.71893491e-01 0.00000000e+00\n",
      " 1.39187395e-03 2.70642157e-04 1.06018873e-03 4.60784314e-07\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 5.38461538e-01\n",
      " 8.26667730e-08 4.96786042e-01 1.00000000e+00 0.00000000e+00\n",
      " 1.34649123e-01 5.38461538e-01 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 5.00000000e-01 1.35361552e-01\n",
      " 8.59589041e-03 1.11111111e-01 0.00000000e+00 3.10285625e-02\n",
      " 7.16101695e-01], shape=(41,), dtype=float64)\n",
      "attack example label: tf.Tensor(1, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# deal with attack train dataset\n",
    "attack_train_dataset = attack_train_dataset.map(parse_feature_label)\n",
    "attack_train_dataset = attack_train_dataset.shuffle(buffer_size=attack_train.shape[0] * 5)  # randomize\n",
    "attack_train_dataset = attack_train_dataset.batch(100) # make batch\n",
    "\n",
    "# View a single example entry from a batch\n",
    "attack_features, attack_label = iter(attack_train_dataset).next()\n",
    "print(\"attack example features:\", attack_features[0])\n",
    "print(\"attack example label:\", attack_label[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(input_shape=len(RELEVANT_FEATURES), output_shape=FEATURE_NUM_MODIFIED)\n",
    "discriminator = Discriminator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.train.AdamOptimizer(learning_rate=LEARNING_RATE)\n",
    "discriminator_optimizer = tf.train.AdamOptimizer(learning_rate=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Tensorflow Training Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.contrib.eager.python.checkpointable_utils.InitializationOnlyStatus at 0x2ae4163ae668>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_counter = tf.train.get_or_create_global_step()\n",
    "summary_writer = tf.contrib.summary.create_file_writer(\n",
    "      OUTPUT_DIR, flush_millis=1000)\n",
    "checkpoint_prefix = os.path.join(CHECKPOINT_DIR, 'ckpt')\n",
    "latest_cpkt = tf.train.latest_checkpoint(CHECKPOINT_DIR)\n",
    "if latest_cpkt:\n",
    "    print('Using latest checkpoint at ' + latest_cpkt)\n",
    "model_objects = {\n",
    "    'generator': generator,\n",
    "    'discriminator': discriminator,\n",
    "    'generator_optimizer': generator_optimizer,\n",
    "    'discriminator_optimizer': discriminator_optimizer,\n",
    "    'step_counter': step_counter\n",
    "}\n",
    "checkpoint = tfe.Checkpoint(**model_objects)\n",
    "# Restore variables on creation if a checkpoint exists.\n",
    "checkpoint.restore(latest_cpkt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #1 (step 15): 2.657003\n",
      "\n",
      "Train time for epoch #2 (step 30): 1.152268\n",
      "\n",
      "Train time for epoch #3 (step 45): 1.036232\n",
      "\n",
      "Train time for epoch #4 (step 60): 1.151313\n",
      "\n",
      "Train time for epoch #5 (step 75): 1.042687\n",
      "\n",
      "Train time for epoch #6 (step 90): 1.147477\n",
      "\n",
      "Train time for epoch #7 (step 105): 1.147046\n",
      "\n",
      "Train time for epoch #8 (step 120): 1.052617\n",
      "\n",
      "Train time for epoch #9 (step 135): 1.163255\n",
      "\n",
      "Train time for epoch #10 (step 150): 1.147148\n",
      "\n",
      "Train time for epoch #11 (step 165): 1.236153\n",
      "\n",
      "Train time for epoch #12 (step 180): 1.005451\n",
      "\n",
      "Train time for epoch #13 (step 195): 1.001777\n",
      "\n",
      "Train time for epoch #14 (step 210): 1.193196\n",
      "\n",
      "Train time for epoch #15 (step 225): 1.131258\n",
      "\n",
      "Train time for epoch #16 (step 240): 1.127695\n",
      "\n",
      "Train time for epoch #17 (step 255): 1.013791\n",
      "\n",
      "Train time for epoch #18 (step 270): 1.093749\n",
      "\n",
      "Train time for epoch #19 (step 285): 1.055559\n",
      "\n",
      "Train time for epoch #20 (step 300): 1.085957\n",
      "\n",
      "Train time for epoch #21 (step 315): 1.190973\n",
      "\n",
      "Train time for epoch #22 (step 330): 1.074047\n",
      "\n",
      "Train time for epoch #23 (step 345): 1.092640\n",
      "\n",
      "Train time for epoch #24 (step 360): 1.066596\n",
      "\n",
      "Train time for epoch #25 (step 375): 1.186753\n",
      "\n",
      "Train time for epoch #26 (step 390): 1.136027\n",
      "\n",
      "Train time for epoch #27 (step 405): 1.068233\n",
      "\n",
      "Train time for epoch #28 (step 420): 1.049955\n",
      "\n",
      "Train time for epoch #29 (step 435): 1.154274\n",
      "\n",
      "Train time for epoch #30 (step 450): 1.131654\n",
      "\n",
      "Train time for epoch #31 (step 465): 0.995176\n",
      "\n",
      "Train time for epoch #32 (step 480): 1.221169\n",
      "\n",
      "Train time for epoch #33 (step 495): 0.961747\n",
      "\n",
      "Train time for epoch #34 (step 510): 1.111655\n",
      "\n",
      "Train time for epoch #35 (step 525): 0.991981\n",
      "\n",
      "Train time for epoch #36 (step 540): 1.144691\n",
      "\n",
      "Train time for epoch #37 (step 555): 0.975578\n",
      "\n",
      "Train time for epoch #38 (step 570): 1.141840\n",
      "\n",
      "Train time for epoch #39 (step 585): 1.128420\n",
      "\n",
      "Train time for epoch #40 (step 600): 1.123373\n",
      "\n",
      "Train time for epoch #41 (step 615): 1.069845\n",
      "\n",
      "Train time for epoch #42 (step 630): 1.002463\n",
      "\n",
      "Train time for epoch #43 (step 645): 1.045676\n",
      "\n",
      "Train time for epoch #44 (step 660): 1.051358\n",
      "\n",
      "Train time for epoch #45 (step 675): 1.057322\n",
      "\n",
      "Train time for epoch #46 (step 690): 1.108759\n",
      "\n",
      "Train time for epoch #47 (step 705): 1.040000\n",
      "\n",
      "Train time for epoch #48 (step 720): 1.151576\n",
      "\n",
      "Train time for epoch #49 (step 735): 1.087402\n",
      "\n",
      "Train time for epoch #50 (step 750): 1.103736\n",
      "\n",
      "Train time for epoch #51 (step 765): 1.038741\n",
      "\n",
      "Train time for epoch #52 (step 780): 1.010855\n",
      "\n",
      "Train time for epoch #53 (step 795): 1.078588\n",
      "\n",
      "Train time for epoch #54 (step 810): 0.988567\n",
      "\n",
      "Train time for epoch #55 (step 825): 1.069155\n",
      "\n",
      "Train time for epoch #56 (step 840): 1.044271\n",
      "\n",
      "Train time for epoch #57 (step 855): 1.090703\n",
      "\n",
      "Train time for epoch #58 (step 870): 0.998081\n",
      "\n",
      "Train time for epoch #59 (step 885): 1.069719\n",
      "\n",
      "Train time for epoch #60 (step 900): 1.064589\n",
      "\n",
      "Train time for epoch #61 (step 915): 1.089372\n",
      "\n",
      "Train time for epoch #62 (step 930): 1.189770\n",
      "\n",
      "Train time for epoch #63 (step 945): 1.045121\n",
      "\n",
      "Train time for epoch #64 (step 960): 1.059572\n",
      "\n",
      "Train time for epoch #65 (step 975): 1.043606\n",
      "\n",
      "Train time for epoch #66 (step 990): 1.147389\n",
      "\n",
      "Train time for epoch #67 (step 1005): 1.137463\n",
      "\n",
      "Train time for epoch #68 (step 1020): 0.935221\n",
      "\n",
      "Train time for epoch #69 (step 1035): 1.014967\n",
      "\n",
      "Train time for epoch #70 (step 1050): 1.068809\n",
      "\n",
      "Train time for epoch #71 (step 1065): 1.054564\n",
      "\n",
      "Train time for epoch #72 (step 1080): 1.025612\n",
      "\n",
      "Train time for epoch #73 (step 1095): 0.930426\n",
      "\n",
      "Train time for epoch #74 (step 1110): 1.063207\n",
      "\n",
      "Train time for epoch #75 (step 1125): 1.028251\n",
      "\n",
      "Train time for epoch #76 (step 1140): 1.115244\n",
      "\n",
      "Train time for epoch #77 (step 1155): 1.105587\n",
      "\n",
      "Train time for epoch #78 (step 1170): 1.031950\n",
      "\n",
      "Train time for epoch #79 (step 1185): 1.107644\n",
      "\n",
      "Train time for epoch #80 (step 1200): 1.077553\n",
      "\n",
      "Train time for epoch #81 (step 1215): 1.142355\n",
      "\n",
      "Train time for epoch #82 (step 1230): 1.046731\n",
      "\n",
      "Train time for epoch #83 (step 1245): 1.003886\n",
      "\n",
      "Train time for epoch #84 (step 1260): 1.110640\n",
      "\n",
      "Train time for epoch #85 (step 1275): 1.097576\n",
      "\n",
      "Train time for epoch #86 (step 1290): 1.002110\n",
      "\n",
      "Train time for epoch #87 (step 1305): 1.050678\n",
      "\n",
      "Train time for epoch #88 (step 1320): 1.000145\n",
      "\n",
      "Train time for epoch #89 (step 1335): 1.114149\n",
      "\n",
      "Train time for epoch #90 (step 1350): 1.177819\n",
      "\n",
      "Train time for epoch #91 (step 1365): 1.025821\n",
      "\n",
      "Train time for epoch #92 (step 1380): 1.133200\n",
      "\n",
      "Train time for epoch #93 (step 1395): 0.998750\n",
      "\n",
      "Train time for epoch #94 (step 1410): 1.186797\n",
      "\n",
      "Train time for epoch #95 (step 1425): 1.077084\n",
      "\n",
      "Train time for epoch #96 (step 1440): 1.088604\n",
      "\n",
      "Train time for epoch #97 (step 1455): 1.002041\n",
      "\n",
      "Train time for epoch #98 (step 1470): 1.098902\n",
      "\n",
      "Train time for epoch #99 (step 1485): 1.059536\n",
      "\n",
      "Train time for epoch #100 (step 1500): 0.997823\n",
      "\n",
      "Train time for epoch #101 (step 1515): 1.101586\n",
      "\n",
      "Train time for epoch #102 (step 1530): 0.986529\n",
      "\n",
      "Train time for epoch #103 (step 1545): 1.059529\n",
      "\n",
      "Train time for epoch #104 (step 1560): 1.059872\n",
      "\n",
      "Train time for epoch #105 (step 1575): 0.949349\n",
      "\n",
      "Train time for epoch #106 (step 1590): 1.074606\n",
      "\n",
      "Train time for epoch #107 (step 1605): 1.013965\n",
      "\n",
      "Train time for epoch #108 (step 1620): 1.129143\n",
      "\n",
      "Train time for epoch #109 (step 1635): 1.068341\n",
      "\n",
      "Train time for epoch #110 (step 1650): 1.041907\n",
      "\n",
      "Train time for epoch #111 (step 1665): 1.011735\n",
      "\n",
      "Train time for epoch #112 (step 1680): 1.146703\n",
      "\n",
      "Train time for epoch #113 (step 1695): 1.042131\n",
      "\n",
      "Train time for epoch #114 (step 1710): 0.989106\n",
      "\n",
      "Train time for epoch #115 (step 1725): 1.080451\n",
      "\n",
      "Train time for epoch #116 (step 1740): 1.101325\n",
      "\n",
      "Train time for epoch #117 (step 1755): 1.058030\n",
      "\n",
      "Train time for epoch #118 (step 1770): 1.192693\n",
      "\n",
      "Train time for epoch #119 (step 1785): 0.983541\n",
      "\n",
      "Train time for epoch #120 (step 1800): 1.104673\n",
      "\n",
      "Train time for epoch #121 (step 1815): 1.057049\n",
      "\n",
      "Train time for epoch #122 (step 1830): 1.138469\n",
      "\n",
      "Train time for epoch #123 (step 1845): 1.108829\n",
      "\n",
      "Train time for epoch #124 (step 1860): 1.105306\n",
      "\n",
      "Train time for epoch #125 (step 1875): 1.098925\n",
      "\n",
      "Train time for epoch #126 (step 1890): 1.027511\n",
      "\n",
      "Train time for epoch #127 (step 1905): 1.076681\n",
      "\n",
      "Train time for epoch #128 (step 1920): 1.124103\n",
      "\n",
      "Train time for epoch #129 (step 1935): 1.025580\n",
      "\n",
      "Train time for epoch #130 (step 1950): 1.256204\n",
      "\n",
      "Train time for epoch #131 (step 1965): 0.990409\n",
      "\n",
      "Train time for epoch #132 (step 1980): 1.143319\n",
      "\n",
      "Train time for epoch #133 (step 1995): 0.941886\n",
      "\n",
      "Train time for epoch #134 (step 2010): 1.037952\n",
      "\n",
      "Train time for epoch #135 (step 2025): 1.045688\n",
      "\n",
      "Train time for epoch #136 (step 2040): 1.013787\n",
      "\n",
      "Train time for epoch #137 (step 2055): 1.053506\n",
      "\n",
      "Train time for epoch #138 (step 2070): 0.996706\n",
      "\n",
      "Train time for epoch #139 (step 2085): 1.081151\n",
      "\n",
      "Train time for epoch #140 (step 2100): 1.024330\n",
      "\n",
      "Train time for epoch #141 (step 2115): 1.059553\n",
      "\n",
      "Train time for epoch #142 (step 2130): 1.035835\n",
      "\n",
      "Train time for epoch #143 (step 2145): 1.048143\n",
      "\n",
      "Train time for epoch #144 (step 2160): 1.119516\n",
      "\n",
      "Train time for epoch #145 (step 2175): 1.069287\n",
      "\n",
      "Train time for epoch #146 (step 2190): 1.054619\n",
      "\n",
      "Train time for epoch #147 (step 2205): 1.001925\n",
      "\n",
      "Train time for epoch #148 (step 2220): 1.163221\n",
      "\n",
      "Train time for epoch #149 (step 2235): 1.099736\n",
      "\n",
      "Train time for epoch #150 (step 2250): 1.084556\n",
      "\n",
      "Train time for epoch #151 (step 2265): 0.967718\n",
      "\n",
      "Train time for epoch #152 (step 2280): 1.123855\n",
      "\n",
      "Train time for epoch #153 (step 2295): 1.071021\n",
      "\n",
      "Train time for epoch #154 (step 2310): 1.196742\n",
      "\n",
      "Train time for epoch #155 (step 2325): 1.075728\n",
      "\n",
      "Train time for epoch #156 (step 2340): 1.064731\n",
      "\n",
      "Train time for epoch #157 (step 2355): 1.033988\n",
      "\n",
      "Train time for epoch #158 (step 2370): 1.011075\n",
      "\n",
      "Train time for epoch #159 (step 2385): 1.079062\n",
      "\n",
      "Train time for epoch #160 (step 2400): 1.086433\n",
      "\n",
      "Train time for epoch #161 (step 2415): 1.178693\n",
      "\n",
      "Train time for epoch #162 (step 2430): 1.030891\n",
      "\n",
      "Train time for epoch #163 (step 2445): 1.110612\n",
      "\n",
      "Train time for epoch #164 (step 2460): 1.101541\n",
      "\n",
      "Train time for epoch #165 (step 2475): 0.978413\n",
      "\n",
      "Train time for epoch #166 (step 2490): 0.963270\n",
      "\n",
      "Train time for epoch #167 (step 2505): 1.018824\n",
      "\n",
      "Train time for epoch #168 (step 2520): 1.064633\n",
      "\n",
      "Train time for epoch #169 (step 2535): 1.032029\n",
      "\n",
      "Train time for epoch #170 (step 2550): 1.158020\n",
      "\n",
      "Train time for epoch #171 (step 2565): 1.085195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #172 (step 2580): 1.185393\n",
      "\n",
      "Train time for epoch #173 (step 2595): 1.047542\n",
      "\n",
      "Train time for epoch #174 (step 2610): 1.074981\n",
      "\n",
      "Train time for epoch #175 (step 2625): 1.050221\n",
      "\n",
      "Train time for epoch #176 (step 2640): 1.135132\n",
      "\n",
      "Train time for epoch #177 (step 2655): 1.004740\n",
      "\n",
      "Train time for epoch #178 (step 2670): 1.006137\n",
      "\n",
      "Train time for epoch #179 (step 2685): 1.050610\n",
      "\n",
      "Train time for epoch #180 (step 2700): 1.135757\n",
      "\n",
      "Train time for epoch #181 (step 2715): 1.092459\n",
      "\n",
      "Train time for epoch #182 (step 2730): 0.990758\n",
      "\n",
      "Train time for epoch #183 (step 2745): 1.024459\n",
      "\n",
      "Train time for epoch #184 (step 2760): 1.122186\n",
      "\n",
      "Train time for epoch #185 (step 2775): 1.127692\n",
      "\n",
      "Train time for epoch #186 (step 2790): 1.017190\n",
      "\n",
      "Train time for epoch #187 (step 2805): 1.039683\n",
      "\n",
      "Train time for epoch #188 (step 2820): 1.062749\n",
      "\n",
      "Train time for epoch #189 (step 2835): 1.104456\n",
      "\n",
      "Train time for epoch #190 (step 2850): 1.048669\n",
      "\n",
      "Train time for epoch #191 (step 2865): 1.078442\n",
      "\n",
      "Train time for epoch #192 (step 2880): 1.108313\n",
      "\n",
      "Train time for epoch #193 (step 2895): 1.181962\n",
      "\n",
      "Train time for epoch #194 (step 2910): 1.062677\n",
      "\n",
      "Train time for epoch #195 (step 2925): 1.132944\n",
      "\n",
      "Train time for epoch #196 (step 2940): 0.998787\n",
      "\n",
      "Train time for epoch #197 (step 2955): 1.103250\n",
      "\n",
      "Train time for epoch #198 (step 2970): 1.077540\n",
      "\n",
      "Train time for epoch #199 (step 2985): 1.016559\n",
      "\n",
      "Train time for epoch #200 (step 3000): 1.053686\n"
     ]
    }
   ],
   "source": [
    "# with tf.device('/gpu:0'):\n",
    "import utils, models\n",
    "reload(utils)\n",
    "reload(models)\n",
    "from models import Generator, Discriminator\n",
    "from utils import max_norm, parse_feature_label, loss, grad, sample_n_number, train_one_epoch\n",
    "\n",
    "for _ in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    with summary_writer.as_default():\n",
    "        train_one_epoch(benign_dataset=benign_train_dataset,\n",
    "                    attack_dataset=attack_train_dataset,\n",
    "                    log_interval=LOG_INTERVAL,\n",
    "                    modified_feature_num=FEATURE_NUM_MODIFIED,\n",
    "                    **model_objects)\n",
    "    end = time.time()\n",
    "    checkpoint.save(checkpoint_prefix)\n",
    "    print('\\nTrain time for epoch #%d (step %d): %f' %\n",
    "        (checkpoint.save_counter.numpy(),\n",
    "         checkpoint.step_counter.numpy(),\n",
    "         end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
