{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Network\n",
    "\n",
    "In this notebook, we'll be building a generative adversarial network (GAN) trained on the network flow dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/sj2363/hsn/attack_generate/gan_attack_generate/.env/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 1.8.0\n",
      "Eager execution: True\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from importlib import reload\n",
    "import os\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as tfe\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "print(\"TensorFlow version: {}\".format(tf.VERSION))\n",
    "print(\"Eager execution: {}\".format(tf.executing_eagerly()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils, models\n",
    "reload(utils)\n",
    "reload(models)\n",
    "from models import Generator, Discriminator\n",
    "from utils import max_norm, parse_feature_label, train_one_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDS_DATASET = os.path.join('data', 'ids2017_sampled.csv')\n",
    "RELEVANT_FEATURES = [' Source Port', ' Destination Port', ' Flow Duration', 'Total Length of Fwd Packets', ' Total Length of Bwd Packets', 'Bwd Packet Length Max', ' Bwd Packet Length Min', 'Flow Bytes/s', ' Flow IAT Mean', ' Flow IAT Std', ' Flow IAT Max', ' Flow IAT Min', 'Fwd IAT Total', ' Fwd IAT Mean', ' Fwd IAT Std', ' Fwd IAT Min', 'Bwd IAT Total', ' Bwd IAT Mean', ' Bwd IAT Std', ' Bwd IAT Min', 'Fwd PSH Flags', ' Bwd PSH Flags', ' Fwd URG Flags', ' Fwd Header Length', ' Bwd Packets/s', ' Packet Length Mean', ' ACK Flag Count', ' Down/Up Ratio', ' Avg Fwd Segment Size', ' Fwd Header Length.1', 'Fwd Avg Bytes/Bulk', ' Fwd Avg Packets/Bulk', ' Bwd Avg Bytes/Bulk', 'Bwd Avg Bulk Rate', 'Subflow Fwd Packets', ' Subflow Fwd Bytes', 'Init_Win_bytes_forward', ' act_data_pkt_fwd', ' Active Std', ' Active Min', ' Idle Max']\n",
    "LABEL_NAME = ' Label'\n",
    "BENIGN_LABEL = 0\n",
    "ATTACK_LABEL = 2\n",
    "TRAIN_FRAC = 0.3\n",
    "FEATURE_NUM_MODIFIED = 2\n",
    "LEARNING_RATE = 0.01\n",
    "OUTPUT_DIR = 'SUMMARY/'\n",
    "CHECKPOINT_DIR = 'CHECKPOINT/'\n",
    "EPOCHS = 200\n",
    "LOG_INTERVAL = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flow ID, Source IP, Source Port, Destination IP, Destination Port, Protocol, Timestamp, Flow Duration, Total Fwd Packets, Total Backward Packets,Total Length of Fwd Packets, Total Length of Bwd Packets, Fwd Packet Length Max, Fwd Packet Length Min, Fwd Packet Length Mean, Fwd Packet Length Std,Bwd Packet Length Max, Bwd Packet Length Min, Bwd Packet Length Mean, Bwd Packet Length Std,Flow Bytes/s, Flow Packets/s, Flow IAT Mean, Flow IAT Std, Flow IAT Max, Flow IAT Min,Fwd IAT Total, Fwd IAT Mean, Fwd IAT Std, Fwd IAT Max, Fwd IAT Min,Bwd IAT Total, Bwd IAT Mean, Bwd IAT Std, Bwd IAT Max, Bwd IAT Min,Fwd PSH Flags, Bwd PSH Flags, Fwd URG Flags, Bwd URG Flags, Fwd Header Length, Bwd Header Length,Fwd Packets/s, Bwd Packets/s, Min Packet Length, Max Packet Length, Packet Length Mean, Packet Length Std, Packet Length Variance,FIN Flag Count, SYN Flag Count, RST Flag Count, PSH Flag Count, ACK Flag Count, URG Flag Count, CWE Flag Count, ECE Flag Count, Down/Up Ratio, Average Packet Size, Avg Fwd Segment Size, Avg Bwd Segment Size, Fwd Header Length.1,Fwd Avg Bytes/Bulk, Fwd Avg Packets/Bulk, Fwd Avg Bulk Rate, Bwd Avg Bytes/Bulk, Bwd Avg Packets/Bulk,Bwd Avg Bulk Rate,Subflow Fwd Packets, Subflow Fwd Bytes, Subflow Bwd Packets, Subflow Bwd Bytes,Init_Win_bytes_forward, Init_Win_bytes_backward, act_data_pkt_fwd, min_seg_size_forward,Active Mean, Active Std, Active Max, Active Min,Idle Mean, Idle Std, Idle Max, Idle Min, Label\r\n",
      "214102,192.168.10.8,50305,23.194.108.67,80,6,5/7/2017 9:35,5559809,3,1,12,0.0,6,0,4.0,3.464101615,0,0,0.0,0.0,2.158347526,0.719449175,1853269.667,3189322.073,5535956.0,39.0,5559809.0,2779904.5,3897645.41,5535956.0,23853.0,0.0,0.0,0.0,0.0,0.0,0,0,0,0,72,32,0.539586881,0.179862294,0,6,2.4,3.286335345,10.8,0,0,0,1,0,0,0,0,0,3.0,4.0,0.0,72,0,0,0,0,0,0,3,12,1,0,8192,29200,2,20,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0\r\n",
      "36502,172.217.11.3,80,192.168.10.8,49917,6,5/7/2017 9:31,18,1,1,6,6.0,6,6,6.0,0.0,6,6,6.0,0.0,666666.6667,111111.1111,18.0,0.0,18.0,18.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0,0,0,0,20,20,55555.55556,55555.55556,6,6,6.0,0.0,0.0,0,0,0,0,1,1,0,0,1,9.0,6.0,6.0,20,0,0,0,0,0,0,1,6,1,6,343,16560,0,20,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0\r\n",
      "24975,192.168.10.50,80,172.16.0.1,51484,6,5/7/2017 11:00,12859,1,3,0,18.0,0,0,0.0,0.0,6,6,6.0,0.0,1399.797807,311.0661793,4286.333333,6734.794825,12049.0,1.0,0.0,0.0,0.0,0.0,0.0,12050.0,6025.0,8519.2225,12049.0,1.0,0,0,0,0,32,60,77.76654483,233.2996345,0,6,3.6,3.286335345,10.8,0,0,0,0,1,0,0,0,3,4.5,0.0,6.0,32,0,0,0,0,0,0,1,0,3,18,235,0,0,32,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0\r\n",
      "151291,192.168.10.19,27610,192.168.10.3,53,17,5/7/2017 3:08,231,2,2,62,94.0,31,31,31.0,0.0,47,47,47.0,0.0,675324.6753,17316.01732,77.0,91.27978966,179.0,3.0,3.0,3.0,0.0,3.0,3.0,49.0,49.0,0.0,49.0,49.0,0,0,0,0,40,40,8658.008658,8658.008658,31,47,37.4,8.76356092,76.8,0,0,0,0,0,0,0,0,1,46.75,31.0,47.0,40,0,0,0,0,0,0,2,62,2,94,-1,-1,1,20,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0\r\n"
     ]
    }
   ],
   "source": [
    "# quick view of dataset\n",
    "!head -n5 {IDS_DATASET}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv\n",
    "df = pd.read_csv(IDS_DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract relevant features and label name\n",
    "df = df[RELEVANT_FEATURES + [LABEL_NAME]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract bengin and attack flows we want\n",
    "benign_df, attack_df = df[(df[LABEL_NAME] == BENIGN_LABEL)], df[(df[LABEL_NAME] == ATTACK_LABEL)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/sj2363/hsn/attack_generate/gan_attack_generate/.env/lib/python3.6/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "# rewrite label values\n",
    "benign_df.loc[:, LABEL_NAME] = 0\n",
    "attack_df.loc[:, LABEL_NAME] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to numpy\n",
    "benign, attack = benign_df.values, attack_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max normalization\n",
    "benign[:, :len(RELEVANT_FEATURES)] = max_norm(benign[:, :len(RELEVANT_FEATURES)])\n",
    "attack[:, :len(RELEVANT_FEATURES)] = max_norm(attack[:, :len(RELEVANT_FEATURES)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/sj2363/hsn/attack_generate/gan_attack_generate/.env/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# do train, test split separately on benign and attack\n",
    "benign_train, benign_test = train_test_split(benign, train_size=TRAIN_FRAC)\n",
    "attack_train, attack_test = train_test_split(attack, train_size=TRAIN_FRAC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat to get testing data\n",
    "test_np = np.concatenate([benign_test, attack_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to benign train dataset and attack train dataset\n",
    "benign_train_dataset, attack_train_dataset = tf.data.Dataset.from_tensor_slices(benign_train), tf.data.Dataset.from_tensor_slices(attack_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benign example features: tf.Tensor(\n",
      "[9.51466683e-01 8.26536500e-04 1.60019653e-06 4.33813815e-04\n",
      " 3.03030303e-06 7.27739726e-03 1.46299484e-01 1.31828706e-02\n",
      " 1.00884034e-06 1.02241212e-06 1.19491524e-06 6.24024951e-08\n",
      " 4.00000000e-07 4.06779661e-07 0.00000000e+00 4.06779661e-07\n",
      " 2.50000000e-08 2.54237288e-08 0.00000000e+00 2.54237288e-08\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.70189229e-04\n",
      " 1.04712042e-02 4.06959153e-02 0.00000000e+00 1.42857143e-01\n",
      " 1.42302717e-02 1.70189229e-04 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 5.36250536e-05 4.33813815e-04\n",
      " 0.00000000e+00 5.43714659e-05 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00], shape=(41,), dtype=float64)\n",
      "benign example label: tf.Tensor(0, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# deal with benign train dataset\n",
    "benign_train_dataset = benign_train_dataset.map(parse_feature_label)\n",
    "benign_train_dataset = benign_train_dataset.shuffle(buffer_size=benign_train.shape[0] * 5)  # randomize\n",
    "benign_train_dataset = benign_train_dataset.batch(100) # make batch\n",
    "\n",
    "# View a single example entry from a batch\n",
    "benign_features, benign_label = iter(benign_train_dataset).next()\n",
    "print(\"benign example features:\", benign_features[0])\n",
    "print(\"benign example label:\", benign_label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attack example features: tf.Tensor(\n",
      "[9.27791950e-01 0.00000000e+00 8.33178279e-06 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 2.52933677e-05 0.00000000e+00 8.39830516e-06 5.47288360e-02\n",
      " 8.32773116e-06 2.52290080e-05 0.00000000e+00 3.81098732e-02\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 5.76923077e-02\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 5.76923077e-02 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 9.38356164e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00], shape=(41,), dtype=float64)\n",
      "attack example label: tf.Tensor(1, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# deal with attack train dataset\n",
    "attack_train_dataset = attack_train_dataset.map(parse_feature_label)\n",
    "attack_train_dataset = attack_train_dataset.shuffle(buffer_size=attack_train.shape[0] * 5)  # randomize\n",
    "attack_train_dataset = attack_train_dataset.batch(100) # make batch\n",
    "\n",
    "# View a single example entry from a batch\n",
    "attack_features, attack_label = iter(attack_train_dataset).next()\n",
    "print(\"attack example features:\", attack_features[0])\n",
    "print(\"attack example label:\", attack_label[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(input_shape=len(RELEVANT_FEATURES), output_shape=FEATURE_NUM_MODIFIED)\n",
    "discriminator = Discriminator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.train.AdamOptimizer(learning_rate=LEARNING_RATE)\n",
    "discriminator_optimizer = tf.train.AdamOptimizer(learning_rate=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Tensorflow Training Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.contrib.eager.python.checkpointable_utils.InitializationOnlyStatus at 0x2b25e3eba278>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_counter = tf.train.get_or_create_global_step()\n",
    "summary_writer = tf.contrib.summary.create_file_writer(\n",
    "      OUTPUT_DIR, flush_millis=1000)\n",
    "checkpoint_prefix = os.path.join(CHECKPOINT_DIR, 'ckpt')\n",
    "latest_cpkt = tf.train.latest_checkpoint(CHECKPOINT_DIR)\n",
    "if latest_cpkt:\n",
    "    print('Using latest checkpoint at ' + latest_cpkt)\n",
    "model_objects = {\n",
    "    'generator': generator,\n",
    "    'discriminator': discriminator,\n",
    "    'generator_optimizer': generator_optimizer,\n",
    "    'discriminator_optimizer': discriminator_optimizer,\n",
    "    'step_counter': step_counter\n",
    "}\n",
    "checkpoint = tfe.Checkpoint(**model_objects)\n",
    "# Restore variables on creation if a checkpoint exists.\n",
    "checkpoint.restore(latest_cpkt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #1 (step 17): 0.949358\n",
      "\n",
      "Train time for epoch #2 (step 32): 0.910028\n",
      "\n",
      "Train time for epoch #3 (step 47): 0.899970\n",
      "\n",
      "Train time for epoch #4 (step 62): 0.907768\n",
      "\n",
      "Train time for epoch #5 (step 77): 0.959347\n",
      "\n",
      "Train time for epoch #6 (step 92): 0.852803\n",
      "\n",
      "Train time for epoch #7 (step 107): 0.933444\n",
      "\n",
      "Train time for epoch #8 (step 122): 0.863941\n",
      "\n",
      "Train time for epoch #9 (step 137): 1.112682\n",
      "\n",
      "Train time for epoch #10 (step 152): 0.899961\n",
      "\n",
      "Train time for epoch #11 (step 167): 0.844659\n",
      "\n",
      "Train time for epoch #12 (step 182): 0.845366\n",
      "\n",
      "Train time for epoch #13 (step 197): 0.861766\n",
      "\n",
      "Train time for epoch #14 (step 212): 0.953034\n",
      "\n",
      "Train time for epoch #15 (step 227): 1.016708\n",
      "\n",
      "Train time for epoch #16 (step 242): 0.823033\n",
      "\n",
      "Train time for epoch #17 (step 257): 0.851288\n",
      "\n",
      "Train time for epoch #18 (step 272): 0.987166\n",
      "\n",
      "Train time for epoch #19 (step 287): 0.980430\n",
      "\n",
      "Train time for epoch #20 (step 302): 1.025977\n",
      "\n",
      "Train time for epoch #21 (step 317): 0.834800\n",
      "\n",
      "Train time for epoch #22 (step 332): 0.928468\n",
      "\n",
      "Train time for epoch #23 (step 347): 0.856416\n",
      "\n",
      "Train time for epoch #24 (step 362): 0.881345\n",
      "\n",
      "Train time for epoch #25 (step 377): 0.903245\n",
      "\n",
      "Train time for epoch #26 (step 392): 0.897632\n",
      "\n",
      "Train time for epoch #27 (step 407): 0.913231\n",
      "\n",
      "Train time for epoch #28 (step 422): 0.868320\n",
      "\n",
      "Train time for epoch #29 (step 437): 0.906505\n",
      "\n",
      "Train time for epoch #30 (step 452): 0.972667\n",
      "\n",
      "Train time for epoch #31 (step 467): 1.040360\n",
      "\n",
      "Train time for epoch #32 (step 482): 0.854544\n",
      "\n",
      "Train time for epoch #33 (step 497): 0.830014\n",
      "\n",
      "Train time for epoch #34 (step 512): 0.901151\n",
      "\n",
      "Train time for epoch #35 (step 527): 0.879487\n",
      "\n",
      "Train time for epoch #36 (step 542): 0.860232\n",
      "\n",
      "Train time for epoch #37 (step 557): 0.940097\n",
      "\n",
      "Train time for epoch #38 (step 572): 1.010896\n",
      "\n",
      "Train time for epoch #39 (step 587): 0.902259\n",
      "\n",
      "Train time for epoch #40 (step 602): 0.871572\n",
      "\n",
      "Train time for epoch #41 (step 617): 0.933305\n",
      "\n",
      "Train time for epoch #42 (step 632): 0.843329\n",
      "\n",
      "Train time for epoch #43 (step 647): 0.846866\n",
      "\n",
      "Train time for epoch #44 (step 662): 0.933122\n",
      "\n",
      "Train time for epoch #45 (step 677): 0.778441\n",
      "\n",
      "Train time for epoch #46 (step 692): 0.908957\n",
      "\n",
      "Train time for epoch #47 (step 707): 0.880912\n",
      "\n",
      "Train time for epoch #48 (step 722): 0.891042\n",
      "\n",
      "Train time for epoch #49 (step 737): 0.878182\n",
      "\n",
      "Train time for epoch #50 (step 752): 0.962326\n",
      "\n",
      "Train time for epoch #51 (step 767): 0.903601\n",
      "\n",
      "Train time for epoch #52 (step 782): 0.940745\n",
      "\n",
      "Train time for epoch #53 (step 797): 0.874546\n",
      "\n",
      "Train time for epoch #54 (step 812): 0.825922\n",
      "\n",
      "Train time for epoch #55 (step 827): 1.010057\n",
      "\n",
      "Train time for epoch #56 (step 842): 0.867398\n",
      "\n",
      "Train time for epoch #57 (step 857): 0.938353\n",
      "\n",
      "Train time for epoch #58 (step 872): 0.842246\n",
      "\n",
      "Train time for epoch #59 (step 887): 0.957368\n",
      "\n",
      "Train time for epoch #60 (step 902): 0.872267\n",
      "\n",
      "Train time for epoch #61 (step 917): 0.857521\n",
      "\n",
      "Train time for epoch #62 (step 932): 0.947181\n",
      "\n",
      "Train time for epoch #63 (step 947): 0.781424\n",
      "\n",
      "Train time for epoch #64 (step 962): 0.898956\n",
      "\n",
      "Train time for epoch #65 (step 977): 0.911767\n",
      "\n",
      "Train time for epoch #66 (step 992): 0.831446\n",
      "\n",
      "Train time for epoch #67 (step 1007): 1.000480\n",
      "\n",
      "Train time for epoch #68 (step 1022): 0.846980\n",
      "\n",
      "Train time for epoch #69 (step 1037): 0.956105\n",
      "\n",
      "Train time for epoch #70 (step 1052): 0.885489\n",
      "\n",
      "Train time for epoch #71 (step 1067): 0.953971\n",
      "\n",
      "Train time for epoch #72 (step 1082): 0.947738\n",
      "\n",
      "Train time for epoch #73 (step 1097): 0.788572\n",
      "\n",
      "Train time for epoch #74 (step 1112): 0.867059\n",
      "\n",
      "Train time for epoch #75 (step 1127): 0.873130\n",
      "\n",
      "Train time for epoch #76 (step 1142): 0.937976\n",
      "\n",
      "Train time for epoch #77 (step 1157): 0.828345\n",
      "\n",
      "Train time for epoch #78 (step 1172): 0.905803\n",
      "\n",
      "Train time for epoch #79 (step 1187): 0.852272\n",
      "\n",
      "Train time for epoch #80 (step 1202): 0.848817\n",
      "\n",
      "Train time for epoch #81 (step 1217): 0.864971\n",
      "\n",
      "Train time for epoch #82 (step 1232): 0.842537\n",
      "\n",
      "Train time for epoch #83 (step 1247): 0.932371\n",
      "\n",
      "Train time for epoch #84 (step 1262): 0.895136\n",
      "\n",
      "Train time for epoch #85 (step 1277): 0.907171\n",
      "\n",
      "Train time for epoch #86 (step 1292): 0.896039\n",
      "\n",
      "Train time for epoch #87 (step 1307): 0.897180\n",
      "\n",
      "Train time for epoch #88 (step 1322): 0.900497\n",
      "\n",
      "Train time for epoch #89 (step 1337): 0.832614\n",
      "\n",
      "Train time for epoch #90 (step 1352): 0.887195\n",
      "\n",
      "Train time for epoch #91 (step 1367): 1.016212\n",
      "\n",
      "Train time for epoch #92 (step 1382): 0.889993\n",
      "\n",
      "Train time for epoch #93 (step 1397): 0.899745\n",
      "\n",
      "Train time for epoch #94 (step 1412): 0.835858\n",
      "\n",
      "Train time for epoch #95 (step 1427): 0.932691\n",
      "\n",
      "Train time for epoch #96 (step 1442): 0.871118\n",
      "\n",
      "Train time for epoch #97 (step 1457): 0.875950\n",
      "\n",
      "Train time for epoch #98 (step 1472): 0.828289\n",
      "\n",
      "Train time for epoch #99 (step 1487): 0.895090\n",
      "\n",
      "Train time for epoch #100 (step 1502): 0.998224\n",
      "\n",
      "Train time for epoch #101 (step 1517): 0.962407\n",
      "\n",
      "Train time for epoch #102 (step 1532): 1.017657\n",
      "\n",
      "Train time for epoch #103 (step 1547): 0.879477\n",
      "\n",
      "Train time for epoch #104 (step 1562): 0.876272\n",
      "\n",
      "Train time for epoch #105 (step 1577): 0.905097\n",
      "\n",
      "Train time for epoch #106 (step 1592): 0.924574\n",
      "\n",
      "Train time for epoch #107 (step 1607): 0.912933\n",
      "\n",
      "Train time for epoch #108 (step 1622): 0.835606\n",
      "\n",
      "Train time for epoch #109 (step 1637): 0.915473\n",
      "\n",
      "Train time for epoch #110 (step 1652): 0.915138\n",
      "\n",
      "Train time for epoch #111 (step 1667): 0.853331\n",
      "\n",
      "Train time for epoch #112 (step 1682): 0.945382\n",
      "\n",
      "Train time for epoch #113 (step 1697): 0.949979\n",
      "\n",
      "Train time for epoch #114 (step 1712): 0.887512\n",
      "\n",
      "Train time for epoch #115 (step 1727): 0.888746\n",
      "\n",
      "Train time for epoch #116 (step 1742): 0.847138\n",
      "\n",
      "Train time for epoch #117 (step 1757): 0.848979\n",
      "\n",
      "Train time for epoch #118 (step 1772): 0.868966\n",
      "\n",
      "Train time for epoch #119 (step 1787): 0.929511\n",
      "\n",
      "Train time for epoch #120 (step 1802): 0.906982\n",
      "\n",
      "Train time for epoch #121 (step 1817): 0.909170\n",
      "\n",
      "Train time for epoch #122 (step 1832): 0.837688\n",
      "\n",
      "Train time for epoch #123 (step 1847): 0.963802\n",
      "\n",
      "Train time for epoch #124 (step 1862): 0.803498\n",
      "\n",
      "Train time for epoch #125 (step 1877): 0.894865\n",
      "\n",
      "Train time for epoch #126 (step 1892): 0.795799\n",
      "\n",
      "Train time for epoch #127 (step 1907): 0.903527\n",
      "\n",
      "Train time for epoch #128 (step 1922): 0.936065\n",
      "\n",
      "Train time for epoch #129 (step 1937): 0.840901\n",
      "\n",
      "Train time for epoch #130 (step 1952): 0.859589\n",
      "\n",
      "Train time for epoch #131 (step 1967): 0.912621\n",
      "\n",
      "Train time for epoch #132 (step 1982): 0.959450\n",
      "\n",
      "Train time for epoch #133 (step 1997): 0.849847\n",
      "\n",
      "Train time for epoch #134 (step 2012): 0.904134\n",
      "\n",
      "Train time for epoch #135 (step 2027): 0.845891\n",
      "\n",
      "Train time for epoch #136 (step 2042): 0.908008\n",
      "\n",
      "Train time for epoch #137 (step 2057): 1.022833\n",
      "\n",
      "Train time for epoch #138 (step 2072): 0.834411\n",
      "\n",
      "Train time for epoch #139 (step 2087): 0.904671\n",
      "\n",
      "Train time for epoch #140 (step 2102): 0.904658\n",
      "\n",
      "Train time for epoch #141 (step 2117): 0.825683\n",
      "\n",
      "Train time for epoch #142 (step 2132): 0.937174\n",
      "\n",
      "Train time for epoch #143 (step 2147): 0.884754\n",
      "\n",
      "Train time for epoch #144 (step 2162): 0.892082\n",
      "\n",
      "Train time for epoch #145 (step 2177): 0.843371\n",
      "\n",
      "Train time for epoch #146 (step 2192): 0.882930\n",
      "\n",
      "Train time for epoch #147 (step 2207): 0.871686\n",
      "\n",
      "Train time for epoch #148 (step 2222): 0.872040\n",
      "\n",
      "Train time for epoch #149 (step 2237): 0.891869\n",
      "\n",
      "Train time for epoch #150 (step 2252): 0.917975\n",
      "\n",
      "Train time for epoch #151 (step 2267): 0.886517\n",
      "\n",
      "Train time for epoch #152 (step 2282): 0.789591\n",
      "\n",
      "Train time for epoch #153 (step 2297): 0.929926\n",
      "\n",
      "Train time for epoch #154 (step 2312): 0.813079\n",
      "\n",
      "Train time for epoch #155 (step 2327): 1.023046\n",
      "\n",
      "Train time for epoch #156 (step 2342): 0.901999\n",
      "\n",
      "Train time for epoch #157 (step 2357): 0.906853\n",
      "\n",
      "Train time for epoch #158 (step 2372): 0.906721\n",
      "\n",
      "Train time for epoch #159 (step 2387): 0.885905\n",
      "\n",
      "Train time for epoch #160 (step 2402): 0.898082\n",
      "\n",
      "Train time for epoch #161 (step 2417): 0.825876\n",
      "\n",
      "Train time for epoch #162 (step 2432): 0.942297\n",
      "\n",
      "Train time for epoch #163 (step 2447): 0.882374\n",
      "\n",
      "Train time for epoch #164 (step 2462): 0.889590\n",
      "\n",
      "Train time for epoch #165 (step 2477): 0.866638\n",
      "\n",
      "Train time for epoch #166 (step 2492): 0.822964\n",
      "\n",
      "Train time for epoch #167 (step 2507): 0.917005\n",
      "\n",
      "Train time for epoch #168 (step 2522): 0.937701\n",
      "\n",
      "Train time for epoch #169 (step 2537): 0.911241\n",
      "\n",
      "Train time for epoch #170 (step 2552): 0.912637\n",
      "\n",
      "Train time for epoch #171 (step 2567): 0.917155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #172 (step 2582): 0.971344\n",
      "\n",
      "Train time for epoch #173 (step 2597): 0.897443\n",
      "\n",
      "Train time for epoch #174 (step 2612): 0.845800\n",
      "\n",
      "Train time for epoch #175 (step 2627): 1.004210\n",
      "\n",
      "Train time for epoch #176 (step 2642): 0.962278\n",
      "\n",
      "Train time for epoch #177 (step 2657): 0.950958\n",
      "\n",
      "Train time for epoch #178 (step 2672): 1.007994\n",
      "\n",
      "Train time for epoch #179 (step 2687): 0.826452\n",
      "\n",
      "Train time for epoch #180 (step 2702): 1.008381\n",
      "\n",
      "Train time for epoch #181 (step 2717): 0.911419\n",
      "\n",
      "Train time for epoch #182 (step 2732): 0.934361\n",
      "\n",
      "Train time for epoch #183 (step 2747): 0.947963\n",
      "\n",
      "Train time for epoch #184 (step 2762): 0.908216\n",
      "\n",
      "Train time for epoch #185 (step 2777): 0.951457\n",
      "\n",
      "Train time for epoch #186 (step 2792): 0.939260\n",
      "\n",
      "Train time for epoch #187 (step 2807): 0.900995\n",
      "\n",
      "Train time for epoch #188 (step 2822): 0.857592\n",
      "\n",
      "Train time for epoch #189 (step 2837): 0.834122\n",
      "\n",
      "Train time for epoch #190 (step 2852): 0.946331\n",
      "\n",
      "Train time for epoch #191 (step 2867): 0.868977\n",
      "\n",
      "Train time for epoch #192 (step 2882): 1.032376\n",
      "\n",
      "Train time for epoch #193 (step 2897): 0.790697\n",
      "\n",
      "Train time for epoch #194 (step 2912): 1.007622\n",
      "\n",
      "Train time for epoch #195 (step 2927): 0.851427\n",
      "\n",
      "Train time for epoch #196 (step 2942): 0.848183\n",
      "\n",
      "Train time for epoch #197 (step 2957): 0.993119\n",
      "\n",
      "Train time for epoch #198 (step 2972): 0.826955\n",
      "\n",
      "Train time for epoch #199 (step 2987): 0.962916\n",
      "\n",
      "Train time for epoch #200 (step 3002): 0.899060\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    for _ in range(EPOCHS):\n",
    "        start = time.time()\n",
    "        with summary_writer.as_default():\n",
    "            train_one_epoch(benign_dataset=benign_train_dataset,\n",
    "                        attack_dataset=attack_train_dataset,\n",
    "                        log_interval=LOG_INTERVAL,\n",
    "                        modified_feature_num=FEATURE_NUM_MODIFIED,\n",
    "                        **model_objects)\n",
    "        end = time.time()\n",
    "        checkpoint.save(checkpoint_prefix)\n",
    "        print('\\nTrain time for epoch #%d (step %d): %f' %\n",
    "            (checkpoint.save_counter.numpy(),\n",
    "             checkpoint.step_counter.numpy(),\n",
    "             end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
