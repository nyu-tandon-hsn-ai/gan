{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Network\n",
    "\n",
    "In this notebook, we'll be building a generative adversarial network (GAN) trained on the network flow dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/sj2363/hsn/attack_generate/gan_attack_generate/.env/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 1.8.0\n",
      "Eager execution: True\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from importlib import reload\n",
    "import os\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as tfe\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "print(\"TensorFlow version: {}\".format(tf.VERSION))\n",
    "print(\"Eager execution: {}\".format(tf.executing_eagerly()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils, models\n",
    "reload(utils)\n",
    "reload(models)\n",
    "from models import Generator, Discriminator\n",
    "from utils import max_norm, parse_feature_label, train_one_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDS_DATASET = os.path.join('data', 'ids2017_sampled.csv')\n",
    "RELEVANT_FEATURES = [' Source Port', ' Destination Port', ' Flow Duration', 'Total Length of Fwd Packets', ' Total Length of Bwd Packets', 'Bwd Packet Length Max', ' Bwd Packet Length Min', 'Flow Bytes/s', ' Flow IAT Mean', ' Flow IAT Std', ' Flow IAT Max', ' Flow IAT Min', 'Fwd IAT Total', ' Fwd IAT Mean', ' Fwd IAT Std', ' Fwd IAT Min', 'Bwd IAT Total', ' Bwd IAT Mean', ' Bwd IAT Std', ' Bwd IAT Min', 'Fwd PSH Flags', ' Bwd PSH Flags', ' Fwd URG Flags', ' Fwd Header Length', ' Bwd Packets/s', ' Packet Length Mean', ' ACK Flag Count', ' Down/Up Ratio', ' Avg Fwd Segment Size', ' Fwd Header Length.1', 'Fwd Avg Bytes/Bulk', ' Fwd Avg Packets/Bulk', ' Bwd Avg Bytes/Bulk', 'Bwd Avg Bulk Rate', 'Subflow Fwd Packets', ' Subflow Fwd Bytes', 'Init_Win_bytes_forward', ' act_data_pkt_fwd', ' Active Std', ' Active Min', ' Idle Max']\n",
    "LABEL_NAME = ' Label'\n",
    "BENIGN_LABEL = 0\n",
    "ATTACK_LABEL = 2\n",
    "TRAIN_FRAC = 0.3\n",
    "FEATURE_NUM_MODIFIED = 2\n",
    "LEARNING_RATE = 0.01\n",
    "OUTPUT_DIR = 'SUMMARY/'\n",
    "CHECKPOINT_DIR = 'CHECKPOINT/'\n",
    "EPOCHS = 200\n",
    "LOG_INTERVAL = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flow ID, Source IP, Source Port, Destination IP, Destination Port, Protocol, Timestamp, Flow Duration, Total Fwd Packets, Total Backward Packets,Total Length of Fwd Packets, Total Length of Bwd Packets, Fwd Packet Length Max, Fwd Packet Length Min, Fwd Packet Length Mean, Fwd Packet Length Std,Bwd Packet Length Max, Bwd Packet Length Min, Bwd Packet Length Mean, Bwd Packet Length Std,Flow Bytes/s, Flow Packets/s, Flow IAT Mean, Flow IAT Std, Flow IAT Max, Flow IAT Min,Fwd IAT Total, Fwd IAT Mean, Fwd IAT Std, Fwd IAT Max, Fwd IAT Min,Bwd IAT Total, Bwd IAT Mean, Bwd IAT Std, Bwd IAT Max, Bwd IAT Min,Fwd PSH Flags, Bwd PSH Flags, Fwd URG Flags, Bwd URG Flags, Fwd Header Length, Bwd Header Length,Fwd Packets/s, Bwd Packets/s, Min Packet Length, Max Packet Length, Packet Length Mean, Packet Length Std, Packet Length Variance,FIN Flag Count, SYN Flag Count, RST Flag Count, PSH Flag Count, ACK Flag Count, URG Flag Count, CWE Flag Count, ECE Flag Count, Down/Up Ratio, Average Packet Size, Avg Fwd Segment Size, Avg Bwd Segment Size, Fwd Header Length.1,Fwd Avg Bytes/Bulk, Fwd Avg Packets/Bulk, Fwd Avg Bulk Rate, Bwd Avg Bytes/Bulk, Bwd Avg Packets/Bulk,Bwd Avg Bulk Rate,Subflow Fwd Packets, Subflow Fwd Bytes, Subflow Bwd Packets, Subflow Bwd Bytes,Init_Win_bytes_forward, Init_Win_bytes_backward, act_data_pkt_fwd, min_seg_size_forward,Active Mean, Active Std, Active Max, Active Min,Idle Mean, Idle Std, Idle Max, Idle Min, Label\r\n",
      "214102,192.168.10.8,50305,23.194.108.67,80,6,5/7/2017 9:35,5559809,3,1,12,0.0,6,0,4.0,3.464101615,0,0,0.0,0.0,2.158347526,0.719449175,1853269.667,3189322.073,5535956.0,39.0,5559809.0,2779904.5,3897645.41,5535956.0,23853.0,0.0,0.0,0.0,0.0,0.0,0,0,0,0,72,32,0.539586881,0.179862294,0,6,2.4,3.286335345,10.8,0,0,0,1,0,0,0,0,0,3.0,4.0,0.0,72,0,0,0,0,0,0,3,12,1,0,8192,29200,2,20,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0\r\n",
      "36502,172.217.11.3,80,192.168.10.8,49917,6,5/7/2017 9:31,18,1,1,6,6.0,6,6,6.0,0.0,6,6,6.0,0.0,666666.6667,111111.1111,18.0,0.0,18.0,18.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0,0,0,0,20,20,55555.55556,55555.55556,6,6,6.0,0.0,0.0,0,0,0,0,1,1,0,0,1,9.0,6.0,6.0,20,0,0,0,0,0,0,1,6,1,6,343,16560,0,20,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0\r\n",
      "24975,192.168.10.50,80,172.16.0.1,51484,6,5/7/2017 11:00,12859,1,3,0,18.0,0,0,0.0,0.0,6,6,6.0,0.0,1399.797807,311.0661793,4286.333333,6734.794825,12049.0,1.0,0.0,0.0,0.0,0.0,0.0,12050.0,6025.0,8519.2225,12049.0,1.0,0,0,0,0,32,60,77.76654483,233.2996345,0,6,3.6,3.286335345,10.8,0,0,0,0,1,0,0,0,3,4.5,0.0,6.0,32,0,0,0,0,0,0,1,0,3,18,235,0,0,32,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0\r\n",
      "151291,192.168.10.19,27610,192.168.10.3,53,17,5/7/2017 3:08,231,2,2,62,94.0,31,31,31.0,0.0,47,47,47.0,0.0,675324.6753,17316.01732,77.0,91.27978966,179.0,3.0,3.0,3.0,0.0,3.0,3.0,49.0,49.0,0.0,49.0,49.0,0,0,0,0,40,40,8658.008658,8658.008658,31,47,37.4,8.76356092,76.8,0,0,0,0,0,0,0,0,1,46.75,31.0,47.0,40,0,0,0,0,0,0,2,62,2,94,-1,-1,1,20,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0\r\n"
     ]
    }
   ],
   "source": [
    "# quick view of dataset\n",
    "!head -n5 {IDS_DATASET}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv\n",
    "df = pd.read_csv(IDS_DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract relevant features and label name\n",
    "df = df[RELEVANT_FEATURES + [LABEL_NAME]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract bengin and attack flows we want\n",
    "benign_df, attack_df = df[(df[LABEL_NAME] == BENIGN_LABEL)], df[(df[LABEL_NAME] == ATTACK_LABEL)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/sj2363/hsn/attack_generate/gan_attack_generate/.env/lib/python3.6/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "# rewrite label values\n",
    "benign_df.loc[:, LABEL_NAME] = 0\n",
    "attack_df.loc[:, LABEL_NAME] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to numpy\n",
    "benign, attack = benign_df.values, attack_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max normalization\n",
    "benign[:, :len(RELEVANT_FEATURES)] = max_norm(benign[:, :len(RELEVANT_FEATURES)])\n",
    "attack[:, :len(RELEVANT_FEATURES)] = max_norm(attack[:, :len(RELEVANT_FEATURES)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/sj2363/hsn/attack_generate/gan_attack_generate/.env/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# do train, test split separately on benign and attack\n",
    "benign_train, benign_test = train_test_split(benign, train_size=TRAIN_FRAC)\n",
    "attack_train, attack_test = train_test_split(attack, train_size=TRAIN_FRAC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat to get testing data\n",
    "test_np = np.concatenate([benign_test, attack_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to benign train dataset and attack train dataset\n",
    "benign_train_dataset, attack_train_dataset = tf.data.Dataset.from_tensor_slices(benign_train), tf.data.Dataset.from_tensor_slices(attack_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benign example features: tf.Tensor(\n",
      "[6.67455206e-01 8.26536500e-04 1.65020267e-06 5.78418420e-04\n",
      " 3.35115865e-06 8.04794521e-03 1.61790017e-01 1.33476247e-02\n",
      " 1.04004159e-06 1.08950601e-06 1.25423728e-06 3.12012476e-08\n",
      " 4.08333333e-07 4.15254237e-07 0.00000000e+00 4.15254237e-07\n",
      " 8.33333333e-09 8.47457627e-09 0.00000000e+00 8.47457627e-09\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.70189229e-04\n",
      " 1.01522843e-02 4.84114977e-02 0.00000000e+00 1.42857143e-01\n",
      " 1.89736956e-02 1.70189229e-04 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 5.36250536e-05 5.78418420e-04\n",
      " 0.00000000e+00 5.43714659e-05 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00], shape=(41,), dtype=float64)\n",
      "benign example label: tf.Tensor(0, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# deal with benign train dataset\n",
    "benign_train_dataset = benign_train_dataset.map(parse_feature_label)\n",
    "benign_train_dataset = benign_train_dataset.shuffle(buffer_size=benign_train.shape[0] * 5)  # randomize\n",
    "benign_train_dataset = benign_train_dataset.batch(100) # make batch\n",
    "\n",
    "# View a single example entry from a batch\n",
    "benign_features, benign_label = iter(benign_train_dataset).next()\n",
    "print(\"benign example features:\", benign_features[0])\n",
    "print(\"benign example label:\", benign_label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attack example features: tf.Tensor(\n",
      "[3.50056689e-02 0.00000000e+00 8.40744984e-09 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 3.82653066e-08 0.00000000e+00 8.47457634e-09 1.65343915e-04\n",
      " 8.40336142e-09 3.81679394e-08 0.00000000e+00 7.68344218e-05\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 5.76923077e-02\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 5.76923077e-02 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 9.38356164e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00], shape=(41,), dtype=float64)\n",
      "attack example label: tf.Tensor(1, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# deal with attack train dataset\n",
    "attack_train_dataset = attack_train_dataset.map(parse_feature_label)\n",
    "attack_train_dataset = attack_train_dataset.shuffle(buffer_size=attack_train.shape[0] * 5)  # randomize\n",
    "attack_train_dataset = attack_train_dataset.batch(100) # make batch\n",
    "\n",
    "# View a single example entry from a batch\n",
    "attack_features, attack_label = iter(attack_train_dataset).next()\n",
    "print(\"attack example features:\", attack_features[0])\n",
    "print(\"attack example label:\", attack_label[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(input_shape=len(RELEVANT_FEATURES), output_shape=FEATURE_NUM_MODIFIED)\n",
    "discriminator = Discriminator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.train.AdamOptimizer(learning_rate=LEARNING_RATE)\n",
    "discriminator_optimizer = tf.train.AdamOptimizer(learning_rate=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Tensorflow Training Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.contrib.eager.python.checkpointable_utils.InitializationOnlyStatus at 0x2ba81fd992b0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_counter = tf.train.get_or_create_global_step()\n",
    "summary_writer = tf.contrib.summary.create_file_writer(\n",
    "      OUTPUT_DIR, flush_millis=1000)\n",
    "checkpoint_prefix = os.path.join(CHECKPOINT_DIR, 'ckpt')\n",
    "latest_cpkt = tf.train.latest_checkpoint(CHECKPOINT_DIR)\n",
    "if latest_cpkt:\n",
    "    print('Using latest checkpoint at ' + latest_cpkt)\n",
    "model_objects = {\n",
    "    'generator': generator,\n",
    "    'discriminator': discriminator,\n",
    "    'generator_optimizer': generator_optimizer,\n",
    "    'discriminator_optimizer': discriminator_optimizer,\n",
    "    'step_counter': step_counter\n",
    "}\n",
    "checkpoint = tfe.Checkpoint(**model_objects)\n",
    "# Restore variables on creation if a checkpoint exists.\n",
    "checkpoint.restore(latest_cpkt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #1 (step 16): 1.534575\n",
      "\n",
      "Train time for epoch #2 (step 31): 1.222377\n",
      "\n",
      "Train time for epoch #3 (step 46): 1.346656\n",
      "\n",
      "Train time for epoch #4 (step 61): 1.335705\n",
      "\n",
      "Train time for epoch #5 (step 76): 1.291707\n",
      "\n",
      "Train time for epoch #6 (step 91): 1.339791\n",
      "\n",
      "Train time for epoch #7 (step 106): 1.258762\n",
      "\n",
      "Train time for epoch #8 (step 121): 1.307727\n",
      "\n",
      "Train time for epoch #9 (step 136): 1.287761\n",
      "\n",
      "Train time for epoch #10 (step 151): 1.371519\n",
      "\n",
      "Train time for epoch #11 (step 166): 1.255022\n",
      "\n",
      "Train time for epoch #12 (step 181): 1.281898\n",
      "\n",
      "Train time for epoch #13 (step 196): 1.400596\n",
      "\n",
      "Train time for epoch #14 (step 211): 1.245561\n",
      "\n",
      "Train time for epoch #15 (step 226): 1.362233\n",
      "\n",
      "Train time for epoch #16 (step 241): 1.326281\n",
      "\n",
      "Train time for epoch #17 (step 256): 1.193607\n",
      "\n",
      "Train time for epoch #18 (step 271): 1.251435\n",
      "\n",
      "Train time for epoch #19 (step 286): 1.301348\n",
      "\n",
      "Train time for epoch #20 (step 301): 1.282299\n",
      "\n",
      "Train time for epoch #21 (step 316): 1.344952\n",
      "\n",
      "Train time for epoch #22 (step 331): 1.381540\n",
      "\n",
      "Train time for epoch #23 (step 346): 1.352876\n",
      "\n",
      "Train time for epoch #24 (step 361): 1.288867\n",
      "\n",
      "Train time for epoch #25 (step 376): 1.228725\n",
      "\n",
      "Train time for epoch #26 (step 391): 1.222827\n",
      "\n",
      "Train time for epoch #27 (step 406): 1.264260\n",
      "\n",
      "Train time for epoch #28 (step 421): 1.170361\n",
      "\n",
      "Train time for epoch #29 (step 436): 1.357458\n",
      "\n",
      "Train time for epoch #30 (step 451): 1.291658\n",
      "\n",
      "Train time for epoch #31 (step 466): 1.201477\n",
      "\n",
      "Train time for epoch #32 (step 481): 1.321359\n",
      "\n",
      "Train time for epoch #33 (step 496): 1.242224\n",
      "\n",
      "Train time for epoch #34 (step 511): 1.275738\n",
      "\n",
      "Train time for epoch #35 (step 526): 1.249292\n",
      "\n",
      "Train time for epoch #36 (step 541): 1.319184\n",
      "\n",
      "Train time for epoch #37 (step 556): 1.215192\n",
      "\n",
      "Train time for epoch #38 (step 571): 1.303730\n",
      "\n",
      "Train time for epoch #39 (step 586): 1.327501\n",
      "\n",
      "Train time for epoch #40 (step 601): 1.287946\n",
      "\n",
      "Train time for epoch #41 (step 616): 1.251554\n",
      "\n",
      "Train time for epoch #42 (step 631): 1.362822\n",
      "\n",
      "Train time for epoch #43 (step 646): 1.304734\n",
      "\n",
      "Train time for epoch #44 (step 661): 1.262569\n",
      "\n",
      "Train time for epoch #45 (step 676): 1.288287\n",
      "\n",
      "Train time for epoch #46 (step 691): 1.387063\n",
      "\n",
      "Train time for epoch #47 (step 706): 1.356520\n",
      "\n",
      "Train time for epoch #48 (step 721): 1.253920\n",
      "\n",
      "Train time for epoch #49 (step 736): 1.400414\n",
      "\n",
      "Train time for epoch #50 (step 751): 1.339350\n",
      "\n",
      "Train time for epoch #51 (step 766): 1.245887\n",
      "\n",
      "Train time for epoch #52 (step 781): 1.282046\n",
      "\n",
      "Train time for epoch #53 (step 796): 1.348344\n",
      "\n",
      "Train time for epoch #54 (step 811): 1.263928\n",
      "\n",
      "Train time for epoch #55 (step 826): 1.240008\n",
      "\n",
      "Train time for epoch #56 (step 841): 1.277906\n",
      "\n",
      "Train time for epoch #57 (step 856): 1.224583\n",
      "\n",
      "Train time for epoch #58 (step 871): 1.268284\n",
      "\n",
      "Train time for epoch #59 (step 886): 1.311295\n",
      "\n",
      "Train time for epoch #60 (step 901): 1.243082\n",
      "\n",
      "Train time for epoch #61 (step 916): 1.254233\n",
      "\n",
      "Train time for epoch #62 (step 931): 1.257214\n",
      "\n",
      "Train time for epoch #63 (step 946): 1.402281\n",
      "\n",
      "Train time for epoch #64 (step 961): 1.255085\n",
      "\n",
      "Train time for epoch #65 (step 976): 1.263132\n",
      "\n",
      "Train time for epoch #66 (step 991): 1.310913\n",
      "\n",
      "Train time for epoch #67 (step 1006): 1.306919\n",
      "\n",
      "Train time for epoch #68 (step 1021): 1.235898\n",
      "\n",
      "Train time for epoch #69 (step 1036): 1.223273\n",
      "\n",
      "Train time for epoch #70 (step 1051): 1.317848\n",
      "\n",
      "Train time for epoch #71 (step 1066): 1.347301\n",
      "\n",
      "Train time for epoch #72 (step 1081): 1.331137\n",
      "\n",
      "Train time for epoch #73 (step 1096): 1.304418\n",
      "\n",
      "Train time for epoch #74 (step 1111): 1.287219\n",
      "\n",
      "Train time for epoch #75 (step 1126): 1.259843\n",
      "\n",
      "Train time for epoch #76 (step 1141): 1.186048\n",
      "\n",
      "Train time for epoch #77 (step 1156): 1.327756\n",
      "\n",
      "Train time for epoch #78 (step 1171): 1.184791\n",
      "\n",
      "Train time for epoch #79 (step 1186): 1.234250\n",
      "\n",
      "Train time for epoch #80 (step 1201): 1.283634\n",
      "\n",
      "Train time for epoch #81 (step 1216): 1.295906\n",
      "\n",
      "Train time for epoch #82 (step 1231): 1.193321\n",
      "\n",
      "Train time for epoch #83 (step 1246): 1.225880\n",
      "\n",
      "Train time for epoch #84 (step 1261): 1.271271\n",
      "\n",
      "Train time for epoch #85 (step 1276): 1.261757\n",
      "\n",
      "Train time for epoch #86 (step 1291): 1.272703\n",
      "\n",
      "Train time for epoch #87 (step 1306): 1.226510\n",
      "\n",
      "Train time for epoch #88 (step 1321): 1.209731\n",
      "\n",
      "Train time for epoch #89 (step 1336): 1.274928\n",
      "\n",
      "Train time for epoch #90 (step 1351): 1.232997\n",
      "\n",
      "Train time for epoch #91 (step 1366): 1.323830\n",
      "\n",
      "Train time for epoch #92 (step 1381): 1.234471\n",
      "\n",
      "Train time for epoch #93 (step 1396): 1.290585\n",
      "\n",
      "Train time for epoch #94 (step 1411): 1.217581\n",
      "\n",
      "Train time for epoch #95 (step 1426): 1.311181\n",
      "\n",
      "Train time for epoch #96 (step 1441): 1.352830\n",
      "\n",
      "Train time for epoch #97 (step 1456): 1.200850\n",
      "\n",
      "Train time for epoch #98 (step 1471): 1.262990\n",
      "\n",
      "Train time for epoch #99 (step 1486): 1.291584\n",
      "\n",
      "Train time for epoch #100 (step 1501): 1.246991\n",
      "\n",
      "Train time for epoch #101 (step 1516): 1.469508\n",
      "\n",
      "Train time for epoch #102 (step 1531): 1.340273\n",
      "\n",
      "Train time for epoch #103 (step 1546): 1.338869\n",
      "\n",
      "Train time for epoch #104 (step 1561): 1.297505\n",
      "\n",
      "Train time for epoch #105 (step 1576): 1.242110\n",
      "\n",
      "Train time for epoch #106 (step 1591): 1.249176\n",
      "\n",
      "Train time for epoch #107 (step 1606): 1.297589\n",
      "\n",
      "Train time for epoch #108 (step 1621): 1.283012\n",
      "\n",
      "Train time for epoch #109 (step 1636): 1.228664\n",
      "\n",
      "Train time for epoch #110 (step 1651): 1.285754\n",
      "\n",
      "Train time for epoch #111 (step 1666): 1.225001\n",
      "\n",
      "Train time for epoch #112 (step 1681): 1.220005\n",
      "\n",
      "Train time for epoch #113 (step 1696): 1.301790\n",
      "\n",
      "Train time for epoch #114 (step 1711): 1.295833\n",
      "\n",
      "Train time for epoch #115 (step 1726): 1.275742\n",
      "\n",
      "Train time for epoch #116 (step 1741): 1.248989\n",
      "\n",
      "Train time for epoch #117 (step 1756): 1.439037\n",
      "\n",
      "Train time for epoch #118 (step 1771): 1.350589\n",
      "\n",
      "Train time for epoch #119 (step 1786): 1.286266\n",
      "\n",
      "Train time for epoch #120 (step 1801): 1.236430\n",
      "\n",
      "Train time for epoch #121 (step 1816): 1.312570\n",
      "\n",
      "Train time for epoch #122 (step 1831): 1.335001\n",
      "\n",
      "Train time for epoch #123 (step 1846): 1.282979\n",
      "\n",
      "Train time for epoch #124 (step 1861): 1.331266\n",
      "\n",
      "Train time for epoch #125 (step 1876): 1.326246\n",
      "\n",
      "Train time for epoch #126 (step 1891): 1.223957\n",
      "\n",
      "Train time for epoch #127 (step 1906): 1.312943\n",
      "\n",
      "Train time for epoch #128 (step 1921): 1.385416\n",
      "\n",
      "Train time for epoch #129 (step 1936): 1.316839\n",
      "\n",
      "Train time for epoch #130 (step 1951): 1.283524\n",
      "\n",
      "Train time for epoch #131 (step 1966): 1.290087\n",
      "\n",
      "Train time for epoch #132 (step 1981): 1.254562\n",
      "\n",
      "Train time for epoch #133 (step 1996): 1.218990\n",
      "\n",
      "Train time for epoch #134 (step 2011): 1.138253\n",
      "\n",
      "Train time for epoch #135 (step 2026): 1.242964\n",
      "\n",
      "Train time for epoch #136 (step 2041): 1.297012\n",
      "\n",
      "Train time for epoch #137 (step 2056): 1.241281\n",
      "\n",
      "Train time for epoch #138 (step 2071): 1.238961\n",
      "\n",
      "Train time for epoch #139 (step 2086): 1.338243\n",
      "\n",
      "Train time for epoch #140 (step 2101): 1.323929\n",
      "\n",
      "Train time for epoch #141 (step 2116): 1.246585\n",
      "\n",
      "Train time for epoch #142 (step 2131): 1.347217\n",
      "\n",
      "Train time for epoch #143 (step 2146): 1.251043\n",
      "\n",
      "Train time for epoch #144 (step 2161): 1.233571\n",
      "\n",
      "Train time for epoch #145 (step 2176): 1.281403\n",
      "\n",
      "Train time for epoch #146 (step 2191): 1.288869\n",
      "\n",
      "Train time for epoch #147 (step 2206): 1.243898\n",
      "\n",
      "Train time for epoch #148 (step 2221): 1.280308\n",
      "\n",
      "Train time for epoch #149 (step 2236): 1.322510\n",
      "\n",
      "Train time for epoch #150 (step 2251): 1.277249\n",
      "\n",
      "Train time for epoch #151 (step 2266): 1.278202\n",
      "\n",
      "Train time for epoch #152 (step 2281): 1.294613\n",
      "\n",
      "Train time for epoch #153 (step 2296): 1.263965\n",
      "\n",
      "Train time for epoch #154 (step 2311): 1.367263\n",
      "\n",
      "Train time for epoch #155 (step 2326): 1.272207\n",
      "\n",
      "Train time for epoch #156 (step 2341): 1.281870\n",
      "\n",
      "Train time for epoch #157 (step 2356): 1.384115\n",
      "\n",
      "Train time for epoch #158 (step 2371): 1.232375\n",
      "\n",
      "Train time for epoch #159 (step 2386): 1.366602\n",
      "\n",
      "Train time for epoch #160 (step 2401): 1.311128\n",
      "\n",
      "Train time for epoch #161 (step 2416): 1.275286\n",
      "\n",
      "Train time for epoch #162 (step 2431): 1.202118\n",
      "\n",
      "Train time for epoch #163 (step 2446): 1.238441\n",
      "\n",
      "Train time for epoch #164 (step 2461): 1.234079\n",
      "\n",
      "Train time for epoch #165 (step 2476): 1.282485\n",
      "\n",
      "Train time for epoch #166 (step 2491): 1.310702\n",
      "\n",
      "Train time for epoch #167 (step 2506): 1.285501\n",
      "\n",
      "Train time for epoch #168 (step 2521): 1.352956\n",
      "\n",
      "Train time for epoch #169 (step 2536): 1.197265\n",
      "\n",
      "Train time for epoch #170 (step 2551): 1.349247\n",
      "\n",
      "Train time for epoch #171 (step 2566): 1.254458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time for epoch #172 (step 2581): 1.251042\n",
      "\n",
      "Train time for epoch #173 (step 2596): 1.283273\n",
      "\n",
      "Train time for epoch #174 (step 2611): 1.336829\n",
      "\n",
      "Train time for epoch #175 (step 2626): 1.223984\n",
      "\n",
      "Train time for epoch #176 (step 2641): 1.281697\n",
      "\n",
      "Train time for epoch #177 (step 2656): 1.393901\n",
      "\n",
      "Train time for epoch #178 (step 2671): 1.335229\n",
      "\n",
      "Train time for epoch #179 (step 2686): 1.195389\n",
      "\n",
      "Train time for epoch #180 (step 2701): 1.281116\n",
      "\n",
      "Train time for epoch #181 (step 2716): 1.284389\n",
      "\n",
      "Train time for epoch #182 (step 2731): 1.369133\n",
      "\n",
      "Train time for epoch #183 (step 2746): 1.242917\n",
      "\n",
      "Train time for epoch #184 (step 2761): 1.291498\n",
      "\n",
      "Train time for epoch #185 (step 2776): 1.259474\n",
      "\n",
      "Train time for epoch #186 (step 2791): 1.268484\n",
      "\n",
      "Train time for epoch #187 (step 2806): 1.340425\n",
      "\n",
      "Train time for epoch #188 (step 2821): 1.348798\n",
      "\n",
      "Train time for epoch #189 (step 2836): 1.359559\n",
      "\n",
      "Train time for epoch #190 (step 2851): 1.262174\n",
      "\n",
      "Train time for epoch #191 (step 2866): 1.350200\n",
      "\n",
      "Train time for epoch #192 (step 2881): 1.284421\n",
      "\n",
      "Train time for epoch #193 (step 2896): 1.431724\n",
      "\n",
      "Train time for epoch #194 (step 2911): 1.221723\n",
      "\n",
      "Train time for epoch #195 (step 2926): 1.326339\n",
      "\n",
      "Train time for epoch #196 (step 2941): 1.296052\n",
      "\n",
      "Train time for epoch #197 (step 2956): 1.305177\n",
      "\n",
      "Train time for epoch #198 (step 2971): 1.337184\n",
      "\n",
      "Train time for epoch #199 (step 2986): 1.273239\n",
      "\n",
      "Train time for epoch #200 (step 3001): 1.387907\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    for _ in range(EPOCHS):\n",
    "        start = time.time()\n",
    "        with summary_writer.as_default():\n",
    "            train_one_epoch(benign_dataset=benign_train_dataset,\n",
    "                        attack_dataset=attack_train_dataset,\n",
    "                        log_interval=LOG_INTERVAL,\n",
    "                        modified_feature_num=FEATURE_NUM_MODIFIED,\n",
    "                        **model_objects)\n",
    "        end = time.time()\n",
    "        checkpoint.save(checkpoint_prefix)\n",
    "        print('\\nTrain time for epoch #%d (step %d): %f' %\n",
    "            (checkpoint.save_counter.numpy(),\n",
    "             checkpoint.step_counter.numpy(),\n",
    "             end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
